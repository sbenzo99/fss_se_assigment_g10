2025-10-03|||Release: v4.57.0
2025-10-03|||v4.57.0 Branch (#41310)
2025-09-16|||Harmonize CacheLayer names (#40892)
2025-09-11|||Fix edge case for tokenize (#36277) (#36555)
2025-09-11|||[Docs] Add missing class documentation for optimizer_schedules (#31870,  #23010) (#40761)
2025-09-01|||Fix inexistent imports (#40580)
2025-09-01|||ðŸš¨ Remove Group Beam Search decoding strategy (#40495)
2025-08-29|||Dev version
2025-08-26|||[pipeline] Add Keypoint Matching pipeline (#39970)
2025-08-19|||Add Kosmos-2.5 (#31711)
2025-08-14|||make model doc device agnostic (#40143)
2025-08-11|||Remove deprecated cache-related objects (#40035)
2025-08-08|||[core] Refactor the Cache logic to make it simpler and more general (#39797)
2025-08-05|||Dev version
2025-08-05|||Add GPT OSS model from OpenAI  (#39923)
2025-08-01|||[typecheck] proper export of private symbols (#39729)
2025-07-25|||dev version 4.55
2025-07-23|||FP-Quant support (#38696)
2025-07-22|||ðŸŽ¯ Trackio integration (#38814)
2025-07-22|||[cache refactor] Move all the caching logic to a per-layer approach (#39106)
2025-07-21|||Refactor `MambaCache` to `modeling_mamba.py` (#38086)
2025-07-16|||Remove runtime conditions for type checking (#37340)
2025-07-11|||Add mistral common support (#38906)
2025-06-26|||Dev version
2025-06-17|||Add LightGlue model (#31718)
2025-05-22|||ðŸš¨ðŸš¨[core] Completely rewrite the masking logic for all attentions (#37866)
2025-05-20|||v4.53.0.dev0
2025-05-12|||ðŸ”´ Video processors as a separate class (#35206)
2025-04-28|||Add Bitnet model (#37742)
2025-04-22|||Add AutoRound quantization support (#37393)
2025-04-22|||Introduce GradientCheckpointingLayer (#37223)
2025-04-18|||Model debugger upgrades (#37391)
2025-04-11|||[agents] remove agents ðŸ§¹  (#37368)
2025-04-11|||Simplify soft dependencies and update the dummy-creation process (#36827)
2025-04-10|||Add image classifier donut & update loss calculation for all swins  (#37224)
2025-04-09|||Add glm4 (#37388)
2025-04-05|||v4.52.0.dev0
2025-04-05|||Add llama4 (#37307)
2025-04-04|||[RoPE] abstract dynamic RoPE update under a decorator âœ¨  (#37249)
2025-03-31|||Create and Expose SamVisionModel as public for better accessibility (#36493)
2025-03-31|||Remove deprecated code (#37059)
2025-03-31|||Adding Qwen3 and Qwen3MoE (#36878)
2025-03-28|||[WIP] add deepseek-v3 (#35926)
2025-03-26|||Support QuestionAnswering Module for ModernBert based models. (#35566)
2025-03-26|||Allow easy registration of custom attention functions (#36889)
2025-03-25|||Add Phi4 multimodal (#36939)
2025-03-21|||push v4.51.0.dev0
2025-03-20|||Add model visual debugger (#36798)
2025-03-21|||Add Prompt Depth Anything Model (#35401)
2025-03-20|||Support loading Quark quantized models in Transformers (#36372)
2025-03-20|||Shieldgemma2 (#36678)
2025-03-19|||Just import torch AdamW instead (#36177)
2025-03-18|||Add Mistral3 (#36790)
2025-03-12|||HPU support (#36424)
2025-03-12|||Gemma3 (#36658)
2025-03-07|||Integrate SwanLab for offline/online experiment tracking and local visualization (#36433)
2025-03-04|||Add aya (#36521)
2025-03-01|||Add Got-OCR 2 Fast image processor and refactor slow one (#36185)
2025-02-21|||Add SigLIP 2 (#36323)
2025-02-20|||SmolVLM2 (#36126)
2025-02-17|||v4.45.0-dev0
2025-02-14|||add shared experts for upcoming Granite 4.0 language models (#35894)
2025-02-14|||Add ImageProcessorFast to Qwen2.5-VL processor (#36164)
2025-02-13|||Efficient Inference Kernel for SpQR  (#34976)
2025-02-13|||Adding FP8 Quantization to transformers (#36026)
2025-02-13|||Move `DataCollatorForMultipleChoice` from the docs to the package (#34763)
2025-02-10|||Add Apple's Depth-Pro for depth estimation (#34583)
2025-02-06|||Adding RT-DETRv2 for object detection (#34773)
2025-02-04|||Refactoring of ImageProcessorFast (#35069)
2025-02-04|||Add DAB-DETR for object detection (#30803)
2025-01-31|||Add GOT-OCR 2.0 to Transformers (#34721)
2025-01-27|||Add Zamba2 (#34517)
2025-01-23|||add qwen2.5vl (#35569)
2025-01-21|||Remove old `benchmark` code (#35730)
2025-01-21|||add Qwen2-VL image processor fast (#35733)
2025-01-21|||Add LlavaImageProcessor (#33191)
2025-01-20|||Fixes, improvements to `timm` import behaviour (#35800)
2025-01-20|||Add SuperGlue model (#29886)
2025-01-16|||ðŸ§¹ remove `generate`-related objects and methods scheduled for removal in v4.48 (#35677)
2025-01-13|||Add-helium (#35669)
2025-01-10|||v4.49.0-dev
2025-01-10|||[WIP] Emu3: add model (#33770)
2025-01-10|||Add Moonshine  (#34784)
2025-01-08|||Add ViTPose (#30530)
2025-01-08|||Add TextNet (#34979)
2025-01-07|||Add diffllama (#34083)
2024-12-24|||Add DINOv2 with registers (#35348)
2024-12-23|||HIGGS Quantization Support (#34997)
2024-12-20|||Implement AsyncTextIteratorStreamer for asynchronous streaming (#34931)
2024-12-20|||FEAT : Adding VPTQ quantization method to HFQuantizer (#34770)
2024-12-19|||Add ModernBERT to Transformers (#35158)
2024-12-19|||Add the Bamba Model (#34982)
2024-12-17|||Add ColPali to ðŸ¤— transformers (#33736)
2024-12-13|||Add Cohere2 model (#35224)
2024-12-11|||Add TimmWrapper (#34564)
2024-12-06|||Add Aria (#34157)
2024-12-05|||Dev version
2024-12-05|||Add I-JEPA (#33125)
2024-12-03|||Automatic compilation in generate: do not rely on inner function (#34923)
2024-11-28|||Add optimized `PixtralImageProcessorFast` (#34836)
2024-11-25|||Fix import structure for Fast Image processors (#34859)
2024-11-25|||Rename OLMo November to OLMo2 (#34864)
2024-11-19|||Add Image Processor Fast Deformable DETR (#34353)
2024-11-18|||Add OLMo November 2024 (#34551)
2024-10-31|||Add image text to text pipeline (#34170)
2024-10-30|||Add Image Processor Fast RT-DETR (#34354)
2024-10-24|||v4.47.0.dev0
2024-10-23|||Add SynthID (watermerking by Google DeepMind) (#34350)
2024-10-21|||Add DetrImageProcessorFast (#34063)
2024-10-18|||add Glm (#33823)
2024-10-17|||Fix Gradient Accumulation issue (#34191)
2024-10-17|||removes decord  (#33987)
2024-10-16|||Moshi integration (#33624)
2024-10-14|||Mistral-related models for QnA (#34045)
2024-10-09|||FEAT : Adding BitNet quantization method to HFQuantizer (#33410)
2024-10-08|||Add auto model for image-text-to-text (#32472)
2024-10-08|||Add support for __all__ and potentilly deleting functions (#33859)
2024-10-06|||[WIP] Add Tokenizer for MyT5 Model (#31286)
2024-10-04|||Add Zamba (#30950)
2024-10-04|||PhiMoE (#33363)
2024-09-25|||Add Idefics 3! (#32473)
2024-09-25|||Dev release
2024-09-25|||Add MLLama (#33703)
2024-09-25|||Add OmDet-Turbo (#31843)
2024-09-25|||HFQuantizer implementation for compressed-tensors library (#31704)
2024-09-25|||fix code quality after merge
2024-09-25|||[Pixtral] Improve docs, rename model (#33491)
2024-09-20|||Granitemoe (#33207)
2024-09-18|||Codec integration (#33565)
2024-09-18|||Decorator for easier tool building (#33439)
2024-09-14|||Add support for Pixtral (#33449)
2024-09-10|||Make StaticCache configurable at model construct time (#32830)
2024-09-10|||Import structure & first three model refactors (#31329)
2024-09-09|||Add visit webpage tool (#33353)
2024-09-05|||Llava Onevision: add model (#32673)
2024-09-03|||Add OLMoE (#32406)
2024-08-30|||Create local Transformers Engine (#33218)
2024-08-29|||Add a static cache that offloads to the CPU or other device (#32161)
2024-08-27|||Granite language models (#31502)
2024-08-27|||ðŸš¨ Add Blip2ForImageTextRetrieval (#29261)
2024-08-26|||support qwen2-vl (#32318)
2024-08-23|||Forbid `PretrainedConfig` from saving `generate` parameters; Update deprecations in `generate`-related code ðŸ§¹  (#32659)
2024-08-19|||Add Descript-Audio-Codec model (#31494)
2024-08-19|||Add Flax Dinov2 (#31960)
2024-08-14|||Add TorchAOHfQuantizer (#32306)
2024-08-14|||Support MUSA (Moore Threads GPU) backend in transformers (#31913)
2024-08-12|||Add new model (#32615)
2024-08-08|||Add Qwen2-Audio (#32137)
2024-08-06|||dev version 4.45.0
2024-08-06|||Add codestral mamba2 (#32080)
2024-08-06|||Add Nemotron HF Support (#31699)
2024-08-06|||Cache: create docs (#32150)
2024-07-29|||Add stream messages from agent run for gradio chatbot (#32142)
2024-07-23|||Dev version: v4.44.0.dev0
2024-07-23|||Enhancing SFT Training Efficiency Using Packing and FlashAttention2 with Position IDs (#31629)
2024-07-23|||Llama: RoPE refactor (#32135)
2024-07-22|||Add new quant method (#32047)
2024-07-18|||Chameleon: minor fixes after shipping (#32037)
2024-07-17|||Chameleon: add model (#31534)
2024-07-16|||fix: Fixed incorrect dictionary assignment in `src/transformers/__init__.py` (#31993)
2024-07-12|||Adding hiera (#30356)
2024-07-11|||Refactor flash attention implementation in transformers (#31446)
2024-07-08|||Add ZoeDepth (#30136)
2024-07-02|||[whisper] static kv cache (#31166)
2024-06-27|||v4.43.0.dev0
2024-06-27|||Add gemma 2 (#31659)
2024-06-26|||Add LLaVa NeXT Video (#31252)
2024-06-25|||Add video modality for InstrucBLIP (#30182)
2024-06-22|||New model support RTDETR (#29077)
2024-06-11|||Fast image processor (#28847)
2024-06-07|||Remove ConversationalPipeline and Conversation object (#31165)
2024-05-28|||Deprecate low use models (#30781)
2024-05-23|||[Port] TensorFlow implementation of Mistral (#29708)
2024-05-23|||Quantized KV Cache (#30483)
2024-05-20|||Add TokenClassification for Mistral, Mixtral and Qwen2 (#29878)
2024-05-17|||v4.42.dev.0
2024-05-16|||Fix VideoLlava imports (#30867)
2024-05-15|||Add Video Llava  (#29733)
2024-05-14|||Add PaliGemma (#30814)
2024-05-14|||Add JetMoE model (#30005)
2024-05-14|||Add Watermarking LogitsProcessor and WatermarkDetector (#29676)
2024-05-13|||Port IDEFICS to tensorflow (#26870)
2024-05-09|||Generate: add `min_p` sampling (#30639)
2024-05-09|||Removal of deprecated maps (#30576)
2024-05-07|||Reboot Agents (#30387)
2024-05-02|||Add HQQ quantization support (#29637)
2024-05-02|||Docs: add missing `StoppingCriteria` autodocs (#30617)
2024-04-25|||Add WSD scheduler (#30231)
2024-04-24|||Phi-3 (#30423)
2024-04-23|||[FEAT]: EETQ quantizer support (#30262)
2024-04-19|||Add TF swiftformer (#23342)
2024-04-18|||Dev version
2024-04-18|||Add DBRX Model (#29921)
2024-04-18|||Add jamba (#29943)
2024-04-17|||Add OLMo model family (#29890)
2024-04-15|||Add Idefics2 (#30253)
2024-04-11|||Adding grounding dino (#26087)
2024-04-10|||Add recurrent gemma (#30143)
2024-03-27|||add Cambricon MLUs support (#29627)
2024-03-27|||Add Qwen2MoE (#29377)
2024-03-26|||Replace 'decord' with 'av' in VideoClassificationPipeline (#29747)
2024-03-25|||Remove static pretrained maps from the library's internals (#29112)
2024-03-21|||Generate: remove legacy generation mixin imports (#29782)
2024-03-20|||Add LLaVa-1.6, bis (#29586)
2024-03-20|||SuperPointModel -> SuperPointForKeypointDetection (#29757)
2024-03-20|||v4.40.0.dev.0
2024-03-19|||Implementation of SuperPoint and AutoModelForKeypointDetection (#28966)
2024-03-18|||Add MusicGen Melody (#28819)
2024-03-15|||[Quantization] Quanto quantizer (#29023)
2024-03-15|||Cohere Model Release (#29622)
2024-03-13|||Add PvT-v2 Model (#26812)
2024-03-11|||Make torch xla available on GPU (#29334)
2024-03-09|||feat: use `warning_advice` for tensorflow warning (#29540)
2024-03-08|||[tests] add the missing `require_sacremoses` decorator  (#29504)
2024-03-07|||v4.39 deprecations ðŸ§¼  (#29492)
2024-03-05|||[`Add Mamba`] Adds support for the `Mamba` models (#28094)
2024-03-04|||Add UDOP (#22940)
2024-02-28|||Starcoder2 model - bis (#29215)
2024-02-26|||Adding SegGPT (#27735)
2024-02-26|||Add feature extraction mapping for automatic metadata update (#28944)
2024-02-21|||[ `gemma`] Adds support for Gemma ðŸ’Ž (#29167)
2024-02-21|||v4.39.dev.0
2024-02-14|||AQLM quantizer support (#28928)
2024-02-14|||Add SiglipForImageClassification and CLIPForImageClassification (#28952)
2024-02-14|||Add `StableLM` (#28810)
2024-02-08|||[`Core generation`] Adds support for static KV cache (#27931)
2024-02-06|||Adds LlamaForQuestionAnswering class in modeling_llama.py along with AutoModel Support  (#28777)
2024-02-05|||Image Feature Extraction pipeline (#28216)
2024-02-01|||Adding [T5/MT5/UMT5]ForTokenClassification (#28443)
2024-01-31|||Flax mistral (#26943)
2024-01-30|||`HfQuantizer` class for quantization-related stuff in `modeling_utils.py` (#26610)
2024-01-28|||[`Siglip`] protect from imports if sentencepiece not installed (#28737)
2024-01-25|||Add Depth Anything (#28654)
2024-01-19|||v4.38.dev.0
2024-01-18|||Add new meta w2v2-conformer BERT-like model (#28165)
2024-01-17|||Add qwen2 (#28436)
2024-01-12|||TF: purge `TFTrainer` (#28483)
2024-01-08|||Add SigLIP (#26522)
2024-01-03|||Add FastSpeech2Conformer (#23439)
2023-12-22|||Add Swinv2 backbone (#27742)
2023-12-13|||Dev version
2023-12-13|||Adds VIP-llava to transformers (#27932)
2023-12-11|||[`Add Mixtral`] Adds support for the Mixtral MoE (#27942)
2023-12-08|||Generate: New `Cache` abstraction and Attention Sinks support (#26681)
2023-12-07|||[`Llava`]Â Add Llava to transformers (#27662)
2023-12-07|||Add Llama Flax Implementation (#24587)
2023-12-05|||[Time series] Add PatchTSMixer (#26247)
2023-11-30|||Add SeamlessM4T v2 (#27779)
2023-11-29|||[Time series] Add patchtst (#27581)
2023-11-28|||Add BeitBackbone (#25952)
2023-11-24|||Deprecate `TransfoXL` (#27607)
2023-11-22|||Add UnivNet Vocoder Model for Tortoise TTS Diffusers Integration (#24799)
2023-11-22|||TVP model (#25856)
2023-11-14|||Revert "[time series] Add PatchTST (#25927)" (#27486)
2023-11-13|||[time series] Add PatchTST (#25927)
2023-11-10|||Add Phi-1 and Phi-1_5 (#26170)
2023-11-10|||Add CLVP (#24745)
2023-11-09|||Adds dvclive callback (#27352)
2023-11-08|||Add numpy alternative to FE using torchaudio (#26339)
2023-11-03|||Fuyu protection (#27248)
2023-11-02|||Dev version
2023-11-02|||Add TensorFlow implementation of ConvNeXTv2  (#25558)
2023-11-01|||[WhisperForCausalLM] Add WhisperForCausalLM for speculative decoding (#27195)
2023-11-01|||[`core` / `Quantization` ] AWQ integration (#27045)
2023-10-30|||Add `Kosmos-2` model (#24709)
2023-10-25|||[`docs`] Add `MaskGenerationPipeline` in docs (#27063)
2023-10-23|||Add Seamless M4T model (#25693)
2023-10-19|||Add fuyu model (#26911)
2023-10-13|||Add OWLv2, bis (#26668)
2023-10-03|||v4.35.0.dev0
2023-09-27|||[Mistral] Mistral-7B-v0.1 support (#26447)
2023-09-26|||Add Nougat (#25942)
2023-09-22|||Add image to image pipeline (#25393)
2023-09-19|||Add ViTMatte (#25843)
2023-09-15|||Add BROS (#23190)
2023-09-12|||[`Persimmon`] Add support for persimmon (#26042)
2023-09-05|||Add TFDebertaV2ForMultipleChoice (#25932)
2023-09-05|||Patch with accelerate xpu (#25714)
2023-09-04|||v4.34.dev.0
2023-09-01|||add VITS model (#24085)
2023-08-29|||[DINOv2] Add backbone class (#25520)
2023-08-29|||Add ViTDet (#25524)
2023-08-25|||[`CodeLlama`] Add support for `CodeLlama` (#25740)
2023-08-25|||ðŸš¨ðŸš¨ðŸš¨ [`Refactor`] Move third-party related utility files into `integrations/` folder ðŸš¨ðŸš¨ðŸš¨ (#25599)
2023-08-25|||Generate: add missing logits processors docs (#25653)
2023-08-25|||Add FlaxCLIPTextModelWithProjection (#25254)
2023-08-21|||Add Pop2Piano (#21785)
2023-08-21|||v4.33.0.dev0
2023-08-18|||new model: IDEFICS via HuggingFaceM4 (#24796)
2023-08-18|||Make TTS automodels importable (#25595)
2023-08-18|||[`PEFT`] Peft integration alternative design  (#25077)
2023-08-17|||Add Text-To-Speech pipeline (#24952)
2023-08-10|||GPTQ integration (#25062)
2023-08-04|||Document check copies (#25291)
2023-07-27|||Add bloom flax (#25094)
2023-07-25|||[`T5`, `MT5`, `UMT5`] Add [T5, MT5, UMT5]ForSequenceClassification (#24726)
2023-07-25|||[`MPT`] Add MosaicML's `MPT` model to transformers (#24629)
2023-07-24|||Pvt model (#24720)
2023-07-20|||Deprecate unused OpenLlama architecture (#24922)
2023-07-18|||Add DINOv2 (#24016)
2023-07-18|||add ascend npu accelerator support (#24879)
2023-07-17|||4.32.0.dev0
2023-07-17|||Add bark (#24086)
2023-07-13|||Deprecate models (#24787)
2023-07-11|||Add ViViT (#22518)
2023-07-11|||Falcon port (#24523)
2023-07-10|||Add Multi Resolution Analysis (MRA) (New PR) (#24513)
2023-07-07|||[`MT5`] Fix CONFIG_MAPPING issue leading it to load umt5 class (#24678)
2023-07-04|||Fix audio feature extractor deps (#24636)
2023-07-03|||[`Umt5`]  Add google's umt5 to `transformers` (#24477)
2023-06-29|||Check all objects are equally in the main `__init__` file (#24573)
2023-06-29|||Add Musicgen (#24109)
2023-06-27|||[`T5`] Add T5ForQuestionAnswering and MT5ForQuestionAnswering (#24481)
2023-06-26|||Add InstructBLIP (#23460)
2023-06-23|||[AutoModel] Add AutoModelForTextEncoding (#24305)
2023-06-22|||Refactor hyperparameter search backends (#24384)
2023-06-21|||Check auto mappings could be imported via `from transformers` (#24400)
2023-06-21|||Generate: add SequenceBiasLogitsProcessor (#24334)
2023-06-20|||Update tiny models for pipeline testing. (#24364)
2023-06-14|||[WIP] add EnCodec model (#23655)
2023-06-07|||v4.31.0.dev0
2023-06-07|||Add AzureOpenAiAgent (#24058)
2023-06-06|||Add TimmBackbone model (#22619)
2023-06-02|||Add MobileViTv2 (#22820)
2023-05-31|||Add TensorFlow implementation of  EfficientFormer (#22620)
2023-05-30|||[Time-Series] Autoformer model (#21891)
2023-05-19|||TF port of the Segment Anything Model (SAM) (#22970)
2023-05-18|||Add local agent (#23438)
2023-05-12|||Add swiftformer (#22686)
2023-05-09|||Test composition (#23214)
2023-05-09|||v4.30.0.dev0
2023-05-09|||Add RWKV-4 (#22797)
2023-05-05|||Add FlaxWhisperForAudioClassification model (#23173)
2023-05-04|||Revert "Add FlaxWhisperForAudioClassification model" (#23154)
2023-05-04|||Add FlaxWhisperForAudioClassification model (#22883)
2023-05-04|||GPTNeoXForQuestionAnswering (#23059)
2023-05-03|||GPTNeoForQuestionAnswering (#23057)
2023-05-03|||Add focalnet backbone (#23104)
2023-05-02|||GPT2ForQuestionAnswering (#23030)
2023-05-01|||Add `BioGPTForSequenceClassification` (#22253)
2023-04-28|||add open-llama model with ckpt (#22795)
2023-04-27|||added GPTNeoForTokenClassification (#22908)
2023-04-27|||added GPTNeoXForTokenClassification (#23002)
2023-04-26|||Add TensorFlow Wav2Vec2 for sequence classification (#22073)
2023-04-23|||Add FocalNet (#21532)
2023-04-21|||Expose AutoModelForMaskGeneration (#22910)
2023-04-20|||Add `automatic-mask-generation` pipeline for Segment Anything Model (SAM) (#22840)
2023-04-19|||Add Segment Anything Model (SAM) (#22654)
2023-04-12|||v4.29.0.dev0
2023-04-12|||add model resources for CPMAnt (new) (#20906)
2023-04-11|||add GPTNeoXForSequenceClassification (#22671)
2023-04-10|||Add GPTBigCode model (Optimized GPT2 with MQA from Santacoder & BigCode) (#22575)
2023-04-06|||Adding Llama FastTokenizer support. (#22264)
2023-04-04|||Flax Regnet (#21867)
2023-04-04|||Add TF port of BLIP (#22090)
2023-04-03|||Generate: `TextIteratorStreamer` (streamer for gradio) (#22501)
2023-04-03|||added biogpt token classifier (#22447)
2023-03-30|||Generate: basic token streaming (#22449)
2023-03-27|||[WIP]`NLLB-MoE` Adds the moe model (#22024)
2023-03-25|||Resnet flax (#21472)
2023-03-24|||Add Mega: Moving Average Equipped Gated Attention (#21766)
2023-03-23|||Fix various imports (#22281)
2023-03-22|||Add Pix2Struct (#21400)
2023-03-17|||Add LlamaForSequenceClassification (#22209)
2023-03-17|||LLaMA house-keeping (#22216)
2023-03-16|||LLaMA Implementation (#21955)
2023-03-14|||v4.28.0.dev0
2023-03-14|||Add ConvNeXT V2 (#21679)
2023-03-13|||add new model of MGP-STR (#21418)
2023-03-13|||Add AutoModelForZeroShotImageClassification (#22087)
2023-03-10|||Fix imports of TF MobileViT (#22065)
2023-03-08|||[WIP] Add BridgeTowerForContrastiveLearning (#21964)
2023-03-08|||[Time-Series] informer model (#21099)
2023-03-07|||[DETR and friends] Remove is_timm_available (#21814)
2023-03-07|||[Whisper] Add model for audio classification (#21754)
2023-03-01|||Add ALIGN to transformers (#21741)
2023-03-01|||Add TFVisionTextDualEncoder (#21873)
2023-02-28|||[`Blip2`] Add `Blip2Model` (#21817)
2023-02-27|||[Pipeline] Add zero shot audio classificatoin pipeline (#21600)
2023-02-21|||Add WhisperTokenizerFast (#21222)
2023-02-20|||Add EfficientNet (#21563)
2023-02-20|||add GPTSAN model (reopen) (#21291)
2023-02-20|||add flax whisper implementation (#20479)
2023-02-17|||[`bnb`] Introducing `BitsAndBytesConfig` (#21579)
2023-02-16|||[CLAP] Add CLAP to the library (#21370)
2023-02-15|||Add TVLT (#20725)
2023-02-15|||Add Ernie-M Model to huggingface (#21349)
2023-02-10|||Add X-MOD (#20939)
2023-02-09|||Add BLIP-2 (#21441)
2023-02-08|||no more dummies for speech processors (#21517)
2023-02-07|||Add inverse sqrt learning rate scheduler (#21495)
2023-02-07|||Cleanup quality (#21493)
2023-02-03|||[WIP] add SpeechT5 model (#18922)
2023-01-31|||Add DETA (#20983)
2023-01-25|||Add BridgeTower model (#20775)
2023-01-24|||Fix MaskFormerImageProcessor.post_process_instance_segmentation (#21256)
2023-01-23|||v4.27.0.dev0
2023-01-20|||Efficientformer (#20459)
2023-01-19|||Graphormer model for Graph Classification (#20968)
2023-01-19|||Add OneFormer Model (#20577)
2023-01-18|||Add AWS Neuron torchrun support (#20806)
2023-01-18|||Remove Roberta Dependencies from XLM Roberta Flax and Tensorflow models (#21047)
2023-01-16|||Add Mask2Former (#20792)
2023-01-16|||Add UperNet (#20648)
2023-01-05|||Remove T5 dependency from mT5 model (#20949)
2023-01-04|||Add AltCLIP (#20446)
2023-01-03|||Add GIT (GenerativeImage2Text) (#20295)
2023-01-03|||`MinNewTokensLengthLogitsProcessor` for `.generate` method #20814 (#20892)
2022-12-21|||Add BLIP (#20716)
2022-12-19|||Implement Roberta PreLayerNorm (#20305)
2022-12-16|||Add Swin2SR (#19784)
2022-12-16|||Add Universal Segmentation class + mapping (#20766)
2022-12-14|||Add Swin backbone (#20769)
2022-12-14|||Remove image_transforms functions from init (#20704)
2022-12-13|||[NAT, DiNAT] Add backbone class (#20654)
2022-12-12|||Add gpt-sw3 model to transformers (#20209)
2022-12-08|||Add video classification pipeline (#20151)
2022-12-07|||Add TFBartForSequenceClassification (#20570)
2022-12-07|||Add BiT + ViT hybrid (#20550)
2022-12-05|||Add BioGPT (#20420)
2022-12-02|||[New Model] Add TimeSformer model (#18908)
2022-12-01|||v4.26.0.dev0
2022-11-30|||Fix style
2022-12-01|||Add Chinese-CLIP implementation (#20368)
2022-11-30|||Fix TF nightly tests (#20507)
2022-11-30|||Add segmentation + object detection image processors (#20160)
2022-11-29|||add in layer gpt2 tokenizer (#20421)
2022-11-29|||Fix init import_structure sorting (#20477)
2022-11-29|||Add Donut image processor (#20425)
2022-11-28|||[Maskformer] Add MaskFormerSwin backbone (#20344)
2022-11-28|||[AutoBackbone] Improve API (#20407)
2022-11-21|||Add Audio Spectogram Transformer (#19981)
2022-11-21|||add MobileNetV1 model (#17799)
2022-11-21|||Generate: add generation config class (#20218)
2022-11-18|||Add Neighborhood Attention Transformer (NAT) and Dilated NAT (DiNAT) models (#20219)
2022-11-17|||Add AutoBackbone + ResNetBackbone (#20229)
2022-11-15|||[CLIP] allow loading projection layer in vision and text model (#18962)
2022-11-15|||New logging support to "Trainer" Class (ClearML Logger) (#20184)
2022-11-15|||Add Switch transformers (#19323)
2022-11-14|||Fix tapas scatter (#20149)
2022-11-14|||add MobileNetV2 model (#17845)
2022-11-10|||Add Jukebox model (replaces #16875) (#17826)
2022-11-09|||Generate: move generation_*.py src files into generation/*.py (#20096)
2022-11-08|||AutoImageProcessor (#20111)
2022-11-08|||Add RocBert (#20013)
2022-11-08|||Add CLIPSeg (#20066)
2022-10-31|||v4.25.0.dev0
2022-11-01|||Add ESMFold (#19977)
2022-10-18|||Add table transformer [v2] (#19614)
2022-10-17|||Removed XLMModel inheritance from FlaubertModel(torch+tf) (#19432)
2022-10-17|||TF port of ESM (#19587)
2022-10-12|||Image transforms library (#18520)
2022-10-12|||Add depth estimation pipeline (#18618)
2022-10-12|||Add LiLT (#19450)
2022-10-11|||[CvT] Tensorflow implementation (#18597)
2022-10-11|||Decouples `XLMProphet` model from `Prophet`  (#19406)
2022-10-11|||Make `XLMRoberta` model and config independent from `Roberta` (#19359)
2022-10-10|||Dev version
2022-10-10|||Add TF whisper (#19378)
2022-10-10|||Add `OPTForQuestionAnswering` (#19402)
2022-10-07|||Make `Camembert` TF version independent from `Roberta` (#19364)
2022-10-07|||[WIP] Add ZeroShotObjectDetectionPipeline (#18445) (#18930)
2022-10-05|||Add WhisperModel to transformers (#19166)
2022-10-05|||Making camembert independent from roberta, clean (#19337)
2022-10-04|||Add `BloomForQuestionAnswering` (#19310)
2022-09-30|||time series forecasting model (#17965)
2022-09-30|||Poc to use safetensors (#19175)
2022-09-30|||Rebase ESM PR and update all file formats (#19055)
2022-09-30|||Add MarkupLM (#19198)
2022-09-29|||[TensorFlow] Adding GroupViT (#18020)
2022-09-22|||MSN (Masked Siamese Networks) for ViT (#18815)
2022-09-22|||[fix] Add DeformableDetrFeatureExtractor (#19140)
2022-09-22|||Add support for conditional detr (#18948)
2022-09-14|||Dev version
2022-09-14|||Add support for Japanese GPT-NeoX-based model by ABEJA, Inc. (#18814)
2022-09-14|||Add Deformable DETR (#17281)
2022-09-09|||Neptune.ai integration improvements (#18934)
2022-09-09|||add task_type_id to BERT to support ERNIE-2.0 and ERNIE-3.0 models (#18686)
2022-09-08|||Add X-CLIP (#18852)
2022-09-07|||Add DocumentQuestionAnswering pipeline (#18414)
2022-09-02|||PEGASUS-X (#18551)
2022-09-02|||Fix naming issue with ImageToText pipeline (#18864)
2022-09-01|||Add Image To Text Generation pipeline (#18821)
2022-09-01|||TensorFlow MobileViT (#18555)
2022-08-31|||Add LayoutLMForQuestionAnswering model (#18407)
2022-08-30|||[LayoutLMv3] Add TensorFlow implementation (#18678)
2022-08-24|||Add TF implementation of `XGLMModel` (#16543)
2022-08-12|||Add Donut (#18488)
2022-08-12|||Add `TFAutoModelForSemanticSegmentation` to the main `__init__.py` (#18600)
2022-08-10|||`bitsandbytes` - `Linear8bitLt` integration into `transformers` models (#17901)
2022-08-08|||Clean up hub (#18497)
2022-08-04|||Add `TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING` (#18469)
2022-08-04|||Add VideoMAE (#17821)
2022-08-02|||Adding fine-tuning models to LUKE (#18353)
2022-07-27|||Add swin transformer v2 (#17469)
2022-07-27|||Dev version
2022-07-26|||Add ViltForTokenClassification e.g. for Named-Entity-Recognition (NER) (#17924)
2022-07-22|||Add OWL-ViT model for zero-shot object detection (#17938)
2022-07-21|||[SegFormer] TensorFlow port (#17910)
2022-07-20|||Adding OPTForSeqClassification class (#18123)
2022-07-18|||NLLB tokenizer (#18126)
2022-07-13|||Add TF DeiT implementation (#17806)
2022-07-04|||Add TF ResNet model (#17427)
2022-06-29|||Flax t5 Encoder (#17784)
2022-06-29|||add MobileViT model (#17354)
2022-06-29|||Add MVP model (#17787)
2022-06-29|||TF implementation of RegNets (#17554)
2022-06-28|||Adding GroupViT Models (#17313)
2022-06-27|||Add a TF in-graph tokenizer for BERT (#17701)
2022-06-24|||Add CodeGen model (#17443)
2022-06-24|||Nezha Pytorch implementation (#17776)
2022-06-16|||v4.21.0.dev0
2022-06-14|||Add `BloomForSequenceClassification` and `BloomForTokenClassification` classes (#17639)
2022-06-13|||Add `LongT5` model (#16792)
2022-06-13|||Add Visual Question Answering (VQA) pipeline (#17286)
2022-06-09|||BLOOM  (#17474)
2022-06-08|||Add TFData2VecVision for semantic segmentation (#17271)
2022-06-08|||M-CTC-T Model (#16402)
2022-06-03|||Allow from transformers import TypicalLogitsWarper (#17477)
2022-06-01|||Adding LeViT Model by Facebook (#17466)
2022-05-31|||Opt in flax and tf (#17388)
2022-05-24|||[WIP] Adding GPT-NeoX-20B (#16659)
2022-05-24|||Add LayoutLMv3 (#17060)
2022-05-18|||Add CvT (#17299)
2022-05-18|||Add trajectory transformer (#17141)
2022-05-17|||Add support for pretraining recurring span selection to Splinter (#17247)
2022-05-17|||Add Wav2Vec2Conformer (#16812)
2022-05-16|||Add Tensorflow Swin model (#16988)
2022-05-12|||Dev version
2022-05-12|||Add OPT (#17088)
2022-05-11|||[feat] Add FLAVA model (#16654)
2022-05-11|||[WIP] Enable reproducibility for distributed trainings (#16907)
2022-05-10|||Add DebertaV2ForMultipleChoice (#17135)
2022-05-09|||[WIP] Fix Pyright static type checking by replacing if-else imports with try-except (#16578)
2022-05-09|||Fix quality and repo consistency
2022-05-09|||add `mobilebert` onnx configs (#17029)
2022-05-04|||Add Data2Vec for Vision in TF (#17008)
2022-05-03|||[FlaxBert] Add ForCausalLM (#16995)
2022-05-02|||Allow all imports from transformers (#17050)
2022-05-02|||Add YOLOS (#16848)
2022-04-20|||Fix custom init sorting script (#16864)
2022-04-20|||add DebertaV2 fast tokenizer (#15529)
2022-04-18|||[Data2Vec] Add data2vec vision (#16760)
2022-04-12|||Moved functions to pytorch_utils.py (#16625)
2022-04-08|||Add TAPEX (#16473)
2022-04-07|||RegNet (#16188)
2022-04-06|||TF generate refactor - Beam Search (#16374)
2022-04-06|||Dev version
2022-03-29|||Add TF ViT MAE (#16255)
2022-03-28|||Add DPT (#15991)
2022-03-25|||Add TF implementation of GPT-J (#15623)
2022-03-23|||Decision transformer gym (#15845)
2022-03-23|||Reorganize file utils (#16264)
2022-03-22|||Add GLPN (#16199)
2022-03-15|||Visual Attention Network (VAN) (#16027)
2022-03-14|||[WIP] Resnet (#15770)
2022-03-14|||Add TFCamembertForCausalLM and ONNX integration test (#16073)
2022-03-11|||Move QDQBert in just PyTorch block (#16062)
2022-03-10|||Add Document Image Transformer (DiT) (#15984)
2022-03-09|||Add FlaxBartForCausalLM (#15995)
2022-03-05|||Constrained Beam Search [*With* Disjunctive Decoding] (#15761)
2022-03-04|||Add missing support for Flax XLM-RoBERTa (#15900)
2022-03-04|||Making MaskFormerForInstanceSegmentation. (#15934)
2022-03-03|||v4.18.0.dev.0
2022-03-02|||TF generate refactor - Sample (#15793)
2022-03-02|||Maskformer (#15682)
2022-03-01|||Add Data2Vec (#15507)
2022-02-28|||Flax Speech-Encoder-Decoder Model (#15613)
2022-02-25|||Add TFConvNextModel (#15750)
2022-02-23|||Enable `image-segmentation` on `AutoModelForSemanticSegmentation` (#15647)
2022-02-23|||Adding ZeroShotImageClassificationPipeline (#12119)
2022-02-18|||Add PLBart (#13269)
2022-02-17|||Add SimMIM (#15586)
2022-02-17|||Add PoolFormer (#15531)
2022-02-15|||TF generate refactor - Greedy Search (#15562)
2022-02-10|||Constrained Beam Search [without disjunctive decoding] (#15416)
2022-02-09|||PoC for a ProcessorMixin class (#15549)
2022-02-08|||Add TFSpeech2Text (#15113)
2022-02-07|||Add ConvNeXT (#15277)
2022-02-07|||[torch_int_div] Correct true division in generation (#15498)
2022-02-04|||Standardize semantic segmentation models outputs (#15469)
2022-02-02|||Save code of registered custom models (#15379)
2022-01-29|||Add support for XLM-R XL and XXL models by modeling_xlm_roberta_xl.py (#13727)
2022-01-28|||Add XGLM models (#14876)
2022-01-27|||Docs for version v4.16.0
2022-01-27|||Release: v4.16.0
2022-01-27|||Add proper documentation for Keras callbacks (#15374)
2022-01-26|||Add YOSO (#15091)
2022-01-21|||Add Swin Transformer (#15085)
2022-01-19|||Add ViLT (#14895)
2022-01-19|||Add FastTokenizer to REALM (#15211)
2022-01-18|||Add MAE (#15120)
2022-01-18|||Add REALM (#13292)
2022-01-14|||Make sure all submodules are properly registered (#15144)
2022-01-11|||Add Nystromformer (#14659)
2022-01-10|||Add TFVisionEncoderDecoderModel (#14148)
2022-01-04|||Add Flax RoFormer (#15005)
2021-12-29|||remove absl workaround as it's no longer needed (#14909)
2021-12-27|||Add `ElectraForCausalLM` -> Enable Electra encoder-decoder model (#14729)
2021-12-23|||Add TFCLIPModel (#13967)
2021-12-22|||Docs for v4.16.0dev0
2021-12-22|||Release: v4.15.0
2021-12-20|||Add SD and SV heads for WavLM (#14847)
2021-12-17|||Wav2Vec2 meets phonemes (#14353)
2021-12-16|||Add WavLM (#14354)
2021-12-16|||Add Speaker Diarization and Verification heads (#14723)
2021-12-15|||Docs for v4.14.0
2021-12-15|||Release: v4.14.0
2021-12-09|||Docs for v4.14.0dev0
2021-12-09|||Release: v4.13.0
2021-12-08|||Move pyctcdecode (#14686)
2021-12-08|||Fixes in init (#14681)
2021-12-08|||[AutoProcessor] Add Wav2Vec2WithLM & small fix (#14675)
2021-12-08|||Add Perceiver IO (#14487)
2021-12-08|||[Wav2Vec2] PyCTCDecode Integration to support language model boosted decoding (#14339)
2021-12-07|||Add mLUKE (#14640)
2021-12-07|||Add GPTJForQuestionAnswering (#14503)
2021-12-03|||Make DefaultDataCollator importable from root (#14588)
2021-12-02|||[Flax] Add FlaxBlenderbotSmall (#14576)
2021-12-01|||FlaxGPTJ (#14396)
2021-11-30|||VisionTextDualEncoder (#13511)
2021-11-30|||[Flax] Add FlaxBlenderbot (#13633)
2021-11-30|||Tapas tf (#13393)
2021-11-29|||Rename ImageGPT (#14526)
2021-11-24|||Fix feature extraction utils import (#14515)
2021-11-22|||Auto processor (#14465)
2021-11-19|||Add QDQBert model and quantization examples of SQUAD task (#14066)
2021-11-18|||Add ImageGPT (#14240)
2021-11-09|||Add TFViTModel (#13778)
2021-11-09|||Add FlaxVisionEncoderDecoderModel (#13359)
2021-11-03|||Add LayoutXLMProcessor (and LayoutXLMTokenizer, LayoutXLMTokenizerFast) (#14115)
2021-11-02|||Add PushToHubCallback in main init (#14246)
2021-11-01|||Add BeitForSemanticSegmentation (#14096)
2021-10-29|||Add `BlenderbotTokenizerFast` (#13720)
2021-10-29|||Adding `batch_size` support for (almost) all pipelines (#13724)
2021-10-28|||v4.13.0.dev0
2021-10-28|||Release v4.12.0
2021-10-28|||Add SegFormer (#14019)
2021-10-26|||Add Unispeech & Unispeech-SAT (#13963)
2021-10-18|||[Speech] Refactor Examples (#14040)
2021-10-18|||Add BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese (#13788)
2021-10-15|||Add the SEW and SEW-D speech models (#13962)
2021-10-14|||Scatter dummies + skip pipeline tests (#13996)
2021-10-13|||Add TrOCR + VisionEncoderDecoderModel (#13874)
2021-10-13|||Add TFEncoderDecoderModel + Add cross-attention to some TF models (#13222)
2021-10-08|||Move to TF only
2021-10-08|||Style
2021-10-08|||Register `keras_callbacks` as a submodule
2021-10-08|||Image Segmentation pipeline (#13828)
2021-09-30|||[DPR] Correct init (#13796)
2021-09-27|||Docs for version v4.11.0
2021-09-27|||Release: v4.11.0
2021-09-23|||Add SigOpt HPO to transformers trainer api (#13572)
2021-09-22|||Add BlenderBot small tokenizer to the init (#13367)
2021-09-21|||beit-flax (#13515)
2021-09-21|||Add Speech AutoModels (#13655)
2021-09-20|||Add FNet (#13045)
2021-09-14|||[Flax] Addition of FlaxPegasus (#13420)
2021-09-08|||Object detection pipeline (#12886)
2021-09-06|||Add TAPAS MLM-only models (#13408)
2021-09-01|||Properly register missing submodules in main init (#13372)
2021-09-01|||Add SpeechEncoderDecoder & Speech2Text2 (#13186)
2021-09-01|||Add the `AudioClassificationPipeline` (#13342)
2021-09-01|||Add template for adding flax models (#12441)
2021-08-31|||GPT-J-6B (#13022)
2021-08-31|||Docs for v4.10.0
2021-08-31|||Release: v4.10.0
2021-08-31|||TF/Numpy variants for all DataCollator classes (#13105)
2021-08-31|||Deberta_v2 tf (#13120)
2021-08-31|||Add GPT2ForTokenClassification (#13290)
2021-08-30|||Add missing module __spec__ (#13321)
2021-08-30|||albert flax (#13294)
2021-08-30|||distilbert-flax (#13324)
2021-08-30|||Add LayoutLMv2 + LayoutXLM (#12604)
2021-08-27|||Add Wav2Vec2 & Hubert ForSequenceClassification (#13153)
2021-08-23|||Make Flax GPT2 working with cross attention (#13008)
2021-08-17|||Add splinter (#12955)
2021-08-12|||Deberta tf (#12972)
2021-08-06|||[WIP] Disentangle auto modules from other modeling files (#13023)
2021-08-04|||Add BEiT (#12994)
2021-08-04|||[Flax] Correctly Add MT5 (#12988)
2021-08-02|||Place BigBirdTokenizer in sentencepiece-only objects (#12975)
2021-07-24|||Add RemBERT model code to huggingface (#10692)
2021-07-22|||Docs for v4.10.0dev0
2021-07-22|||Release: v4.9.0
2021-07-09|||Add TFHubertModel (#12206)
2021-07-09|||[Flax] Add flax marian (#12595)
2021-07-08|||Init pickle (#12567)
2021-07-07|||[Flax] Add FlaxMBart (#12236)
2021-07-06|||FlaxGPTNeo (#12493)
2021-06-30|||[Flax] Add wav2vec2 (#12271)
2021-06-30|||Add CANINE (#12024)
2021-06-23|||v4.9.0.dev0
2021-06-23|||Release: v4.8.0
2021-06-23|||Add all XxxPreTrainedModel to the main init (#12314)
2021-06-23|||Flax T5 (#12150)
2021-06-22|||add FlaxAutoModelForImageClassification in main init (#12298)
2021-06-18|||[Flax] FlaxAutoModelForSeq2SeqLM (#12228)
2021-06-17|||Docs for v4.8.0
2021-06-17|||Release: v4.7.0
2021-06-16|||Hubert (#11889)
2021-06-16|||[Flax] Add Beam Search (#12131)
2021-06-15|||Flax Big Bird (#11967)
2021-06-14|||Adding TFWav2Vec2Model (#11617)
2021-06-14|||FlaxBart (#11537)
2021-06-10|||Flax VisionTransformer (#11951)
2021-06-09|||Wav2Vec2 Pretraining (#11306)
2021-06-09|||Add DETR (#11653)
2021-06-02|||VisualBERT (#10534)
2021-06-01|||ByT5 model (#11971)
2021-06-01|||Add FlaxCLIP (#11883)
2021-05-28|||Added Sequence Classification class in GPTNeo (#11906)
2021-05-27|||Flax Generate (#11777)
2021-05-20|||Add new model RoFormer (use rotary position embedding ) (#11684)
2021-05-19|||FlaxGPT2 (#11556)
2021-05-12|||Docs for v4.7.0.dev0
2021-05-12|||Release: v4.6.0
2021-05-12|||CLIP (#11445)
2021-05-10|||Big Bird Fast Tokenizer implementation (#11075)
2021-05-07|||Add the ImageClassificationPipeline (#11598)
2021-05-07|||Add BigBirdPegasus (#10991)
2021-05-04|||[Flax] Add Electra models (#11426)
2021-05-04|||[FlaxRoberta] Add FlaxRobertaModels & adapt run_mlm_flax.py (#11470)
2021-05-03|||Add LUKE (#11223)
2021-04-30|||Implement Fast Tokenization for Deberta (#11387)
2021-04-30|||Adding `AutomaticSpeechRecognitionPipeline`. (#11337)
2021-04-13|||Add DeiT (PyTorch) (#11056)
2021-04-10|||Add a special tokenizer for CPM model (#11068)
2021-04-08|||Add nvidia megatron models (#10911)
2021-04-07|||Dummies multi backend (#11100)
2021-04-06|||Auto feature extractor (#11097)
2021-04-06|||Development on v4.6.0dev0
2021-04-06|||Release v4.5.0
2021-04-05|||Refactor AutoModel classes and add Flax Auto classes (#11027)
2021-04-04|||Add a script to check inits are consistent (#11024)
2021-04-01|||Add Vision Transformer and ViTFeatureExtractor (#10950)
2021-03-31|||[Flax] Add other BERT classes (#10977)
2021-03-30|||GPT Neo (#10848)
2021-03-30|||BigBird (#10183)
2021-03-26|||Add ImageFeatureExtractionMixin (#10905)
2021-03-25|||Reorder init imports
2021-03-25|||Fix typo
2021-03-25|||Sort init imports
2021-03-25|||Layout lm tf 2 (#10636)
2021-03-23|||[Generate] Add save mode logits processor to remove nans and infs if necessary (#10769)
2021-03-19|||Sort init import (#10801)
2021-03-16|||Patches full import failure when sentencepiece is not installed (#10752)
2021-03-16|||Patches the full import failure and adds a test (#10750)
2021-03-16|||Development on v4.5.0dev0
2021-03-16|||Release v4.4.0
2021-03-12|||Adding new parameter to `generate`:  `max_time`. (#9846)
2021-03-10|||Speech2TextTransformer (#10175)
2021-03-09|||[FeatureExtractorSavingUtils] Refactor PretrainedFeatureExtractor (#10594)
2021-03-09|||Add TFRag (#9002)
2021-03-06|||Add m2m100 (#10236)
2021-02-28|||Introduce save_strategy training argument (#10286)
2021-02-26|||I-BERT model support (#10153)
2021-02-25|||[PretrainedFeatureExtractor] + Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2Tokenizer (#10324)
2021-02-19|||Integrate DeBERTa v2(the 1.5B model surpassed human performance on Suâ€¦ (#10018)
2021-02-15|||Add mBART-50 (#10154)
2021-02-09|||Deprecate Wav2Vec2ForMaskedLM and add Wav2Vec2ForCTC (#10089)
2021-02-04|||Bump version
2021-02-04|||Release: 4.3.0.rc1
2021-02-04|||BartForCausalLM analogs to `ProphetNetForCausalLM` (#9128)
2021-02-02|||Wav2Vec2 (#9659)
2021-01-27|||ConvBERT Model (#9717)
2021-01-20|||Add DeBERTa head models (#9691)
2021-01-19|||New run_seq2seq script (#9605)
2021-01-13|||v4.3.0.dev0
2021-01-13|||Release: v4.2.0
2021-01-12|||Improve LayoutLM (#9476)
2021-01-12|||[TFBart] Split TF-Bart (#9497)
2021-01-07|||Transformers fast import part 2 (#9446)
2021-01-05|||[PyTorch Bart] Split Bart into different models (#9343)
2021-01-05|||LED (#9278)
2020-12-22|||Seq2seq trainer (#9241)
2020-12-21|||add base model classes to  bart subclassed models (#9230)
2020-12-21|||[RAG] Add Ray implementation for distributed retrieval (#9197)
2020-12-19|||Added TF TransfoXL Sequence Classification (#9169)
2020-12-18|||Added TF CTRL Sequence Classification (#9151)
2020-12-17|||setup.py development version
2020-12-17|||Release: v4.1.1
2020-12-17|||Release: v4.1.0
2020-12-16|||TableQuestionAnsweringPipeline (#9145)
2020-12-16|||AutoModelForTableQuestionAnswering (#9154)
2020-12-16|||[Flax] Align FlaxBertForMaskedLM with BertForMaskedLM, implement from_pretrained, init (#9054)
2020-12-15|||[WIP] Tapas v4 (tres) (#9117)
2020-12-15|||[TF Bart] Refactor TFBart (#9029)
2020-12-15|||Added TF OpenAi GPT1 Sequence Classification (#9105)
2020-12-09|||[Bart] Refactor - fix issues, consistency with the library, naming (#8900)
2020-12-09|||Flax Masked Language Modeling training example (#8728)
2020-12-09|||Add MP Net 2 (#9004)
2020-12-09|||Diverse beam search 2 (#9006)
2020-12-07|||Copyright (#8970)
2020-12-07|||Add TFGPT2ForSequenceClassification based on DialogRPT (#8714)
2020-12-03|||Don't warn that models aren't available if Flax is available. (#8841)
2020-12-02|||Transfoxl seq classification (#8868)
2020-12-01|||Make the big table creation/check platform independent (#8856)
2020-12-01|||Ctrl for sequence classification (#8812)
2020-11-30|||fix pypi complaint on version naming
2020-11-30|||Release: v4.0.0
2020-11-30|||Add T5 Encoder for Feature Extraction (#8717)
2020-11-27|||Add barthez model (#8393)
2020-11-25|||Big model table (#8774)
2020-11-24|||[core] implement support for run-time dependency version checking (#8645)
2020-11-23|||Add early stopping callback to pytorch trainer (#8581)
2020-11-19|||Release: v4.0.0-rc-1
2020-11-19|||Tf longformer for sequence classification (#8231)
2020-11-18|||Fix missing space in multiline warning (#8593)
2020-11-17|||Fix init for MT5 (#8591)
2020-11-17|||T5 & mT5 (#8552)
2020-11-16|||Reorganize repo (#8580)
2020-11-16|||Update version to v4.0.0-dev (#8568)
2020-11-12|||Add TFDPR (#8203)
2020-11-10|||Add missing import (#8444)
2020-11-10|||Release: v3.5.0
2020-11-09|||[Tests] Add Common Test for Training + Fix a couple of bugs (#8415)
2020-11-04|||Clean up data collators and datasets (#8308)
2020-11-03|||Data collator for token classification (#8274)
2020-11-03|||Refactoring the generate() function (#6949)
2020-10-30|||TFMarian, TFMbart, TFPegasus, TFBlenderbot (#7987)
2020-10-22|||# Add whole word mask support for lm fine-tune (#7925)
2020-10-21|||Add TFBartForConditionalGeneration (#5411)
2020-10-20|||Release: v3.4.0
2020-10-20|||Add Flax dummy objects (#7918)
2020-10-19|||ProphetNet (#7157)
2020-10-19|||Integrate Bert-like model on Flax runtime. (#3722)
2020-10-18|||[Dependencies|tokenizers] Make both SentencePiece and Tokenizers optional dependencies (#7659)
2020-10-16|||Herbert polish model (#7798)
2020-10-13|||Gpt1 for sequence classification (#7683)
2020-10-08|||Adding Fast tokenizers for SentencePiece based tokenizers - Breaking: remove Transfo-XL fast tokenizer (#7141)
2020-10-07|||Blenderbot (#7418)
2020-10-07|||Trainer callbacks (#7596)
2020-10-06|||Add GPT2ForSequenceClassification based on DialogRPT (#7501)
2020-10-05|||Allow soft dependencies in the namespace with ImportErrors at use (#7537)
2020-10-05|||SqueezeBERT architecture (#7083)
2020-10-01|||Clean the Trainer state (#7490)
2020-09-30|||Add DeBERTa model (#5929)
2020-09-29|||Release: v3.3.1
2020-09-28|||Release: v3.3.0
2020-09-23|||Ensure that integrations are imported before transformers or ml libs (#7330)
2020-09-22|||RAG (#6813)
2020-09-22|||Release: v3.2.0
2020-09-22|||Add LayoutLM Model (#7064)
2020-09-19|||Add new pre-trained models BERTweet and PhoBERT (#6129)
2020-09-17|||[ported model] FSMT (FairSeq MachineTranslation) (#6940)
2020-09-10|||Fix CI with change of name of nlp (#7054)
2020-09-10|||Add TF Funnel Transformer (#7029)
2020-09-10|||Add "Leveraging Pretrained Checkpoints for Generation" Seq2Seq models. (#6594)
2020-09-10|||Albert pretrain datasets/ datacollator (#6168)
2020-09-08|||Funnel transformer (#6908)
2020-09-03|||Adding the LXMERT pretraining model (MultiModal  languageXvision)  to HuggingFace's suite of models (#5793)
2020-09-02|||[pipelines] Text2TextGenerationPipeline (#6744)
2020-09-01|||[EncoderDecoder] Add xlm-roberta to encoder decoder (#6878)
2020-09-01|||Release: v3.1.0
2020-08-31|||Dataset and DataCollator for BERT Next Sentence Prediction (NSP) task (#6644)
2020-08-27|||Add AdaFactor optimizer from fairseq (#6722)
2020-08-26|||Centralize logging (#6434)
2020-08-24|||Add hyperparameter search to Trainer (#6576)
2020-08-24|||Update repo to isort v5 (#6686)
2020-08-21|||CamembertForCausalLM (#6577)
2020-08-20|||Trainer automatically drops unused columns in nlp datasets (#6449)
2020-08-14|||MBartForConditionalGeneration (#6441)
2020-08-12|||[EncoderDecoder] Add encoder-decoder for roberta/ vanilla longformer (#6411)
2020-08-12|||Adding PaddingDataCollator (#6442)
2020-08-11|||lr_schedulers: add get_polynomial_decay_schedule_with_warmup (#6361)
2020-08-11|||PegasusForConditionalGeneration (torch version) (#6340)
2020-08-10|||TF Longformer (#5764)
2020-08-06|||Adds comet_ml to the list of auto-experiment loggers (#6176)
2020-08-05|||Add SequenceClassification and MultipleChoice TF models to Electra (#6227)
2020-08-04|||fix zero shot pipeline docs (#6245)
2020-07-30|||Addition of a DialoguePipeline (#5516)
2020-07-29|||[WIP] Test TF Flaubert + Add {XLM, Flaubert}{TokenClassification, MultipleCâ€¦ (#5614)
2020-07-17|||[cleanups] make Marian save as Marian (#5830)
2020-07-14|||[Reformer classification head] Implement the reformer model classification head for text classification (#5198)
2020-07-13|||FlaubertForTokenClassification  (#5644)
2020-07-07|||[Almost all TF models] TF clean up: add missing CLM / MLM loss; fix T5 naming and keras compile (#5395)
2020-07-07|||[examples] Add trainer support for question-answering (#4829)
2020-07-07|||Add DPR model (#5279)
2020-07-07|||Added data collator for permutation (XLNet) language modeling and related calls (#5522)
2020-07-06|||Release: v3.0.2
2020-07-03|||Release: 3.0.1
2020-07-01|||[Reformer] Add Masked LM Reformer (#5426)
2020-07-01|||finish reformer qa head (#5433)
2020-07-01|||Clean up diffs in Trainer/TFTrainer (#5417)
2020-06-30|||Documentation for the Trainer API (#5383)
2020-06-30|||Move GenerationMixin to separate file (#5254)
2020-06-29|||Release: v3.0.0
2020-06-29|||[Docs] Benchmark docs (#5360)
2020-06-22|||Benchmarks (#4912)
2020-06-19|||Add MobileBert (#4901)
2020-06-19|||ElectraForMultipleChoice (#4954)
2020-06-16|||Eli5 examples (#4968)
2020-06-15|||Add DistilBertForMultipleChoice (#5032)
2020-06-15|||[HUGE] Refactoring tokenizers backend - padding - truncation - pre-tokenized pipeline - fast tokenizers - tests (#4510)
2020-06-15|||Make DataCollator a callable (#5015)
2020-06-14|||BartTokenizerFast (#4878)
2020-06-13|||BartForQuestionAnswering (#4908)
2020-06-12|||Add AlbertForMultipleChoice (#4959)
2020-06-12|||[AutoModel] Split AutoModelWithLMHead into clm, mlm, encoder-decoder (#4933)
2020-06-11|||ElectraForQuestionAnswering (#4913)
2020-06-09|||[Benchmark] add tpu and torchscipt for benchmark (#4850)
2020-06-08|||Add XLMRobertaForQuestionAnswering (#4855)
2020-06-08|||Expose classes used in documentation (#4808)
2020-06-07|||Export PretrainedBartModel from __init__ (#4819)
2020-06-05|||Tensorflow improvements (#4530)
2020-06-04|||Introduce a new tensor type for return_tensors on tokenizer for NumPy (#4585)
2020-06-02|||Release: v2.11.0
2020-06-02|||Kill model archive maps (#4636)
2020-05-29|||[Longformer] Multiple choice for longformer (#4645)
2020-05-28|||LongformerForTokenClassification (#4638)
2020-05-27|||[Benchmark] Memory benchmark utils (#4198)
2020-05-28|||LongformerForSequenceClassification (#4580)
2020-05-26|||LongformerTokenizerFast (#4547)
2020-05-25|||Longformer for question answering (#4500)
2020-05-22|||Release: v2.10.0
2020-05-22|||added functionality for electra classification head (#4257)
2020-05-19|||Longformer (#4352)
2020-05-13|||Release: v2.9.1
2020-05-12|||Add MultipleChoice to TFTrainer [WIP] (#4270)
2020-05-10|||[Marian] documentation and AutoModel support (#4152)
2020-05-07|||Add AlbertForPreTraining and TFAlbertForPreTraining models. (#4057)
2020-05-07|||Release: v2.9.0
2020-05-07|||Reformer (#3351)
2020-05-06|||TF version of the trainer (#4017)
2020-05-07|||Include ElectraPreTrainedModel into __init__ (#4173)
2020-04-28|||MarianMTModel.from_pretrained('Helsinki-NLP/opus-marian-en-de') (#3908)
2020-04-28|||Clean Encoder-Decoder models with Bart/T5-like API and add generate possibility (#3383)
2020-04-22|||Pipeline for Text Generation: GenerationPipeline (#3758)
2020-04-21|||Trainer (#3800)
2020-04-17|||Question Answering support for Albert and Roberta in TF (#3812)
2020-04-10|||[examples] Generate argparsers from type hints on dataclasses (#3669)
2020-04-10|||Multilingual BART - (#3602)
2020-04-06|||Release: v2.8.0
2020-04-03|||ELECTRA (#3257)
2020-03-30|||Release: v2.7.0
2020-03-26|||Add missing token classification for XLM (#3277)
2020-03-26|||Adds translation pipeline (#3419)
2020-03-24|||Expose missing mappings (see #3415)
2020-03-24|||Release: v2.6.0
2020-03-23|||[examples] Use AutoModels in more examples
2020-03-20|||Clean special token init in modeling_....py (#3264)
2020-03-19|||Support T5 Generation (#3228)
2020-03-19|||Export ALBERT main layer in TensorFlow (#3354)
2020-03-18|||Adding LM Head to Transfo-XL and first step to fixing problem with Adaptive Embeddings in TransfoXL (#3286)
2020-03-17|||Add Summarization to Pipelines (#3128)
2020-03-17|||CPU/GPU memory benchmarking utilities - Remove support for python 3.5 (now only 3.6+) (#3186)
2020-03-16|||add camembert for Question answering for examples
2020-03-16|||Add TF2 version of FlauBERT (#2700)
2020-03-05|||Rename BartForMaskedLM -> BartForConditionalGeneration (#3114)
2020-03-03|||Add generate() functionality to TF 2.0 (#3063)
2020-02-27|||NER support for Albert in run_ner.py and NerPipeline (#2983)
2020-02-26|||Delete all mentions of Model2Model (#3019)
2020-02-24|||Release: v2.5.1
2020-02-23|||* Added support for Albert when fine-tuning for NER
2020-02-21|||Added CamembertForQuestionAnswering (#2746)
2020-02-20|||New BartModel (#2745)
2020-02-19|||Release: v2.5.0
2020-02-19|||Integrate fast tokenizers library inside transformers (#2674)
2020-02-13|||[pipeline] Alias NerPipeline as TokenClassificationPipeline
2020-01-31|||Patch: v2.4.1
2020-01-31|||Release: v2.4.0
2020-01-30|||fill_mask helper (#2576)
2020-01-15|||Add Flaubert
2020-01-07|||Apply quality and style requirements once again
2020-01-07|||Apply quality and style requirements
2020-01-07|||Add TF2 CamemBERT model
2020-01-08|||Apply style
2020-01-08|||Add TF2 XLM-RoBERTa model
2020-01-24|||Add AutoModelForPreTraining
2019-12-24|||BertTokenizerFast
2019-12-24|||GPT2TokenizerFast
2019-12-22|||Move source code inside a src subdirectory.