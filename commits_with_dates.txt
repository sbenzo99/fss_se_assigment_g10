2025-11-12|||[models] Add AudioFlamingo3 integration (#40290)
2025-11-12|||handle inputs from Siglip/Siglip2 non-automapped encoder layers (#41930)
2025-11-12|||feat(kernels): add opt-out flag to disable kernels hub usage through the lib (#41990)
2025-11-12|||update torchao doc (#42139)
2025-11-12|||add rmsnorm kernels support for npu (#42106)
2025-11-12|||fix test failure of speculative_generation on xpu (#42052)
2025-11-12|||Fixes Flash Attention implementation for models  (#42149)
2025-11-12|||fix failure of tests/models/shieldgemma2/test_modeling_shieldgemma2.p‚Ä¶ (#42022)
2025-11-12|||extend test_beam_search_early_stop_heuristic case to other device (#42078)
2025-11-12|||add xpu to valid hardware for torch.compile (#42079)
2025-11-12|||fix: improve visibility of ValueError root causes in model config loading (#41972)
2025-11-11|||T5 migration to new masking interface (#41804)
2025-11-11|||[`T5Gemma`] Fix cross attention cache (#41890)
2025-11-11|||:rotating_light: Fix gradient checkpointing for several models and improve test robustness   (#41818)
2025-11-11|||Fix logic error in `prepare_inputs_for_generation` cache slicing condition (#41764)
2025-11-11|||Add dinov3 autobackbone (#41276)
2025-11-11|||Enforce check_auto_docstring (#41635)
2025-11-11|||Avoid mutating user-provided arguments in preprocessing utils (#42126)
2025-11-11|||Bugfix/remove emojis from print (#42091)
2025-11-11|||DataCollatorForLanguageModeling warning error fixed (#42144)
2025-11-11|||Fix T5Gemma module structure (#42145)
2025-11-11|||fix: improve video processing fps assignment logic (#42009)
2025-11-11|||update deps table (#42120)
2025-11-10|||Remove unused functions in `image_transforms.py` (#42044)
2025-11-10|||Fix MaskFormer/Mask2Former fast image processors (#41393)
2025-11-10|||Fix model name test for compressed tensors  (#42128)
2025-11-10|||Fix GPT-2 Flash Attention 2 generation with left-padding (#41966)
2025-11-10|||[`Attn Masks`] Non-vmap default for attention masks (#41852)
2025-11-10|||fix qwen2vl/qwen3vl video processor temporal padding when num_frames%temporal_patch_size!=1 (#42083)
2025-11-10|||üìù docs(smolvlm): fix variable name in batch inference example (#42123)
2025-11-10|||fix continuous batching issues, extend ut cases to xpu (#41830)
2025-11-10|||Fix base model prefix in VLMs (#42059)
2025-11-10|||[Bugfix] fix qwen3vl expand generation with video (#42089)
2025-11-10|||Correctly handle unbatched audio inputs in Gemma3nAudioFeatureExtractor (#42076)
2025-11-10|||Fix return metadata checking logic (#42108)
2025-11-08|||Revert "permissions worflows fix" (#42110)
2025-11-08|||add xpu support in test_modeling_janus.py::JanusIntegrationTest::test‚Ä¶ (#41986)
2025-11-07|||[v5] üö®Refactor subprocessors handling in processors (#41633)
2025-11-07|||Reinstate self.scaling in Gemma3nTextAttention (#41751)
2025-11-08|||Fix Auto classes to support dynamically registered processors (#41865)
2025-11-07|||Fix modular docstring for Mixtral (#42041)
2025-11-07|||feat(ci): add continuous batching to benchmarks (#41916)
2025-11-07|||4.1V Model and GLM-4.5V Model Conversion Code Updates (#41784)
2025-11-07|||permissions worflows fix (#42080)
2025-11-07|||QwenVL: add skipped keys in `setattr` as well (#41808)
2025-11-06|||Fix inconsistency of commit sha during the workflow run (#42074)
2025-11-06|||Fix security issue 5 (#42072)
2025-11-06|||add workflow to check permissions and advise a set of permissions req‚Ä¶ (#42071)
2025-11-06|||fix tensor device placement issue of 2 UT cases (#41921)
2025-11-06|||Fix logic in setting self.fsdp when it is False (#41974)
2025-11-06|||[deepspeed tests fixes] (#41925)
2025-11-06|||Fix missing arg in check_docstring (#42054)
2025-11-06|||Revert back to use GitHub context  (#42066)
2025-11-06|||Fix KeyError in _is_package_available for packages with dotted names (#42050)
2025-11-06|||Fix KeyError in GPT-OSS weight conversion script (#42007)
2025-11-06|||Fix another `Argument list too long` in `pr_slow_ci_suggestion.yml` (#42061)
2025-11-06|||Be careful at explicit checkout actions (#42060)
2025-11-05|||Fix transformers serve following chat template output update
2025-11-06|||Annoying typo in attention error message (#42037)
2025-11-06|||Avoid explicit checkout in workflow (#42057)
2025-11-06|||Fix Qwen3-Omni RoPE (#41778)
2025-11-06|||Fix AutoImageProcessor.register and documentation in auto processing modules (#41864)
2025-11-05|||Fix `pr_slow_ci_suggestion.yml` after #42023 (#42049)
2025-11-05|||Cleanup workflow - part 1 (#42023)
2025-11-05|||Remove some custom datasets defined in codebase (#41511)
2025-11-05|||update `huggingface_hub` dependency version (#42033)
2025-11-05|||üî¥  Isolate prefill from generation loops (#40652)
2025-11-05|||Fix the order of methods in processor loading (#42031)
2025-11-05|||Change trigger time for AMD CI (#42034)
2025-11-05|||extend fp_quant cases to xpu (#41833)
2025-11-05|||[tests] Add Context-parallel CI tests (#41860)
2025-11-05|||CodeQL workflow for security analysis (#42015)
2025-11-05|||fix `deeepspeed` in AMD docker file (#42025)
2025-11-04|||[FPQuant] MXFP8 and MXFP4 backwards support (#41897)
2025-11-04|||[v5] Deprecate Text2Text and related pipelines (#41996)
2025-11-04|||[kernels] Fix XPU layernorm kernel (#41583)
2025-11-04|||add fuyu fast image processors (#41817)
2025-11-04|||Add GLPNImageProcessorFast  (#41725)
2025-11-05|||Fix default image_rows and image_cols initialization in Idefics3 and SmolVLM processors (#41871)
2025-11-04|||Fix issue with from pretrained and kwargs in image processors (#41997)
2025-11-04|||add back `logging_dir` (#42013)
2025-11-04|||Fix continuous batching tests (#42012)
2025-11-04|||Reduce the number of benchmark in the CI (#42008)
2025-11-04|||Correct syntax error in trainer.md (#42001)
2025-11-04|||Fix `torch+deepspeed` docker file (#41985)
2025-11-04|||DOC Fix typo in argument name: pseudoquant (#41994)
2025-11-04|||[kernels] change import time in KernelConfig (#42004)
2025-11-04|||Fix `run slow v2`: empty report when there is only one model (#42002)
2025-11-04|||Fixed wrong padding value in OWLv2 (#41938)
2025-11-03|||Integrate colqwen2.5 using colqwen2 modelling code (#40600)
2025-11-04|||fix 3 failed test cases for video_llama_3 model on Intel XPU (#41931)
2025-11-03|||fix (CI): Refactor SSH runners (#41991)
2025-11-03|||More data in benchmarking (#41848)
2025-11-03|||Move the Mi355 to regular docker (#41989)
2025-11-03|||[kernels]¬†Add Tests & CI for kernels (#41765)
2025-11-03|||Fix `torchcodec` version in quantization docker file (#41988)
2025-11-03|||docs: add continuous batching page (#41847)
2025-11-03|||fix: dict[RopeParameters] to dict[str, RopeParameters] (#41963)
2025-11-03|||test tensor parallel: make tests for dense model more robust (#41968)
2025-11-03|||Use indices as position_ids in modernebert (#41789)
2025-11-02|||add support for saving encoder only so any parakeet model can be loaded for inference (#41969)
2025-11-02|||Fix `autoawq[kernels]` installation in quantization docker file (#41978)
2025-11-02|||Fix `detectron2` installation in docker files (#41975)
2025-11-01|||Run slow v2 (#41914)
2025-10-31|||Fix typo in image_processing_lfm2_vl_fast (#41940)
2025-10-31|||make recurrent_gemma and voxtral cases pass on xpu (#41958)
2025-10-31|||[v5] Return a BatchEncoding dict from apply_chat_template by default (#41626)
2025-10-31|||V4.57.1 training ci: Refactor `test_tensor_parallel.py` (#41918)
2025-10-31|||Fix: prevent .gitignore truncation in run_clm_no_trainer.py (#41957)
2025-10-31|||fix prepare_config_and_inputs_for_common bug in llava test (#41942)
2025-10-30|||Fix: Gemma3TextConfig rope scaling assignments (#41934)
2025-10-30|||Fix rope_parameters for gemma3 weights conversion script (#41922)
2025-10-30|||fix some ut failures on XPU w/ torch 2.9 (#41941)
2025-10-30|||Minor fix in docker image build workflow (#41949)
2025-10-29|||Cache latest pytorch amd image locally on mi325 CI runner cluster (#41926)
2025-10-29|||fix some ut failures on XPU w/ torch 2.9 (#41923)
2025-10-29|||Update some workflow files (#41892)
2025-10-29|||Fix Florence2 conversion script model_type KeyError (#41866)
2025-10-29|||Allow parse_response to accept token IDs (#41849)
2025-10-29|||Fix invalid examples in QwenVL model docstrings and add Qwen3VL example (#41812)
2025-10-29|||Add 6 huggingface notebooks on AMD dev cloud (#41883)
2025-10-29|||evaluate>=0.4.6 is needed (#41920)
2025-10-29|||speed up loading checkpoints for zero stage 3 (#41850)
2025-10-28|||Fix: avoid duplicate token in maybe_load_adapters (#41903)
2025-10-28|||make lfm2_moe integration test pass on XPU (#41796)
2025-10-27|||revert changes in _is_package_available (#41891)
2025-10-27|||Fix installation cmds in docs (#41887)
2025-10-27|||Fix torch.no_grad decorator in VLMS (#41888)
2025-06-06|||Adds Universal Intelligence to awesome transformers documentation
2025-10-25|||CI workflow for Flash Attn (#41857)
2025-10-24|||:rotating_light: [`Clip`] Fix masking and enable flash attention on all model types (#41750)
2025-10-24|||Fix TypeError: find_adapter_config_file() got an unexpected keyword argument '_adapter_model_path' (#41604)
2025-10-24|||Share embedding modules in BART, not only weights (#41821)
2025-10-24|||Fix const parsing for dict inputs in chat schemas (#41824)
2025-10-24|||Fix Qwen2Audio flash attention mask format for generation (#41843)
2025-10-24|||Fix MXFP4 quantizer to support variable num_local_experts and hidden_size (#41795)
2025-10-24|||Remove redundant code from Qwen3VLProcessor (#41836)
2025-10-24|||further reducing flakiness in `utils/check_bad_commit.py` (#41658)  (#41815)
2025-10-24|||extend 2 blip2 and falcon_h1 test cases to xpu (#41825)
2025-10-24|||extend 2 trainer test cases to xpu (#41829)
2025-10-24|||extend bitnet cases to xpu, all 8 cases pass (#41831)
2025-10-24|||unpin torch/torchcodec for CircleCI (#41839)
2025-10-23|||[Parakeet] add output_attention_mask (#41694)
2025-10-23|||transformers serve quantization docs + some api fixes for bitsandbytes (#41253)
2025-10-23|||Deprecate warmup_ratio (#41326)
2025-10-23|||transformers cli default flag fix (#41761)
2025-10-23|||Fixed some grammar mistakes (#41802)
2025-10-23|||Fixed grammar mistakes (#41799)
2025-10-23|||[Trainer] remove env vars  (#41697)
2025-10-23|||Fix Qwen3Next dtype API usage (#41735)
2025-10-23|||Add a safeguard around a flaky test in gemma2 (#41811)
2025-10-23|||make apollo test case pass (#41805)
2025-10-23|||Bump AMD docker (#41792)
2025-10-23|||flash attn pytest marker (#41781)
2025-10-23|||[`Onnx docs`] Remove some traces (#41791)
2025-10-23|||[quantization] fix torchao tests after 0.14.0 release (#41777)
2025-10-22|||Fix attention mask in mamba layers (#41790)
2025-10-22|||Fix chat schema tests (#41793)
2025-10-22|||fix type annotation typo in docstring (#41788)
2025-10-22|||Swap columns and rows of the grid layout in LFM2-VL (#41755)
2025-10-22|||[quantization] Skip Fp8 tests when hardware capability < 8.9 (#41785)
2025-10-22|||[quantization] fix compressed_tensors tests (#41780)
2025-10-22|||[v5] Delete legacy chat template saving (#41648)
2025-10-22|||fix: Gemma 3 weights conversion vision and multimodal projector paths (#41767)
2025-10-22|||Fix CUDA index out of bounds for q_idx in VLM token type masking for Gemma3, PaliGemma, and example modular (#41757)
2025-10-22|||Remove invalid `@staticmethod` from module-level get_device_and_memory_breakdown (#41747)
2025-10-22|||Fix bark after #41445 (#41645)
2025-10-22|||Add LightGlue fast image processor (#41670)
2025-10-21|||Chat response parsing (#40894)
2025-10-21|||Simplify pipeline padding logic (#41667)
2025-10-21|||Modernize CLIP modeling code  (#41546)
2025-10-21|||[v5] Remove deprecated tranformers.onnx (#41700)
2025-10-21|||Update type hints in modeling_rope_utils.py to use | syntax (#41714)
2025-10-21|||Fix graphormer model compilation with Cython 3.1.4 (#41671)
2025-10-21|||Reduce warning noise caused by Tensor.new_tensor (#41748)
2025-10-21|||[kernels] Add version to function mapping (#41685)
2025-10-21|||Fixed incorrect model_type for qwen2vl and qwen2.5vl when config is saved and loaded again (#41758)
2025-10-21|||[v5] Delete `videos` from image processing classes  (#41607)
2025-10-21|||upgrade xpu docker file to torch 2.8 (#41551)
2025-10-20|||Add vision contribution guide (#41456)
2025-10-20|||Docs(zh-hans): Refine wording for professionalism in README (#40943)
2025-10-20|||Small Fix for imports  (#41411)
2025-10-20|||Apply RUFF PIE rules (#41727)
2025-10-20|||Fix documentation issues (#41726)
2025-10-20|||Update type hints in tokenization_utils.py to use | syntax (#41713)
2025-10-20|||[doc] remove broken notebooks on AMD Dev Cloud (#41743)
2025-10-20|||Revert "Remove upper version bound of pandas" (#41744)
2025-10-20|||Fix typo in LFM-VL (#41742)
2025-10-20|||Fix Qwen3-Omni inference when mixing video and image inputs in one batch (#41741)
2025-10-20|||Gemma3 conversion script maintenance (#41704)
2025-10-20|||feat: add benchmark v2 ci with results pushed to dataset (#41672)
2025-10-17|||further improve `utils/check_bad_commit.py` (#41658) (#41690)
2025-10-17|||Update `run_name` docs in TrainingArguments (#41705)
2025-10-17|||pin torchcodec on CI docker image (#41703)
2025-10-18|||üåê [i18n-KO] Translated gemma3n.md to Korean (#40873)
2025-10-17|||[docs] Manual tp-plan (#41674)
2025-10-17|||Simplify GQA conditions in sdpa_attention.py (#41699)
2025-10-17|||[`Attn`] Allow dynamic causality in SDPA via Kwargs (#41692)
2025-10-17|||Remove upper version bound of pandas (#41677)
2025-10-17|||Enable  FURB rules in ruff (#41395)
2025-10-17|||Remove skipped tests without parents (#41691)
2025-10-17|||üö® Remove torch.fx support (#41683)
2025-10-17|||Fix Pylint warnings (#41644)
2025-10-17|||Enable faiss-cpu on Windows (#41678)
2025-10-17|||üö® [v5] Refactor RoPE for layer types (#39847)
2025-10-17|||Use | for Optional and Union typing  (#41675)
2025-10-17|||Fix MarkDown syntax (#41676)
2025-10-17|||üö® Remove torchscript support (#41688)
2025-10-17|||path validation for security reason (#41256)
2025-10-17|||Remove  require_torch_bf16_gpu (#40979)
2025-10-17|||Remove deprecated `use_auth_token` parameter (#41666)
2025-10-17|||torch 2.9 still don't ‚ù§Ô∏è torchcodec 0.8 üíî (#41686)
2025-10-17|||Fix ckpt in docs (#41659)
2025-10-16|||Adding superglue fast image processing (#41394)
2025-10-17|||:globe_with_meridians: [i18n-KO] Translated `ko-LFM2.md` to Korean (#41502)
2025-10-17|||üåê [i18n-KO] Translated llama4.md to Korean (#40396)
2025-10-17|||üåê [i18n-KO] Translated `code_llama.md` to Korean (#40558)
2025-10-17|||[i18n-KO] Translated `big_bird.md` to Korean (#40445)
2025-10-17|||üåê [i18n-KO] Translated sam_hq.md to Korean (#41340)
2025-10-17|||üåê [i18n-KO] Translated `chat_extras.md` to Korean (#39863)
2025-10-16|||[Trainer] [Breaking change] `use_cache` default to `False` (#41585)
2025-10-16|||Erroring when KernelConfig is passed without use_kernels = True (#41657)
2025-10-16|||improve `utils/check_bad_commit.py` (#41658)
2025-10-16|||Improve package version check (#41661)
2025-10-16|||Small changes to benchmarking script (#41662)
2025-10-16|||Fix serving continuous batching (#41624)
2025-10-16|||Fix dtype casting with quantization (#41665)
2025-10-16|||Add in-out modalities as class attribute per model (#41366)
2025-10-16|||Switch to CB if cache_implementation == paged (#41655)
2025-10-16|||Use | for Optional and Union typing (#41646)
2025-10-16|||[`Masks`] Fix mask handling in eager for vision models (#41625)
2025-10-16|||purge HF_HUB_ENABLE_HF_TRANSFER; promote Xet (#41656)
2025-10-16|||[Fix] Deepseek V3 expert bias routing (#41647)
2025-10-16|||[kernels] refactor function kernel calling (#41577)
2025-10-16|||Double router compute? (#41653)
2025-10-16|||Fix confusing cls assignment (#41642)
2025-10-16|||Fix typos in documentation (#41641)
2025-10-16|||Format MarkDown documentation and tiny fixes (#41638)
2025-10-16|||Fix EncoderDecoder cache (#41612)
2025-10-16|||Adjust device logging level and add minor fixes (#41636)
2025-10-16|||Fix fp32_ln for various models (#41605)
2025-10-16|||[CI] Build translated docs (#41632)
2025-10-16|||[`Ernie 4.5 Moe`] Fix Moe and offloading (#41385)
2025-10-16|||[`Executorch`] Simplify for encoder models (#41627)
2025-10-16|||fix check inputs for text2text pipeline (#41556)
2025-10-16|||Fix FP-Quant quantization fallback CPU dispatch. (#41619)
2025-10-16|||Migrate transformers cli to Typer (#41487)
2025-10-16|||Add missing dates to docs (#41576)
2025-10-16|||Remove randomly added script (#41650)
2025-10-16|||Fix tokenization test (#41649)
2025-10-16|||Allow passing `tp_plan` in `from_pretrained` directly (#41435)
2025-10-16|||Add aux loss for GLM-4.5V (#41564)
2025-10-16|||üö® [v5] Toggle the serialization format in processors (#41474)
2025-10-15|||Add Backbone API fine-tuning tutorial (#41590)
2025-10-15|||Update executorch.md (#41582)
2025-10-15|||[docs] Duplicate entry (#41591)
2025-10-15|||Fix quantization base class  (#41613)
2025-10-15|||Remove deprecated code (#41616)
2025-10-15|||Remove the head masking block in some vision models (#41620)
2025-10-15|||[chat template] update when "push_to_hub" (#39815)
2025-10-15|||Fix video processing channel format (#41603)
2025-10-15|||enable sdpa enable gqa logic for Ascend NPU (#41601)
2025-10-15|||Add fast path for bidirectional mask creation to fix regression (#41586)
2025-10-15|||Update a dataset reop link (#41618)
2025-10-15|||Reinstate early CUDA init fix (#41617)
2025-10-15|||torch 2.9 don't ‚ù§Ô∏è torchcodec üíî  (#41610)
2025-10-15|||More markdown file fixes (#41599)
2025-10-15|||Fix trainer simple tests (#41449)
2025-10-15|||Import `expand_device_map` instead of redefining it (#41608)
2025-10-15|||[`Docs`] Fix changed references (#41614)
2025-10-15|||Update issue template  (#41573)
2025-10-15|||remove ray_scope and check_quantized_param (#41587)
2025-10-15|||fix some case failures lead by "`torch.compile` recompiled part of th‚Ä¶ (#41558)
2025-10-15|||Add `logits_to_keep` to many older CausalLM models (#41335)
2025-10-15|||[device_map] Accelerate loading by computing device_map much faster (#41548)
2025-10-15|||Enable non-streaming mode in `transformers serve` (#41446)
2025-10-14|||Benchmark overhaul (#41408)
2025-10-14|||Gemma3 fixes (#41572)
2025-10-14|||Fix typsetting and content of llm_tutorial_optimization.md (#41172)
2025-10-14|||Revert some breaking changes bnb (#41581)
2025-10-14|||Add __iter__ to DynamicCache (#41569)
2025-10-14|||[VisionEncoderDecoderModel] Update loss function (#40863)
2025-10-14|||Revert "add rmsnorm kernels support for Intel XPU" (#41579)
2025-10-14|||add rmsnorm kernels support for Intel XPU (#41563)
2025-10-14|||Add conditional checks to _check_and_adjust_attn_implementation() (#41542)
2025-10-14|||Add DINOv3Backbone for ConvNext variant (#40651)
2025-10-14|||delete some tokenizer tests using pickle (#41514)
2025-10-14|||[kernels] rm mra kernels (#41507)
2025-10-14|||[Qwen3VLMoe] Fixed: Expected self.dtype to be equal to src.dtype - routing_weights casting (#41420)
2025-10-14|||Fix an import error with PreTrainModel (#41571)
2025-10-14|||Patch MistralCommonTokenizer (#41439)
2025-10-14|||[Qwen3VL] fix device mismatch error for FSDP2 training (#41536)
2025-10-13|||Remove references to AutoModelForVision2Seq (#41513)
2025-10-13|||[`from_pretrained`] Small refactor `from_pretrained`: move around unrelated stuff (#41445)
2025-10-13|||[model] Add VideoLLaMA3 implementation (#40499)
2025-10-13|||Add VideoMAE video processor  (#41534)
2025-10-13|||Fixed typos and formatting (#34215)
2025-10-13|||üö® [v5] `generate` delegates default cache initialization to the model (#41505)
2025-10-13|||Enable modular files from other libraries (#41372)
2025-10-13|||Add AMD developer cloud support (#41126)
2025-10-13|||Restore cuda graphs to continuous batching (#41421)
2025-10-13|||[SAM] Fix typing hints  (#41506)
2025-10-13|||Fixed Type-hints in function defintions (#41525)
2025-10-13|||Add MLlama fast image processor (#41391)
2025-10-13|||[Qwen3VL] fix: hidden_states in place modification error (#41535)
2025-10-10|||[testing] reduce runtime of `HunYuanMoEV1IntegrationTest:test_model_generation` (#41373)
2025-10-10|||Fix Latex typesetting in documentation (#41177)
2025-10-10|||Allow optuna's catch kwargs passthrough (#41496)
2025-10-10|||remove `tpu_num_cores` (#41383)
2025-10-10|||Remove outdated flags (#41512)
2025-10-10|||add Trainer import to .md in appropriate cell block for training.ipynb transformers_doc (#41484)
2025-10-10|||Fix detectron2 import (#41510)
2025-10-10|||Revert `local_rank` deletion and some cleaning (#41504)
2025-10-10|||Bump to hfh 1.0.0.rc5 to fix test (#41508)
2025-10-10|||More trainer cleaning  (#41489)
2025-10-10|||[QoL] modular conversion shows LoC saved (#41500)
2025-10-10|||Set `truncation` to `False` in Qwen3Omni to avoid default truncation (#41473)
2025-10-10|||[voxtral] language detection + skipping lang:xx (#41225)
2025-10-10|||fix gemma3n case failure (#41426)
2025-10-10|||Fix some tests (#41503)
2025-10-10|||[causallm tester] automate pipeline mappings + bloom tests (#41318)
2025-10-10|||[Parakeet] unnecessary warning & auto mapping (#41412)
2025-10-10|||Fixed tiny incorrect imports in `glm4v` (#41483)
2025-10-10|||Try to remove `pickle` - `BloomTokenizerFast` (#41466)
2025-10-10|||[kernels] rm yoso kernel (#41495)
2025-10-10|||[kernels] Remove RWKV kernel finally ! (#41493)
2025-10-10|||fix bnb model loading (#41499)
2025-10-10|||Streaming should be handled at the request-level rather than at the istance level (#41444)
2025-10-10|||Remove DISABLE_KERNEL_MAPPING flag (#41475)
2025-10-10|||Update philosophy (#41438)
2025-10-09|||Remove `local_rank` arg from `TrainingArguments` (#41382)
2025-10-09|||deprecate `jit_mode_eval` (#41376)
2025-10-09|||[Trainer] deprecate ray scope (#41403)
2025-10-09|||[`CI`] Fix copies on main (#41486)
2025-10-09|||deprecate `overwrite_output_dir` (#41323)
2025-10-09|||`report_to` default changed to "none" + cleaning deprecated env var (#41375)
2025-10-10|||Update GLM-4.6 doc (#41471)
2025-10-09|||Remove deprecated args in Trainer for v5 (#41404)
2025-10-09|||Remove `past_index` (#41384)
2025-10-09|||Remove SigOpt (#41479)
2025-10-09|||Fix bnb fsdp loading for pre-quantized checkpoint (#41415)
2025-10-09|||RT-Detr correct 2d positional embeddings for non-square images (#41380)
2025-10-09|||Add Code World Model (CWM) (#41199)
2025-10-09|||enhance patched_tearDown to support python 3.11+ (#41429)
2025-10-09|||[Fix] Fix test file error (#40973)
2025-10-09|||:rotating_light: [`Attention Masks`] Bidirectional masks for encoder and encoder-decoder models (#41265)
2025-10-09|||[v5] remove load_in_4bit and load_in_8bit (#41287)
2025-10-09|||Cleaning hub kernels  (#41477)
2025-10-09|||Change RT-Detr docs to reflect fixed 640x640 input size (#41364)
2025-10-09|||Remove infer_device (#41088)
2025-10-09|||Pickle - part 2 (#41476)
2025-10-09|||Import Callable from collections.abc (#41130)
2025-10-09|||Fix tests fsdp (#41422)
2025-10-09|||Fix auto model configuration for encoder of perceptionlm (#41464)
2025-10-09|||Remove KERAS_NLP_IMPORT_ERROR (#41468)
2025-10-09|||üö® [v5] Rendundant code in nested configs (#41314)
2025-10-09|||[kernels] Cleanup deta kernel (#41470)
2025-10-09|||Update GLM-4.1V MMRope implementation (#41182)
2025-10-09|||[v5] rm `utils/tf_ops/` (#41402)
2025-10-09|||Subconfig is a class attribute (#41308)
2025-10-09|||üö® [v5] Rename left traces of `past_key_value` in BERT-like models (#41448)
2025-10-08|||Fix doc (#41457)
2025-10-08|||Fix generate outputs and simplify cache tests (#41440)
2025-10-08|||enable some falcon-mamba uts on xpu (#41428)
2025-10-08|||Update hqq.md (#41452)
2025-10-08|||Validate processing kwargs with @strict from huggingface_hub  (#40793)
2025-10-08|||Add Top-H decoding (entropy-bounded truncation) as a LogitsWarper for text generation (#40837)
2025-10-08|||[testing] Fix `JetMoeIntegrationTest` (#41377)
2025-10-08|||[`JetMoe`] Fix KV head repetition and padding free (#41423)
2025-10-08|||Remove Python 3.9 classifier (#41410)
2025-10-08|||:facepalm: CB nit!  (#41413)
2025-10-08|||[torchao] Add regex support for ModuleFqnToConfig (#41242)
2025-10-08|||enable new model uts to xpu and fix some failures on xpu (#41386)
2025-10-08|||Use accelerator API to free device memory (#41195)
2025-10-08|||Fixing comments in __init__ file (#41414)
2025-10-08|||[v5] Bump min version of bitsandbytes to 0.46.1  (#41283)
2025-10-08|||üö® [v5] Prune `prune_heads` (#41417)
2025-10-08|||üö®üö® Remove all traces of legacy cache format (#41378)
2025-10-08|||Tiny Cleanup - Removed duplicate class field definition's (#41293)
2025-10-08|||v5 dev version (#41436)
2025-10-07|||Fix overriding common_kwargs defaults in processor calls (#41381)
2025-10-07|||Remove deprecation warning (#41425)
2025-10-07|||[v5] Delete left traces of feature extractor (#41321)
2025-10-07|||Fix incorrect assignment in `update_device_map` for GPTQ quantizer (#41328)
2025-10-07|||[v5] Bump accelerate to 1.1.0  (#41234)
2025-10-07|||Fix early CUDA initialisation (#41409)
2025-10-07|||Prefer raising `TypeError` exception for invalid type (#41346)
2025-10-07|||[Model] Lfm2Moe (#41401)
2025-10-07|||Fix test for model with dotted name and relative imports (#41343)
2025-10-07|||[Cache] lfm2 cache: allocate empty kv layers during init (#41396)
2025-10-07|||[kernels] Kernel Config  (#41232)
2025-10-07|||Correct numerical regression in vision embeddings (#41374)
2025-10-07|||fix resample in asr pipeline (#41298)
2025-10-06|||fix asr ut failures (#41332)
2025-10-06|||[`v5`] Sync Bert and Bart eager attention (#41248)
2025-10-06|||Update from pretrained error when loading (#33380)
2025-10-06|||serve: add non-streaming mode to /v1/responses; stream event parity; remove placeholder logprobs (#41353)
2025-10-06|||[`CB`] Refactors the way we access paged (#41370)
2025-10-06|||Remove unused function patameters (#41358)
2025-10-06|||make some ut cases pass on xpu w/ latest torch (#41337)
2025-10-06|||Remove unnecessary list comprehension (#41305)
2025-10-06|||Fixes in check_model_inputs, GPTBigCodeModel and ImageGPTModel (#40811)
2025-10-06|||Use canonical get_size_with_aspect_ratio (with max_size) from transformers.image_transforms to fix #37939 (#41284)
2025-10-06|||Fix flash_attention.py: wrong argument passing for attn_implementation (#41347)
2025-10-06|||[testing] update `test_longcat_generation_cpu` (#41368)
2025-10-06|||üö® Remove BetterTransformer (#41367)
2025-10-06|||Better typehints for `apply_chat_template` (#41355)
2025-10-06|||Fix typo in model proposal template (#41352)
2025-10-06|||:rotating_light: [`v5`] Remove relative position embeddings (for bert like models) (#41170)
2025-10-06|||Fixing a typo for BLT model (#41325)
2025-10-06|||[`ModularChecker`] QOL for the modular checker (#41361)
2025-10-06|||Check model inputs - hidden states (#40994)
2025-10-06|||Fix trainer for py3.9 (#41359)
2025-10-06|||Standardize `PretrainedConfig` to `PreTrainedConfig` (#41300)
2025-10-06|||üö® Bump to Python 3.10 and rework how we check 3rd-party libraries existence (#41268)
2025-10-06|||Rope for Qwen2--5-vl (#41173)
2025-10-06|||Fixed tiny incorrect import in `gemma3` (#41354)
2025-10-04|||`JetMoe` Fix jetmoe after #40132 (#41324)
2025-10-03|||Fix lr_scheduler_parsing (#41322)
2025-10-03|||Fix jamba (#41309)
2025-10-03|||Security/fuyu (#41320)
2025-10-03|||AutoAWQ tests  (#41295)
2025-10-03|||üö® [unbloating] unify `TypedDict` usage in processing (#40931)
2025-10-03|||Minor security fix for `ssh-runner.yml` (#41317)
2025-10-03|||Add modular detector (#41289)
2025-10-03|||download and use HF Hub Cache (#41181)
2025-10-03|||Fix README.md error when installing from source (#41303)
2025-10-03|||Italian translation for README.md (#41269)
2025-10-02|||FIX: Bug in PEFT integration delete_adapter method (#41252)
2025-10-02|||:rotating_light: [`DistilBert`] Refactor Attention (#41163)
2025-10-02|||[`Flex Attn`] Fix lse x attention sinks logic   (#41249)
2025-10-02|||Fix mxfp4 dequantization (#41292)
2025-10-02|||üö® [V5] Remove deprecated `resume_download` (#41122)
2025-10-02|||Build doc in 2 jobs: `en` and `other languages` (#41290)
2025-10-02|||Remove some previous team members from allow list of triggering Github Actions (#41263)
2025-10-02|||Fix - remove deprecated args checking in deepspeed intergrations (#41282)
2025-10-02|||Remove `test_initialization` (#41261)
2025-10-02|||[docs] remove references to recently deleted classes in non-`en` docs (onnx, feature processors) (#41286)
2025-10-02|||Add processor and intergration test for qwen3vl (#41277)
2025-10-02|||feat: use `aws-highcpu-32-priv` for amd docker img build (#41285)
2025-10-02||| Fix pylint generator warnings (#41258)
2025-10-02|||Fix unnecessary single-item container checks (#41279)
2025-10-02|||Biogptlogits (#41270)
2025-10-02|||Use max/min (#41280)
2025-10-02|||Unify is_torchvision_v2_available with is_torchvision_available (#41259)
2025-10-02|||fix async client for transformers chat (#41255)
2025-10-02|||üö® [v5] remove deprecated `generate` classes (constraints and beam scorers) (#41223)
2025-10-02|||Allow private Space id for Trackio (#40948)
2025-10-02|||Deprecate Trackio environment variables and deploy to Spaces by default (#40950)
2025-10-02|||MoE + vllm = üòª  (#40132)
2025-10-02|||Fix binding of video frames to video placeholder in `InternVL` model (#41237)
2025-10-02|||Remove SageMakerTrainer (#41267)
2025-10-02|||Fix multi-video timestamp bug in Qwen-3-VL and GLM4V (#41229)
2025-10-02|||Use regex defailed flags (#41264)
2025-10-02|||fix asr pipeline ut failures (#41275)
2025-10-02|||add more activation kernels, follow up  (#40944)
2025-10-01|||docs: update bitsandbytes platform support (#41266)
2025-10-01|||add peft team members to issue/pr template (#41262)
2025-10-01|||Resolve remote custom module path warnings (#41243)
2025-10-01|||Don't convert to `safetensors` on the fly if the call is from testing (#41194)
2025-10-01|||[t5gemma] fix `get_text_config` and related fixes (#40939)
2025-10-01|||[`FA3`] Fix masking and loading logic in same process (#41217)
2025-10-01|||FP-Quant NVFP4 and Python 3.9 support (#39876)
2025-10-01|||Remove all instances of `is_safetensors_available` (#41233)
2025-10-01|||üö® [v5] Remove SinkCache (#41107)
2025-10-01|||Fix pylint warnings (#41222)
2025-10-01|||Use removeprefix and removesuffix (#41240)
2025-10-01|||[V5] Remove deprecated transformers.onnx (#41214)
2025-10-01|||[repo utils] Update `models_to_deprecate.py` (#41231)
2025-10-01|||fix TrainerIntegrationDeepSpeed UT failures (#41236)
2025-10-01|||üö® [v5] Delete feature extractors used for vision (#41174)
2025-10-01|||Use math.log2 (#41241)
2025-10-01|||Video processor accepts single frames on cuda (#41218)
2025-09-30|||fix qwen text config (#41158)
2025-10-01|||Fix white space in documentation (#41157)
2025-09-30|||[docs] Fix tp_plan (#41205)
2025-09-30|||[Trainer] deprecate `num_train_tokens` (#41165)
2025-09-30|||[v5] Remove train kwargs (#41127)
2025-09-30|||[v5] Remove deprecated prediction loop (#41123)
2025-09-30|||[v5] Remove tokenizer from Trainer (#41128)
2025-09-30|||Remove old sagemaker api support  (#41161)
2025-09-30|||[v5] More Training Args cleaning  (#41131)
2025-09-30|||Revert "Fix DeepSpeed mixed precision precedence over Accelerate defaults" (#41124)
2025-09-30|||Fix sliding window attn mask (#41228)
2025-09-30|||Fix typing of train_args (#41142)
2025-09-30|||Unify is_torchvision_v2_available with is_torchvision_available (#41227)
2025-09-30|||update code owners (#41221)
2025-09-30|||Adapt to the SDPA interface to enable the NPU to call FlashAttentionScore (#41143)
2025-09-30|||Remove old Python code (#41226)
2025-09-30|||:rotating_light: [`v5`] Remove headmasking (#41076)
2025-09-30|||[generate] cache missing custom generate file (#41216)
2025-09-30|||Align pull request template to bug report template (#41220)
2025-09-30|||[ESM] add accepts_loss_kwargs=False to EsmPreTrainedModel (#41006)
2025-09-30|||Trainer: Pass `num_items_in_batch` to `compute_loss` in `prediction_step` (#41183)
2025-09-30|||Avoid assumption that model has config attribute in deepspeed (#41207)
2025-09-30|||Wait for main process in _save_checkpoint to ensure best checkpoint exists (#40923)
2025-09-30|||Deprecate `half_precision_backend` (#41134)
2025-09-30|||Fix Qwen3-Omni audio_token_id serialization issue (#41192)
2025-09-30|||docs/examples(speech): pin CTC commands to Hub datasets; add Windows notes (#41027)
2025-09-30|||Remove unnecessary Optional typing (#41198)
2025-09-29|||[docs] Fix links (#41110)
2025-09-29|||Embed interactive timeline in docs (#41015)
2025-09-29|||Fix docker quantization (#41201)
2025-09-29|||Fix 8bit bnb loading (#41200)
2025-09-30|||Fix EXAONE-4.0 dummy id (#41089)
2025-09-29|||Add EdgeTAM (#39800)
2025-09-29|||[`Kernels Attention`] Change fallback logic to error out on explicit kernels request and include FA3 (#41010)
2025-09-29|||Make quantizers good citizens loading-wise (#41138)
2025-09-29|||Separate docker images for Nvidia and AMD in benchmarking (#41119)
2025-09-29|||Fix attention sink implementation in flex attention (#41083)
2025-09-29|||fix(trainer): Avoid moving model with device_map (#41032)
2025-09-29|||enable flex attention ut cases on XPU (#40989)
2025-09-29|||Bump hfh prerelease version (#41175)
2025-09-29|||Fix inaccurate train_tokens_per_second when resuming from checkpoint (#41156)
2025-09-29|||[v5] Remove `model_parallel` deprecated feature  (#41166)
2025-09-29|||More typing fixes (#41102)
2025-09-29|||[tests] `CausalLMTester` automatically infers other test classes from `base_model_class` üêõ üî´  (#41066)
2025-09-29|||[XPU] Add MXFP4 support for XPU (#41117)
2025-09-29|||CI Runners - move amd runners mi355 and 325 to runner group (#41193)
2025-09-29|||Modernbert fix (#41056)
2025-09-26|||handle flash slow tests (#41072)
2025-09-26|||Enable fa in amd docker (#41069)
2025-09-26|||Remove data from examples (#41168)
2025-09-26|||Fix flash-attn for paged_attention when no kernels (#41078)
2025-09-25|||Improve `add_dates` script (#41167)
2025-09-26|||Add language specifiers to code blocks of markdown files (#41114)
2025-09-25|||Force new vision models addition to include a fast image processor (#40802)
2025-09-25|||Simplify and improve model loading logic (#41103)
2025-09-25|||Fix format of compressed_tensors.md (#41155)
2025-09-25|||Add Parakeet (#39062)
2025-09-25|||extend gemma3n integration ut cases on XPU (#41071)
2025-09-25|||Fix single quotes in markdown (#41154)
2025-09-25|||Adapt and test huggingface_hub v1.0.0 (#40889)
2025-09-25|||Fix: align Qwen2.5-VL inference rope index with training by passing s‚Ä¶ (#41153)
2025-09-24|||Fix loading logic flaw with regards to unexpected and missing keys (#40850)
2025-09-24|||dummy commit (#41133)
2025-09-24|||Fixed loading LongT5 from legacy checkpoints (#40724)
2025-09-24|||Fixed MXFP4 model storage issue (#41118)
2025-09-24|||üö®Refactor: Update text2text generation pipelines to use max_new_tokens‚Ä¶ (#40928)
2025-09-24|||Remove self-assignment (#41062)
2025-09-24|||Fix broken `` expressions in markdown files (#41113)
2025-09-24|||Fix the error where a keyword argument appearing before *args (#41099)
2025-09-24|||[Qwen3-next] Fix dimension mismatch in torch_chunk_gated_delta_rule and torch_recurrent_gated_delta_rule (#40963) (#41036)
2025-09-24|||[torchao safetensors] integrate torchao safetensors support with transformers  (#40735)
2025-09-24|||Support loading LFM2 GGUF (#41111)
2025-09-24|||üö® [V5] Remove deprecated training arguments  (#41017)
2025-09-24|||Update ruff to 0.13.1 + target Python 3.10 + apply fixes (#37809)
2025-09-24|||Format empty lines and white space in markdown files. (#41100)
2025-09-23|||Remove bad test skips (#41109)
2025-09-23|||Fix `_get_test_info` for inherited tests (#41106)
2025-09-23|||[tests] gpt2 + `CausalLMModelTester` (#41003)
2025-09-23|||üö® [generate] update paligemma mask updates (and other assisted generation-related fixes) (#40917)
2025-09-23|||docs: Fix Tool Use links and remove dead RAG links (#41104)
2025-09-23|||fix wrong height and width when read video use torchvision (#41091)
2025-09-23|||Remove tf and flax from Chinese documentation (#41057)
2025-09-23|||Remove unused arguments (#40916)
2025-09-23|||Fix typing (#40788)
2025-09-23|||Fix typos in documentation (#41087)
2025-09-23|||Remove mention of TensorFlow/Flax/JAX from English documentation (#41058)
2025-09-23|||Fix argument name in benchmarking script (#41086)
2025-09-23|||Switch to `python:3.10-slim` for CircleCI docker images (#41067)
2025-09-23|||Minor addition, no split modules for VideoMAEE (#41051)
2025-09-23|||fix crash when using chat to send 2+ request to gptoss (#40536)
2025-09-23|||Update team member list for some CI workflows (#41094)
2025-09-22|||Improve documentation and errors in Mamba2-based models (#41063)
2025-09-22|||[i18n-bn] Add Bengali language README file (#40935)
2025-09-22|||Update quantization CI (#41068)
2025-09-22|||Fix CI jobs being all red üî¥ (false positive) (#41059)
2025-09-22|||Remove <frameworkcontent> and <pt> tags from documentation (#41055)
2025-09-22|||Ci utils (#40978)
2025-09-22|||Add write token for uploading benchmark results to the Hub (#41047)
2025-09-22|||Simplify unnecessary Optional typing (#40839)
2025-09-22|||Remove repeated import (#40937)
2025-09-22|||[testing] Fix `seed_oss` (#41052)
2025-09-22|||Add Whole Word Masking and Padding Strategy to DataCollatorForLanguageModeling (#39485)
2025-09-22|||Remove doc of tf and flax (#41029)
2025-09-22|||Fix outdated torch version check (#40925)
2025-09-22|||Fix condition for emitting warning when generation exceeds max model length (#40775)
2025-09-22|||docs: improved RoPE function Docstrings (#41004)
2025-09-22|||Use torch.autocast (#40975)
2025-09-22|||Fix typos in English/Chinese documentation (#41031)
2025-09-22|||Remove optax (#41030)
2025-09-22|||Fix typing of tuples (#41028)
2025-09-22|||[testing] Fix `qwen2_audio` (#41018)
2025-09-22|||Fix Qwen video tests (#41049)
2025-09-22|||Modify Qwen3Omni parameter name since VL changed it (#41045)
2025-09-22|||Making compute_loss_func always take priority in Trainer (#40632)
2025-09-21|||Adding support for Qwen3Omni (#41025)
2025-09-20|||Fix benchmark runner argument name (#41012)
2025-09-19|||Update after #41007 (#41014)
2025-09-19|||Fix Glm4v test (#41011)
2025-09-19|||Fix `PhimoeIntegrationTest` (#41007)
2025-09-19|||üö® [lightglue] fix: matches order changed because of early stopped indices (#40859)
2025-09-19|||üö® [v5] remove deprecated entry point (#40997)
2025-09-19|||Patch more `unittest.case.TestCase.assertXXX` methods (#41008)
2025-09-19|||[tests] update `test_left_padding_compatibility` (and minimize overwrites) (#40980)
2025-09-19|||üö® [v5] remove generate output retrocompatibility aliases (#40998)
2025-09-19|||fix dict like init for ModelOutput (#41002)
2025-09-19|||RUFF fix on CI scripts (#40805)
2025-09-19|||Fix more dates in model cards and wrong modalities in _toctree.yml (#40955)
2025-09-19|||Fix typoes in src and tests (#40845)
2025-09-19|||Make `EfficientLoFTRModelTest` faster (#41000)
2025-09-19|||[`RMSNorm`] Fix rms norm init for models that center around 1 (#40796)
2025-09-19|||[docs] rm stray tf/flax autodocs references (#40999)
2025-09-19|||blt wip (#38579)
2025-09-19|||[testing] test `num_hidden_layers` being small in model tester (#40992)
2025-09-19|||ENH: Enable readline support for transformers chat (#40911)
2025-09-19|||Remove [[autodoc]] refs to TF/Flax objects (#40996)
2025-09-19|||üî¥[`Attention`] Bert-based Models Attention Refactor (#38301)
2025-09-19|||Benchmarking v2 GH workflows (#40716)
2025-09-18|||Remove `set_model_tester_for_less_flaky_tests` (#40982)
2025-09-18|||üö®üö®üö® Fully remove Tensorflow and Jax support library-wide (#40760)
2025-09-18|||Track the CI (model) jobs that don't produce test output files (process being killed etc.) (#40981)
2025-09-18|||Revert change in `compile_friendly_resize` (#40645)
2025-09-18|||Add captured actual outputs to CI artifacts (#40965)
2025-09-18|||[tests] Really use small models in all fast tests (#40945)
2025-09-18|||Fix Issue #39030: AutoTokenizer.from_pretrained does not propagate token (#40956)
2025-09-18|||[timm_wrapper] better handling of "Unknown model" exception in timm (#40951)
2025-09-18|||[Trainer] Fix DP loss (#40799)
2025-09-18|||Use `skip_predictor=True` in vjepa2 `get_vision_features` (#40966)
2025-09-18|||Fix outdated version checks of accelerator (#40969)
2025-09-18|||Add new model LFM2-VL (#40624)
2025-09-18|||FIX(trainer): ensure final checkpoint is saved when resuming training (#40347)
2025-09-18|||Update expected values for one more `test_speculative_generation` after #40949 (#40967)
2025-09-18|||Don't list dropout in eager_paged_attention_forward (#40924)
2025-09-18|||Add FlexOlmo model (#40921)
2025-09-18|||Standardize audio embedding function name for audio multimodal models (#40919)
2025-09-17|||Update expected values for some `test_speculative_generation` (#40949)
2025-09-17|||Fix `Glm4vModelTest::test_eager_matches_fa2_generate` (#40947)
2025-09-17|||Remove nested import logic for torchvision (#40940)
2025-09-17|||Consistent naming for images kwargs (#40834)
2025-09-17|||Raise error instead of warning when using meta device in from_pretrained (#40942)
2025-09-17|||Fix `Glm4vMoeIntegrationTest` (#40930)
2025-09-17|||Fix trainer tests (#40823)
2025-09-17|||docs(i18n): Correct the descriptive text in the README_zh-hans.md (#40941)
2025-09-17|||Intel CPU dockerfile (#40806)
2025-09-17|||[models] remove unused `import torch.utils.checkpoint`  (#40934)
2025-09-17|||[DOC] Add missing dates in model cards (#40922)
2025-09-17|||Add LongCat-Flash (#40730)
2025-09-17|||Add support for Florence-2 training (#40914)
2025-09-17|||Minor fix for #40727 (#40929)
2025-09-17|||Adding activation kernels (#40890)
2025-09-17|||[torchao safetensors] renaming get_state_dict function (#40774)
2025-09-17|||Fix #40067: Add dedicated UMT5 support to GGUF loader (config, tokenizer, test) (#40218)
2025-09-17|||[Llama4] Remove `image_sizes` arg and deprecate `vision_feature_layer` (#40832)
2025-09-17|||Processor load with multi-processing (#40786)
2025-09-17|||[Docs] Adding documentation of MXFP4 Quantization (#40885)
2025-09-16|||Fix dtype in Paligemma (#40912)
2025-09-16|||üî¥Make `center_crop` fast equivalent to slow (#40856)
2025-09-16|||[generate] misc fixes (#40906)
2025-09-16|||[gemma3] `Gemma3ForConditionalGeneration` compatible with assisted generation (#40791)
2025-09-16|||disable `test_fast_is_faster_than_slow` (#40909)
2025-09-16|||Remove `runner_map` (#40880)
2025-09-16|||Improve module name handling for local custom code (#40809)
2025-09-16|||remove dummy EncodingFast (#40864)
2025-09-16|||Add Olmo3 model (#40778)
2025-09-16|||Set seed for `Glm4vIntegrationTest` (#40905)
2025-09-16|||[cache] Only use scalars in `get_mask_sizes` (#40907)
2025-09-16|||Harmonize CacheLayer names (#40892)
2025-09-16|||[cache] Merge static sliding and static chunked layer (#40893)
2025-09-16|||Fix flaky `Gemma3nAudioFeatureExtractionTest::test_dither` (#40902)
2025-09-16|||Fix getter  regression (#40824)
2025-09-16|||Fixing the call to kernelize (#40628)
2025-09-16|||Make debugging failing tests (check and update expect output values) easier üî•  (#40727)
2025-09-15|||[generate] remove docs of a feature that no longer exists (#40895)
2025-09-16|||üåê [i18n-KO] Translated `imageprocessor.md` to Korean (#39557)
2025-09-16|||üåê [i18n-KO] Translated smolvlm.md to Korean (#40414)
2025-09-15|||Remove dict branch of attention_mask in sdpa_attention_paged_forward (#40882)
2025-09-15|||Fix deta loading & dataclass (#40878)
2025-09-15|||Add Fast PromptDepthAnything Processor (#40602)
2025-09-15|||Use torch.expm1 and torch.log1p for better numerical results (#40860)
2025-09-15|||Clarify passing is_causal in sdpa_attention_paged_forward (#40838)
2025-09-15|||üî¥ Move variable output controls to `_prepare_generation_config ` (#40715)
2025-09-15|||Fix modular consistency (#40883)
2025-09-15|||[`VaultGemma`] Update expectations in integration tests (#40855)
2025-09-15|||Adding Support for Qwen3-VL Series (#40795)
2025-09-15|||[Qwen3 Next] Use numerically stable `rsqrt` (#40848)
2025-09-15|||Update model tags and integration references in bug report (#40881)
2025-09-15|||fix: XIELU act parameters not being casted to correct dtype (#40812)
2025-09-15|||fix florence kwargs  (#40826)
2025-09-15|||[docstrings / type hints] Update outdated annotations for `past_key_values`  (#40803)
2025-09-15|||[Bug fix #40813] Fix base_model_tp_plan of Starcoder2 model. (#40814)
2025-09-14|||Redirect MI355 CI results to dummy dataset (#40862)
2025-09-14|||Fix TrainingArguments.parallelism_config NameError with accelerate<1.10.1 (#40818)
2025-09-13|||Use checkpoint in auto_class_docstring (#40844)
2025-09-12|||[generate] Always use decoder config to init cache (#40772)
2025-09-12|||[tests] move generative tests away from `test_modeling_common.py` (#40854)
2025-09-12|||[test] Fix test_eager_matches_sdpa incorrectly skipped (#40852)
2025-09-12|||add: differential privacy research model (#40851)
2025-09-12|||[Sam2Video] Fix video inference with batched boxes and add test (#40797)
2025-09-12|||[SAM2] Fix inconsistent results with original implementation with input boxes (#40800)
2025-09-12|||[tests] re-enable aria fast tests (#40846)
2025-09-12|||Fixes for continuous batching (#40828)
2025-09-12|||Fix the misalignment between the l2norm in GDN of Qwen3-Next and the implementation in the FLA library. (#40842)
2025-09-12|||Replace image classification loss functions to `self.loss_function` (#40764)
2025-09-12|||Update no split modules in T5Gemma model (#40810)
2025-09-12|||Adds Causal Conv 1D kernel for mamba models (#40765)
2025-09-12|||Add VideoProcessors to auto-backend requirements (#40843)
2025-09-12|||Improve torch_dtype checks (#40808)
2025-09-12|||üåê [i18n-KO] Translated clipseg.md to Korean (#39903)
2025-09-11|||[`Jetmoe`] Fix RoPE (#40819)
2025-09-11|||Push generation config along with checkpoints (#40804)
2025-09-11|||add general hub test for Fast Image Processors in test_image_processing_utils (#40086)
2025-09-11|||Fix typos in src (#40782)
2025-09-11|||Align torch implementation of Gated DeltaNet in Qwen3-Next with fla library. (#40807)
2025-09-11|||‚ö†Ô∏è üî¥ Add ministral model (#40247)
2025-09-11|||Fix config dtype parsing for Emu3 edge case (#40766)
2025-09-11|||Fix edge case for tokenize (#36277) (#36555)
2025-09-11|||feature: Add robust token counting with padding exclusion  (#40416)
2025-09-11|||Fix DeepSpeed mixed precision precedence over Accelerate defaults (#39856)
2025-09-11|||[Docs] Add missing class documentation for optimizer_schedules (#31870,  #23010) (#40761)
2025-09-11|||fix_image_processing_fast_for_glm4v (#40483)
2025-09-11|||Remove use_ipex option from Trainer (#40784)
2025-09-10|||Move num_items_in_batch to correct device before accelerator.gather (#40773)
2025-09-11|||Fix the issue that csm model cannot work with pipeline mode. (#39349)
2025-09-10|||Fix dotted model names (#40745)
2025-09-10|||Read config pattern for Qwen3Next (#40792)
2025-09-10|||Use functools.cached_property (#40607)
2025-09-10|||Fix invalid PipelineParallel member (#40789)
2025-09-10|||Fix typos in tests and util (#40780)
2025-09-10|||Fix doc for PerceptionLMForConditionalGeneration forward. (#40733)
2025-09-10|||üö® Fix Inconsistant `input_feature` length and `attention_mask` length in `WhisperFeatureExtractor` (#39221)
2025-09-10|||Enable ruff on benchmark and scripts (#40634)
2025-09-10|||[processors] Unbloating simple processors (#40377)
2025-09-10|||Remove reference of video_load_backend and video_fps for processor (#40719)
2025-09-10|||Fix gpt-oss router_indices in EP (#40545)
2025-09-10|||Adding Support for Qwen3-Next (#40771)
2025-09-09|||[docs] CPU install (#40631)
2025-09-09|||[pipeline] ASR pipeline kwargs are forwared to `generate` (#40375)
2025-09-10|||Fix crash when executing MambaCache sample code (#40557)
2025-09-09|||[RoPE] run RoPE tests when the model uses RoPE (#40630)
2025-09-09|||[tests] update `test_past_key_values_format` and delete overwrites (#40701)
2025-09-09|||rm src/transformers/convert_pytorch_checkpoint_to_tf2.py (#40718)
2025-09-09|||[deprecations] Remove generate-related deprecations up to v4.56 (#40729)
2025-09-09|||Support sliding window in CB (#40688)
2025-09-09|||[generate] `PromptLookupCandidateGenerator` won't generate forbidden tokens (#40726)
2025-09-09|||Fix: swanlab `public.cloud.experiment_url` api error (#40763)
2025-09-09|||Add EfficientLoFTRImageProcessorFast for GPU-accelerated image processing (#40215)
2025-09-08|||Fix Bark failing tests (#39478)
2025-09-09|||üåê [i18n-KO] Translated 'xclip.md' to Korean (#39594)
2025-09-08|||Fix `continue_final_message` in `apply_chat_template` to prevent substring matching issues (#40732)
2025-09-08|||Fix inconsistency in SeamlessM4T and SeamlessM4Tv2 docs (#39364)
2025-09-09|||Fix more typos (#40627)
2025-09-09|||Remove unnecessary tildes from documentation (#40748)
2025-09-08|||docs: add continuous batching to serving (#40758)
2025-09-08|||feat: err when unsupported attn impl is set w/ `--continuous_batching` (#40618)
2025-09-08|||remove FSDP prefix when using save_pretrained with FSDP2 (#40207)
2025-09-08|||remove gemmas eager training warning (#40744)
2025-09-08|||Add BF16 support check for MUSA backend (#40576)
2025-09-08|||Set accepts_loss_kwargs to False for ConvNext(|V2)ForImageClassification (#40746)
2025-09-08|||Fix np array typing (#40741)
2025-09-08|||Fix order of mask functions when using `and/or_mask_function` (#40753)
2025-09-08|||[Continous Batching] fix do_Sample=True in continuous batching (#40692)
2025-09-05|||refactor(serve): move `request_id` to headers (#40722)
2025-09-05|||Skip `VitMatteImageProcessingTest::test_fast_is_faster_than_slow` (#40713)
2025-09-05|||Keypoint matching docs (#40541)
2025-09-05|||[`Gemma Embedding`] Fix SWA (#40700)
2025-09-05|||Add Optional typing (#40686)
2025-09-05|||[tests] remove overwrites of removed test (#40720)
2025-09-05|||[serve] re-enable tests (#40717)
2025-09-05|||Fix arguments (#40605)
2025-09-05|||üî¥ Update Glm4V to use config values (#40712)
2025-09-05|||Fix parent classes of AllKwargsForChatTemplate (#40685)
2025-09-05|||[onnx] use logical `or` for grounding dino mask (#40625)
2025-09-05|||[moduar] Add missing `self` in post-process methods (#40711)
2025-09-05|||[tests] fix blip2 edge case (#40699)
2025-09-05|||üö® Allow `check_model_inputs` in core VLMs (#40342)
2025-09-05|||Fix parent classes of ProcessingKwargs (#40676)
2025-09-05|||feat(serve): add healthcheck test (#40697)
2025-09-05|||Fetch more test data with `hf_hub_download` (#40710)
2025-09-04|||Add Fast Image Processor for ImageGPT (#39592)
2025-09-04|||Fetch one missing test data (#40703)
2025-09-04|||Align assisted generate for unified signature in decoding methods (#40657)
2025-09-04|||Avoid `T5GemmaModelTest::test_eager_matches_sdpa_inference` being flaky (#40702)
2025-09-05|||Fix broken Llama4 accuracy in MoE part (#40609)
2025-09-04|||[Glm4.5V] fix vLLM support (#40696)
2025-09-04|||Fix self.dropout_p is not defined for SamAttention/Sam2Attention (#40667)
2025-09-04|||Fix backward compatibility with accelerate in Trainer (#40668)
2025-09-04|||Change docker image to preview for the MI355 CI (#40693)
2025-09-04|||Fixing bug in Voxtral when merging text and audio embeddings (#40671)
2025-09-04|||feat: support request cancellation (#40599)
2025-09-04|||add: embedding model (#40694)
2025-09-04|||Final test data cache - inside CI docker images (#40689)
2025-09-04|||Load a tiny video to make CI faster (#40684)
2025-09-04|||fix broken offline mode when loading tokenizer from hub (#40669)
2025-09-04|||Add codebook_dim attribute to DacVectorQuantize for DacResidualVectorQuantize.from_latents() (#40665)
2025-09-04|||Add sequence classification support for small Gemma 3 text models (#40562)
2025-09-04|||CircleCI docker images cleanup / update / fix (#40681)
2025-09-04|||Mark `Aimv2ModelTest::test_eager_matches_sdpa_inference_04_fp16_pad_right_sdpa_kernels` as flaky (#40683)
2025-09-04|||Avoid night torch CI not run because of irrelevant docker image failing to build  (#40677)
2025-09-04|||Skip more fast v.s slow image processor tests (#40675)
2025-09-03|||Even more test data cached (#40636)
2025-09-03|||Benchmarking V2: framework impl (#40486)
2025-09-03|||refactor: use `tolist` instead of list comprehension calling `.item()` (#40646)
2025-09-03|||Remove overwritten `GitModelTest::test_beam_search_generate` (#40666)
2025-09-03|||Skip `test_prompt_lookup_decoding_matches_greedy_search` for `qwen2_audio` (#40664)
2025-09-03|||Fix warning for output_attentions=True (#40597)
2025-09-03|||Skip `test_fast_is_faster_than_slow` for `Owlv2ImageProcessingTest` (#40663)
2025-09-03|||Update `check_determinism` inside `test_determinism` (#40661)
2025-09-03|||Allow custom args in `custom_generate` Callables and unify generation args structure (#40586)
2025-09-03|||Avoid attention_mask copy in qwen2.5 (#40658)
2025-09-03|||Fix Metaclip modular conversion (#40660)
2025-09-03|||feat(serving): add healthcheck (#40653)
2025-09-03|||fix pipeline dtype (#40638)
2025-09-03|||Mark `LongformerModelTest::test_attention_outputs` as flaky (#40655)
2025-09-03|||Remove TF/Flax examples (#40654)
2025-09-03|||fix MetaCLIP 2 wrong link & wrong model names in the docstrings (#40565)
2025-09-03|||add DeepseekV3ForTokenClassification (#40641)
2025-09-03|||Skip `test_prompt_lookup_decoding_matches_greedy_search` for `voxtral` (#40643)
2025-09-03|||Fix: PIL image load in Processing utils apply_chat_template (#40622)
2025-09-03|||[CP] Add attention_mask to the buffer when the mask is causal  (#40619)
2025-09-03|||[auto-model] propagate kwargs (#40491)
2025-09-03|||fix: gas for gemma fixed (#40591)
2025-09-03|||Fix `too many requests` in `TestMistralCommonTokenizer` (#40623)
2025-09-03|||üåê [i18n-KO] Translated `deepseek_v3.md` to Korean  (#39649)
2025-09-02|||Remove random flag (#40629)
2025-09-03|||Support TF32 flag for MUSA backend (#33187)
2025-09-02|||Enable more ruff UP rules (#40579)
2025-09-02|||Fix invalid typing (#40612)
2025-09-02|||Remove unnecessary pillow version check (#40604)
2025-09-02|||Add collated reports job to Nvidia CI (#40470)
2025-09-02|||Fix flaky `JambaModelTest.test_load_balancing_loss` (#40617)
2025-09-02|||Avoid `too many request` caused by `AutoModelTest::test_dynamic_saving_from_local_repo` (#40614)
2025-09-02|||Fix processor chat template (#40613)
2025-09-02|||fix: continuous batching in `transformers serve` (#40479)
2025-09-02|||Disable cache for `TokenizerTesterMixin` temporarily (#40611)
2025-09-01|||Multiple fixes to FA tests in AMD (#40498)
2025-09-01|||Pin torchcodec to 0.5 in AMD docker (#40598)
2025-09-01|||Reduce more test data fetch (#40595)
2025-09-01|||[`Tests`] Fixup duplicated mrope logic (#40592)
2025-09-01|||Fix quite a lot of FA tests (#40548)
2025-09-01|||Fix for missing default values in encoder decoder  (#40517)
2025-09-01|||Fix `siglip` flaky `test_eager_matches_sdpa_inference` (#40584)
2025-09-01|||Add Copilot instructions (#40432)
2025-09-01|||Fix inexistent imports (#40580)
2025-09-01|||Skip `TvpImageProcessingTest::test_slow_fast_equivalence` (#40593)
2025-09-01|||Fix typos (#40585)
2025-09-01|||üö® Remove Constrained Beam Search decoding strategy (#40518)
2025-09-01|||Support batch size > 1 image-text inference (#36682)
2025-09-01|||üö® Remove Group Beam Search decoding strategy (#40495)
2025-09-01|||Fix custom generate relative imports (#40480)
2025-09-01|||Update `get_*_features` methods + update doc snippets (#40555)
2025-09-01|||Fix llava image processor (#40588)
2025-09-01|||Allow `remi-or` to `run-slow` (#40590)
2025-09-01|||Fix CircleCI step passes in the case of pytest worker crash at test collection time (#40552)
2025-09-01|||Fix `test_eager_matches_sdpa_inference` not run for `CLIP` (#40581)
2025-09-01|||[qwen-vl] fix position ids (#40490)
2025-09-01|||processor tests - use dummy videos (#40537)
2025-08-30|||Set `test_all_params_have_gradient=False` for `DeepseekV2ModelTest` (#40566)
2025-08-30|||remove the redundant non maintained jieba and use rjieba instead (#40383)
2025-08-30|||pin `pytest-rerunfailures<16.0` (#40561)
2025-08-30|||Fix collated reports upload filename (#40556)
2025-08-29|||Dev version
2025-08-29|||Fix `GptOssModelTest::test_assisted_decoding_matches_greedy_search_1_same` (#40551)
2025-08-29|||fix gpt-oss out shape (#40535)
2025-08-29|||Flaky CI is annoying (#40543)
2025-08-29|||Fix gpt-oss rope warning  (#40550)
2025-08-29|||Add bfloat16 support detection for MPS in is_torch_bf16_gpu_available() (#40458)
2025-08-29|||Allow compression on meta device (#39039)
2025-08-29|||Clean-up kernel loading and dispatch (#40542)
2025-08-29|||Redundant code removal (#40534)
2025-08-29|||Fix typos (#40511)
2025-08-29|||Oupsy  (#40544)
2025-08-29|||`tokenizers` bump tokenizers version (#40540)
2025-08-28|||Fix `SeamlessM4Tv2ModelWithTextInputTest::test_retain_grad_hidden_states_attentions` (#40532)
2025-08-28|||Set `test_all_params_have_gradient=False` for `HunYuanMoEV1ModelTest` (#40530)
2025-08-28|||[`Qwen Omni/VL`] Fix fa tests (#40528)
2025-08-28|||Improve Gemma3n model and tests (#39764)
2025-08-28|||Lazy import torchcodec (#40526)
2025-08-28|||Fix typo: 'casual' to 'causal' (#40374)
2025-08-28|||skip some `padding_matches_padding_free_with_position_ids` for FA2 (#40521)
2025-08-28|||Fix mistral3 tests after "[Kosmos 2.5] Rename checkpoints" (#40523)
2025-08-28|||[`kernels`] If flash attention2 is not installed / fails to import (cc on our cluster) default to kernels (#40178)
2025-08-28|||Skip some flex attn tests (#40519)
2025-08-28|||[`FA`] Remaining Cleanup (#40424)
2025-08-28|||[omni modality] support composite processor config (#38142)
2025-08-28|||Use the config for DynamicCache initialization in all modelings (#40420)
2025-08-28|||[serve] fix ` request_id` unexpected (#40501)
2025-08-28|||sped up gguf tokenizer for nemotron test (#40509)
2025-08-28|||correct kes to keys. (#40489)
2025-08-28|||[vision] Improve keypoint-matching models docs (#40497)
2025-08-28|||[Kosmos 2.5] Rename checkpoints (#40338)
2025-08-28|||Add more missing arguments (#40354)
2025-08-28|||Add Apertus (#39381)
2025-08-28|||Update quantization overview for XPU (#40331)
2025-08-28|||fix typo (#40484)
2025-08-28|||Various AMD expectations (#40510)
2025-08-28|||Include machine type in collated reports filename (#40514)
2025-08-27|||[modular] Classes can now be defined and referenced in arbitrary order (without bringing unwanted dependencies) (#40507)
2025-08-27|||docs(pixtral): Update Pixtral model card to new format (#40442)
2025-08-27|||Fix the CI workflow of `merge to main` (#40503)
2025-08-27|||Collated reports: no need to upload artifact (#40502)
2025-08-27|||[Whisper] Add rocm expected results to certain tests (#40482)
2025-08-27|||Fix `qwen2_moe` tests (#40494)
2025-08-27|||[EfficientLoFTR] dynamic image size support (#40329)
2025-08-27|||[ESM] support attention API (#40370)
2025-08-27|||[modular] Remove ambiguity in all calls to parent class methods + fix dependency graph (#40456)
2025-08-27|||[modular] Use multi-processing + fix model import issue (#40481)
2025-08-27|||Validate GptOssConfig rope config after it's fully initialized (#40474)
2025-08-27|||CI when PR merged to `main` (#40451)
2025-08-26|||Fix nightly torch CI (#40469)
2025-08-26|||Not to shock AMD team by the cancelled workflow run notification ‚ù§Ô∏è üíñ (#40467)
2025-08-26|||Update SegFormer model card (#40417)
2025-08-26|||[pipeline] Add Keypoint Matching pipeline (#39970)
2025-08-26|||[RoPE] explicit factor > implicit factor in YaRN (#40320)
2025-08-26|||[fast_image_processor] fix image normalization for resize (#40436)
2025-08-26|||deci gguf support (#38669)
2025-08-26|||Fix extra template loading (#40455)
2025-08-26|||flash_paged: s_aux may not exist (#40434)
2025-08-26|||Continuous batching refactor (#40426)
2025-08-26|||üö® Remove Contrastive Search decoding strategy (#40428)
2025-08-26|||Make cache_config not mandatory (#40316)
2025-08-26|||rename get_cuda_warm_up_factor to get_accelerator_warm_up_factor (#40363)
2025-08-26|||[video processors] decode only sampled videos -> less RAM and faster processing (#39600)
2025-08-26|||fix qwen25-vl grad acc (#40333)
2025-08-26|||[Trainer] accelerate contextparallel support in trainer (#40205)
2025-08-26|||Refactor ViT-like models (#39816)
2025-08-26|||Fix non FA2 tests after FA2 installed in CI docker image (#40430)
2025-08-25|||Fix collated reports model name entry (#40441)
2025-08-25|||InternVL MI325 test expectations (#40387)
2025-08-25|||Fix collated reports uploading (#40440)
2025-08-25|||Fix https://github.com/huggingface/transformers/issues/40292 (#40439)
2025-08-25|||Fix collated reports model directory traversal (#40437)
2025-08-25|||Gemma3 text fixes: Add expectations for MI325 (#40384)
2025-08-26|||üåê [i18n-KO] Translated `models.md` to Korean (#39518)
2025-08-25|||Remove working-dir from collated reports job (#40435)
2025-08-25|||[docs] remove last references to `transformers` TF classes/methods (#40429)
2025-08-25|||Fix typo and improve GPU kernel check error message in MXFP4 quantization (#40349) (#40408)
2025-08-25|||Add `tokenizer_kwargs`  argument to the text generation pipeline (#40364)
2025-08-25|||Update collated reports working directory and --path (#40433)
2025-08-25|||Fix modular for modernbert-decoder (#40431)
2025-08-25|||üö® Remove DoLa decoding strategy (#40082)
2025-08-25|||[`Mxfp4`] Add a way to save with a quantization method (#40176)
2025-08-25|||Fix label smoothing incompatibility with multi-label classification (#40296)
2025-08-25|||Fix processing tests (#40379)
2025-08-25|||Gpt oss optim (#40304)
2025-08-25|||Fix UnboundLocalError in WER metric computation (#40402)
2025-08-25|||Fix typo: 'seperator' to 'separator' in variable names (#40389)
2025-08-25|||Fix CI (hunyuan moe does not support fullgraph) (#40423)
2025-08-25|||Fix typo: 'casual' -> 'causal' in code and documentation (#40371) (#40407)
2025-08-25|||[docs] flax/jax purge (#40372)
2025-08-25|||fix to accept cumulative_seqlens from TransformersKwargs in FA (#40194)
2025-08-25|||:broom: :broom: :broom: Get set decoder cleanup (#39509)
2025-08-25|||Reactivate a lot of tests skipped for no reason anymore (#40378)
2025-08-23|||Run FA2 tests in CI (#40397)
2025-08-22|||HF papers in doc (#40381)
2025-08-23|||Update README_zh-hans.md (#40380)
2025-08-22|||Rework the Cache documentation (#40373)
2025-08-22|||Chat Template Doc Fixes (#40173)
2025-08-22|||Bug Fix: Dynamically set return_lse flag in FlexAttention (#40352)
2025-08-22|||Add GptOssForTokenClassification for GPT-OSS models (#40190)
2025-08-22|||Addiing ByteDance Seed Seed-OSS (#40272)
2025-08-22|||fix(example): align parameter names with the latest function definition for gdino (#40369)
2025-08-22|||[configuration] allow to overwrite kwargs from subconfigs (#40241)
2025-08-22|||[processor] move commonalities to mixin (#40339)
2025-08-22|||‚ö†Ô∏è‚ö†Ô∏è Use `dtype` instead of `torch_dtype` everywhere! (#39782)
2025-08-22|||[pipelines] add support to `skip_special_tokens` in the main text generation pipelines (#40356)
2025-08-22|||Change multimodal data links to HF hub (#40309)
2025-08-22|||wav2vec2 fixes (#40341)
2025-08-22|||Fix idefics3 vision embeddings indices dtype (#40360)
2025-08-22|||HunYuan opensource (#39606)
2025-08-22|||DOCS: Clarification on the use of `label_names` as an argument to TrainingArguments (#40353)
2025-08-21|||[4/N]more docs to device agnostic (#40355)
2025-08-21|||[generate] handle support for cache classes when num enc layers != num dec layers (#40277)
2025-08-21|||Qwen2.5-VL test fixes for ROCm (#40308)
2025-08-21|||[`FA`] Fix some model tests (#40350)
2025-08-21|||Remove more PyTorch 2.2 compatible code (#40337)
2025-08-22|||[detection] use consistent dtype for Conditional and DAB DETR positional embeddings (#40300)
2025-08-21|||[serve] add cors warnings (#40112)
2025-08-21|||Clean up XCodec and other codecs (#40348)
2025-08-21|||[ModernBert] Prevent the attention mask from being None in ModernBertForSequenceClassification (#35991)
2025-08-21|||Fix attention vizualizer (#40285)
2025-08-21|||(small) fix conditional for input_ids and input_embeds in marian (#40045)
2025-08-21|||Update `test_spm_converter_bytefallback_warning` (#40284)
2025-08-21|||T5 test and target device fixes (#40313)
2025-08-21|||Fix links in Glm4vMoe configuration classes to point to the correct H‚Ä¶ (#40310)
2025-08-21|||Fix an infinite loop bug in recursive search of relative imports (#40326)
2025-08-21|||add type hints (#40319)
2025-08-21|||Fix: Only call Trainer.align_special_tokens if model has "config" attribute (#40322)
2025-08-21|||[docs] remove TF references from `/en/model_doc` (#40344)
2025-08-21|||Add missing arguments to class constructors (#40068)
2025-08-21|||Fix deprecation warning version (#40343)
2025-08-21|||Add DeepseekV3ForSequenceClassification for Deepseek V3 models (#40200)
2025-08-21|||Change Qwen2RMSNorm to RMSNorm from PyTorch (#40066)
2025-08-21|||Fix qwen-omni processor text only mode (#40336)
2025-08-21|||[docs] remove flax references from `/en/model_doc` (#40311)
2025-08-21|||Fix chunked attention mask with left-padding (#40324)
2025-08-20|||One cache class to rule them all (#40276)
2025-08-20|||Update notification service amd_daily_ci_workflows definition (#40314)
2025-08-21|||Fix: Apply `get_placeholder_mask` in Ovis2 (#40280)
2025-08-20|||Update CI with nightly torch workflow file (#40306)
2025-08-20|||[`GPT OSS`] Refactor the tests as it was not properly checking the outputs (#40288)
2025-08-20|||No more `natten` (#40287)
2025-08-20|||byebye torch 2.1 (#40317)
2025-08-20|||Add back `_tp_plan` attribute (#39944)
2025-08-20|||Qwen2.5-Omni test fixes (#40307)
2025-08-20|||Add support for Florence-2 (#38188)
2025-08-20|||Remove unnecessary contiguous calls for modern torch (#40315)
2025-08-20|||:rotating_light: [`Flash Attention`] Fix sliding window size (#40163)
2025-08-20|||chore: fix typo in `find_executable_batch_size` to match new 0.9 ratio (#40206)
2025-08-20|||[`fix`] Pass adamw optimizer parameters to StableAdamW (#40184)
2025-08-20|||Fix GOT-OCR2 and Cohere2Vision image processor patches caculation (#40312)
2025-08-20|||Remove OTel SDK dependencies (#40305)
2025-08-20|||Clean up X-Codec. (#40271)
2025-08-20|||[docs] delete more TF/Flax docs (#40289)
2025-08-20|||[`FA`] Fix dtype in varlen with position ids (#40295)
2025-08-20|||Allow to be able to run `torch.compile` tests with `fullgraph=True` (#40164)
2025-08-20|||Add MetaCLIP 2 (#39826)
2025-08-19|||[3/3] make docs device agnostic, all en docs for existing models done  (#40298)
2025-08-19|||make model docs device agnostic (2) (#40256)
2025-08-19|||SmolVLM test fixes (#40275)
2025-08-19|||Adjust ROCm test output expectations (#40279)
2025-08-19|||Standardize BertGeneration model card (#40250)
2025-08-19|||SmolVLM and InternVL: Ensure pixel values are converted to the correct dtype for fp16/bf16 (#40121)
2025-08-20|||Update model card for gpt neox japanese (#39862)
2025-08-19|||docs: Update TrOCR model card to new format (#40240)
2025-08-19|||Standardize RAG model card (#40222)
2025-08-19|||docs(layoutlm): add missing `id=usage` to `<hfoptions>` tag in LayoutLM model card (#40273)
2025-08-19|||Fix chat CLI GPU loading and request_id validation issues (#40230) (#40232)
2025-08-19|||fix which routing method (#40283)
2025-08-19|||Update image_processing_perception_lm_fast.py to allow for proper override of vision_input_type (#40252)
2025-08-19|||Skipping pytree registration in case fsdp is enabled (#40075)
2025-08-19|||Add Kosmos-2.5 (#31711)
2025-08-19|||[detection] fix correct `k_proj` weight and bias slicing in D-FINE (#40257)
2025-08-19|||Fix setting attention for multimodal models (#39984)
2025-08-19|||üö®üö® Switch default compilation to fullgraph=False (#40137)
2025-08-19|||Fix slow static cache export tests (#40261)
2025-08-19|||[detection] fix attention mask for RT-DETR-based models (#40269)
2025-08-19|||set inputs_embeds to None while generate to avoid audio encoder forward in generation process (#40248)
2025-08-19|||Remove MI300 CI (#40270)
2025-08-19|||Skip broken tests (#40157)
2025-08-18|||docs: Update OLMo model card (#40233)
2025-08-18|||Fix benchmark workflow (#40254)
2025-08-18|||Correct typo and update notes in docs Readme (#40234)
2025-08-18|||Model card for NLLB (#40074)
2025-08-18|||fix: Catch correct ConnectionError for additional_chat_templates (#39874)
2025-08-18|||Fixes for EncoderDecoderCache (#40008)
2025-08-18|||[`CI`] Fix repo consistency (#40249)
2025-08-18|||[serve] guard imports (#39825)
2025-08-18|||[typing] fix type annotation error in DepthPro model image processor (#40238)
2025-08-18|||Add `chat_template` (`jinja2`) as an extra dependency (#40128)
2025-08-18|||remove transpose_for_scores call in ESM-2 (#40210)
2025-08-18|||üö® Always return Cache objects in modelings (to align with generate) (#39765)
2025-08-18|||Fix more pylint warnings (#40204)
2025-08-18|||Add Ovis2 model and processor implementation (#37088)
2025-08-18|||AMD scheduled CI ref env file (#40243)
2025-08-18|||Fix ESM token_dropout crash when using inputs_embeds instead of input_ids (#40181)
2025-08-18|||Fix more typos (#40212)
2025-08-18|||[SAM 2] Change checkpoints in docs and tests (#40213)
2025-08-18|||fix error vocab_size at Qwen2_5_VLForConditionalGeneration loss_function (#40130)
2025-08-18|||Use correct `model_input_names` for PixtralImageProcessor (#40226)
2025-08-18|||Revert "Pin torch to 2.7.1 on CircleCI for now" + Final fix for `too long with no output` (#40201)
2025-08-15|||docs: Update LayoutLM model card according to new standardized format (#40129)
2025-08-15|||Fix GPT-OSS `swiglu_limit` not passed in for MXFP4 (#40197)
2025-08-15|||Add X-Codec model (#38248)
2025-08-15|||Benchmarking improvements (#39768)
2025-08-15|||Update: add type hints to check_tokenizers.py (#40094)
2025-08-15|||Fix various Pylint warnings (#40107)
2025-08-15|||Avoid CUDA stream sync (#40060)
2025-08-15|||Remove _prepare_flash_attention_from_position_ids (#40069)
2025-08-15|||Fix typos (#40175)
2025-08-15|||Add repr to EncoderDecoderCache (#40195)
2025-08-15|||Fix fsdp for generic-task models (#40191)
2025-08-15|||fix to avoid modifying a view in place (#40162)
2025-08-14|||make model doc device agnostic (#40143)
2025-08-15|||[MINOR:TYPO] Update base.py (#40169)
2025-08-14|||Update dynamic attnt setter for multimodals (#39908)
2025-08-14|||Pin torch to 2.7.1 on CircleCI for now (#40174)
2025-08-14|||Add dates to the model docs (#39320)
2025-08-14|||Standardize BARTpho model card: badges, new examples, fixed broken im‚Ä¶ (#40051)
2025-08-15|||Add GptOssForSequenceClassification for GPT-OSS models (#40043)
2025-08-14|||build: Add fast image processor tvp (#39529)
2025-08-14|||Fix docs typo (#40167)
2025-08-14|||[bugfix] fix flash-attention2 unavailable error for Ascend NPU (#40151)
2025-08-14|||[FA2] Fix it finally - revert fa kwargs preparation (#40161)
2025-08-14|||Replace `self.tokenizer` by `self.processing_class` (#40119)
2025-08-14|||[Continous Batching] set head_dim when config.head_dim is None (#40159)
2025-08-14|||Fix CI: Use correct import in SAM for torchvision InterpolationMode (#40160)
2025-08-14|||[efficientloftr] fix bugs and follow original cross attn implementation strictly (#40141)
2025-08-14|||[Cohere2Vision] remove unused arg (#40103)
2025-08-14|||Create self-scheduled-amd-mi355-caller.yml (#40134)
2025-08-14|||Update Dockerfiles to install packages inside a virtual environment (#39098)
2025-08-13|||Add pytest marker: `torch_compile_test` and `torch_export_test` (#39950)
2025-08-13|||Fix quantized cache with only cache_implementation in generate (#40144)
2025-08-14|||üåê [i18n-KO] Translated `gemma3.md` to Korean (#39865)
2025-08-14|||updated visualBERT modelcard (#40057)
2025-08-13|||Remove an old badly designed test (#40142)
2025-08-13|||[docs] Fix ko toctree (#40138)
2025-08-14|||Add Segment Anything 2 (SAM2) (#32317)
2025-08-13|||Fix Janus (#40140)
2025-08-13|||gpt oss is important (#40139)
2025-08-14|||üåê [i18n-KO] Translated `pipelines.md` to Korean (#39577)
2025-08-13|||üö® Use lru_cache for sine pos embeddings MaskFormer (#40007)
2025-08-14|||üåê [i18n-KO] Translated grounding-dino.md to Korean (#39861)
2025-08-14|||üåê [i18n-KO] Translated `optimizers.md` to Korean (#40011)
2025-08-13|||üåê [i18n-KO] Translated `gpt2.md` to Korean (#39808)
2025-08-13|||üö®üö®  [generate] ignore `cache_implementation="hybrid"` hub defaults (#40135)
2025-08-14|||üåê [i18n-KO] Translated `main_classes/optimizer_schedules.md` to Korean (#39713)
2025-08-14|||üåê [i18n-KO] Translated `jamba.md` to Korean (#39890)
2025-08-14|||üåê [i18n-KO] Translated `main_classes/processors.md` to Korean (#39519)
2025-08-13|||Fix hidden torchvision>=0.15 dependency issue (#39928)
2025-08-13|||[trainer] handle case where EOS token is None in `generation_config` (#40127)
2025-08-13|||DOCS: Add missing space in SECURITY.md (#40087)
2025-08-13|||Collated reports (#40080)
2025-08-13|||`decoding_method` argument in generate (#40085)
2025-08-13|||[serve] allow array `content` inputs for LLMs (#39829)
2025-08-13|||Fix QuantoQuantizedCache import issues (#40109)
2025-08-13|||changed xLSTMRMSNorm to RMSNorm (#40113)
2025-08-13|||[bugfix] Fix tensor device in Idefics2, Idefics3, and SmolVLM (#39975)
2025-08-13|||üåê [i18n-KO] Translated `tiny_agents.md` to Korean (#39913)
2025-08-13|||remove sequence parallel in llama4 (#40084)
2025-08-13|||Add model card for MobileViT (#40033)
2025-08-12|||[docs] Add reference to HF-maintained `custom_generate` collections (#39894)
2025-08-13|||Fix Causality Handling in Flash Attention to Support Bidirectional Attention (#39707)
2025-08-12|||[trainer] ensure special tokens in model configs are aligned with tokenizer at train time (#38441)
2025-08-12|||[`Flash Attention`] Fix flash attention integration (#40002)
2025-08-12|||Default to dequantize if cpu in device_map for mxfp4 (#39993)
2025-08-12|||Fix error on importing unavailable torch.distributed (#40038)
2025-08-12|||Fix Qwen3 MoE GGUF architecture mismatch (#39976)
2025-08-12|||Switch the order of args in StaticCache (for BC and future logic) (#40100)
2025-08-12|||Fix regression in mllama vision encoder (#40083)
2025-08-12|||Replace `logger.warning` with `logger.warning_once` in `GradientCheckpointingLayer` (#40091)
2025-08-12|||Re-apply make style (#40106)
2025-08-12|||feat: add `is_fast` to ImageProcessor (#39603)
2025-08-12|||Enable SIM rules (#39806)
2025-08-12|||New DynamicSlidingWindowLayer & associated Cache (#40039)
2025-08-12|||Audio encodings now match conv2d weight dtype in Gemma3nAudioSSCPConvBlock (#39743)
2025-08-12|||Causal loss for `ForConditionalGeneration` (#39973)
2025-08-12|||Add glm4.5&&glm4.5V doc (#40095)
2025-08-12|||Update Glm4V processor and add tests (#39988)
2025-08-12|||[docs] Zero Shot Object Detection Task (#40096)
2025-08-12|||[fix] batch inference for llava_onevision (#40021)
2025-08-12|||Revert FA2 kwargs construction (#40029)
2025-08-12|||Fix PerceptionLM image preprocessing for non-tiled image input. (#40006)
2025-08-12|||Update notification service MI325 (#40078)
2025-08-11|||feat: extract rev in attn_implementation kernels via @ (#40009)
2025-08-11|||[`GPT Big Code`] Fix attention scaling (#40041)
2025-08-11|||chore: standardize DeBERTa model card (#37409)
2025-08-11|||Fix `time_spent ` in `notification_service.py`. (#40081)
2025-08-11|||added Textnet fast image processor (#39884)
2025-08-11|||Fix repo consistency (#40077)
2025-08-11|||guard on model.eval when using torch.compile + FSDP2 (#37413)
2025-08-11|||Remove deprecated cache-related objects (#40035)
2025-08-11|||fix: move super().__init__ after vision_config init in Mistral3Config (#40063)
2025-08-11|||[gemma3] update conversion key mapping (#39778)
2025-08-11|||[qwen-vl] fix beam search with videos (#39726)
2025-08-11|||fix: resolve triton version check compatibility on windows (#39986)
2025-08-10|||unpin `torchcodec==0.5.0` and use `torch 2.8` on daily CI (#40072)
2025-08-10|||Update HuBERT model card according to template (#39742)
2025-08-08|||Revert "fix `notification_service.py` about `time_spent`" (#40044)
2025-08-08|||GLM-4.5V Model Support (#39805)
2025-08-08|||fix `notification_service.py` about `time_spent` (#40037)
2025-08-08|||Bnb failling tests (#40026)
2025-08-08|||Tie weights recursively on all submodels (#39996)
2025-08-08|||fix
2025-08-08|||[core] Refactor the Cache logic to make it simpler and more general (#39797)
2025-08-08|||Fix missing None default values for Gemma3n model in get_placeholder_mask (#39991) (#40024)
2025-08-08|||Harmonize `past_key_value` to `past_key_valueS` everywhere (#39956)
2025-08-08|||Fix an annoying flaky test (#40000)
2025-08-08|||Higgs modules_to_not_convert standardization (#39989)
2025-08-08|||Fix broken image inference for Fuyu model (#39915)
2025-08-07|||pin torchcodec==0.5.0 for now with torch 2.7.1 on daily CI (#40013)
2025-08-07|||Update expected output values after #39885 (part 2) (#40015)
2025-08-07|||Raising error when quantizing a quantized model (#39998)
2025-08-08|||docs: fix duplication in 'en/optimizers.md' (#40014)
2025-08-07|||unpin torch<2.8 on circleci (#40012)
2025-08-07|||FA2 can continue generation from cache (#39843)
2025-08-08|||Fix default values of getenv (#39867)
2025-08-07|||Fix HGNetV2 Model Card and Image Classification Pipeline Usage Tips (#39965)
2025-08-07|||fix: remove CHAT_TEMPLATE import in tests for deepseek-vl (#40003)
2025-08-07|||Fix missing video inputs for PerceptionLM. (#39971)
2025-08-07|||Fix int4 quantized model cannot work with cpu (#39724)
2025-08-07|||Update expected output values after #39885 (part 1) (#39990)
2025-08-07|||Fix consistency (#39995)
2025-08-07|||[typing] Fix return typehint for decoder and inv_freq annotation (#39610)
2025-08-07|||Bump transformers from 4.48.0 to 4.53.0 in /examples/tensorflow/language-modeling-tpu (#39967)
2025-08-07|||Fix gemma3n feature extractor's incorrect squeeze (#39919)
2025-08-07|||[Idefics] fix device mismatch (#39981)
2025-08-07|||Various test fixes for AMD (#39978)
2025-08-07|||Support input_embeds in torch exportable decoders (#39836)
2025-08-07|||[superglue] Fixed the way batch mask was applied to the scores before match assignment computation (#39968)
2025-08-07|||Gemma3 fixes (#39960)
2025-08-06|||Modular fix: remove the model name in `find_file_type` (#39897)
2025-08-07|||chore: update Deformable_Detr model card (#39902)
2025-08-07|||[bugfix] fix flash_attention_2 unavailable error on Ascend NPU (#39844)
2025-08-06|||Fix `fix_and_overwrite` mode of `utils/check_docstring.py` (#39369)
2025-08-06|||remove `triton_kernels` dep with `kernels` instead (#39926)
2025-08-07|||[image processor] fix glm4v (#39964)
2025-08-06|||fix typo (#39936)
2025-08-06|||Fix grammatical error in MoE variable name: expert_hitted ‚Üí expert_hit, hitted_experts ‚Üí hit_experts (#39959)
2025-08-06|||docs: fix typo in 'quantization-aware training' (#39904)
2025-08-06|||Enable gpt-oss mxfp4 on older hardware (sm75+) (#39940)
2025-08-06|||Fix MXFP4 quantizer validation to allow CPU inference with dequantize option (#39953)
2025-08-06|||[docs] ko toc fix (#39927)
2025-08-06|||circleci: pin torch 2.7.1 until `torchcodec` is updated (#39951)
2025-08-06|||Fix CI: Tests failing on CPU due to `torch.device('cpu').index` being None (#39933)
2025-08-05|||Avoid `utils/check_bad_commit.py` failing due to rate limit (requesting  `api.github.com`) (#39918)
2025-08-05|||[CI] post-`GptOss` fixes for green CI (#39929)
2025-08-05|||Dev version
2025-08-05|||gpt_oss last chat template changes (#39925)
2025-08-05|||Add GPT OSS model from OpenAI  (#39923)
2025-08-06|||üåê [i18n-KO] Translated `cache_explanation.md` to Korean (#39535)
2025-08-05|||Export SmolvLM (#39614)
2025-08-05|||[docs] update object detection guide (#39909)
2025-08-05|||run model debugging with forward arg (#39905)
2025-08-05|||Revert "remove dtensors, not explicit (#39840)" (#39912)
2025-08-05|||Fix aria tests (#39879)
2025-08-05|||Fix eval thread fork bomb (#39717)
2025-08-05|||Replace video_fps with fps in tests (#39898)
2025-08-05|||Fix misleading WandB error when WANDB_DISABLED is set (#39891)
2025-08-05|||Avoid aliasing in cond's branches for torch 2.8 (#39488)
2025-08-05|||[qwen] remove unnecessary CUDA sync in qwen2_5_vl (#39870)
2025-08-05|||fix test_working_of_tp failure of accelerate ut (#39828)
2025-08-05|||[`Exaone4`] Fixes the attn implementation!  (#39906)
2025-08-05|||Reorder serving docs (#39634)
2025-08-05|||chore: update DETR model card (#39822)
2025-08-04|||Add support for `ModernBertForMultipleChoice` (#39232)
2025-08-04|||send some feedback when manually building doc via comment (#39889)
2025-08-04|||Update cohere2 vision test (#39888)
2025-08-04|||[DOCS] : Improved mimi model card (#39824)
2025-08-04|||Fix link to models in README (#39880)
2025-08-04|||[typing] better return type hint for `AutoModelForCausalLM` and `AutoModelForImageTextToText` (#39881)
2025-08-04|||Set `torch.backends.cudnn.allow_tf32 = False` for CI (#39885)
2025-08-04|||Replace `Tokenizer` with `PreTrainedTokenizerFast` in `ContinuousBatchProcessor` (#39858)
2025-08-04|||Rework add-new-model-like with modular and make test filenames coherent (#39612)
2025-08-04|||Fix quant docker for fp-quant  (#39641)
2025-08-04|||[core] Fix attn_implementation setter with missing `sub_configs` (#39855)
2025-08-04|||Add support for including in-memory videos (not just files/urls) in apply_chat_template (#39494)
2025-08-04|||Use comment to build doc on PRs (#39846)
2025-08-03|||Refactor label name handling for PEFT models in Trainer class (#39265)
2025-08-03|||Improve `is_wandb_available` function to verify WandB installation (#39875)
2025-08-01|||remove dtensors, not explicit (#39840)
2025-08-01|||Allow `TrackioCallback` to work when pynvml is not installed (#39851)
2025-08-01|||[image-processing] deprecate `plot_keypoint_matching`, make `visualize_keypoint_matching` as a standard (#39830)
2025-08-01|||Add fast image processor Janus, Deepseek VL, Deepseek VL hybrid (#39739)
2025-08-01|||Fix responses add tests (#39848)
2025-08-01|||Update ux cb (#39845)
2025-08-01|||Add MM Grounding DINO (#37925)
2025-08-01|||[typecheck] proper export of private symbols (#39729)
2025-08-01|||[`attn_implementation`] remove recursive, allows custom kernels with wrappers (#39823)
2025-08-01|||[VLMs] split out "get placeholder mask" to helper (#39777)
2025-08-01|||Fix tp cb (#39838)
2025-07-31|||Fix bad markdown links (#39819)
2025-07-31|||Fix broken links (#39809)
2025-07-31|||[cohere2 vision] move doc to multimodal section (#39820)
2025-07-31|||Update documentation for Cohere2Vision models (#39817)
2025-07-31|||[Model] Cohere2 Vision (#39810)
2025-07-31|||[docs] fix korean docs yet again (#39813)
2025-07-31|||feat(tokenization): add encode_message to tokenize messages one by one (#39507)
2025-07-30|||fix: providing a tensor to cache_position in model.generate kwargs always crashes because of boolean test (#39300)
2025-07-30|||Add callback to monitor progress in whisper transcription (#37483)
2025-07-30|||Update mT5 model card (#39702)
2025-07-30|||Update model card for Cohere2 (Command R7B) (#39604)
2025-07-30|||standardized BARThez model card (#39701)
2025-07-30|||Fix re-compilations for cross attention cache (#39788)
2025-07-30|||Simplify conditional code (#39781)
2025-07-30|||Fix an invalid condition (#39762)
2025-07-30|||fix chameleonvision UT failure (#39646)
2025-07-30|||Super tiny update (#39727)
2025-07-30|||more info in `model_results.json` (#39783)
2025-07-30|||[ASR pipline] fix with datasets 4.0 (#39504)
2025-07-30|||enable static cache on vision encoder decoder (#39773)
2025-07-30|||Fix Evolla and xLSTM tests (#39769)
2025-07-29|||Don't set `run_name` when none (#39695)
2025-07-29|||Standardize CLAP model card format (#39738)
2025-07-29|||docs: Update EfficientLoFTR documentation (#39620)
2025-07-29|||Fix OmDet test after arg deprecation (#39766)
2025-07-30|||Remove python3.7 reference from doc link (#39706)
2025-07-29|||[docs] Ko doc fixes after toc update (#39660)
2025-07-29|||Fix Cache.max_cache_len max value for Hybrid models (#39737)
2025-07-29|||fix(trainer): Correct loss scaling for incomplete gradient accumulation steps (#39659)
2025-07-30|||üåê [i18n-KO] Translated `how_to_hack_models.md` to Korean (#39536)
2025-07-30|||üåê [i18n-KO] Translated `perf_train_gpu_one.md` to Korean (#39552)
2025-07-30|||üåê [i18n-KO] Translated `pipeline_gradio.md` to Korean (#39520)
2025-07-30|||üåê [i18n-KO] Translated `tokenizer.md` to Korean (#39532)
2025-07-30|||üåê [i18n-KO] Translated `tvp.md` to Korean (#39578)
2025-07-30|||üåê [i18n-KO] Translated albert.md to Korean (#39524)
2025-07-30|||üåê [i18n-KO] Translated `main_classes/peft.md` (#39515)
2025-07-29|||[modenbert] fix regression (#39750)
2025-07-29|||add `libcst` to `extras["testing"]` in `setup.py` (#39761)
2025-07-29|||Fix version issue in modeling_utils.py (#39759)
2025-07-29|||Enable xpu allocator on caching_allocator_warmup (#39654)
2025-07-29|||Support loading Qwen3 MoE GGUF (#39638)
2025-07-29|||Fix GPT2 with cross attention (#39754)
2025-07-29|||Avoid OOM when other tests are failing (#39758)
2025-07-29|||AMD disable torchcodec (#39757)
2025-07-29|||Use `--gpus all` in workflow files (#39752)
2025-07-29|||Apply several ruff SIM rules   (#37283)
2025-07-29|||Fix mamba regression (#39728)
2025-07-29|||Update IMPORTANT_MODELS list (#39734)
2025-07-29|||update `GemmaIntegrationTest::test_model_2b_bf16_dola` again (#39731)
2025-07-29|||Fix: add back base model plan (#39733)
2025-07-29|||[Fix] import two missing typos in `models/__init__.py` for typo checking (#39745)
2025-07-29|||fix cache inheritance (#39748)
2025-07-29|||extend more trainer test cases to XPU, all pass (#39652)
2025-07-29|||BLIPs clean-up  (#35560)
2025-07-29|||Add Fast Segformer Processor (#37024)
2025-07-28|||Superpoint fast image processor (#37804)
2025-07-28|||Fix AMD dockerfile for audio models (#39669)
2025-07-28|||Fix cache-related tests (#39676)
2025-07-28|||Fix Layer device placement in Caches (#39732)
2025-07-28|||Fix `Qwen2AudioForConditionalGeneration.forward()` and `test_flash_attn_kernels_inference_equivalence` (#39503)
2025-07-28|||skip `Glm4MoeModelTest::test_torch_compile_for_training` (#39670)
2025-07-28|||Update `QAPipelineTests::test_large_model_course` after #39193 (#39666)
2025-07-28|||mllama outputs refactor (#39643)
2025-07-28|||Remove all expired deprecation cycles (#39725)
2025-07-28|||[`CI`] Add Eric to comment slow ci (#39601)
2025-07-28|||PATCH: add back n-dim device-mesh + fix tp trainer saving (#39693)
2025-07-28|||Add self-hosted runner scale set workflow for mi325 CI (#39651)
2025-07-28|||[configuration] remove redundant `classmethod` (#38812)
2025-07-28|||update ernie model card (#39657)
2025-07-28|||[processors] add tests for helper fn (#39629)
2025-07-28|||xpu optimization for generation case (#39573)
2025-07-28|||fix(tokenization): check token.content for trie (#39587)
2025-07-28|||Fix missing initialization of `FastSpeech2Conformer` (#39689)
2025-07-26|||fix missing model._tp_size from ep refactor (#39688)
2025-07-25|||More robust tied weight test (#39681)
2025-07-25|||dev version 4.55
2025-07-25|||Add padding-free to Granite hybrid moe models  (#39677)
2025-07-25|||Fix tied weight test (#39680)
2025-07-26|||fix break for ckpt without _tp_plan (#39658)
2025-07-26|||Add EXAONE 4.0 model (#39129)
2025-07-26|||Support `typing.Literal` as type of tool parameters or return value (#39633)
2025-07-25|||Add ep (#39501)
2025-07-25|||bad_words_ids no longer slow on mps (#39556)
2025-07-25|||Add xlstm model (#39665)
2025-07-25|||Use auto_docstring for perception_lm fast image processor (#39679)
2025-07-25|||fix: HWIO to OIHW (#39200)
2025-07-25|||Fix auto_docstring crashing when dependencies are missing (#39564)
2025-07-25|||Add support for DeepseekAI's DeepseekVL (#36248)
2025-07-25|||Add missing flag for CacheLayer (#39678)
2025-07-26|||Add evolla rebase main (#36232)
2025-07-25|||update expected outputs for whisper after #38778 (#39304)
2025-07-25|||fix `kyutai` tests (#39416)
2025-07-25|||Fixes the BC (#39636)
2025-07-25|||Delete bad rebasing functions (#39672)
2025-07-25|||[`Ernie 4.5`] Post merge adaptations (#39664)
2025-07-25|||[CI] revert device in `test_export_static_cache` (#39662)
2025-07-25|||Fix ModernBERT Decoder model (#39671)
2025-07-25|||üö®[Fast Image Processor] Force Fast Image Processor for Qwen2_VL/2_5_VL + Refactor (#39591)
2025-07-25|||Rename huggingface_cli to hf (#39630)
2025-07-25|||fix(voxtral): correct typo in apply_transcription_request (#39572)
2025-07-25|||make fixup (#39661)
2025-07-25|||[docs] fix ko cache docs (#39644)
2025-07-25|||Make pytorch examples UV-compatible (#39635)
2025-07-25|||revert change to cu_seqlen_k and max_k when preparing from position_ids (#39653)
2025-07-25|||Fix: explicit not none check for tensors in flash attention (#39639)
2025-07-25|||[attention] fix test for packed padfree masking (#39582)
2025-07-24|||Add owlv2 fast processor (#39041)
2025-07-24|||revert behavior of _prepare_from_posids (#39622)
2025-07-24|||[Voxtral] values for A10 runners (#39605)
2025-07-24|||[timm] new timm pin (#39640)
2025-07-24|||[efficientloftr] fix model_id in tests (#39621)
2025-07-24|||Update recent processors for vLLM backend (#39583)
2025-07-23|||[Docs] Translate audio_classification.md from English to Spanish (#39513)
2025-07-23|||standardized YOLOS model card according to template in #36979 (#39528)
2025-07-23|||Feature/standardize opt model card (#39568)
2025-07-23|||üî¥ Fix EnCodec internals and integration tests (#39431)
2025-07-23|||Fix DAC integration tests and checkpoint conversion. (#39313)
2025-07-23|||Move openai import (#39613)
2025-07-23|||Transformers serve VLM (#39454)
2025-07-23|||Fix important models CI (#39576)
2025-07-23|||Fix typos and grammar issues in documentation and code (#39598)
2025-07-23|||Allow `device_mesh` have multiple dim  (#38949)
2025-07-23|||enable triton backend on awq xpu (#39443)
2025-07-23|||[idefics3] fix for vLLM (#39470)
2025-07-23|||fix moe routing_weights (#39581)
2025-07-23|||FP-Quant support (#38696)
2025-07-23|||Rename `supports_static_cache` to `can_compile_fullgraph` (#39505)
2025-07-23|||[Trackio] Allow single-gpu training and monitor power (#39595)
2025-07-23|||Generic task-specific base classes (#39584)
2025-07-23|||Fix DynamicCache and simplify Cache classes a bit (#39590)
2025-07-23|||Mask2former & Maskformer Fast Image Processor (#35685)
2025-07-22|||üéØ Trackio integration (#38814)
2025-07-23|||[WIP] Add OneformerFastImageProcessor (#38343)
2025-07-22|||Fix link in "Inference server backends" doc (#39589)
2025-07-22|||Torchdec RuntimeError catch  (#39580)
2025-07-22|||[Paged-Attention] Handle continuous batching for repetition penalty (#39457)
2025-07-22|||updated mistral3 model card (#39531)
2025-07-23|||Update `docs/source/ko/_toctree.yml` (#39516)
2025-07-22|||[cache refactor] Move all the caching logic to a per-layer approach (#39106)
2025-07-22|||General weight initialization scheme  (#39579)
2025-07-22|||Add AMD GPU expectations for LLaVA tests (#39486)
2025-07-22|||Kernels flash attn (#39474)
2025-07-22|||Add AMD expectations to Mistral3 tests (#39481)
2025-07-22|||[docs] Create page on inference servers with transformers backend (#39550)
2025-07-22|||[docs] update attention implementation and cache docs (#39547)
2025-07-22|||Add AMD test expectations to DETR model (#39539)
2025-07-22|||[timm_wrapper] add support for gradient checkpointing (#39287)
2025-07-22|||Fixes needed for n-d parallelism and TP (#39562)
2025-07-22|||Bump AMD container for 2.7.1 PyTorch (#39458)
2025-07-22|||Add EfficientLoFTR model (#36355)
2025-07-22|||[gemma3] fix bidirectional image mask (#39396)
2025-07-22|||Update OLMoE model card (#39344)
2025-07-21|||Update modernbertdecoder docs (#39453)
2025-07-21|||[`CI`] Fix post merge ernie 4.5 (#39561)
2025-07-21|||[Fast image processors] Improve handling of image-like inputs other than images (segmentation_maps) (#39489)
2025-07-21|||[`Ernie 4.5`] Add ernie text models (#39228)
2025-07-21|||Refactor embedding input/output getter/setter (#39339)
2025-07-22|||üåê [i18n-KO] Translated `perf_infer_gpu_multi.md` to Korean (#39441)
2025-07-21|||[Fast image processor] refactor fast image processor glm4v (#39490)
2025-07-21|||fix ndim check of device_mesh for TP (#39538)
2025-07-21|||Refactor `MambaCache` to `modeling_mamba.py` (#38086)
2025-07-21|||Fix Docstring of BarkProcessor (#39546)
2025-07-21|||use the enable_gqa param in torch.nn.functional.scaled_dot_product_at‚Ä¶ (#39412)
2025-07-21|||Fix missing initializations for models created in 2023 (#39239)
2025-07-21|||Raise `TypeError` instead of ValueError for invalid types (#38660)
2025-07-21|||Fix pylint warnings (#39477)
2025-07-21|||Fix Qwen Omni integration test (#39553)
2025-07-21|||üö®üö®üö® [Trainer] Enable `average_tokens_across_devices` by default in `TrainingArguments` (#39395)
2025-07-21|||Rename `_supports_flash_attn_2` in examples and tests (#39471)
2025-07-21|||Fix the check in flex test (#39548)
2025-07-21|||Fix bad tensor shape in failing Hubert test. (#39502)
2025-07-21|||GLM-4 Update (#39393)
2025-07-21|||[qwen2 vl] fix packing with all attentions (#39447)
2025-07-21|||[gemma3] support sequence classification task (#39465)
2025-07-18|||Fix placeholders replacement logic in auto_docstring (#39433)
2025-07-18|||Update SAM/SAM HQ attention implementation + fix Cuda sync issues (#39386)
2025-07-18|||Improve @auto_docstring doc and rename `args_doc.py` to `auto_docstring.py` (#39439)
2025-07-18|||Add fast image processor SAM (#39385)
2025-07-18|||Fix BatchEncoding.to() for nested elements (#38985)
2025-07-18|||[gemma3] Fix do_convert_rgb in image processors. (#39438)
2025-07-18|||[chat template] return assistant mask in processors (#38545)
2025-07-18|||[dependencies] Update `datasets` pin (#39500)
2025-07-18|||Slack CI bot: set default result for non-existing artifacts (#39499)
2025-07-18|||üö®üö® Fix and simplify attention implementation dispatch and subconfigs handling (#39423)
2025-07-18|||[dependencies] temporary pyarrow pin (#39496)
2025-07-18|||Add voxtral (#39429)
2025-07-17|||Fix typing order (#39467)
2025-07-17|||Add unified logits_to_keep support to LLMClass (#39472)
2025-07-17|||[serve] Add speech to text (`/v1/audio/transcriptions`) (#39434)
2025-07-17|||Update integration_utils.py (#39469)
2025-07-17|||fix: ImageTextToTextPipeline handles user-defined generation_config (#39374)
2025-07-17|||Enable some ruff checks for performance and readability (#39383)
2025-07-17|||Fix convert_and_export_with_cache failures for GPU models (#38976)
2025-07-17|||Update `GemmaIntegrationTest::test_model_2b_bf16_dola` (#39362)
2025-07-17|||fix a comment typo in utils.py (#39459)
2025-07-17|||Use newer typing notation (#38934)
2025-07-17|||Fix tests due to breaking change in accelerate (#39451)
2025-07-17|||fix max_length calculating using cu_seq_lens (#39341)
2025-07-17|||fix(pipelines): QA pipeline returns fewer than top_k results in batch mode (#39193)
2025-07-16|||Corrections to PR #38642 and enhancements to Wav2Vec2Processor __call__ and pad docstrings (#38822)
2025-07-16|||create ijepa modelcard (ref : PR  #36979 ). (#39354)
2025-07-17|||Improve grammar and clarity in perf_hardware.md (#39428)
2025-07-17|||fix cached file error when repo type is dataset (#36909)
2025-07-16|||Fix indentation bug in SmolVLM image processor causing KeyError (#39452)
2025-07-16|||Updated Megatron conversion script for gpt2 checkpoints  (#38969)
2025-07-16|||[`CI`] Fix partially red CI (#39448)
2025-07-16|||Fixes #39204: add fallback if get_base_model missing (#39226)
2025-07-16|||make the loss context manager easier to extend (#39321)
2025-07-16|||Remove something that should have never been there (#38254)
2025-07-16|||Fix processor tests (#39450)
2025-07-16|||[Bugfix] [Quantization] Remove unused init arg (#39324)
2025-07-16|||Better typing for model.config (#39132)
2025-07-16|||Fix typo in generation configuration for Janus model weight conversion (#39432)
2025-07-16|||Responses API in `transformers serve` (#39155)
2025-07-16|||[cache] make all classes cache compatible finally (#38635)
2025-07-16|||docs: add missing numpy import to minimal example (#39444)
2025-07-16|||Remove runtime conditions for type checking (#37340)
2025-07-16|||Add StableAdamW Optimizer  (#39446)
2025-07-16|||add test scanner (#39419)
2025-07-16|||Fix missing definition of diff_file_url in notification service (#39445)
2025-07-16|||Add¬†cosine_with_min_lr_schedule_with_warmup_lr_rate¬†scheduler in Trainer (#31870)
2025-07-16|||Change log level from warning to info for scheduled request logging in `ContinuousBatchProcessor` (#39372)
2025-07-16|||Defaults to adamw_torch_fused for  Pytorch>=2.8 (#37358)
2025-07-16|||Fix L270 - hasattr("moe_args") returning False error (#38715)
2025-07-16|||[chat template] add a testcase for kwargs (#39415)
2025-07-16|||Fixed a bug calculating cross entropy loss in `JetMoeForCausalLM` (#37830)
2025-07-16|||Remove double soft-max in load-balancing loss. Fixes #39055 . (#39056)
2025-07-16|||[Core] [Offloading] Fix saving offloaded submodules (#39280)
2025-07-16|||[autodocstring] add video and audio inputs (#39420)
2025-07-16|||CI workflow for performed test regressions (#39198)
2025-07-15|||docs: update LightGlue docs (#39407)
2025-07-15|||docs: update SuperGlue docs (#39406)
2025-07-15|||[vlm] fix loading of retrieval VLMs (#39242)
2025-07-15|||handle training summary when creating modelcard but offline mode is set (#37095)
2025-07-15|||Remove residual quantization attribute from dequantized models (#39373)
2025-07-15|||Remove deprecated audio utils functions (#39330)
2025-07-15|||Fix bugs in pytorch example run_clm when streaming is enabled (#39286)
2025-07-15|||Fix bugs from pipeline preprocessor overhaul (#39425)
2025-07-15|||refactor: remove `set_tracer_provider` and `set_meter_provider` calls (#39422)
2025-07-15|||Fix invalid property (#39384)
2025-07-15|||set document_question_answering pipeline _load_tokenizer to True (#39411)
2025-07-15|||Ignore extra position embeddings weights for ESM (#39063)
2025-07-15|||support loading qwen3 gguf (#38645)
2025-07-15|||Add ModernBERT Decoder Models - ModernBERT, but trained with CLM! (#38967)
2025-07-15|||Fix typo in `/v1/models` output payload (#39414)
2025-07-15|||[refactor] set attention implementation (#38974)
2025-07-14|||[siglip] fix pooling comment (#39378)
2025-07-14|||Update phi4_multimodal.md (#38830)
2025-07-15|||[Docs] Fix typo in CustomTrainer compute_loss method and adjust loss reduction logic (#39391)
2025-07-14|||Use np.pad instead of np.lib.pad. (#39346)
2025-07-14|||Totally rewrite how pipelines load preprocessors (#38947)
2025-07-14|||[examples] fix do_reduce_labels argument for run_semantic_segmentation_no_trainer (#39322)
2025-07-14|||Fix Lfm2 and common tests (#39398)
2025-07-14|||Deprecate AutoModelForVision2Seq (#38900)
2025-07-14|||[Qwen2.5-VL] Fix torch.finfo() TypeError for integer attention_mask_tensor (#39333)
2025-07-14|||[BLIP] remove cache from Qformer (#39335)
2025-07-14|||[shieldgemma] fix checkpoint loading (#39348)
2025-07-12|||Fix overriding Fast Image/Video Processors instance attributes affect other instances (#39363)
2025-07-12|||update docker file to use latest `timm` (for `perception_lm`) (#39380)
2025-07-11|||Update Model Card for Encoder Decoder Model (#39272)
2025-07-11|||fix gpt2 usage doc (#39351)
2025-07-11|||Updated CamemBERT model card to new standardized format (#39227)
2025-07-11|||Update Readme to Run Multiple Choice Script from Example Directory (#39323)
2025-07-11|||Add mistral common support (#38906)
2025-07-11|||Remove device check in HQQ quantizer (#39299)
2025-07-11|||Verbose error in fix mode for utils/check_docstrings.py (#38915)
2025-07-11|||fix failing `test_sdpa_can_dispatch_on_flash` (#39259)
2025-07-11|||update cb TP (#39361)
2025-07-11|||Fix link for testpypi (#39360)
2025-07-11|||PerceptionLM (#37878)
2025-07-10|||Updated Switch Transformers model card with standardized format (Issue #36979) (#39305)
2025-07-10|||[modular] speedup check_modular_conversion with multiprocessing (#37456)
2025-07-10|||Add a default value for `position_ids` in masking_utils (#39310)
2025-07-10|||[Core] [Offloading] Enable saving offloaded models with multiple shared tensor groups (#39263)
2025-07-10|||[tests] tag serve tests as slow  (#39343)
2025-07-10|||[modeling][lfm2] LFM2: Remove deprecated seen_tokens (#39342)
2025-07-10|||LFM2 (#39340)
2025-07-10|||[server] add tests and fix passing a custom `generation_config` (#39230)
2025-07-10|||Handle DAC conversion when using weight_norm with newer PyTorch versions (#36393)
2025-07-10|||fix `phi3` tests (#39312)
2025-07-10|||fix Glm4v batch videos forward (#39172)
2025-07-10|||Delete deprecated stuff (#38838)
2025-07-09|||Fix broken SAM after #39120 (#39289)
2025-07-10|||enable static cache on TP model (#39164)
2025-07-10|||Fix `max_length_q` and `max_length_k` types to `flash_attn_varlen_func` (#37206)
2025-07-10|||Granite speech speedups (#39197)
2025-07-09|||Fix typo: langauge -> language (#39317)
2025-07-09|||docs: update LLaVA-NeXT model card (#38894)
2025-07-09|||skip files in `src/` for doctest (for now) (#39316)
2025-07-09|||Updated the Model docs - for the MARIAN model (#39138)
2025-07-09|||add `stevhliu` to the list in `self-comment-ci.yml` (#39315)
2025-07-09|||Fix consistency and a few docstrings warnings (#39314)
2025-07-10|||üåê [i18n-KO] Translated quark.md to Korean (#39268)
2025-07-09|||Add DeepSeek V2 Model into Transformers (#36400)
2025-07-09|||[sliding window] revert and deprecate (#39301)
2025-07-09|||[modular] Allow method with the same name in case of @property decorator (#39308)
2025-07-09|||skip `test_torchscript_*` for now until the majority of the community ask for it (#39307)
2025-07-09|||fix `aria` tests (#39277)
2025-07-09|||[flash attn 3] bring back flags (#39294)
2025-07-09|||Fix SDPA attention precision issue in Qwen2.5-VL (#37363)
2025-07-09|||[Tests] Update model_id in AIMv2 Tests (#39281)
2025-07-08|||Update T5gemma (#39210)
2025-07-08|||Add torchcodec in docstrings/tests for `datasets` 4.0 (#39156)
2025-07-08|||[lightglue] add support for remote code DISK keypoint detector (#39253)
2025-07-08|||fix flaky `test_generate_compile_model_forward` (#39276)
2025-07-08|||Refactor `PretrainedConfig.__init__` method to make it more explicit (#39158)
2025-07-08|||[smollm3] add tokenizer mapping for `smollm3` (#39271)
2025-07-08|||[pagged-attention] fix off-by-1 error in pagged attention generation (#39258)
2025-07-08|||[CI] fix docs (#39273)
2025-07-08|||Add Aimv2 model (#36625)
2025-07-08|||Add Doge model (#35891)
2025-07-08|||Fix errors when use verl to train GLM4.1v model (#39199)
2025-07-08|||fix recompiles due to instance key, and deepcopy issues (#39270)
2025-07-08|||fix(generation): stop beam search per-instance when heuristic satisfied (#38778)
2025-07-08|||remove broken block (#39255)
2025-07-08|||Skip `test_eager_matches sdpa generate` and update an integration test for blip-like models (#39248)
2025-07-08|||Fix license text, duplicate assignment, and typo in constant names (#39250)
2025-07-08|||fix xpu failures on PT 2.7 and 2.8 w/o IPEX and enable hqq cases on XPU (#39187)
2025-07-08|||Glm 4 doc (#39247)
2025-07-07|||Update LED model card (#39233)
2025-07-07|||fix some flaky tests in `tests/generation/test_utils.py` (#39254)
2025-07-07|||Simplify Mixtral and its modular children (#39252)
2025-07-07|||Add `segmentation_maps` support to MobileNetV2ImageProcessor (#37312)
2025-07-07|||Clarify per_device_train_batch_size scaling in TrainingArguments (#38‚Ä¶ (#38857)
2025-07-07|||Add Korean translation for glossary.md (#38804)
2025-07-07|||Update tiny-agents example (#39245)
2025-07-07|||adjust input and output texts for test_modeling_recurrent_gemma.py (#39190)
2025-07-07|||enable xpu on kv-cache and hqq doc (#39246)
2025-07-07|||Fix patch helper (#39216)
2025-07-07|||RotaryEmbeddings change `is not None` -> `isinstance(..., dict)` (#39145)
2025-07-07|||fix `fastspeech2_conformer` tests (#39229)
2025-07-07|||[bugfix] fix flash attention 2 unavailable error on Ascend NPU (#39166)
2025-07-07|||[modular] Simplify logic and docstring handling (#39185)
2025-07-07|||Make _compute_dynamic_ntk_parameters exportable (#39171)
2025-07-07|||fix bug using FSDP V1 will lead to model device not properly set (#39177)
2025-07-07|||Don't send new comment if the previous one is less than 30 minutes (unless the content is changed) (#39170)
2025-07-07|||fix typo in Gemma3n notes (#39196)
2025-07-07|||[modular] Follow global indexing and attribute setting, and their dependencies (#39180)
2025-07-07|||Fix missing fast tokenizer/image_processor in whisper/qwen2.5-omni processor (#39244)
2025-07-07|||[vjepa2] replace einsum with unsqueeze (#39234)
2025-07-07|||Expectations re-order and corrected FA3 skip (#39195)
2025-07-07|||[video processors] Support float fps for precise frame sampling (#39134)
2025-07-05|||Refactor the way we handle outputs for new llamas and new models (#39120)
2025-07-04|||Update expected values (after switching to A10) - part 8 - Final (#39220)
2025-07-04|||Update expected values (after switching to A10) - part 7 (#39218)
2025-07-04|||Add packed tensor format support for flex/sdpa/eager through the mask! (#39194)
2025-07-03|||Update expected values (after switching to A10) - part 6 (#39207)
2025-07-03|||Update expected values (after switching to A10) - part 5 (#39205)
2025-07-03|||Fix continuous batching in `transformers serve` (#39149)
2025-07-03|||[serve] Cursor support, move docs into separate page, add more examples (#39133)
2025-07-03|||[typing] better return typehints for `from_pretrained` (#39184)
2025-07-03|||Update expected values (after switching to A10) - part 4 (#39189)
2025-07-03|||[`Dia`] Change ckpt path in docs (#39181)
2025-07-03|||Fix many HPU failures in the CI (#39066)
2025-07-03|||Decouple device_map='auto' and tp_plan='auto'  (#38942)
2025-07-03|||when delaying optimizer creation only prepare the model (#39152)
2025-07-03|||[glm4v] fix video inference (#39174)
2025-07-02|||Test fixes for Aria (and some Expectation for llava_next_video) (#39131)
2025-07-02|||Update expected values (after switching to A10) - part 3 (#39179)
2025-07-02|||Update expected values (after switching to A10) - part 2 (#39165)
2025-07-02|||Random serve fixes (#39176)
2025-07-02|||[serve] Model name or path should be required (#39178)
2025-07-02|||[generate] document non-canonical beam search default behavior (#39000)
2025-07-02|||[docs] ViTPose (#38630)
2025-07-02|||Reduce Glm4v model test size significantly (#39173)
2025-07-02|||Fix missing initializations for models created in 2024 (#38987)
2025-07-02|||Blip2 fixes (#39080)
2025-07-02|||Fix multimodal processor get duplicate arguments when receive kwargs for initialization (#39125)
2025-07-02|||üö®üö®üö® [eomt] make EoMT compatible with pipeline (#39122)
2025-07-02|||[smolvlm] fix video inference (#39147)
2025-07-02|||fix default value of config to match checkpionts in LLaVa-OV models (#39163)
2025-07-01|||Add activation sparsity reference in gemma3n doc (#39160)
2025-07-01|||fix `llama` tests (#39161)
2025-07-01|||Update expected values (after switching to A10) (#39157)
2025-07-01|||Suggest jobs to use in `run-slow` (#39100)
2025-07-02|||update bnb ground truth (#39117)
2025-07-01|||fix: remove undefined variable (#39146)
2025-07-01|||Change `@lru_cache()` to `@lru_cache` to match styles from #38883. (#39093)
2025-07-01|||Fix: Ensure wandb logs config in offline mode (#38992)
2025-07-01|||Fix missing fsdp & trainer jobs in daily CI (#39153)
2025-07-01|||[superglue] fix wrong concatenation which made batching results wrong (#38850)
2025-07-01|||[VLMs] support passing embeds along with pixels (#38467)
2025-07-01|||[typing] LlamaAttention return typehint  (#38998)
2025-07-01|||[qwen2-vl] fix FA2 inference (#39121)
2025-07-01|||feat: support indivisible shards for TP model loading and TPlizing. (#37220)
2025-07-01|||fix caching_allocator_warmup with tie weights (#39070)
2025-07-01|||üö® Don't use cache in non-generative models (#38751)
2025-07-01|||Several fixes for Gemma3n (#39135)
2025-07-01|||Fix key mapping for VLMs (#39029)
2025-06-30|||[Whisper] update token timestamps tests (#39126)
2025-06-30|||Update BigBirdPegasus model card (#39104)
2025-06-30|||switch default xpu tp backend to pytorch built-in XCCL from pytorch 2.8 (#39024)
2025-06-30|||docs: correct two typos in awesome-transformers.md (#39102)
2025-06-30|||Enable XPU doc (#38929)
2025-06-30|||Fix chat (#39128)
2025-06-30|||Licenses (#39127)
2025-06-30|||Split `transformers chat` and `transformers serve`  (#38443)
2025-06-30|||All CI jobs with A10 (#39119)
2025-06-30|||docs: Gemma 3n audio encoder (#39087)
2025-06-30|||Fix some bug for finetune and batch infer For GLM-4.1V (#39090)
2025-06-30|||fix UT failures on XPU w/ stock PyTorch 2.7 & 2.8 (#39116)
2025-06-27|||skip some `test_sdpa_can_dispatch_on_flash` (#39092)
2025-06-28|||Fixes the failing test `test_is_split_into_words` in `test_pipelines_token_classification.py` (#39079)
2025-06-27|||Sandeepyadav1478/2025 06 19 deberta v2 model card update (#38895)
2025-06-27|||[fix] Add FastSpeech2ConformerWithHifiGan (#38207)
2025-06-27|||TST Fix PEFT integration test bitsandbytes config (#39082)
2025-06-27|||Fix: unprotected import of tp plugin (#39083)
2025-06-28|||Add Fast Image Processor for Chameleon (#37140)
2025-06-27|||fix `dots1` tests (#39088)
2025-06-27|||guard torch distributed check (#39057)
2025-06-27|||Add Fast Image Processor for mobileViT (#37143)
2025-06-27|||add fast image processor nougat (#37661)
2025-06-27|||TST PEFT integration tests with pipeline generate (#39086)
2025-06-27|||fixed typo for docstring in prepare_inputs method (#39071)
2025-06-27|||fix `mistral3` tests (#38989)
2025-06-27|||[Whisper] üö® Fix pipeline word timestamp: timestamp token is end of token time !!! (#36632)
2025-06-27|||Pipeline: fix unnecessary warnings (#35753)
2025-06-27|||‚ú® Add EoMT Model ||  üö® Fix Mask2Former loss calculation (#37610)
2025-06-27|||fix a bunch of XPU UT failures on stock PyTorch 2.7 and 2.8 (#39069)
2025-06-27|||Uninstallling Flash attention from quantization docker (#39078)
2025-06-27|||Fix initialization of OneFormer (#38901)
2025-06-27|||fix `Gemma3nProcessorTest` (#39068)
2025-06-27|||Cleanup Attention class for Siglip and dependent models (#39040)
2025-06-27|||[Whisper] fix shape mismatch in tests (#39074)
2025-06-26|||[docs] Tensor parallelism (#38241)
2025-06-26|||[docs] @auto_docstring (#39011)
2025-06-26|||Update PEGASUS-X model card (#38971)
2025-06-26|||[docs] Model contribution (#38995)
2025-06-26|||fix `layoutlmv3` tests (#39050)
2025-06-26|||Update SuperPoint model card (#38896)
2025-06-26|||fix `t5gemma` tests (#39052)
2025-06-26|||fix `test_compare_unprocessed_logit_scores` (#39053)
2025-06-26|||[`Flex Attn`] Fix torch 2.5.1 incompatibilities (#37406)
2025-06-26|||Dev version
2025-06-26|||[Modeling] Fix encoder CPU offloading for whisper (#38994)
2025-06-26|||Gemma 3n (#39059)
2025-06-26|||[tests] remove tests from libraries with deprecated support (flax, tensorflow_text, ...) (#39051)
2025-06-26|||[Whisper] Pipeline: handle long form generation (#35750)
2025-06-26|||add _keep_in_fp32_modules_strict (#39058)
2025-06-26|||fix condition where torch_dtype auto collides with model_kwargs. (#39054)
2025-06-26|||[qwen2-vl] fix vision attention scaling (#39043)
2025-06-26|||polishing docs: error fixes for clarity (#39042)
2025-06-26|||Create test for #38916 (custom generate from local dir with imports) (#39015)
2025-06-26|||Internvl fix (#38946)
2025-06-26|||[`Generate`] Fix no grad on some models (#39008)
2025-06-26|||Add Dia model (#38405)
2025-06-26|||Fix Bad Outputs in Fast Path for GraniteMoeHybrid (#39033)
2025-06-26|||Granite speech speedup + model saving bugfix (#39028)
2025-06-25|||[tests] remove TF tests (uses of `require_tf`) (#38944)
2025-06-25|||Two ReDOS fixes (#39013)
2025-06-25|||[Kyutai-STT] correct model type + model id (#39035)
2025-06-25|||Add SmolLM3 (#38755)
2025-06-25|||refactor: remove custom BarkLayerNorm (#39003)
2025-06-25|||Fix grammatical error in models documentation (#39019)
2025-06-25|||Remove script datasets in tests (#38940)
2025-06-25|||fix gemma3 grad acc (#37208)
2025-06-26|||fix: astronomical loss with ModernBERT when using gradient checkpointing (#38982) (#38983)
2025-06-25|||Support for Flash Attention 3 (#38972)
2025-06-25|||Fix the seamless_m4t cannot work on Gaudi (#38363)
2025-06-25|||[Model] add dots1 (#38143)
2025-06-25|||Encoder-Decoder Gemma (#38332)
2025-06-25|||GLM-4.1V Model support (#38431)
2025-06-25|||Drop unnecessary tokens in GPT2Model generation (#39016)
2025-06-25|||[video processor] support torchcodec and decrease cuda memory usage (#38880)
2025-06-25|||[AutoModelForMaskGeneration] Remove duplicate code (#38622)
2025-06-25|||Fix graph break in torch.compile when using FA2 with attention_mask=None and batch size > 1 (#37332)
2025-06-25|||Add zero dim tensor check when using flash_attention (#38280)
2025-06-25|||[LightGlue] Fixed attribute usage from descriptor_dim to keypoint_detector_descriptor_dim (#39021)
2025-06-24|||Add Hugging Face authentication procedure for IDEs (PyCharm, VS Code,‚Ä¶ (#38954)
2025-06-24|||[HPU][Critical Issue Fix] ThreadPool instead of Pool for parallel pre-processing (#39002)
2025-06-24|||Skip sdpa dispatch on flash test due to unsupported head dims (#39010)
2025-06-24|||Update self-comment-ci.yml user list (#39014)
2025-06-24|||Fix bugs in DynamicCache (#37880)
2025-06-24|||Add kyutai stt (#38909)
2025-06-24|||Add kernelize to transformers (#38205)
2025-06-24|||Granite speech - minor fixes to support training with the HF trainer (#38833)
2025-06-24|||Fix undeterministic order in modular dependencies (#39005)
2025-06-24|||Skip non-selected experts for qwen3_moe (#38133)
2025-06-24|||Update attention_visualizer.py (#37860)
2025-06-24|||Added scikit-learn to the example image-classification requirements.txt (#37506)
2025-06-24|||Fixes for Arcee model (#39001)
2025-06-24|||Add Arcee model support (#38621)
2025-06-24|||[`Attention`] Small fix on output attentions (#38948)
2025-06-24|||Removing extra space in large command for speech-pretraining example (#38705)
2025-06-24|||[qwen] refactor attentions for vision/audio (#38930)
2025-06-24|||üî¥ Update default `dtype` for pipelines to `auto` (#38882)
2025-06-23|||[docs] Typos - Single GPU efficient training features (#38964)
2025-06-23|||Fix `rag` (#38585)
2025-06-23|||[Feature] Support `is_split_into_words` in the `TokenClassificationPipeline`. (#38818)
2025-06-23|||fix `mistral` and `mistral3` tests (#38978)
2025-06-23|||Add support for auto_docstring with model outputs (#38242)
2025-06-23|||fix: add __bool__ operator to tokenizer to avoid bloated asserts (#38899)
2025-06-23|||Add Idefics2/3 and SmolVLM Fast image processors + improvements for fast image processors (#38157)
2025-06-23|||Break tie in Expectations and gemma3 fixes (#38943)
2025-06-23|||Apply GradientCheckpointingLayer to the whole repo (#38913)
2025-06-23|||Remove dead protected imports (#38980)
2025-06-23|||[modular] CLI allows positional arguments, and more defaults names for the optional arg (#38979)
2025-06-23|||Fix(informer): Correct tensor shape for input_size=1 (#38856)
2025-06-23|||Fix DTensor import compatibility for PyTorch < 2.5 (#38836)
2025-06-23|||Gaudi3 CI (#38790)
2025-06-21|||Update blip model card (#38513)
2025-06-20|||Fix custom generate from local directory (#38916)
2025-06-20|||Switch to use A10 progressively (#38936)
2025-06-20|||Fix more flaky `test_initialization` (#38932)
2025-06-20|||Correctly raise error for awq quantization (#38945)
2025-06-20|||Pin PyTorch extras for AMD containers (#38941)
2025-06-20|||Add kwargs for timm.create_model in TimmWrapper (#38860)
2025-06-20|||[static cache] fix device map per layer in VLMs (#38488)
2025-06-20|||Remove `ALL_LAYERNORM_LAYERS` (#38922)
2025-06-20|||add pytorch-xpu Dockerfile (#38875)
2025-06-20|||Modernbert fixes (#38912)
2025-06-20|||Skip some tests for now (#38931)
2025-06-19|||Remove deprecated classes in modeling_utils.py (#38919)
2025-06-19|||feat: add flexible Liger Kernel configuration to TrainingArguments (#38911)
2025-06-19|||Allow make-fixup on main branch, albeit slowly (#38892)
2025-06-19|||feat: Add granite architectures to auto tokenizer name mappings (#38802)
2025-06-19|||Fix ReDOS in tokenizer digit substitution (#38844)
2025-06-19|||Skip sdpa tests if submodule does not support sdpa (#38907)
2025-06-19|||Fix `FalconMambaIntegrationTests` (#38566)
2025-06-19|||align xpu's autocast behavior w/ cuda by using device agnostic torch APIs (#38284)
2025-06-19|||Fix unnecessary super calls (#38897)
2025-06-19|||Fix `fsmt` tests (#38904)
2025-06-19|||[phi-4] use mel filters from audio utils (#36966)
2025-06-19|||Use `raise from e` in `hub.py` utility (#37241)
2025-06-19|||Add support for specifying revisions when pushing to Hub via internal Trainer call (#36852)
2025-06-19|||Update bamba model card (#38853)
2025-06-18|||[video processor] fix slow tests (#38881)
2025-06-18|||36978 | Fast image processor for DPT model (#37481)
2025-06-18|||Docs: Add custom fine-tuning tutorial to TrOCR model page (#38847)
2025-06-19|||log: Add logging when using split_batches and per_device_train_batch_size (#38633)
2025-06-19|||[bugfix] fix ATTN_MASK_NPU device mismatch error on multi-device NPU ‚Ä¶ (#38876)
2025-06-18|||Fix loop var naming (#38885)
2025-06-18|||More PYUP fixes (#38883)
2025-06-18|||null deepspeed_plugin in args for wandb callback fake trainer (#38867)
2025-06-18|||Fixed markdown for BertTokenizer's '[CLS]' token. (#38506)
2025-06-18|||Fix HQQ model param device transfer issue (#38466)
2025-06-18|||Fix `qwen3_moe` tests (#38865)
2025-06-18|||üö®üö® Fix initialization of Mask2Former (#38864)
2025-06-18|||Fix `phi4_multimodal` tests (#38816)
2025-06-18|||enable misc test cases on XPU (#38852)
2025-06-17|||Post-PR fixes! (#38868)
2025-06-17|||No more Tuple, List, Dict (#38797)
2025-06-17|||Update roc bert docs (#38835)
2025-06-18|||Update CvT documentation with improved usage examples and additional ‚Ä¶ (#38731)
2025-06-17|||Add LightGlue model (#31718)
2025-06-17|||Fix `qwen3` tests (#38862)
2025-06-17|||Improve `auxiliary_in_channels` default behavior in UperNet (#37540)
2025-06-17|||Fix `qwen2_5_vl` tests (#38845)
2025-06-17|||Allow customization of sdpa in executorch.py (#38827)
2025-06-17|||Fix incorrect width ratio calculation in Llama4 image processor (#38842)
2025-06-17|||[video processor] fix BC when no video config if found (#38840)
2025-06-16|||Remove merge conflict artifacts in Albert model doc (#38849)
2025-06-16|||Updated aya_vision.md (#38749)
2025-06-16|||GraniteMoeHybrid: Allow for only shared expert case. (#38801)
2025-06-16|||[BugFix] QA pipeline edge case: `align_to_words=True` in `QuestionAnsweringPipeline` can lead to duplicate answers (#38761)
2025-06-16|||Fix broken tag in Longformer model card (#38828)
2025-06-16|||Fix broken notebooks link in Italian training docs (#38834)
2025-06-16|||Fix peft integration (#38841)
2025-06-16|||add default mapping to peft integration
2025-06-16|||bugfix: propage weight key_mapping to peft to fix 3.52 VLM renaming  (#38627)
2025-06-16|||Fix redundant code in Janus (#38826)
2025-06-16|||[internvl] fix video inference (#38811)
2025-06-14|||Updated Albert model Card (#37753)
2025-06-14|||[docs] updated roberta model card (#38777)
2025-06-13|||[docs] Update docs moved to the course (#38800)
2025-06-13|||fixed docstring in modular_qwen2_5_vl.py (#38798)
2025-06-13|||Add V-JEPA for video classification model (#38788)
2025-06-13|||Fix trainer.py not showing signature columns (#38465)
2025-06-13|||Fix a minor security issue (#38815)
2025-06-13|||change fsdp_strategy to fsdp in TrainingArguments in accelerate doc (#38807)
2025-06-13|||Refactor DBRX tests to use CausalLMModelTest base classes (#38475)
2025-06-13|||Use `wandb.run.url` instead of `wandb.run.get_url()` (deprecated) (#38817)
2025-06-13|||Expectation fixes and added AMD expectations (#38729)
2025-06-13|||Fix `llava_next` tests (#38813)
2025-06-13|||Better pipeline type hints ‚ú® (#38049)
2025-06-13|||Simplify and update trl examples (#38772)
2025-06-13|||Use HF papers (#38184)
2025-06-13|||Disable custom MRA kernels for ROCm (#38738)
2025-06-13|||Unbreak optimum-executorch (#38646)
2025-06-13|||Fix configs and doc for the Qwens (#38808)
2025-06-13|||Fix erroneous docstring for the ordering of SWA layers (#38794)
2025-06-13|||[docs] update cache docs with new info (#38775)
2025-06-12|||refactor create_token_type_ids_from_sequences (#37681)
2025-06-12|||Updated moonshine modelcard (#38711)
2025-06-12|||Add missing div in Pegasus model card (#38773)
2025-06-12|||[Docs] New DiT model card (#38721)
2025-06-12|||Remove all traces of `low_cpu_mem_usage` (#38792)
2025-06-12|||build: :pushpin: Remove upper bound on PyTorch (#38789)
2025-06-12|||Fix `mllama` (#38704)
2025-06-12|||Initialize flash attn flag (#38768)
2025-06-12|||Fix Typos in Comments: "quantitation" ‚Üí "quantization", "averege" ‚Üí "average" (#38766)
2025-06-12|||Reword README in light of model definitions (#38762)
2025-06-12|||Fix `llava_onevision` tests (#38791)
2025-06-12|||Fix `qwen_2_5 omni` (#38658)
2025-06-12|||[docs] Add int4wo + 2:4 sparsity example to TorchAO README (#38592)
2025-06-12|||Update PULL_REQUEST_TEMPLATE.md (#38770)
2025-06-12|||Reduce verbosity for `average_tokens_across_devices=True` and `world size = 1` (#38785)
2025-06-12|||Skip some export tests on torch 2.7 (#38677)
2025-06-12|||[video processors] support frame sampling within processors (#38105)
2025-06-12|||Fix masking utils (#38783)
2025-06-12|||[Hotfix] Fix style bot  (#38779)
2025-06-12|||[masking utils] check `None` instead of try/except (#38561)
2025-06-11|||Add Qwen2 MoE model card (#38649)
2025-06-11|||Update altCLIP model card (#38306)
2025-06-11|||chore(pixtral): emit block attention mask when using flash attention (#38741)
2025-06-11|||Make style bot trigger CI after push (#38754)
2025-06-11|||Update pegasus model card (#38675)
2025-06-11|||fix(qwen3_moe): pass kwargs to self_attn (#38691)
2025-06-11|||Deprecate TF + JAX (#38758)
2025-06-11|||Update repo consistency check (#38763)
2025-06-11|||Remove IPEX requirement for bitsandbytes on CPU (#38594)
2025-06-11|||Prepare for TF+Jax deprecation (#38760)
2025-06-11|||Better typing for num_items_in_batch (#38728)
2025-06-11|||Add V-JEPA 2 (#38746)
2025-06-11|||Add z-loss to Bamba for v2 (#37842)
2025-06-11|||Revert "Trigger doc-builder job after style bot" (#38735)
2025-06-11|||[DeepSeek-V3] implement when q_lora_rank is None (#38743)
2025-06-11|||fix: bf16 with TPU is allowed in configuration (#38670)
2025-06-11|||from 1.11.0, torchao.prototype.low_bit_optim is promoted to torchao.optim (#38689)
2025-06-11|||fix: Add method to get image features in PaliGemmaForConditionalGeneration (#38730)
2025-06-11|||[llava] fix integration tests with Siglip (#38732)
2025-06-11|||Fixed a multiple-devices issue in SmolVLM model (#38736)
2025-06-10|||New canine model card (#38631)
2025-06-10|||Add AGENTS.md (#38734)
2025-06-10|||Fix typo in Language Modeling example scripts and update TPU type (#38652)
2025-06-10|||[add-new-model-like] Robust search & proper outer '),' in tokenizer mapping (#38703)
2025-06-10|||Use OSError (#38712)
2025-06-10|||Fix `llava` tests (#38722)
2025-06-10|||Logging message for ``` is_bitsandbytes_available() ```  (#38528)
2025-06-10|||Update some tests for torch 2.7.1 (#38701)
2025-06-10|||Fix smart resize (#38706)
2025-06-10|||Standardize ByT5 model card format (#38699)
2025-06-09|||Fix `aya_vision` test (#38674)
2025-06-09|||Created model card for xlm-roberta-xl (#38597)
2025-06-09|||Update XLM-RoBERTa model documentation with enhanced usage examples and improved layout (#38596)
2025-06-09|||Created model card for XLM model (#38595)
2025-06-09|||Drop as_target_processor from the _call_ and pad methods (#38642)
2025-06-09|||Docs: update bitsandbytes torch.compile compatibility (#38651)
2025-06-09|||Fix TypeError: 'NoneType' object is not iterable for esm (#38667) (#38668)
2025-06-09|||Fix retrieve function signature and remove faiss requirement (#38624)
2025-06-09|||Fix some models import (#38694)
2025-06-09|||Fix attention mask expansion when converting to executorch (#38637)
2025-06-09|||fix: "check out" as verb (#38678)
2025-06-09|||Fixed modeling_auto.py MODEL_FOR_MASK_GENERATION_MAPPING_NAMES variable (#38664)
2025-06-09|||Fix qwen2-audio chat template audio placeholder insertion (#38640)
2025-06-08|||Use torch 2.7.1 on daily CI (#38620)
2025-06-07|||Fix `InternVL` integration test (#38612)
2025-06-06|||Skip torchscript tests for 2 models (#38643)
2025-06-07|||remove ipex_optimize_model usage (#38632)
2025-06-06|||Better CI (#38552)
2025-06-06|||fix torch_dtype on awq (#38463)
2025-06-06|||fix total batch size calculation in trainer (#38286)
2025-06-06|||Don't run `AriaForConditionalGenerationModelTest` on CircleCI (#38615)
2025-06-06|||fix: support grad clipping for TP through replicating non-sharded modules (#36132)
2025-06-06|||Improve `test_initialization` for `SwiftFormer` (#38636)
2025-06-06|||update `ColQwen2ModelIntegrationTest` (#38583)
2025-06-06|||[generation] bring back tests on vision models (#38603)
2025-06-06|||Use torch 2.7.1 on CircleCI jobs (#37856)
2025-06-06|||Improve `test_initialization` (#38607)
2025-06-06|||enable more test cases on xpu (#38572)
2025-06-06|||Fix `MiniMax` (docs and integration tests checkpoint) (#38575)
2025-06-06|||Updated Aria model card (#38472)
2025-06-06|||[Nit] Add Note on SigOpt being in Public Archive Mode (#38610)
2025-06-06|||Fix typo in LLaVa documentation (#38618)
2025-06-06|||docs: fix dark mode logo display. (#38586)
2025-06-05|||Fix `return_dict=False` giving errors in a few VLM models (#38519)
2025-06-05|||Remove `isort` from dependencies (#38616)
2025-06-05|||fix spelling errors  (#38608)
2025-06-05|||Avoid overwrite existing local implementation when loading remote custom model (#38474)
2025-06-05|||Allow `mlm_probability` to be set to `None` when `mlm=False` in DataCollatorForLanguageModeling (#38522) (#38537)
2025-06-05|||Bump torch from 2.6.0 to 2.7.1 in /examples/flax/vision (#38606)
2025-06-05|||pin pandas (#38605)
2025-06-05|||Remove custom pytest and pluggy (#38589)
2025-06-05|||[qwen-omni] fix sliding window (#38525)
2025-06-05|||added fast image processor for ZoeDepth and expanded tests accordingly (#38515)
2025-06-04|||Updated deprecated typing imports with equivalents for Python 3.9+ (#38546)
2025-06-04|||New gpt neo model card (#38505)
2025-06-04|||tests/roformer: fix couple roformer tests on gpus (#38570)
2025-06-04|||[Dinov2] Enable device_map="auto" support (#38487)
2025-06-04|||feat: add `repository` field to benchmarks table (#38582)
2025-06-04|||Docs: fix code formatting in torchao docs (#38504)
2025-06-04|||allow custom head_dim for qwen2_moe (#37188)
2025-06-04|||fix(attention_visualizer): add default value for image_seq_length (#38577)
2025-06-04|||[`FlexAttn`] Fix models with unique characteristics (#38433)
2025-06-04|||Fix `deepseekv3` (#38562)
2025-06-04|||update `utils/notification_service.py` for AMD vs Nvidia (#38563)
2025-06-04|||Fix `chameleon` tests (#38565)
2025-06-04|||Add support for MiniMax's MiniMax-Text-01 (#35831)
2025-06-04|||[janus] Fix failing tests on mi3XX (#38426)
2025-06-03|||[docs] Format fix (#38414)
2025-06-03|||Fix hqq issue (#38551)
2025-06-03|||Name change AOPermod -> ModuleFqn (#38456)
2025-06-03|||Fix `utils/notification_service.py` (#38556)
2025-06-03|||Explicitly setting encoding in tokenization_utils_base.py (#38553)
2025-06-03|||[TP] Change command in tests to `python3` (#38555)
2025-06-03|||[bugfix] [WIP] fix apply_rotary_emb error on Ascend NPU (#38491)
2025-06-03|||Update docker image to use `av` (#38548)
2025-06-03|||update emu3 test (#38543)
2025-06-03|||Don't use default attn if pre-set in sub-config (#38526)
2025-06-03|||[tests] expand flex-attn test for vision models (#38434)
2025-06-02|||Fix blip2 tests (#38510)
2025-06-02|||Fix `Gemma2IntegrationTest` (#38492)
2025-06-02|||Remove type annotation in Siglip Attention Module (#38503)
2025-06-02|||Num parameters in model.safetensors.index.json (#38531)
2025-06-02|||[flax/mistral] support sliding_window: null in config (#37402)
2025-06-02|||Fix amp deprecation issue (#38100)
2025-06-02|||remove unhandled parameter (#38145)
2025-06-02|||Add ColQwen2 to ü§ó transformers (#35778)
2025-06-02|||[generate] move `SinkCache` to a `custom_generate` repo (#38399)
2025-06-02|||[generate] add soft deprecations on custom generation methods (#38406)
2025-06-02|||Update Loss Functions to Accept Tensor num_items_in_batch (#38029)
2025-06-02|||[seamless_m4t] Skip some tests when speech is not available (#38430)
2025-06-02|||Fix setting FLASH_ATTENTION_DETERMINISTIC after importing (#37185)
2025-06-02|||Remove deprecated use_flash_attention_2 parameter (#37131)
2025-05-31|||[docs] add xpu environment variable for gpu selection (#38194)
2025-05-30|||protect dtensor import  (#38496)
2025-05-30|||Align TP check (#38328)
2025-05-30|||[Tests] Reduced model size for albert-test model (#38480)
2025-05-30|||Bump torch from 2.2.0 to 2.6.0 in /examples/flax/vision (#37618)
2025-05-30|||Fix incorrect bbox_embed initialization when decoder_bbox_embed_share=False in GroundingDINO (#38238)
2025-05-30|||Fix convert_internvl_weights_to_hf.py to support local paths (#38264)
2025-05-30|||make it go brrrr (#38409)
2025-05-30|||fix: handle no scheduler passed by user (#38407)
2025-05-30|||[Qwen2.5-Omni] Fix dtype of cos,sin when used with flash attention (#38453)
2025-05-29|||Fix `Gemma3IntegrationTest` (#38471)
2025-05-29|||Cleanup `BatchFeature` and `BatchEncoding` (#38459)
2025-05-29|||Fix TypeError in save_pretrained error handling (fixes #38422) (#38449)
2025-05-29|||üî¥ [VLM] modeling updates (#38317)
2025-05-29|||[Tests] Clean up test cases for few models (#38315)
2025-05-28|||feat: add cache retention for requests (#38446)
2025-05-28|||Fix GLM4 checkpoints (#38412)
2025-05-28|||Merge type hints from `microsoft/python-type-stubs` (post dropping support for Python 3.8) (#38335)
2025-05-29|||Model card for mobilenet v1 and v2 (#37948)
2025-05-29|||Updated the model card for ViTMAE (#38302)
2025-05-28|||Updated the Model docs - for the ALIGN model (#38072)
2025-05-28|||Fix handling of slow/fast image processors in image_processing_auto.py (#38161)
2025-05-28|||Fix `from_args_and_dict` ProcessorMixin (#38296)
2025-05-28|||Fix MoE gradient test (#38438)
2025-05-28|||Remove redundant test_sdpa_equivalence test (#38436)
2025-05-28|||Trigger doc-builder job after style bot (#38398)
2025-05-28|||Fix convert weights for InternVL (#38233)
2025-05-28|||Fix typo in tokenization_utils_base.py docstring (#38418)
2025-05-28|||[core] support tensor-valued _extra_state values in `from_pretrained` (#38155)
2025-05-28|||üî¥[`Attention`] Attention refactor for Whisper-based models (#38235)
2025-05-28|||make Llama4TextMoe forward more readable (#37529)
2025-05-28|||Fix CircleCI not triggered when PR is opened from a branch of `huggingface/transformers` (#38413)
2025-05-28|||Update error when using additional and/or masks (#38429)
2025-05-28|||Disable mi210 scheduled CI (#38411)
2025-05-28|||enable large_gpu and torchao cases on XPU (#38355)
2025-05-28|||Update `CsmForConditionalGenerationIntegrationTest` (#38424)
2025-05-28|||[qwen-vl] Look for vocab size in text config (#38372)
2025-05-28|||Fix an error in verify_tp_plan for keys without '.' (#38420)
2025-05-28|||Change slack channel for mi250 CI (#38410)
2025-05-28|||Add mi300 to amd daily ci workflows definition (#38415)
2025-05-27|||Updated model card for OLMo2 (#38394)
2025-05-27|||Falcon-H1 - Fix auto_docstring and add can_return_tuple decorator (#38260)
2025-05-28|||Update granite.md (#37791)
2025-05-28|||New bart model card (#37858)
2025-05-28|||Updated BERTweet model card. (#37981)
2025-05-27|||Updated BigBird Model card as per #36979. (#37959)
2025-05-27|||Updated Zoedepth model card (#37898)
2025-05-27|||Update Model Card for Mamba-2 (#37951)
2025-05-27|||[mllama] Allow `pixel_values` with `inputs_embeds` (#38334)
2025-05-27|||[tests] remove overload for deleted test (`test_offloaded_cache_implementation`) (#37896)
2025-05-27|||[cleanup] delete deprecated kwargs in qwen2_audio üßπ  (#38404)
2025-05-27|||[CSM] update model id (#38211)
2025-05-27|||Add report_repo_id to mi300 workflow (#38401)
2025-05-27|||[CSM] infer codec model with no_grad + audio eos label (#38215)
2025-05-27|||Fix Qwen2.5-VL Video Processor (#38366)
2025-05-27|||[chat] use the checkpoint's `generation_config.json` as base parameterization (#38330)
2025-05-27|||Fix convert to original state dict for VLMs (#38385)
2025-05-27|||[chat] improvements for thinking models and reduce default verbosity (#38322)
2025-05-27|||guard size mismatch check to only quantized models (#38397)
2025-05-27|||[aya vision] fix processor for vLLM (#38371)
2025-05-27|||[video utils] group and reorder by number of frames (#38374)
2025-05-27|||[paligemma] fix processor with suffix (#38365)
2025-05-27|||[transformers x vLLM] standardize processors (#37915)
2025-05-27|||Fix image token mask in Gemma3 (#38295)
2025-05-26|||Add AMD MI300 CI caller leveraging self-hosted runner scale set workflow in hf-workflows (#38132)
2025-05-26|||Stop autoconverting custom code checkpoints (#37751)
2025-05-26|||update gemma tests (#38384)
2025-05-26|||[cli] cli usable without torch (#38386)
2025-05-26|||:rotating_light: :rotating_light: Fix custom code saving (#37716)
2025-05-26|||Stop TF weight rename reDOS (#38325)
2025-05-26|||fix typo: `tokenizer` -> `tokenize` (#38357)
2025-05-26|||fix typos (#38336)
2025-05-26|||Better check in `initialize_weights` (#38382)
2025-05-26|||Use one `utils/notification_service.py` (#38379)
2025-05-26|||for now disable compile (#38383)
2025-05-26|||Improved cache docs (#38060)
2025-05-26|||[Falcon H1] Fix slow path forward pass (#38320)
2025-05-26|||Protect `get_default_device` for torch<2.3 (#38376)
2025-05-26|||Fix incorrect batching audio index calculation for Phi-4-Multimodal  (#38103)
2025-05-26|||Fix all import errors based on older torch versions (#38370)
2025-05-26|||[`OPT`] Fix attention scaling (#38290)
2025-05-26|||switch to device agnostic device calling for test cases (#38247)
2025-05-26|||[VLMs] add helpers for get/set embedding (#38144)
2025-05-25|||Uninstall `kernels` for AMD docker images (#38354)
2025-05-25|||Hot fix for AMD CI workflow (#38349)
2025-05-24|||new failure CI reports for all jobs  (#38298)
2025-05-23|||[docs]: update roformer.md model card (#37946)
2025-05-23|||docs(swinv2): Update SwinV2 model card to new standard format (#37942)
2025-05-23|||Update BioGPT model card (#38214)
2025-05-23|||Remove duplicate docstring: resample (#38305)
2025-05-23|||Never fallback to eager implicitly (#38327)
2025-05-23|||Use Gradient Checkpointing Layer in Jamba & Blip Related Models (#38310)
2025-05-23|||:rotating_light: :rotating_light: Inherited CausalLM Tests (#37590)
2025-05-23|||Enhance Model Loading By Providing Parallelism, Uses Optional Env Flag (#36835)
2025-05-23|||[`FlexAttention`] Reenable flex for encoder-decoder and make the test more robust (#38321)
2025-05-23|||refactor can_save_slow_tokenizer (#37722)
2025-05-23|||[performance_optim] reduce frequency of declaring attention_mask in Ascend NPU flash attention (#38278)
2025-05-23|||üö®Early-errorüö® config will error out if `output_attentions=True` and the attn implementation is wrong (#38288)
2025-05-23|||Fix some tests (especially compile with fullgraph=True on Python<3.11) (#38319)
2025-05-23|||add `vasqu` to `self-comment-ci.yml` (#38324)
2025-05-23|||[custom_generate] don't forward `custom_generate` and `trust_remote_code` (#38304)
2025-05-23|||Expose AutoModelForTimeSeriesPrediction for import (#38307)
2025-05-23|||[Whisper + beam search] fix usage of `beam_indices` (#38259)
2025-05-23|||[tf/flax] handle `forced_decoder_ids` deletion (#38316)
2025-05-23|||Adds use_repr to model_addition_debugger_context (#37984)
2025-05-23|||Fix typo: change 'env' to 'environment' in .circleci/config.yml (#38273)
2025-05-23|||Fix run_slow (#38314)
2025-05-23|||[emu3] fix conversion script (#38297)
2025-05-23|||[Tests] Cleanup Janus Testcase (#38311)
2025-05-22|||Oups typo for HybridChunkedCache (#38303)
2025-05-22|||Add CB (#38085)
2025-05-22|||Fix HybridChunedCache & Llama4 (#38299)
2025-05-22|||üî¥üî¥üî¥ [`Attention`] Refactor Attention Interface for Bart-based Models (#38108)
2025-05-22|||Update CI Docker base image for AMD tests (#38261)
2025-05-22|||refine `transformers env` output (#38274)
2025-05-22|||More typing in src/transformers/training_args.py (#38106)
2025-05-22|||Fix tp error when torch distributed is already initialized (#38294)
2025-05-22|||add `liger-kernel` to docker file (#38292)
2025-05-22|||üö®üö®[core] Completely rewrite the masking logic for all attentions (#37866)
2025-05-22|||[Whisper] handle deprecation of `forced_decoder_ids` (#38232)
2025-05-22|||[whisper] move processor test into processor test file üßπ  (#38266)
2025-05-22|||add XPU info print in print_env (#38282)
2025-05-22|||docs(swin): Update Swin model card to standard format (#37628)
2025-05-21|||Update Model Card for Mamba (#37863)
2025-05-21|||Protect ParallelInterface (#38262)
2025-05-22|||Remove Japanese sequence_classification doc and update references (#38246)
2025-05-21|||assign the correct torchao data layout for xpu (#37781)
2025-05-21|||Fix: missing else branch to handle "--load_best_model_at_end" in training_args.py (#38217)
2025-05-21|||Improve typing in TrainingArgument (#36944)
2025-05-21|||Simplify DTensor Check for modeling_utils.py (#38245)
2025-05-21|||[whisper] small changes for faster tests (#38236)
2025-05-21|||Clearer error on import failure (#38257)
2025-05-21|||Add tearDown method to Quark to solve OOM issues (#38234)
2025-05-21|||fix multi-image case for llava-onevision (#38084)
2025-05-21|||[`compile`] re-enable for Qwen-VL models (#38127)
2025-05-21|||[Falcon H1] Fix Typo in Integration Test (#38256)
2025-05-21|||[MODEL] Add Falcon H1 (#38249)
2025-05-21|||tp plan should not be NONE (#38255)
2025-05-20|||Revert parallelism temporarily (#38240)
2025-05-20|||CI reporting improvements (#38230)
2025-05-20|||Protect ParallelInterface
2025-05-20|||v4.53.0.dev0
2025-05-20|||[gemma3] fix bidirectional attention mask (#38080)
2025-05-20|||[mllama] fix loading and inference (#38223)
2025-05-20|||Add padding-free to bamba (#35861)
2025-05-20|||Fixing Bitnet after use_rms_norm introduction (#38229)
2025-05-20|||Enable Quantize KV Cache for Mistral Model (#35042)
2025-05-20|||parallelism goes brrr (#37877)
2025-05-20|||Fix Llama4 (#38222)
2025-05-20|||Mamba2 remove unecessary test parameterization (#38227)
2025-05-20|||Minor llama4 fixes (#38123)
2025-05-20|||fix dead flax links modeling_flax_pytorch_utils.py (#38212)
2025-05-20|||Make `train_dataset` attribute in `_get_train_sampler` optional  (#38226)
2025-05-20|||In Llama4 fix wrongly inverted causal attention mask when using SDPA implementation (#38094)
2025-05-20|||Disable torchscript tests for AriaForConditionalGenerationModelTest (#38225)
2025-05-20|||Add support to Marimo Notebooks and Enverge.ai (#38210)
2025-05-20|||New cache tests and refactored Hybrid Cache (#37972)
2025-05-20|||Add `Llama4TextModel` to `AutoModel` mapping (#38162)
2025-05-20|||Remove trust_remote_code=True tests from bnb quantization tests (MPT now integrated) (#38206)
2025-05-20|||[fix] sliding window attention mask (#38045)
2025-05-20|||Fix broken example generation script for Llama3 (#38062)
2025-05-20|||Fix: make docs work better with doc builder (#38213)
2025-05-20|||enable misc cases on XPU & use device agnostic APIs for cases in tests (#38192)
2025-05-20|||Qwen2.5-Omni: Update modeling_qwen2_5_omni.py to fix error when loading quantized weights with AutoAWQ.  (#38013)
2025-05-19|||Feat: save_pretrained for tensor parallel (and other parallelisms) models (#37919)
2025-05-20|||[doc] fix bugs in `how_to_hack_models.md` (#38198)
2025-05-20|||Translating model_doc/bert.md to Chinese (#37806)
2025-05-19|||Tensor parallel docs (#38178)
2025-05-19|||üö®üö®üö®  [pipelines] update defaults in pipelines that can `generate` (#38129)
2025-05-19|||[image-text-to-text pipeline] Accept a chat as a positional arg (#38204)
2025-05-19|||[SAM-HQ] Update names in the docs (#38058)
2025-05-19|||Remove Deprecated `verbose` arg in LayerWiseDummyScheduler (#38197)
2025-05-19|||Make HF implementation match original OLMo 2 models for lower precisions (#38131)
2025-05-19|||[docs] add Audio import (#38195)
2025-05-19|||[docs] minor fixes in `models.md` (#38193)
2025-05-19|||Pass `eps` to `Mistral3RMSNorm` (#38026)
2025-05-19|||Resolve Python logger warnings (#38183)
2025-05-19|||Support for transformers explicit filename (#38152)
2025-05-19|||[generation] Less verbose warnings by default (#38179)
2025-05-19|||Add adam_kwargs for Apollo Optimizer (#38168)
2025-05-19|||Refactor `get_XXX_dataloader` from Trainer (#38090)
2025-05-16|||[tests] remove `test_sdpa_equivalence` (redundant) (#37911)
2025-05-17|||fix bug in distributed loss test (#38166)
2025-05-16|||Fix import torchao.prototype.low_bit_optim since torchao  v0.11 (#38174)
2025-05-16|||Add args support for fast image processors (#37018)
2025-05-16|||[ESM] Add flash-attention-2 backend for ESM-2 (#38023)
2025-05-16|||Feat: add warnings for unused keys and rules in tensor parallel (#37893)
2025-05-16|||remove some commands from `fetch_tests` CircleCI job (#38176)
2025-05-16|||Disable `convert to draft` workflow (#38177)
2025-05-16|||Disable `Trigger CircleCI by ready for review` (#38171)
2025-05-16|||clean autoawq cases on xpu (#38163)
2025-05-16|||Bart: new cache format (#35314)
2025-05-16|||[VLMs] add helpers to get multimodal encodings (#37743)
2025-05-16|||Add optional RMSNorm support to BitNet quantization (config + layers) (#38087)
2025-05-16|||Fix Qwen2.5 Omni `SinusoidsPositionEmbedding` precision (#38151)
2025-05-16|||Include output embedding as well with `include_embedding` flag (#37935)
2025-05-16|||enable autoround cases on XPU (#38167)
2025-05-15|||[FIX] Save speed metrics to logs (#38136)
2025-05-15|||Omit creation of positional IDs within ESM if applicable (#38089)
2025-05-15|||disable deepspeed when setting up fake trainer (#38101)
2025-05-15|||enable trainer test cases on xpu (#38138)
2025-05-15|||Hotfix: Flash Attention 2 support in Pixtral (#38146)
2025-05-15|||[generate] Run custom generation code from the Hub (#36405)
2025-05-15|||Remove head mask in generative models (#35786)
2025-05-15|||enable csm integration cases on xpu, all passed (#38140)
2025-05-15|||[Qwen3] Qwen3 MoE add tp plan for expert mlps (#38135)
2025-05-14|||Fix incorrect attention mask truncate in WhisperFlashAttention2 (#36477)
2025-05-15|||enable d_fine finetuning properly (#37962)
2025-05-14|||Add `manueldeprada` to `run_slow` whitelist (#38126)
2025-05-14|||[docs] add uv installation instructions for source builds (#37968)
2025-05-14|||Update trainer.md (#38113)
2025-05-14|||Add config validation and style tweaks (#37589)
2025-05-14|||Fix auto batch size finder test (#38125)
2025-05-14|||Fix temporal padding in Qwen2VLImageProcessor when the number of frames is not divisible by temporal_patch_size (#38076)
2025-05-14|||[video processor] fix tests (#38104)
2025-05-14|||enable finegrained_fp8 and granite_speech cases on XPU (#38036)
2025-05-14|||Fix description and formatting errors in code docs (#38074)
2025-05-13|||Add style bot (#38102)
2025-05-13|||[CSM] update test for t4 runners (#38110)
2025-05-14|||Add Fast Image Processor for vilt (#37304)
2025-05-13|||Fix InternVL interpolate_pos_encoding and add to video_processing_auto (#38092)
2025-05-13|||fix `check_bad commit.py` gives wrong results (#38107)
2025-05-13|||[bug] fix llava processor to calculate unpadding size correctly (#37988)
2025-05-13|||Fix `past_key_values` type hint in model output types (#37953)
2025-05-13|||Fix bug in prefill_chunk_size that ignores disable_compile flag (#38067)
2025-05-13|||[smolvlm] skip the test (#38099)
2025-05-13|||Disable report callbacks for certain training tests (#38088)
2025-05-13|||fix: Propagate `lr_scheduler_kwargs` options to create LR Scheduler when LayerWiseDummyOptimizer is used (#34559)
2025-05-13|||add timeout for downloading the `librispeech_asr` dataset (#38073)
2025-05-13|||update `require_read_token` (#38093)
2025-05-12|||Refactor image processor phi4 (#36976)
2025-05-12|||uninstall `kernels` from docker images (#38083)
2025-05-12|||update seed_worker to set seed based on worker_id and rank (#37980)
2025-05-12|||Fix tot update in trainer (#37923)
2025-05-12|||fix the inconsist docstring in apply_chat_template (#38069)
2025-05-12|||chore(qwen2): display warning log only when sliding window attention ‚Ä¶ (#36316)
2025-05-12|||Fix mt5 test on AMD devices (#38081)
2025-05-12|||docs: fix md style (#38057)
2025-05-12|||Add AMD expectation to test_gpt2_sample (#38079)
2025-05-12|||Fix OneFormer integration test (#38016)
2025-05-12|||[`chat`] generate parameterization powered by `GenerationConfig` and UX-related changes (#38047)
2025-05-12|||[VLM] fix loading issues (#38051)
2025-05-12|||üî¥ Video processors as a separate class (#35206)
2025-05-10|||fix(conversion): Fix size mismatch error during TF->PT model loading (#38014)
2025-05-10|||enable generation fsdp/utils cases on XPU (#38009)
2025-05-09|||Fix linalg.norm for CovnNextV2 (#38015)
2025-05-09|||Fix cache update! (#38046)
2025-05-09|||Fix reduce-labels in BEIT Fast Image Processor (#38042)
2025-05-09|||Re-Enable `Trigger CircleCI via GitHub Actions when "ready for review" (#37885)` (#38041)
2025-05-09|||Support for version spec in requires & arbitrary mismatching depths across folders (#37854)
2025-05-09|||Do not erase a cache_position passed explicitly to generate(), if there is one (#37986)
2025-05-09|||Disable `Trigger CircleCI via GitHub Actions when `ready for review` (#38038)
2025-05-09|||Trigger CircleCI via GitHub Actions when `ready for review` (#37885)
2025-05-09|||[Temporary] Log some information in some pytest/pluggy internal places (#37996)
2025-05-09|||enable utils test cases on XPU (#38005)
2025-05-09|||make mistral3 pass on xpu (#37882)
2025-05-09|||fix document masking for chunked attention (#37429)
2025-05-08|||[`AutoDocstring`] Based on inspect parsing of the signature (#33771)
2025-05-09|||update bnb tests (#38011)
2025-05-09|||enable mamba2 integration cases on xpu (#38006)
2025-05-09|||make `test_speculative_decoding_non_distil` device-agnostic (#38010)
2025-05-08|||[VLMs]  support attention backends (#37576)
2025-05-08|||Fix wording in `torchscript.md` (#38004)
2025-05-08|||Fix incorrect installation instructions (for issue #37476) (#37640)
2025-05-08|||Skip `test_push_to_hub_with_saves_each_epoch` for now (#38022)
2025-05-08|||[caches] Raise exception on offloaded static caches + multi device (#37974)
2025-05-08|||[CI] remove duplicated message on GH comment to run slow tests (#37970)
2025-05-08|||Print commit SHA on slack message for new model notification. (#38019)
2025-05-08|||Fix `Optional` typing (#38018)
2025-05-08|||Enable RUF013 to enforce optional typing (#37266)
2025-05-08|||Add ALL_ATTENTION_FUNCTIONS compatibility for Pixtral model (#37960)
2025-05-08|||Fix `pad` image transform for batched inputs (#37544)
2025-05-08|||Add Swin2SR ImageProcessorFast (#37169)
2025-05-07|||üî¥ [VLM] Add base model without head  (#37033)
2025-05-07|||[CSM] tiny fix on generation (#38001)
2025-05-07|||Add CSM model (#36719)
2025-05-07|||Add a check to import_utils.py to allow for use of faiss_gpu installation (#37997)
2025-05-07|||remove duplicate code (#37991)
2025-05-07|||[chat template] separate jinja logic from tokenizers  (#37602)
2025-05-07|||make aya vision 5 integration tests pass on xpu (#37990)
2025-05-07|||[offload] respect `max_memory` argument when factoring in unused reserved memory (#37982)
2025-05-07|||Fix Qwen models export with torch 2.7 (#37985)
2025-05-07|||[Fast Processor] BEiT (#37005)
2025-05-06|||Fix donut backtracking (#37788)
2025-05-06|||Enable granite speech 3.3 tests (#37560)
2025-05-06|||fix FSDP + torch.compile bug when saving pretrained model  (#37725)
2025-05-06|||enable xpu in test_trainer (#37774)
2025-05-06|||Fix typo (#37964)
2025-05-06|||[speech2text] fix init of sinusoidal embeddings  (#37931)
2025-05-06|||Fix typos (#37978)
2025-05-06|||Small typo lines 47 and 199 perf_infer_gpu_one.md (#37938)
2025-05-06|||fix docs serving typos. (#37936)
2025-05-06|||add job links to new model failure report (#37973)
2025-05-06|||[llava] one pixel is missing from padding when length is odd (#37819)
2025-05-06|||[tests] Smaller model in slow cache tests (#37922)
2025-05-06|||add xpu memory check  (#37969)
2025-05-06|||üö®üö®üö® Fix forward of Dinov2ForImageClassification for models with registers (#37836)
2025-05-05|||Add GraniteMoeHybrid support for 4.0 (#37658)
2025-05-05|||[Ready to Merge][HFQuantizer] Squelch pydantic warnings (#37726)
2025-05-05|||Fix incorrect type annotation in get_auxiliary_logits (#37955)
2025-05-05|||[generate] Fix `vocab_size` access for multimodal models (#37937)
2025-05-05|||Use T4 single GPU runner with more CPU RAM (#37961)
2025-05-05|||[core] reuse unused reserved cuda memory when loading models (#37920)
2025-05-05|||More fault tolerant notification service (#37924)
2025-05-05|||[D-FINE] Update names (#37957)
2025-05-02|||[docs] logits docstring (#37929)
2025-05-02|||Break weight tying when quantizing input embedding (#37905)
2025-05-02|||Aligning modling code for GPT2 to work with vLLM (fallback) (#36934)
2025-05-01|||Add usage example for DINOv2 (#37398)
2025-05-02|||üåê [i18n-KO] Translated `gpu_selection.md` to Korean (#36757)
2025-05-01|||Improve performance of `load_state_dict` (#37902)
2025-05-01|||[chat] clean code and add base help (#37892)
2025-05-01|||Fix typos in strings and comments (#37910)
2025-05-01|||üö® rm already deprecated pad_to_max_length arg (#37617)
2025-04-30|||fixed gemma3 collection path pointing to llama 2 collection. (#37899)
2025-04-30|||Support `AOPerModuleConfig` and `include_embedding` (#37802)
2025-04-30|||Enhance documentation to explain chat-based few-shot prompting (#37828)
2025-04-30|||Fix Qwen3 tp plan with FP8 (#37871)
2025-04-30|||[tests] reset logs in `torch.compile` test (#37894)
2025-04-30|||[tests] Test all cache implementations (#37873)
2025-04-30|||Support FlaxPreTrainedModel to load model checkpoint from local subfolder safetensors (#37732)
2025-04-30|||update comment in image_processing_base.py to reference image_process‚Ä¶ (#37864)
2025-04-30|||Fix: reassign in qwen3 moe model (#37848)
2025-04-30|||uniformize kwargs for VisionTextDualEncoder (#34563)
2025-04-30|||Fix qwen2-vl-docs. (#37879)
2025-04-30|||make sure lr is not a tensor (#37881)
2025-04-30|||fix error for _register_pytree_node in torch2.1.0 and  fix bf16 assertion in xpu and npu (#37839)
2025-04-30|||update Clean_up_tokenization_spaces typos. (#37865)
2025-04-30|||Transformers cli clean command (#37657)
2025-04-30|||Llama Guard updates (#37872)
2025-04-30|||enable internvl UTs on XPU (#37779)
2025-04-30|||Allow override inputs to export recipe (#37508)
2025-04-30|||Skip is_flaky tests in the CI (#37723)
2025-04-30|||Update modeling_llama4.py (#37841)
2025-04-30|||üåê [i18n-KO] Translated `electra.md` to Korean (#36763)
2025-04-29|||Add Intel Gaudi doc (#37855)
2025-04-29|||Processor chat template: pass custom kwargs (#37852)
2025-04-29|||docs: Details for ambigious channel dimension assignment (#37600)
2025-04-29|||Fix Bitnet tokenizer in pipeline (#37861)
2025-04-29|||Fix cache get item return type hints (#37847)
2025-04-29|||Fix check of unecessary packages (issue #37626) (#37825)
2025-04-29|||Revert change that breaks on Torch 2.1 (#37531)
2025-04-29|||[tests] reorganize cache tests and clean memory between tests (#37684)
2025-04-29|||[tests] fix flaky pattern in `test_generate_continue_from_past_key_values` (#37724)
2025-04-29|||Add D-FINE Model into Transformers (#36261)
2025-04-29|||[modular] Fix the prefix-based renaming if the old and new model share a common name suffix (#37829)
2025-04-28|||Fast image processor for VitMatte added and bug in slow version fixed (#37616)
2025-04-28|||Samhq model addition  (#35147)
2025-04-28|||[config] revert #37603 (#37821)
2025-04-28|||change XLA deprecated api (#37741)
2025-04-28|||Fix error of HPU TP (#37782)
2025-04-28|||Add Optional to remaining types (#37808)
2025-04-28|||FIX: Faulty PEFT tests (#37757)
2025-04-28|||Add Bitnet model (#37742)
2025-04-28|||[RT-DETR] Improve docs (#37814)
2025-04-28|||Fix: Correct tensor shape comment in Mamba modeling (#37801)
2025-04-28|||[doc] fix the code examples in qwen doc (#37803)
2025-04-28|||Fix typos in strings and comments (#37799)
2025-04-28|||Define warmup allocator for torchao quantization (#37764)
2025-04-28|||Fix the fsdp config cannot work issue. (#37549)
2025-04-28|||Gemma3 is Torch Exportable (#37728)
2025-04-26|||Fix error message in `hub.py` (#37796)
2025-04-25|||fix performance issue in convert_ids_to_tokens (#37773)
2025-04-26|||chore: update SigLIP2 model card (#37624)
2025-04-26|||[i18n-KO] Translated `keypoint_detection.md` to Korean (#36649)
2025-04-26|||fix mpt test of different outputs from cuda (#37691)
2025-04-25|||Force torch>=2.6 with torch.load to avoid vulnerability issue (#37785)
2025-04-25|||Fix tensor parallel with non-floating dtypes (#37790)
2025-04-25|||Fix typos in strings and comments (#37784)
2025-04-25|||Align gpt2 mask preparation to #37612 (#37787)
2025-04-25|||unpin pytest<8 (#37768)
2025-04-25|||[causal mask] fix preparation with multi-gpu (#37612)
2025-04-25|||üåê [i18n-KO] Translated `roberta.md` to Korean (#37069)
2025-04-24|||Update model card for Gemma (#37674)
2025-04-24|||Fix auto-round hfoption  (#37759)
2025-04-24|||Guard DeepSpeed imports (#37755)
2025-04-24|||[deps] pin max `torch` version  (#37760)
2025-04-24|||Fix typos in comments (#37694)
2025-04-24|||Fix load of rng state for resuming training from checkpoint (#37162)
2025-04-24|||Fix tied weight loading with TP and loading sub state_dicts (#37758)
2025-04-24|||Refine parameter type annotations (#37666)
2025-04-24|||Fix wrong input shapes in doc-string of models (#37729)
2025-04-24|||[generate] fix default autocompile case on gpu (#37756)
2025-04-24|||Fix qwen2_5 get_rope_index tensor device locations (#37597)
2025-04-24|||updated hidden_features for FlaxDinov2SwiGLUFFN in Dinov2  (#37747)
2025-04-24|||[generate] skip compilation on cpu offload (#37709)
2025-04-24|||`GPT2Model` StaticCache support (#35761)
2025-04-24|||[cache] fix `HybridCache` init when `device` is passed (#37718)
2025-04-24|||Expand quantized data type support for tensor parallelism  (#37719)
2025-04-24|||Update `MllamaForConditionalGenerationIntegrationTest` (#37750)
2025-04-24|||Skip all `AriaForConditionalGenerationIntegrationTest` on `T4` (#37746)
2025-04-24|||[performance_optim] define flash attention mask on NPU device directly (#37698)
2025-04-24|||Correctly raise errors when downloading tokenizer files (#37740)
2025-04-24|||Fix `embeds_to_talker` device in Qwen2.5-Omni (#37739)
2025-04-24|||fix: learning_rate logged as tensor causing save issue with deepspeed (#37704)
2025-04-24|||[VLMs] fix flash-attention tests (#37603)
2025-04-24|||Make sure torch_is_available before using torch.distributed (#37693)
2025-04-24|||[tests] fix `test_nemotron_8b_generation_sdpa` (#37665)
2025-04-24|||Fix torchao doc examples (#37697)
2025-04-24|||Fix inference bugs in Qwen2.5 Omni (#37701)
2025-04-24|||Fix Aria tests (#37444)
2025-04-23|||Add Fast Image Processor for MobileNetV1  (#37111)
2025-04-24|||Add Fast Image Processor for PoolFormer (#37182)
2025-04-24|||Add Fast PVT Processor (#37204)
2025-04-24|||enable 4 test_trainer cases on XPU (#37645)
2025-04-23|||Process inputs directly in apply_chat_template in image-text-to-text pipeline (#35616)
2025-04-23|||[tests, `qwen2_5_omni`] fix flaky tests (#37721)
2025-04-23|||Qwen 2.5 Omni: apply video defaults (#37660)
2025-04-23|||[internvl] fix chat template (#37656)
2025-04-23|||TransfoXL is deprecated, don't keep it in tested examples! (#37707)
2025-04-23|||[CI] add back `sacrebleu` (and document why) (#37700)
2025-04-23|||Add maintainers for ROCm/Intel XPU/Ascend NPU (#37678)
2025-04-23|||[cleanup] remove `/model_cards` üßπ üßπ  (#37685)
2025-04-23|||Pin torch == 2.6 on PR CI docker images for now (#37695)
2025-04-23|||enable cpu offloading for Bark on xpu (#37599)
2025-04-23|||fix: remove classmethod from `Qwen2_5OmniConfig.get_text_config` (#37690)
2025-04-23|||Updated model card for mbart and mbart50 (#37619)
2025-04-23|||üåê [i18n-KO] Translated `siglip.md` to Korean (#37145)
2025-04-23|||enable blip2 and emu3 cases on XPU (#37662)
2025-04-22|||Add counters for dataset classes (#37636)
2025-04-22|||[Docs] Move models to appropriate section (#37338)
2025-04-22|||typo update in the parameter name (#37655)
2025-04-22|||[docs] only build `en` docs in push CI (#37677)
2025-04-22|||[cleanup] remove old scripts in `/scripts` üßπ üßπ  (#37676)
2025-04-22|||enable 6 granite cases on xpu (#37569)
2025-04-22|||enable mllama cases on xpu (#37644)
2025-04-22|||Refactor bitsandbytes doc (#37668)
2025-04-22|||Fix no_split_modules for Llama4 pretrained models (#37673)
2025-04-22|||Fix autoround docs  (#37675)
2025-04-22|||Fixing quantization tests (#37650)
2025-04-22|||Add AutoRound quantization support (#37393)
2025-04-22|||Correct warm-up with fp8 (#37670)
2025-04-22|||Fix duplicated weights in fp8 quantization (#37667)
2025-04-22|||[qwen-omni] fix training (#37517)
2025-04-22|||Introduce GradientCheckpointingLayer (#37223)
2025-04-22|||Fixes #37219 : RecurrentGemma crashes for inputs longer than sliding window length (#37613)
2025-04-22|||Fix ValueError when eval_do_concat_batches=False with examples (#37621)
2025-04-22|||[tests] Stricter generate + compilation test -- no recompilations allowed (#37629)
2025-04-22|||[test] update `test_past_key_values_format` (#37614)
2025-04-22|||Add test to ensure unknown exceptions reraising in utils/hub.py::cached_files() (#37651)
2025-04-22|||Support loading Gemma3 QAT GGUF models (#37649)
2025-04-22|||Restructure torchao quantization examples (#37592)
2025-04-22|||[fix gemma] Set default value for output_attentions parameter in Gemma2 and Gemma‚Ä¶ (#37633)
2025-04-22|||[fix] make legacy bnb code work (#37331)
2025-04-22|||Fix Qwen2.5-Omni get_chunked_index chunking functionality (#37631)
2025-04-21|||Refactor phi doc (#37583)
2025-04-21|||Update longformer.md (#37622)
2025-04-21|||fix link in kv_cache.md (#37652)
2025-04-21|||Allow Exclusion of Input IDs from RepetitionPenaltyLogitsProcessor (#37625)
2025-04-21|||Remove torchvision requirement from AutoImageProcessor (#37457)
2025-04-21|||[kernels] use original forward at compile time (#37604)
2025-04-19|||Fix InternVL attention when using qk_norm (38B and 78B) (#37620)
2025-04-19|||chore: update model card for SigLIP (#37585)
2025-04-19|||Fixing the example in generation strategy doc (#37598)
2025-04-18|||Deprecate modeling_utils.py classes (#37298)
2025-04-18|||Add InternVL (2.5 MPO) (#35968)
2025-04-18|||fix issue that some example with no trainer use accelerator.end_train‚Ä¶ (#37435)
2025-04-18|||fix 2 encoder_decoder issues on XPU (#37572)
2025-04-18|||[VLMs] use only `xxx_token_id` for multimodal tokens (#37573)
2025-04-18|||Model debugger upgrades (#37391)
2025-04-18|||[Gemma3] compile ‚ú®  (#37447)
2025-04-18|||enable 6 modeling cases on XPU (#37571)
2025-04-18|||enable 6 gemma2 cases on XPU (#37564)
2025-04-18|||Flag SpeechT5 flaky test (#37587)
2025-04-18|||[Bugfix] Fix flash-attention func param mismatch and softmax_scale default value mistake on Ascend NPU (#37575)
2025-04-18|||remove _run_third_party_device_tests (#37445)
2025-04-18|||Fix some GPU OOM after #37553 (#37591)
2025-04-18|||Gaudi: Add the bf16 support for hpu (#37568)
2025-04-18|||Fix Quark quantization config (#37578)
2025-04-17|||Update Phi4 converter (#37594)
2025-04-17|||Ensure positive warm-up size (#37581)
2025-04-17|||docs: fix typo (#37567)
2025-04-17|||[phi4] update conversion (#37579)
2025-04-17|||Small fix on context manager detection (#37562)
2025-04-17|||Fix qwen2audio wanr -> warn (#37559)
2025-04-17|||[TimesFM] use the main revison instead of revision for integration test (#37558)
2025-04-17|||[qwen-vl] Standardize config (#37268)
2025-04-17|||[chat template] fix security vulnerability (#37523)
2025-04-17|||Add Janus model (#36053)
2025-04-16|||All models can be initialized on meta device (#37563)
2025-04-17|||Bridgetower fast image processor (#37373)
2025-04-16|||Fix Mamba2 Grouped SSD Support in the torch_forward Path (#37533)
2025-04-16|||Add EfficientNet Image PreProcessor (#37055)
2025-04-16|||[vlm] adjust max length for special tokens (#37342)
2025-04-16|||Fix pixel attention mask padding in smolvlm (#37497)
2025-04-16|||Run `test_can_load_with_global_device_set` using a subprocess (#37553)
2025-04-16|||:red_circle: Update CLIP vision attention to new attention interface (#37498)
2025-04-16|||Fix TimesFm doc issue (#37552)
2025-04-16|||Make Ignored Columns ValueError More Informative (#33299)
2025-04-16|||Fix device issue for tapas (with `as_tensor`) (#37551)
2025-04-16|||docs(typo): Update ISSUES.md, fix a small typo (#37542)
2025-04-16|||add FlashAttentionKwargs and seq_idx to flat collator (#36456)
2025-04-16|||Update quantization docs (#37439)
2025-04-16|||Add TimesFM Time Series Forecasting Model (#34082)
2025-04-16|||Refactor torchao docs  (#37490)
2025-04-16|||Keep Quark loading through meta device (#37538)
2025-04-16|||convert scale and zero to cuda when using HQQ backend (#37425)
2025-04-16|||Fixes hqq by following a new path for bias parameter in pre_quantized models (#37530)
2025-04-16|||More appropriate cuda warmup in resource-constrained hardware (#37550)
2025-04-16|||Add Fast Grounding-Dino Processor (#37108)
2025-04-16|||enable 6 rt_detr_v2 cases on xpu (#37548)
2025-04-16|||enable 3 mpt test cases on XPU (#37546)
2025-04-16|||Fix BitsAndBytesConfig JSON serialization in TrainingArguments (#37520)
2025-04-16|||enable `test_offloaded_cache_implementation` on XPU (#37514)
2025-04-16|||enable several cases on XPU (#37516)
2025-04-16|||enable 5 cases on XPU (#37507)
2025-04-15|||Refactor ColPali model documentation (#37309)
2025-04-15|||Update VITS model card (#37335)
2025-04-15|||Fix broken add-fast-image-processor CLI (#37499)
2025-04-15|||Add Fast Conditional-DETR Processor (#37071)
2025-04-15|||Add Fast Chinese-CLIP Processor (#37012)
2025-04-15|||VDR task guide (#37485)
2025-04-15|||fix and enhance pipeline_webserver.md (#36992)
2025-04-15|||Fix missing return type for MLCD docs (#37527)
2025-04-15|||fix: Restore explicit error surfacing for unexpected hub exceptions (#37525)
2025-04-15|||Add Fast Yolos Processor (#37292)
2025-04-15|||Llama4: remove redundant transpose of router_logits (#37468)
2025-04-15|||Add MLCD model (#36182)
2025-04-15|||Change default value of `attn_temperature_tuning` (#37501)
2025-04-15|||Detect and use device context manager or global device in `from_pretrained` (#37216)
2025-04-14|||Don't auto-assign reviewers when the author is in HF (#37500)
2025-04-14|||Remove deprecation warning for `num_logits_to_keep` (#37149)
2025-04-14|||Add Fast owlvit Processor (#37164)
2025-04-14|||[qwen-omni] fix processor (#37493)
2025-04-14|||Fixing gated repo issues (#37463)
2025-04-14|||Fix wrong argparse type in modular checker script (#37472)
2025-04-14|||Add Fast Mobilenet-V2 Processor (#37113)
2025-04-14|||Add ImageProcessorFast to BiT processor (#37180)
2025-04-14|||Add Fast LeViT Processor (#37154)
2025-04-14|||Fix mask handling for flex attention in llama/gemma2/mistral/qwen2 (#37381)
2025-04-14|||[bug] deprecated deta load_cuda_kernel, MultiScaleDeformableAttention (#37443)
2025-04-14|||Add Fast Image Processor for Donut (#37081)
2025-04-14|||Detect and fix most `_init_weights()` issues - make it work for composite models (#37070)
2025-04-14|||Add Fast Image Processor for LayoutLMv3 (#37201)
2025-04-14|||Fixed broken links (#37466)
2025-04-14|||Add Fast Image Processor for LayoutLMv2 (#37203)
2025-04-14|||Add Fast Image Processor for Flava (#37135)
2025-04-14|||[ci] fix doc builder (#37489)
2025-04-14|||Add Fast Image Processor for Perceiver (#37176)
2025-04-14|||Add Qwen2.5-Omni (#36752)
2025-04-14|||Fix tests failed with gated repos. (#37484)
2025-04-14|||Remove `fsspec` dependency which isn't directly used by transformers (#37318)
2025-04-14|||make test_snowman_image_captioning pass on XPU, by sharing same atol w/ ROCM (#37480)
2025-04-14|||fix: (llama4) fix no_split_modules to be picked up for fsdpv1 and v2 sharding (#37462)
2025-04-11|||Fix typing issues with SigLip2 (#37356)
2025-04-11|||[agents] remove agents üßπ  (#37368)
2025-04-11|||Delete hubconf.py (#37455)
2025-04-11|||Add Granite Speech Support (#36801)
2025-04-11|||nit: typing use Llama4TextConfig instead of Llama4Config (#37430)
2025-04-12|||Add XPU case to is_torch_bf16_gpu_available (#37132)
2025-04-12|||Add weights_only=True to torch.load (#37062)
2025-04-11|||:rotating_light: :rotating_light: Allow saving and loading multiple "raw" chat template files (#36588)
2025-04-11|||Disable kernels for quantization (#37446)
2025-04-11|||prevent creating a view/leaf param for low rank optimizers w FSDP (#37379)
2025-04-11|||[Regression] Fix Quark quantized model loading after refactorization (#37407)
2025-04-11|||[processor] clean up mulitmodal tests (#37362)
2025-04-11|||Remove triton mlp kernel, not compiling for some models (#37449)
2025-04-11|||Fix the test fetcher (#37452)
2025-04-11|||Add moe kernels (#37376)
2025-04-11|||Update-kernel-pin (#37448)
2025-04-11|||Simplify soft dependencies and update the dummy-creation process (#36827)
2025-04-11|||Fixes: Corrects file path for CUDA kernels (#37438)
2025-04-11|||enhance require_deterministic_for_xpu (#37437)
2025-04-11|||Remove old code for  PyTorch,  Accelerator and tokenizers (#37234)
2025-04-11|||[Feat] Support npu in modeling models (#37369)
2025-04-10|||Adding to self_comment_ci.yml (#37426)
2025-04-10|||(Part 2) feat: allow for tp_size attr for tplizing the model (#37054)
2025-04-10|||fix: use mtime by default in Trainer._rotate_checkpoints with automatic fallback (#37260)
2025-04-10|||Add GGUF support to Gemma3 Text backbone (#37424)
2025-04-10|||Llama Kernel integration (#37092)
2025-04-10|||Fix require_read_token (#37422)
2025-04-10|||Correctly drop tokens in SwitchTransformer (#37123)
2025-04-10|||Add image classifier donut & update loss calculation for all swins  (#37224)
2025-04-10|||Quark Quantization gated repo (#37412)
2025-04-10|||Fix new failure reports not including anything other than `tests/models/` (#37415)
2025-04-10|||[chat-template] Unify tests and clean up üßº  (#37275)
2025-04-10|||use `rms_norm_eps` for the L2Norm for Llama4 (#37418)
2025-04-10|||Allow rocm systems to run these tests (#37278)
2025-04-10|||from_pretrained should handle xpu case (#37382)
2025-04-10|||Send trainer/fsdp/deepspeed CI job reports to a single channel (#37411)
2025-04-10|||update `kernels` to 0.4.3 (#37419)
2025-04-10|||mark llama4 as not supported with fa2 (#37416)
2025-04-10|||Offloaded hybrid cache for Llama4 (#37401)
2025-04-10|||Fix Llama4 offset (#37414)
2025-04-10|||Restrict & Explain tp_plan for FBgemm (#37404)
2025-04-10|||Handle torch ver in flexattn (#37400)
2025-04-10|||Add warning when failed to acquire other user's lock at model download (#37395)
2025-04-09|||handle torch version edge cases (#37399)
2025-04-09|||the fix that did not get in (#37370)
2025-04-09|||Attention Quantization with FBGemm & TP (#37384)
2025-04-09|||Fix some failing AWQ tests (#37383)
2025-04-09|||Apply torchfix to replace deprecated functions: `_pytree._register_pytree_node` and `torch.cpu.amp.autocast` (#37372)
2025-04-09|||Fix warning message for PEFT models in text-generation pipeline #36783 (#36887)
2025-04-09|||Add "selecting a quantization method" doc (#37159)
2025-04-09|||update deepspeed docker (#37371)
2025-04-09|||Add glm4 (#37388)
2025-04-09|||fix: llama4 conversion script no_rope_layers (#37359)
2025-04-09|||Update composition flag usage (#36263)
2025-04-08|||Preserve requires_grad in pre quantized model (#37354)
2025-04-08|||:rotating_light: :rotating_light: Setup -> setupclass conversion (#37282)
2025-04-08|||fix(qwen): fix shape error when using tp (#36947)
2025-04-08|||prune LM Head for USD (#36695)
2025-04-08|||[core] remove `GenerationMixin` inheritance by default in `PreTrainedModel` (#37173)
2025-04-08|||Skip non-selected experts for mixtral and qwen2_moe (#32429)
2025-04-08|||[llama 4] dynamic rope decorator (#37365)
2025-04-08|||Set vision config to None for Gemma 1B conversion (#37366)
2025-04-08|||fix deepspeed job (#37284)
2025-04-08|||A bit of cleaning üßπüßπ (#37215)
2025-04-08|||Use Python 3.9 syntax in tests (#37343)
2025-04-08|||convert float for yarn related arguments in rope_scaling (#37139)
2025-04-08|||Expose blip2qformer (#37254)
2025-04-08|||Multiple llama4 fixe (#37353)
2025-04-07|||Fixing flex attention for torch=2.6.0 (#37285)
2025-04-07|||more fixes for post-training llama4 (#37329)
2025-04-07|||Remove unnecessary attr assignment (#36837)
2025-04-08|||Updated Model-card for donut (#37290)
2025-04-07|||Add bnb to the list of supported quantization methods for LLama4 (#37348)
2025-04-07|||Update Model Card for Jamba (#37152)
2025-04-07|||Improvements in Gemma2 model card (#37076)
2025-04-07|||Clean up the compressed-tensors integration (#37349)
2025-04-07|||Update Model card for GPT2 (#37101)
2025-04-07|||Update falcon mamba card (#37253)
2025-04-07|||Update model-card for DINOv2 (#37104)
2025-04-07|||updated model card for Mistral (#37156)
2025-04-07|||Remove HQQ from caching allocator warmup (#37347)
2025-04-07|||Update translation template (#37294)
2025-04-07|||fix derived berts `_init_weights` (#37341)
2025-04-07|||Avoid build crashes when torch.version.xpu doesn't exist and fix Llama4 processor tests (#37346)
2025-04-07|||enable 2 llama UT cases on xpu (#37126)
2025-04-07|||byebye torch 2.0 (#37277)
2025-04-07|||Fix torchao usage (#37034)
2025-04-07|||Use Python 3.9 syntax in examples (#37279)
2025-04-07|||Fix `init empty weights` without accelerate (#37337)
2025-04-07|||Fix deepspeed with quantization (#37324)
2025-04-07|||fix llama4 training (#37319)
2025-04-07|||fix flex attn when optional args aren't passed (#37327)
2025-04-05|||v4.52.0.dev0
2025-04-05|||Add llama4 (#37307)
2025-04-05|||Hf Xet extra (#37305)
2025-04-05|||Fix deepspeed loading (part 2) (#37306)
2025-04-05|||Fix deepspeed loading (#37281)
2025-04-04|||Update OpenAI GPT model card (#37255)
2025-04-04|||Updated T5 model card with standardized format (#37261)
2025-04-05|||Updated model card for distilbert (#37157)
2025-04-05|||mobilebert model card update (#37256)
2025-04-04|||Fix: Unexpected Keys, Improve `run_compressed`, Rename Test Folder (#37077)
2025-04-05|||Update model card for Depth Anything (#37065)
2025-04-04|||Disable delay_optimizer_creation in `Trainer` to support fsdp2 (#37147)
2025-04-05|||fix test device spec relative path importing issue (#37190)
2025-04-04|||Fix llava_onevision tests (#37280)
2025-04-04|||[RoPE] abstract dynamic RoPE update under a decorator ‚ú®  (#37249)
2025-04-04|||Hugging Face Hub pin to v0.30.0 for Xet (#37166)
2025-04-04|||[Tests] flaky `test_constrained_beam_search_generate_dict_output`  (#37276)
2025-04-04|||Clarify error message to ensure min 28x28 image supplied for Qwen 2.5 VL (#37264)
2025-04-04|||pin specific `natten` version in docker file  (#37274)
2025-04-04|||Fix deprecated PT functions (#37237)
2025-04-04|||Fix `utils/check_bad_commit.py` (#37272)
2025-04-04|||Introduce modular files for speech models (#35902)
2025-04-04|||update error msg (#37207)
2025-04-03|||[qwen-vl] fix image processor (#37258)
2025-04-03|||Update model card for electra (#37063)
2025-04-03|||Update Model Card for ModernBERT (#37052)
2025-04-03|||chore: Update model doc for code_llama (#37115)
2025-04-03|||Update model card for Cohere (#37056)
2025-04-03|||Purge unused ModelTester code (#37085)
2025-04-03|||feat: updated model card for qwen_2.5_vl (#37099)
2025-04-03|||Add Optional to types (#37163)
2025-04-03|||Adding links to ShieldGemma 2 technical report (#37247)
2025-04-03|||[CI] green llama tests (#37244)
2025-04-03|||Allow flexible generation params arg when checking pipeline specs (#37211)
2025-04-03|||Add support for fast image processing in image-pretraining example (#37021)
2025-04-03|||Fix AST parsing when looking for remote code imports (#37245)
2025-04-03|||enable 2 types of case on XPU (#37198)
2025-04-03|||[CI] lazy loading external datasets (#37218)
2025-04-03|||[tests] fix mamba integration simple inference precision issue (#37193)
2025-04-03|||Fix test (#37213)
2025-04-03|||Add new dim to `num_items_in_batch` if necessary (#36967)
2025-04-03|||[Phi4] add multimodal chat template (#36996)
2025-04-02|||Fix static cache export (#37229)
2025-04-02|||Updated model card for Qwen2  (#37192)
2025-04-02|||Update falcon model card (#37184)
2025-04-03|||Updated the model card for CLIP (#37040)
2025-04-02|||More ReDOS fixes! (#36964)
2025-04-02|||Stop DOSing the Hub in the CI (#37209)
2025-04-02|||[Tests] add `min_new_tokens` to prevent flaky length checks (#37175)
2025-04-02|||No more dtype_byte_size() (#37144)
2025-04-02|||Add py.typed (#37022)
2025-04-02|||[3/N] Use pyupgrade --py39-plus to improve code (#36936)
2025-04-02|||Merge tensor operations with device transfer operations (#37097)
2025-04-02|||Fix some code annotation typos. (#37102)
2025-04-02|||fix: Add 'image-text-to-text' to `TASK_MAPPING` (#37107)
2025-04-02|||Try to avoid/reduce some remaining CI job failures (#37202)
2025-04-02|||Fixes DynamicCache export issues due to control flow and inplace modifications (#36652)
2025-04-02|||Add device workaround for int4 weight only quantization after API update (#36980)
2025-04-02|||Skip code `307` in `RequestCounter` (#36953)
2025-04-02|||[chat-template] fix video loading (#37146)
2025-04-01|||[doc] Fix link for Quark quantization page (#37179)
2025-04-01|||Revert #37031 (#37178)
2025-04-01|||Fix meta state dict loading with quantizers (#37136)
2025-04-01|||Avoid pipeline test failing related to Hub call (#37170)
2025-04-01|||Fixes the inconsistency of the optionality of attention_mask (#37153)
2025-04-01|||Refactor attention for SigLIP based models (#36981)
2025-04-01|||fix XPU UT error case brough by RNG difference btw XPU and CUDA (#37121)
2025-04-01|||[`ModernBERT`] Never save 'reference_compile' config; should be set based on end user (#36305)
2025-04-01|||Make canine model exportable by removing unncessary complicated logic (#37124)
2025-04-01|||Only count num items in batch when needed (#36867)
2025-04-01|||Convert `_VALID_DICT_FIELDS` to class attribute for shared dict parsing in subclasses (#36736)
2025-04-01|||Use public export API on torch 2.5 and future (#36781)
2025-04-01|||enable `test_assisted_decoding_in_different_gpu` test on XPU (#37120)
2025-04-01|||Fix llava xpu tests. (#37130)
2025-04-01|||add gpt2 test on XPU (#37028)
2025-04-01|||Fix std initialization in Idefics variants (#37100)
2025-03-31|||Fix more inefficient PT operations (#37060)
2025-03-31|||Refactor `return_dict` logic to remove complicated if/else paths (#36794)
2025-03-31|||Remove low_cpu_mem_usage and _fast_init (#36963)
2025-03-31|||[qwen3] fix generation tests (#37142)
2025-03-31|||[Feature] Support using FlashAttention2 on Ascend NPU (#36696)
2025-03-31|||skip (#37141)
2025-03-31|||Export T5 (encoder-decoder) to ExecuTorch (#36486)
2025-03-31|||[tests] remove cuda-only test marker in `AwqConfigTest`  (#37032)
2025-03-31|||Create and Expose SamVisionModel as public for better accessibility (#36493)
2025-03-31|||Remove deprecated code (#37059)
2025-03-31|||RWKV: fix mask warning typo (#37114)
2025-03-31|||Fix Gemma3 embedding scaling (#37109)
2025-03-31|||[MLU] Fix FA2 check error, remove deepspeed-mlu deps. (#36159)
2025-03-31|||fix whisper re-compile (#36712)
2025-03-31|||enable tp on CPU (#36299)
2025-03-31|||Fix 4090/ada not detected as having FP8 support (#37067)
2025-03-31|||Support passing flash_attn_kwargs when gradient_checkpointing is enabled (#37037)
2025-03-31|||Gaudi: Fix the pipeline failed issue with hpu device (#36990)
2025-03-31|||Adding Qwen3 and Qwen3MoE (#36878)
2025-03-31|||üåê [i18n-KO] Translated `qwen2_vl.md` to Korean (#36750)
2025-03-28|||Kenlm (#37091)
2025-03-28|||[Cache] rename dtype attribute üö® üö®  (#37044)
2025-03-28|||[generate] beam search -- fix output cropping (#37080)
2025-03-29|||fixed typo. (#37057)
2025-03-28|||Fix AttentionInterface following feedback (#37010)
2025-03-28|||Fix state_dict map location when quantized (#37086)
2025-03-28|||Update w/ new account (#37084)
2025-03-28|||fix tied weigths issue  (#37031)
2025-03-28|||[WIP] add deepseek-v3 (#35926)
2025-03-28|||[blip-2] Fix dtype mismatch when keep in fp32  (#37068)
2025-03-28|||Change deprecated PT functions (#37041)
2025-03-28|||Fix some typos about benchmark scripts. (#37027)
2025-03-28|||Use `lru_cache` for tokenization tests (#36818)
2025-03-28|||fix: AttributeError: 'LlavaProcessor' object has no attribute 'image_token_id' (#37026)
2025-03-28|||Fix SDPA implementation in Qwen2-VL (issues with torch==2.6.0) (#36891)
2025-03-27|||fix: Fully remove legacy cache from Llama (#36958)
2025-03-27|||fixed typo (#37036)
2025-03-27|||Remove deprecated batch_size parameter (#37007)
2025-03-27|||Replace default split function with jnp.split() in flax models (#37001)
2025-03-27|||Set weights_only in torch.load (#36991)
2025-03-27|||Fix typing for None valued variables (#37004)
2025-03-27|||Avoid unnecessary device operations in loss computing (#36950)
2025-03-27|||clean pipeline question_answering. (#36986)
2025-03-27|||[generate, cache] handle more complex device maps (#37014)
2025-03-27|||[audio utils] fix fft_bin_width computation (#36603)
2025-03-27|||[chat templates} support loading audio from video (#36955)
2025-03-27|||Fixup for distill_any_depth conversion script (#37043)
2025-03-27|||Optimize `to_py_obj` for python-native numeric lists and scalars (#36885)
2025-03-27|||fix pegasus init weights and other copied models (#36844)
2025-03-27|||Add Distill Any Depth (#36614)
2025-03-27|||Skip FP8 linear tests For device capability < 9.0(#37008)
2025-03-27|||remove redundant code in trainer (#36994)
2025-03-27|||Mark 2 tests as flaky for now (#37038)
2025-03-27|||[Modeling] Load FP8 safetensors such as DeepSeek (#36828)
2025-03-27|||Fix PixtralProcessor patch_size when spatial_merge_size is used (#37019)
2025-03-26|||Support QuestionAnswering Module for ModernBert based models. (#35566)
2025-03-27|||fix transformers_cli import relative path issue (#36989)
2025-03-26|||[docs] Attention mask image (#36970)
2025-03-27|||Remove deprecated training arguments (#36946)
2025-03-27|||fix typos in the code comments and error messages (#36993)
2025-03-26|||Log the correct learning rate (#36973)
2025-03-26|||Fix device_map check for ggml files (#37003)
2025-03-26|||Fix removing "cpu" from frozenset in bitsandbytes.py to allow better ROCm support. (#36975)
2025-03-26|||Allow easy registration of custom attention functions (#36889)
2025-03-26|||Fix get_device_properties (#36997)
2025-03-26|||Fix Optional type annotation (#36841)
2025-03-26|||Install `networkx==3.2.1` manually in some CircleCI jobs after #36957 (#37000)
2025-03-26|||Use torch.expm1 (#36995)
2025-03-26|||byebye CircleCI TF jobs (#36998)
2025-03-26|||Fix tensor dtype mismatch (#36985)
2025-03-25|||üö®Deprecate legacy argument for image-text-to-text models and adopt new behavior by default (#36307)
2025-03-25|||update bot comment again (#36974)
2025-03-26|||Add ruff target-version (#36971)
2025-03-25|||[docs] Fix image link (#36869)
2025-03-26|||Remove extra tensor clone in PyTorch code (#36748)
2025-03-25|||update examples after ruff being updated (#36972)
2025-03-25|||Updated docker files to use `uv` for installing packages (#36957)
2025-03-25|||typo fixed in README_fr.md (#36951)
2025-03-26|||Change GPUS to GPUs (#36945)
2025-03-25|||Update after #36962 (#36965)
2025-03-25|||Update ruff to `0.11.2` (#36962)
2025-03-25|||[Utils] torch version checks optionally accept dev versions (#36847)
2025-03-25|||Fix cuda index issue in cache allocator (#36937)
2025-03-25|||Support `return_tensors` in audio chat templates (#34601)
2025-03-25|||fix typos in the tests directory (#36932)
2025-03-25|||Export for Phi4-mini (#36780)
2025-03-25|||Fixing _pre_quantization_dtype when torch_dtype is None (#36930)
2025-03-25|||Add Phi4 multimodal (#36939)
2025-03-25|||Deprecate #36741 and map Causal to Conditional (#36917)
2025-03-24|||Disallow Offload to disk for gguf files (#36933)
2025-03-24|||Fix processor kwargs qwen2 vl (#36890)
2025-03-24|||Added support for seed in `DataCollatorForWholeWordMask` (#36903)
2025-03-24|||More precise comment (#36935)
2025-03-24|||Fix pytorch defomr attn path (#36923)
2025-03-24|||[2/N] Use pyupgrade --py39-plus to improve code (#36857)
2025-03-24|||Update `trainer_pt_utils.py` docstrings for consistency (#36912)
2025-03-24|||Fix typos (#36910)
2025-03-24|||Use another repo. for Mistral3 processor testing (#36925)
2025-03-24|||Fix Compressed tensors to_dict_diff (#36922)
2025-03-24|||[chameleon] fix num image token check (#36918)
2025-03-24|||tests: fix asyncio.wait() usage for python>=3.11 (#36898)
2025-03-24|||[Fix] Add `original_max_position_embeddings` to YARN rope_scaling optional keys (#36877)
2025-03-24|||Fix torch version guard at import (#36907)
2025-03-24|||fix Gemma3 Config (#36893)
2025-03-22|||Update installation.md (#36826)
2025-03-21|||[docs] Model docs (#36469)
2025-03-21|||Fix Pan and Scan on batched images Gemma3 (#36864)
2025-03-21|||Simplify keep_in_fp32_modules logic (#36722)
2025-03-21|||fix: loss computation after embeddings resize - mllama (#36840)
2025-03-21|||push v4.51.0.dev0
2025-03-21|||Fix: dtype cannot be str (#36262)
2025-03-21|||Minor Gemma 3 fixes  (#36884)
2025-03-21|||Use `deformable_detr` kernel from the Hub (#36853)
2025-03-21|||Gemma 3 tests expect greedy decoding (#36882)
2025-03-21|||:red_circle: :red_circle: :red_circle: supersede paligemma forward to shift pos id indexing (#36859)
2025-03-21|||add eustlb as an actor
2025-03-21|||[generate] model defaults being inherited only happens for newer models (#36881)
2025-03-21|||Revert "Update deprecated Jax calls (#35919)" (#36880)
2025-03-21|||Make ViTPooler configurable (#36517)
2025-03-21|||chore: fix typos in the tests directory (#36813)
2025-03-21|||Remove call to `.item` in `get_batch_samples` (#36861)
2025-03-21|||FIX FSDP plugin update for QLoRA (#36720)
2025-03-21|||[CI] doc builder without custom image (#36862)
2025-03-21|||Mllama: raise better error (#35934)
2025-03-20|||Refactor Aya Vision with modular (#36688)
2025-03-20|||Add support for seed in `DataCollatorForLanguageModeling` (#36497)
2025-03-20|||[CI] fix update metadata job (#36850)
2025-03-20|||Gemma3: fix test (#36820)
2025-03-20|||[torchao] revert to get_apply_tensor_subclass (#36849)
2025-03-20|||Add model visual debugger (#36798)
2025-03-21|||Add Prompt Depth Anything Model (#35401)
2025-03-20|||Refactor Attention implementation for ViT-based models (#36545)
2025-03-20|||DeepSpeed tensor parallel+ZeRO (#36825)
2025-03-20|||Support loading Quark quantized models in Transformers (#36372)
2025-03-20|||Use pyupgrade --py39-plus to improve code (#36843)
2025-03-20|||Fix hqq skipped modules and dynamic quant (#36821)
2025-03-20|||Fix ONNX export for sequence classification head  (#36332)
2025-03-20|||Shieldgemma2 (#36678)
2025-03-20|||Fix: remove the redundant snippet of _whole_word_mask (#36759)
2025-03-20|||Gemma 3: Adding explicit GenerationConfig and refactoring conversion ‚Ä¶ (#36833)
2025-03-20|||Fix import for torch 2.0, 2.1 - guard typehint for "device_mesh"  (#36768)
2025-03-20|||Update min safetensors bis (#36823)
2025-03-20|||[generate] clarify docstrings: when to inherit `GenerationMixin` (#36605)
2025-03-20|||[modular] Sort modular skips (#36304)
2025-03-20|||Pass state dict (#35234)
2025-03-20|||[qwen2 audio] remove redundant code and update docs (#36282)
2025-03-20|||Update deprecated Jax calls (#35919)
2025-03-20|||Fix fp16 ONNX export for RT-DETR and RT-DETRv2 (#36460)
2025-03-20|||Pass num_items_in_batch directly to loss computation (#36753)
2025-03-20|||Saving `Trainer.collator.tokenizer` in when `Trainer.processing_class` is `None` (#36552)
2025-03-20|||fix tiktoken convert to pass AddedToken to Tokenizer (#36566)
2025-03-20|||[ForCausalLMLoss] allow users to pass shifted labels (#36607)
2025-03-20|||Disable inductor config setter by default (#36608)
2025-03-20|||Fix swanlab global step (#36728)
2025-03-20|||Move the warning to the documentation for DataCollatorWithFlattening (#36707)
2025-03-19|||Just import torch AdamW instead (#36177)
2025-03-19|||Update configuration_qwen2.py (#36735)
2025-03-20|||quick fix fast_image_processor register error (#36716)
2025-03-19|||Add Space to Bitsandbytes doc (#36834)
2025-03-19|||Support tracable dynamicKVcache (#36311)
2025-03-19|||One more fix for reviewer assignment (#36829)
2025-03-19|||[gemma 3] multimodal checkpoints + AutoModelForCausalLM (#36741)
2025-03-19|||enable OffloadedCache on XPU from PyTorch 2.7 (#36654)
2025-03-19|||Add option for ao base configs (#36526)
2025-03-19|||Add attention visualization tool  (#36630)
2025-03-19|||[Generation] remove leftover code from end-to-end compilation (#36685)
2025-03-19|||Fix Device map for bitsandbytes tests (#36800)
2025-03-19|||Remove `dist": "loadfile"` for `pytest` in CircleCI jobs (#36811)
2025-03-19|||fix "Cannot copy out of meta tensor; no data!" issue for BartForConditionalGeneration model (#36572)
2025-03-18|||Expectations test utils (#36569)
2025-03-18|||[generate] ‚ú® vectorized beam search ‚ú® (#35802)
2025-03-18|||Support custom dosctrings in modular (#36726)
2025-03-19|||Fix chameleon's TypeError because inputs_embeds may None (#36673)
2025-03-18|||Fix casting dtype for qunatization (#36799)
2025-03-18|||Fix Mistral3 tests (#36797)
2025-03-18|||Loading optimizations (#36742)
2025-03-18|||Update SHA for `tj-actions/changed-files` (#36795)
2025-03-18|||fix hqq due to recent modeling changes (#36771)
2025-03-18|||Add Mistral3 (#36790)
2025-03-18|||Fix gemma3_text tokenizer in mapping (#36793)
2025-03-18|||Fixing typo in gemma3 image_processor_fast and adding a small test (#36776)
2025-03-18|||chore: fix typos in tests directory (#36785)
2025-03-18|||fix typos in the tests directory (#36717)
2025-03-17|||doc: Clarify `is_decoder` usage in PretrainedConfig documentation (#36724)
2025-03-17|||[docs] Update README (#36265)
2025-03-17|||[CI] remove redundant checks in `test_eager_matches_sdpa_inference` (#36740)
2025-03-17|||[MINOR:TYPO] Update hubert.md (#36733)
2025-03-17|||Fix `TrainingArguments.torch_empty_cache_steps` post_init check (#36734)
2025-03-17|||Fix test isolation for clear_import_cache utility (#36345)
2025-03-17|||fix xpu tests (#36656)
2025-03-17|||Allow ray datasets to be used with trainer (#36699)
2025-03-17|||fix can_generate (#36570)
2025-03-17|||enable/disable compile for quants methods (#36519)
2025-03-17|||üö®üö®üö® Fix sdpa in SAM and refactor relative position embeddings (#36422)
2025-03-15|||[Generation, Gemma 3] When passing a custom `generation_config`, overwrite default values with the model's base `generation_config` (#36684)
2025-03-15|||Update self-push-caller.yml
2025-03-14|||Fix grad accum arbitrary value (#36691)
2025-03-14|||Fix post_init() code duplication (#36727)
2025-03-15|||üåê [i18n-KO] Translated codegen.md to Korean (#36698)
2025-03-14|||[tests] Parameterized `test_eager_matches_sdpa_inference` (#36650)
2025-03-14|||Try working around the processor registration bugs (#36184)
2025-03-14|||Fix/best model checkpoint fix (#35885)
2025-03-14|||[model loading] don't `gc.collect()` if only 1 shard is used (#36721)
2025-03-14|||Cleanup the regex used for doc preprocessing (#36648)
2025-03-14|||Make the flaky list a little more general (#36704)
2025-03-14|||Gemma3 processor typo (#36710)
2025-03-13|||Add support for fast image processors in add-new-model-like CLI (#36313)
2025-03-13|||Final CI cleanup (#36703)
2025-03-14|||Add GGUF support to T5-Encoder (#36700)
2025-03-13|||Handling an exception related to HQQ quantization in modeling (#36702)
2025-03-13|||fix: fsdp sharded state dict wont work for save_only_model knob (#36627)
2025-03-13|||Add loading speed test (#36671)
2025-03-13|||[CI] Automatic rerun of certain test failures (#36694)
2025-03-13|||chore: fix typos in utils module (#36668)
2025-03-13|||Fix dtype for params without tp_plan (#36681)
2025-03-13|||fix type annotation for ALL_ATTENTION_FUNCTIONS (#36690)
2025-03-13|||Change Qwen2_VL image processors to have init and call accept the same kwargs (#36207)
2025-03-13|||Upgrading torch version and cuda version in quantization docker (#36264)
2025-03-14|||fix wandb hp search unable to resume from sweep_id (#35883)
2025-03-13|||Changing the test model in Quanto kv cache (#36670)
2025-03-13|||Fix slicing for 0-dim param (#36580)
2025-03-13|||Update config.torch_dtype correctly (#36679)
2025-03-13|||[Cache] Don't initialize the cache on `meta` device (#36543)
2025-03-12|||Fix rescale normalize inconsistencies in fast image processors (#36388)
2025-03-12|||Refactor siglip2 fast image processor (#36406)
2025-03-12|||Remove differences between init and preprocess kwargs for fast image processors (#36186)
2025-03-12|||[quants] refactor logic for modules_to_not_convert (#36672)
2025-03-12|||Remove hardcoded slow image processor class in processors supporting fast ones (#36266)
2025-03-12|||Fix Failing GPTQ tests (#36666)
2025-03-12|||Don't accidentally mutate the base_model_tp_plan (#36677)
2025-03-12|||[core] Large/full refactor of `from_pretrained` (#36033)
2025-03-12|||Fix bnb regression due to empty state dict (#36663)
2025-03-12|||[CI] gemma 3 `make fix-copies` (#36664)
2025-03-12|||fix block mask typing (#36661)
2025-03-12|||HPU support (#36424)
2025-03-12|||Gemma3 (#36658)
2025-03-12|||fix typos in the docs directory (#36639)
2025-03-11|||Fix gguf docs (#36601)
2025-03-11|||Remove research projects (#36645)
2025-03-11|||[docs] Update docs dependency (#36635)
2025-03-11|||Stop warnings from unnecessary torch.tensor() overuse (#36538)
2025-03-11|||Remove remote code warning (#36285)
2025-03-11|||Fix AriaForConditionalGeneration flex attn test (#36604)
2025-03-11|||Proper_flex (#36643)
2025-03-11|||Fix bugs in mllama image processing (#36156)
2025-03-11|||Refactor some core stuff (#36539)
2025-03-10|||[docs] Serving LLMs (#36522)
2025-03-10|||chore: fix typos in language models (#36586)
2025-03-10|||Fix auto-assign reviewers (#36631)
2025-03-10|||[`HybridCache`] disable automatic compilation (#36620)
2025-03-07|||Fix check for XPU. PyTorch >= 2.6 no longer needs ipex. (#36593)
2025-03-07|||Fixed datatype related issues in `DataCollatorForLanguageModeling` (#36457)
2025-03-07|||Bump jinja2 from 3.1.5 to 3.1.6 in /examples/research_projects/decision_transformer (#36582)
2025-03-07|||Update "who to tag" / "who can review" (#36394)
2025-03-07|||Update chat_extras.md  with content correction (#36599)
2025-03-07|||Github action for auto-assigning reviewers (#35846)
2025-03-07|||Export base streamer. (#36500)
2025-03-07|||avoid errors when the size of `input_ids` passed to `PrefixConstrainedLogitsProcessor` is zero (#36489)
2025-03-06|||Mention UltraScale Playbook üåå in docs (#36589)
2025-03-07|||fix: argument (#36558)
2025-03-06|||[XGLM] tag tests as slow (#36592)
2025-03-06|||[bark] fix loading of generation config (#36587)
2025-03-07|||Integrate SwanLab for offline/online experiment tracking and local visualization (#36433)
2025-03-06|||Modular Conversion --fix_and_overwrite on Windows (#36583)
2025-03-06|||Delete redundancy if case in model_utils (#36559)
2025-03-06|||Bump transformers from 4.38.0 to 4.48.0 in /examples/research_projects/pplm (#36540)
2025-03-06|||chore: enhance message descriptions in parameters,comments,logs and docstrings (#36554)
2025-03-06|||Fix typos . (#36551)
2025-03-06|||Fix typos in tests (#36547)
2025-03-05|||guard torch version for uint16 (#36520)
2025-03-05|||chore: enhance messages in docstrings (#36525)
2025-03-04|||Fix links in quantization doc (#36528)
2025-03-04|||Fix bamba tests amd (#36535)
2025-03-04|||chore: Fix typos in docs and examples (#36524)
2025-03-04|||Add aya (#36521)
2025-03-03|||[docs] Redesign (#31757)
2025-03-03|||Remove unused code (#36459)
2025-03-03|||[Style] fix E721 warnings (#36474)
2025-03-03|||Fix edge case for continue_final_message (#36404)
2025-03-03|||Fix pipeline+peft interaction (#36480)
2025-03-04|||chore: fix message descriptions in arguments and comments (#36504)
2025-03-04|||Fix some typos in docs (#36502)
2025-03-03|||fix torch_dtype, contiguous, and load_state_dict regression (#36512)
2025-03-03|||Fix kwargs UserWarning in SamImageProcessor (#36479)
2025-03-03|||Check `TRUST_REMOTE_CODE` for `RealmRetriever` for security (#36511)
2025-03-03|||Fix loading zero3 weights (#36455)
2025-03-02|||Fix _load_state_dict_into_meta_model with device_map=None (#36488)
2025-03-01|||Fix couples of issues from #36335 (#36453)
2025-03-01|||Add Got-OCR 2 Fast image processor and refactor slow one (#36185)
2025-02-28|||[docs] fix bug in deepspeed config (#36081)
2025-02-28|||Fix loading models with mismatched sizes (#36463)
2025-02-27|||[GroundingDino] Fix grounding dino loss üö® (#31828)
2025-02-27|||Fix `hub_retry` (#36449)
2025-02-27|||Lazy import libraries in `src/transformers/image_utils.py` (#36435)
2025-02-27|||[generate] `torch.distributed`-compatible `DynamicCache` (#36373)
2025-02-27|||[save_pretrained ] Skip collecting duplicated weight (#36409)
2025-02-27|||Add `contents: write` (#36445)
2025-02-27|||Fix another permission (#36444)
2025-02-27|||Fix permission (#36443)
2025-02-27|||Change PR to draft when it is (re)opened (#36417)
2025-02-26|||restrict cache allocator to non quantized model (#36428)
2025-02-26|||Fix Expected output for compressed-tensors tests (#36425)
2025-02-26|||Update form pretrained to make TP a first class citizen (#36335)
2025-02-26|||Fix compressed tensors config (#36421)
2025-02-26|||Universal Speculative Decoding `CandidateGenerator` (#35029)
2025-02-26|||fix: prevent model access error during Optuna hyperparameter tuning (#36395)
2025-02-26|||add recommendations for NPU using flash_attn (#36383)
2025-02-26|||Fixing the docs corresponding to the breaking change in torch 2.6. (#36420)
2025-02-26|||Deprecate transformers.agents (#36415)
2025-02-25|||Add retry hf hub decorator (#35213)
2025-02-26|||Fixed VitDet for non-squre Images (#35969)
2025-02-25|||Security fix for `benchmark.yml` (#36402)
2025-02-25|||Fix convert_to_rgb for SAM ImageProcessor (#36369)
2025-02-25|||[CLI] add import guards (#36376)
2025-02-25|||Fix pytorch integration tests for SAM (#36397)
2025-02-25|||chore: fix function argument descriptions (#36392)
2025-02-25|||fix audio classification pipeline fp16 test on cuda (#36359)
2025-02-25|||[tests] enable autoawq tests on XPU  (#36327)
2025-02-25|||tests: revert change of torch_require_multi_gpu to be device agnostic (#35721)
2025-02-25|||addressing the issue #34611 to make FlaxDinov2 compatible with any batch size (#35138)
2025-02-25|||Added handling for length <2 of suppress_tokens for whisper (#36336)
2025-02-25|||Fix doc formatting in forward passes & modular (#36243)
2025-02-25|||Update _get_eval_sampler to reflect Trainer.tokenizer is deprecation  self.tokenizer -> self.processing_class (#36315)
2025-02-25|||enable torchao quantization on CPU (#36146)
2025-02-25|||Fix `is_causal` fail with compile (#36374)
2025-02-25|||[modular] Do not track imports in functions (#36279)
2025-02-25|||Load models much faster on accelerator devices!! (#36380)
2025-02-25|||Update modeling_llava_onevision.py (#36391)
2025-02-24|||notify new model merged to `main` (#36375)
2025-02-24|||[Modeling] Reduce runtime when loading missing keys (#36312)
2025-02-25|||fix(type): padding_side type should be Optional[str] (#36326)
2025-02-24|||Update amd pytorch index to match base image (#36347)
2025-02-24|||Add autoquant support for torchao quantizer (#35503)
2025-02-24|||Change slack channel for mi250 CI to amd-hf-ci (#36346)
2025-02-24|||Improve model loading for compressed tensor models (#36152)
2025-02-24|||[tests] enable bnb tests on xpu (#36233)
2025-02-21|||Fix exploitable regexes in Nougat and GPTSan/GPTJNeoXJapanese (#36121)
2025-02-21|||Uses Collection in transformers.image_transforms.normalize (#36301)
2025-02-21|||[tests] make quanto tests device-agnostic (#36328)
2025-02-21|||[CI] Check test if the `GenerationTesterMixin` inheritance is correct üêõ üî´  (#36180)
2025-02-21|||Add SigLIP 2 (#36323)
2025-02-21|||VLMs: even more clean-up (#36249)
2025-02-21|||Fix default attention mask of generate in MoshiForConditionalGeneration (#36171)
2025-02-20|||[smolvlm] make CI green (#36306)
2025-02-20|||fix: prevent second save in the end of training if last step was saved already (#36219)
2025-02-20|||Fix typo in Pixtral example (#36302)
2025-02-20|||SmolVLM2 (#36126)
2025-02-20|||Ignore conversion files in test fetcher (#36251)
2025-02-20|||Fix broken CI on release branch due to missing conversion files  (#36275)
2025-02-20|||Make cache traceable (#35873)
2025-02-19|||Fix callback handler reference (#36250)
2025-02-20|||docs: Update README_zh-hans.md (#36269)
2025-02-19|||Add Example for Custom quantization (#36286)
2025-02-19|||[tests] make `test_from_pretrained_low_cpu_mem_usage_equal` less flaky (#36255)
2025-02-19|||[tests] remove flax-pt equivalence and cross tests (#36283)
2025-02-19|||[tests] deflake dither test (#36284)
2025-02-19|||TP initialization module-by-module (#35996)
2025-02-19|||[tests] remove `pt_tf` equivalence tests (#36253)
2025-02-19|||Add dithering to the `Speech2TextFeatureExtractor` API. (#34638)
2025-02-18|||Add support for post-processing kwargs in image-text-to-text pipeline (#35374)
2025-02-18|||Uniformize LlavaNextVideoProcessor kwargs (#35613)
2025-02-18|||Qwen2VL fix cos,sin dtypes to float when used with deepspeed (#36188)
2025-02-18|||Added Support for Custom Quantization (#35915)
2025-02-18|||GitModelIntegrationTest - flatten the expected slice tensor (#36260)
2025-02-18|||Fix XGLM loss computation (PyTorch and TensorFlow) (#35878)
2025-02-18|||feat: add support for tensor parallel training workflow with accelerate (#34194)
2025-02-18|||Remove flakiness in VLMs  (#36242)
2025-02-18|||Fix TorchAoConfig not JSON serializable (#36206)
2025-02-17|||Au revoir flaky `test_fast_is_faster_than_slow` (#36240)
2025-02-17|||[tests] remove `test_export_to_onnx` (#36241)
2025-02-17|||Add compressed tensor in quant dockerfile (#36239)
2025-02-17|||Bump transformers from 4.38.0 to 4.48.0 in /examples/research_projects/codeparrot/examples (#36237)
2025-02-17|||[generate] Fix encoder decoder models attention mask (#36018)
2025-02-17|||[tests] remove tf/flax tests in `/generation` (#36235)
2025-02-17|||v4.45.0-dev0
2025-02-17|||Add missing atol to torch.testing.assert_close where rtol is specified (#36234)
2025-02-17|||[generate] remove cache v4.47 deprecations (#36212)
2025-02-17|||AMD DeepSpeed image additional HIP dependencies (#36195)
2025-02-17|||Fix `LlavaForConditionalGenerationModelTest::test_config` after #36077 (#36230)
2025-02-17|||[tests] fix `EsmModelIntegrationTest::test_inference_bitsandbytes`  (#36225)
2025-02-14|||set `test_torchscript = False` for Blip2 testing  (#35972)
2025-02-14|||Use `args.num_workers` in `check_modular_conversion.py` (#36200)
2025-02-14|||add shared experts for upcoming Granite 4.0 language models (#35894)
2025-02-14|||Add @require_bitsandbytes to Aria test_batched_generation (#36192)
2025-02-14|||[Bugfix] Fix reloading of pixtral/llava configs (#36077)
2025-02-14|||üî¥ VLM: compile compatibility (#35724)
2025-02-14|||Guard against unset resolved_archive_file (#35628)
2025-02-14|||Revert qwen2 breaking changes related to attention refactor (#36162)
2025-02-14|||Add require_read_token to fp8 tests (#36189)
2025-02-14|||New HIGGS quantization interfaces, JIT kernel compilation support. (#36148)
2025-02-14|||Prepare processors for VideoLLMs (#36149)
2025-02-14|||Add ImageProcessorFast to Qwen2.5-VL processor (#36164)
2025-02-14|||Chat template docs (#36163)
2025-02-14|||CI: fix `test-save-trainer` (#36191)
2025-02-14|||Add support for partial rotary embeddings in Phi3 model (#35947)
2025-02-13|||Uniformize OwlViT and Owlv2 processors (#35700)
2025-02-13|||Fix make_batched_videos and add tests (#36143)
2025-02-13|||Fix a mistake in #36175 (#36179)
2025-02-13|||Follow up to SpQR integration (#36176)
2025-02-14|||Fix the key name for _load_rng_state under torch.cuda (#36138)
2025-02-13|||Make `check_repository_consistency` run faster by MP (#36175)
2025-02-14|||Optimize Qwen2VL vision model by precomputing cos/sin embeds before ViT blocks (#35837)
2025-02-13|||Use tqdm auto (#35726)
2025-02-13|||CI: avoid human error, automatically infer generative models (#33212)
2025-02-13|||add disable compile option (#36161)
2025-02-13|||fix training issues (#36158)
2025-02-13|||Efficient Inference Kernel for SpQR  (#34976)
2025-02-13|||Bump transformers from 4.38.0 to 4.48.0 in /examples/research_projects/adversarial (#36168)
2025-02-13|||Bump transformers from 4.38.0 to 4.48.0 in /examples/tensorflow/language-modeling-tpu (#36167)
2025-02-13|||[generate] revert change in Aria: the maximum cache length must match `max_length` (#36120)
2025-02-13|||Fix : fix doc fp8 (#36173)
2025-02-13|||Fix red CI (#36174)
2025-02-13|||[Modular] skip modular checks based on diff (#36130)
2025-02-13|||Remove loading custom kernel for RT-DETRv2 (#36098)
2025-02-13|||Adding FP8 Quantization to transformers (#36026)
2025-02-13|||Helium documentation fixes (#36170)
2025-02-13|||Move `DataCollatorForMultipleChoice` from the docs to the package (#34763)
2025-02-13|||Fix PretrainedTokenizerFast check => Fix PretrainedTokenizerFast Save (#35835)
2025-02-13|||docs: fix return type annotation of `get_default_model_revision` (#35982)
2025-02-13|||qwen2.5vl: fix bugs when using flash2+bf16 or num_return_sequences>1 (#36083)
2025-02-13|||Fix tests for vision models (#35654)
2025-02-13|||Replace deprecated update_repo_visibility (#35970)
2025-02-13|||Fix Gemma2 dtype issue when storing weights in float16 precision (#35398)
2025-02-13|||Add reminder config to issue template and print DS version in env (#35156)
2025-02-13|||Fix PaliGemma Pad Token Masking During Training #35855 (#35859)
2025-02-13|||Mllama fsdp (#36000)
2025-02-12|||Add git LFS to AMD docker image (#36016)
2025-02-12|||skip `test_initialization` for `VitPoseBackboneModelTest` for now (#36154)
2025-02-12|||Fix test fetcher (#36129)
2025-02-12|||Add more rigerous non-slow grad accum tests (#35668)
2025-02-12|||Update doc re list of models supporting TP (#35864)
2025-02-12|||adding option to save/reload scaler (#34932)
2025-02-12|||Fix multi gpu loss sync condition, add doc and test (#35743)
2025-02-12||| Optim: APOLLO optimizer integration (#36062)
2025-02-12|||multi-gpu: fix tensor device placements for various models (#35763)
2025-02-12|||üö® Remove cache migration script (#35810)
2025-02-12|||Bump cryptography from 43.0.1 to 44.0.1 in /examples/research_projects/decision_transformer (#36142)
2025-02-12|||Bump transformers from 4.38.0 to 4.48.0 in /examples/research_projects/vqgan-clip (#36136)
2025-02-12|||Fix Gradient Checkpointing for Deberta & Deberta-V2 using PEFT / Adapters (#35898)
2025-02-12|||[commands] remove deprecated/inoperational commands (#35718)
2025-02-12|||VLM: enable skipped tests (#35746)
2025-02-12|||Add utility for Reload Transformers imports cache for development workflow #35508 (#35858)
2025-02-12|||Whisper: remove redundant assisted generation tests (#34814)
2025-02-12|||added warning to Trainer when label_names is not specified for PeftModel (#32085)
2025-02-12|||add RAdamScheduleFree optimizer (#35313)
2025-02-12|||Add pipeline parallel plan to `PretrainedConfig` and `PreTrainedModel` (#36091)
2025-02-12|||[docs] update awq doc (#36079)
2025-02-12|||[docs] minor doc fix (#36127)
2025-02-11|||Make `output_dir` Optional in `TrainingArguments` #27866 (#35735)
2025-02-11|||update tiktoken integ to use converted (#36135)
2025-02-11|||Fix CI issues  (#35662)
2025-02-11|||Fix max size deprecated warning (#34998)
2025-02-11|||update awesome-transformers.md. (#36115)
2025-02-11|||fix: typos in documentation files (#36122)
2025-02-11|||Add common test for `torch.export` and fix some vision models (#35124)
2025-02-11|||Fix nighlty CIs: missing atols (#35903)
2025-02-10|||AutoformerForPrediction test add atol (#36017)
2025-02-10|||[generate] shape checks in tests compatible with fixed-length caches (+ some minor fixes) (#35993)
2025-02-10|||fix bnb warning (#36116)
2025-02-10|||[Bugfix] fix file name of docstring in utils/check_table.py (#36108)
2025-02-10|||Revert checkpoint tmp dir (#36112)
2025-02-10|||Refactor OPT model (#36101)
2025-02-10|||Remove Multi-threaded image conversion for fast image processors (#36105)
2025-02-10|||Enable pytest live log and show warning logs on GitHub Actions CI runs (#35912)
2025-02-10|||Support constant lr with cooldown (#35453)
2025-02-10|||Add Apple's Depth-Pro for depth estimation (#34583)
2025-02-10|||Paligemma: revert #36084 (#36113)
2025-02-10|||Chat template: update for processor (#35953)
2025-02-10|||Processors: allow tuples of images when checking (#36084)
2025-02-10|||fix MllamaVisionAttention typehint (#35975)
2025-02-08|||[docs] fix not-working example code in `perf_infer_gpu_one.md` (#36087)
2025-02-08|||[docs] fix typo (#36080)
2025-02-08|||[docs] fix model checkpoint name (#36075)
2025-02-07|||Fix OS err (#36094)
2025-02-07|||Move audio top_k tests to the right file and add slow decorator (#36072)
2025-02-07|||Fix bug in apply_rotary_pos_emb_flashatt: in Qwen2-5-VL (#36065)
2025-02-06|||Adding RT-DETRv2 for object detection (#34773)
2025-02-07|||[docs] fix outdated example code in `trainer.md` (#36066)
2025-02-06|||Fix StopStringCriteria to handle tokens above len(tokenizer) (#35797)
2025-02-06|||Fix model kwargs (#35875)
2025-02-06|||Fix words typos in ggml test. (#36060)
2025-02-06|||Nail in edge case of torch dtype being overriden permantly in the case of an error (#35845)
2025-02-06|||Save checkpoint to temporary directory to handle partial saves during failures (#35580)
2025-02-06|||Paligemma: fix generation with Gemma2 (#36044)
2025-02-06|||Update `test_flash_attn_2_can_dispatch_composite_models` (#36050)
2025-02-06|||Fix repo consistency (#36063)
2025-02-06|||Fix usage of unpad_input function (#35925)
2025-02-06|||Iterative generation using Input embeds and `past_key_values` (#35890)
2025-02-06|||Add `Qwen2VLImageProcessorFast` into `Qwen2VLProcessor` (#35987)
2025-02-05|||Fix Audio Classification Pipeline top_k Documentation Mismatch and Bug #35736 (#35771)
2025-02-05|||Fix how we compute the final non-padding token for ForSequenceClassification models (#35911)
2025-02-06|||[docs] no hard-coding cuda (#36043)
2025-02-06|||[docs] fix bugs in the bitsandbytes documentation (#35868)
2025-02-06|||[docs] no hard coding cuda as bnb has multi-backend support (#35867)
2025-02-05|||DeepSpeed github repo move sync (#36021)
2025-02-05|||add support for empty list as input to create_model_card (#36042)
2025-02-05|||Add XPU type for work-around -inf mask causing sdpa NaN issue in modeling files (#35647)
2025-02-05|||Fix synced multi-GPU generation with LLMs and VLMs (#35893)
2025-02-05|||Fix Gemma2 synced multi-GPU generation (#35232)
2025-02-04|||Refactoring of ImageProcessorFast (#35069)
2025-02-04|||Add DAB-DETR for object detection (#30803)
2025-02-04|||Update tests regarding attention types after  #35235 (#36024)
2025-02-04|||CircleCI with python 3.9 (#36027)
2025-02-04|||feat(ci): ignore trufflehog unverified results (#36031)
2025-02-04|||Hotfix for `self-comment-ci.yml` (#36030)
2025-02-04|||Display warning for unknown quants config instead of an error (#35963)
2025-02-04|||Commont bot CI for other jobs (`generation` / `quantization`) (#35341)
2025-02-04|||Fix RMSNormGated in Zamba2 (#35943)
2025-02-04|||Fix device mismatch error in Whisper model during feature extraction (#35866)
2025-02-04|||Refactor (and fix) gpt_neox (#35610)
2025-02-04|||Update Mistral converter (#35967)
2025-02-04|||layernorm_decay_fix (#35927)
2025-02-04|||apply_chat_template: consistent behaviour for return_assistant_tokens_mask=True return_tensors=True (#35582)
2025-02-04|||Fix custom kernel for DeformableDetr, RT-Detr, GroindingDINO, OmDet-Turbo in Pytorch 2.6.0 (#35979)
2025-02-04|||Qwen2-VL: fix rope delta calculation (#36013)
2025-02-03|||Update Granite Vision Model Path / Tests (#35998)
2025-02-03|||Add mean_resizing for every VLMs' resizing_token_embeddings() (#35717)
2025-02-03|||Update-tp test (#35844)
2025-01-31|||use torch 2.6 for daily CI (#35985)
2025-01-31|||Add GOT-OCR 2.0 to Transformers (#34721)
2025-01-31|||[Moshi] disable automatic compilation if the model can't compile (#35992)
2025-01-31|||[Moonshine] compute head_dim_padding at init (#35984)
2025-01-30|||Add support for nested images to LLava and VipLLava (#35558)
2025-01-30|||Handle empty change indices in SAM's mask to rle conversion (#35665)
2025-01-30|||not to use A100 for `benchmark.yml` (#35974)
2025-01-30|||Support batching for UsefulSensors Moonshine (#35922)
2025-01-30|||Less flaky for `TimmBackboneModelTest::test_batching_equivalence` (#35971)
2025-01-30|||Revert p_mask to a list in DQA pipeline (#35964)
2025-01-30|||Whisper: fix static cache CI (#35852)
2025-01-30|||Pixtral: vectorize patch embeddings and enable tests (#35122)
2025-01-30|||[bart] minor test fixes (#35965)
2025-01-30|||Fix is_causal being a tensor (#35791)
2025-01-29|||fix iterator overflow when gradient accumulation is 1 (#35960)
2025-01-29|||[generate] move max time tests (#35962)
2025-01-29|||Update README.md (#35958)
2025-01-29|||[tests] further fix `Tester object has no attribute '_testMethodName'`  (#35781)
2025-01-29|||update docker file `transformers-pytorch-deepspeed-latest-gpu` (#35940)
2025-01-29|||Trainer Refactor: Part 1 (#35567)
2025-01-29|||Output dicts support in text generation pipeline (#35092)
2025-01-29|||Fix flaky `test_assisted_decoding_matches_greedy_search` (#35951)
2025-01-29|||Update `squad_convert_example_to_features` to work with numpy v2 (#35955)
2025-01-29|||Update `unwrap_and_save_reload_schedule` to use `weights_only=False` (#35952)
2025-01-29|||fix `test_generated_length_assisted_generation` (#34935)
2025-01-28|||use torch constraints to check if covariance is positive definite during mean resizing. (#35693)
2025-01-28|||Remove INC notebook reference in documentation (#35936)
2025-01-28|||fix(FA): QKV not being casted to target_dtype for FA with dpo lora (#35834)
2025-01-28|||Test: generate with `torch.compile(model.forward)` as a fast test (#34544)
2025-01-28|||Fix TP initialization (#35860)
2025-01-28|||Qwen-2-5-VL: fix CI (#35935)
2025-01-28|||Fix mask slicing for models with HybridCache (#35681)
2025-01-28|||Fix: loading DBRX back from saved path (#35728)
2025-01-28|||Add default TP plan for all models with backend support (#35870)
2025-01-28|||Use rocm6.2 for AMD images (#35930)
2025-01-28|||Remove `_supports_static_cache = True` for some model classes (#34975)
2025-01-27|||[docs] Fix Zamba2 (#35916)
2025-01-27|||Close Zamba2Config code block (#35914)
2025-01-27|||Fix the config class comparison for remote code models (#35592)
2025-01-27|||[docs] uv install (#35821)
2025-01-27|||Fix typing in audio_utils.chroma_filter_bank (#35888)
2025-01-27|||Split and clean up GGUF quantization tests (#35502)
2025-01-27|||üö®üö®üö® image-classification pipeline single-label and multi-label prob type squashing fns (sigmoid vs softmax) are backwards (#35848)
2025-01-27|||üî¥ üî¥ üî¥  Added `segmentation maps` support for DPT image processor (#34345)
2025-01-27|||Update deepspeed amd image (#35906)
2025-01-27|||Add Zamba2 (#34517)
2025-01-27|||Fix fast image processor warnings in object detection examples (#35892)
2025-01-26|||[doctest] Fixes (#35863)
2025-01-24|||Add `Rocketknight1` to `self-comment-ci.yml` (#35881)
2025-01-25|||add xpu device check in device_placement (#35865)
2025-01-24|||use torch.testing.assertclose instead to get more details about error in cis (#35659)
2025-01-24|||Fix Llava-NeXT / Llava-NeXT Video / Llava-OneVision's token unpadding mismatch (#35779)
2025-01-23|||Fix `test_pipelines_video_classification` that was always failing (#35842)
2025-01-24|||fix apply_chat_template() padding choice (#35828)
2025-01-23|||Fix typo (#35854)
2025-01-24|||[DOC] Fix contamination and missing paragraph in translation (#35851)
2025-01-23|||Granite Vision Support (#35579)
2025-01-23|||Fix more CI tests (#35661)
2025-01-23|||Fix uploading processors/tokenizers to WandB on train end (#35701)
2025-01-23|||Fix GA loss for Deepspeed (#35808)
2025-01-23|||add qwen2.5vl (#35569)
2025-01-23|||[Backend support] Allow `num_logits_to_keep` as Tensor + add flag (#35757)
2025-01-23|||[ `tests`] remove some flash attention class tests (#35817)
2025-01-22|||Fix NoneType type as it requires py>=3.10 (#35843)
2025-01-22|||Add PyTorch version check for FA backend on AMD GPUs (#35813)
2025-01-22|||Fix compatibility issues when using auto_gptq with these older versions (#35830)
2025-01-22|||[chat] docs fix (#35840)
2025-01-22|||Fix `head_dim` in config extracted from Gemma2 GGUF model (#35818)
2025-01-22|||[Chat] Add Chat from TRL üêà  (#35714)
2025-01-22|||Fix : Nemotron tokenizer for GGUF format (#35836)
2025-01-22|||[pipeline] missing import regarding assisted generation (#35752)
2025-01-22|||[gpt2] fix generation tests (#35822)
2025-01-22|||Hotfix: missing `working-directory` in `self-comment-ci.yml` (#35833)
2025-01-22|||Init cache on meta device (#35164)
2025-01-22|||Another security patch for `self-comment-ci.yml` (#35816)
2025-01-21|||Remove pyav pin to allow python 3.11 to be used (#35823)
2025-01-21|||Remove old `benchmark` code (#35730)
2025-01-21|||[Mimi] update test expected values for t4 runners (#35696)
2025-01-21|||Improve modular documentation (#35737)
2025-01-21|||add Qwen2-VL image processor fast (#35733)
2025-01-21|||move fastspeech to audio models (#35788)
2025-01-21|||[i18n-ar] Translated file: `docs/source/ar/tasks/masked_language_modeling.md` into Arabic (#35198)
2025-01-22|||Optimized set_initialized_submodules. (#35493)
2025-01-21|||Remove deprecated `get_cached_models` (#35809)
2025-01-21|||Fixed typo in autoawq version number in an error message for IPEX backend requirements. (#35815)
2025-01-21|||Fix : BLOOM tie_word_embeddings in GGUF (#35812)
2025-01-21|||Auto-add `timm` tag to timm-wrapper models. (#35794)
2025-01-21|||Support adamw_torch_8bit (#34993)
2025-01-21|||add a new flax example for Bert model inference (#34794)
2025-01-21|||[Doc] Adding blog post to model doc for `TimmWrapper` (#35744)
2025-01-21|||Byebye `test_batching_equivalence`'s flakiness (#35729)
2025-01-21|||Add LlavaImageProcessor (#33191)
2025-01-21|||Update AMD Docker image (#35804)
2025-01-21|||Fix  "test_chat_template_dict" in video LLMs (#35660)
2025-01-21|||Deterministic sorting in modular converter when adding new functions (#35795)
2025-01-21|||modular_model_converter bugfix on assignments (#35642)
2025-01-20|||Fixes, improvements to `timm` import behaviour (#35800)
2025-01-20|||Tool calling: support more types (#35776)
2025-01-21|||fix low-precision audio classification pipeline (#35435)
2025-01-21|||Fix vits low-precision dtype (#35418)
2025-01-21|||fix document qa bf16 pipeline (#35456)
2025-01-20|||Don't import torch.distributed when it's not available (#35777)
2025-01-20|||Patch moonshine (#35731)
2025-01-20|||transformers.image_transforms.normalize wrong types (#35773)
2025-01-20|||[fix] cannot import name 'Pop2PianoFeatureExtractor' from 'transformers' (#35604)
2025-01-20|||Skip Falcon 7B GGML Test  (#35783)
2025-01-20|||remove code owners as it was generating too much noise BUT (#35784)
2025-01-20|||Remove read_video and run
2025-01-20|||[generate] update docstring of `SequenceBiasLogitsProcessor` (#35699)
2025-01-20|||fix register_buffer in MimiEuclideanCodebook (#35759)
2025-01-20|||Add SuperGlue model (#29886)
2025-01-20|||[ViTPose] Convert more checkpoints (#35638)
2025-01-20|||Security fix for `self-comment-ci.yml` (#35548)
2025-01-20|||Fix CI for VLMs (#35690)
2025-01-17|||Use AMD CI workflow defined in hf-workflows (#35058)
2025-01-17|||ci: fix xpu skip condition for test_model_parallel_beam_search (#35742)
2025-01-17|||Stop mutating input dicts in audio classification pipeline (#35754)
2025-01-17|||Revert "Unable to use `MimiModel` with DeepSpeed ZeRO-3" (#35755)
2025-01-17|||Restore is_torch_greater_or_equal_than for backward compatibility (#35734)
2025-01-17|||Grounding DINO Processor standardization (#34853)
2025-01-17|||OmDet Turbo processor standardization (#34937)
2025-01-17|||OwlViT/Owlv2 post processing standardization (#34929)
2025-01-17|||Added liger_kernel compatibility with `PeftModel` (#35680)
2025-01-17|||check is added for the report_to variable in TrainingArguments (#35403)
2025-01-17|||Unable to use `MimiModel` with DeepSpeed ZeRO-3 (#34735)
2025-01-17|||Fix some tests (#35682)
2025-01-16|||üö®üö®üö® An attempt to fix #29554. Include 'LayerNorm.' in gamma/beta rename scope, optimize string search. (#35615)
2025-01-17|||Added resource class configuration option for `check_circleci_user` job (#32866)
2025-01-16|||[generate] return Cache object even if passed in a legacy format (#35673)
2025-01-16|||[generate] can instantiate `GenerationConfig(cache_implementation="static")` (#35679)
2025-01-16|||Remove `pt_to_tf` (#35672)
2025-01-16|||üßπ remove `generate`-related objects and methods scheduled for removal in v4.48 (#35677)
2025-01-16|||[cache] add a test to confirm we can use cache at train time (#35709)
2025-01-16|||Remove batch size argument warning when unjustified (#35519)
2025-01-16|||Modular: support for importing functions from any file (#35692)
2025-01-16|||Optimize ForCausalLMLoss by removing unnecessary contiguous() call to reduce memory overhead (#35646)
2025-01-16|||Add proper jinja2 error (#35533)
2025-01-16|||[generation] fix type hint (#35725)
2025-01-16|||Fix the bug that `Trainer` cannot correctly call `torch_jit_model_eval` (#35722)
2025-01-16|||Fix condition when GA loss bug fix is not performed (#35651)
2025-01-16|||Fix: Falcon tie_word_embeddings in GGUF (#35715)
2025-01-16|||Replace deprecated batch_size with max_batch_size when using HybridCache (#35498)
2025-01-16|||Fix typo in /docs/source/ja/model_doc/decision_transformer.md URL (#35705)
2025-01-15|||Fix : Nemotron Processor in GGUF conversion (#35708)
2025-01-15|||Enable gptqmodel (#35012)
2025-01-15|||Add future import for Py < 3.10 (#35666)
2025-01-15|||Clean-up composite configs (#34603)
2025-01-14|||Enhance DataCollatorForLanguageModeling with Configurable Token Replacement Probabilities (#35251)
2025-01-14|||Enhanced Installation Section in README.md (#35094)
2025-01-14|||Fix : add require_read_token for gemma2 gated model (#35687)
2025-01-14|||Fix expected output for ggml test (#35686)
2025-01-14|||Fix : HQQ config when hqq not available (#35655)
2025-01-14|||Update torchao.md: use auto-compilation (#35490)
2025-01-14|||Fix : adding einops lib in the CI docker for some bitsandbytes tests (#35652)
2025-01-13|||Fix `zero_shot_image_classification` documentation guide link in SigLIP (#35671)
2025-01-13|||Add-helium (#35669)
2025-01-13|||[i18n-ar] Translated file : docs/source/ar/tasks/token_classification.md into Arabic (#35193)
2025-01-13|||[tests] make cuda-only tests device-agnostic (#35607)
2025-01-13|||[`Compile`] Only test compiling model forward pass (#35658)
2025-01-13|||Enable different torch dtype in sub models (#34873)
2025-01-13|||[`Phi`] bias should be True (#35650)
2025-01-13|||Removed some duplicated code (#35637)
2025-01-13|||Fix whisper compile (#35413)
2025-01-13|||Fix device in rope module when using dynamic updates (#35608)
2025-01-10|||Update codeowners with individual model owners (#35595)
2025-01-10|||Skip `MobileNetV1ModelTest::test_batching_equivalence` for now (#35614)
2025-01-10|||Fix flaky `test_beam_search_low_memory` (#35611)
2025-01-10|||Let `EarlyStoppingCallback` not require `load_best_model_at_end` (#35101)
2025-01-10|||Added error when sequence length is bigger than max_position_embeddings (#32156)
2025-01-10|||Use inherit tempdir makers for tests + fix failing DS tests (#35600)
2025-01-10|||Fix flaky `test_custom_4d_attention_mask` (#35606)
2025-01-10|||v4.49.0-dev
2025-01-10|||[WIP] Emu3: add model (#33770)
2025-01-10|||Fix flex_attention in training mode (#35605)
2025-01-10|||Remove `benchmark.py` after #34275
2025-01-10|||Chat template: return vectorized output in processors (#34275)
2025-01-10|||Add Moonshine  (#34784)
2025-01-10|||Skip `torchscript` tests if a cache object is in model's outputs (#35596)
2025-01-10|||ModernBert: reuse GemmaRotaryEmbedding via modular + Integration tests (#35459)
2025-01-09|||Add flex_attn to diffllama (#35601)
2025-01-09|||ModernBERT bug fixes (#35404)
2025-01-09|||add `_supports_flex_attn = True` for models that do support it (#35598)
2025-01-10|||[doc] deepspeed universal checkpoint (#35015)
2025-01-09|||Refactor/fix Cohere2 (#35594)
2025-01-09|||[`tokenizers`] Ensure that add_prefix_space is propagated to backend_tokenizer.pre_tokenizer (#35593)
2025-01-09|||Fix modular edge case + modular sorting order (#35562)
2025-01-09|||PR for Issue #22694: Fixed Training Evaluation table display for VSCode (#35557)
2025-01-09|||Small fix rope kwargs (#35589)
2025-01-09|||Fix flaky `SwitchTransformersModelTest::test_training_gradient` (#35587)
2025-01-09|||`tokenizer` train from iterator without pre_tokenizers  (#35396)
2025-01-09|||feat: add TP plan for granite (#35573)
2025-01-09|||[Idefics3] Move image features to same device as input embeds (#35100)
2025-01-09|||Add inputs_embeds param to ModernBertModel (#35373)
2025-01-09|||Fix flaky `test_batching_equivalence` (#35564)
2025-01-09|||Setup loss_type in config at model init time (#34616)
2025-01-09|||Re-add missing __all__ for Cohere and Phi3 (#35578)
2025-01-09|||Minor fix in video text 2 text docs (#35546)
2025-01-09|||More model refactoring! (#35359)
2025-01-09|||Don't show warning for `inv_freq` buffers (#35255)
2025-01-09|||Fix multi-gpu loss (#35395)
2025-01-09|||update code owners (#35576)
2025-01-09|||[i18n-ar] Translated file: `docs/source/ar/tasks/multiple_choice.md` into Arabic (#35199)
2025-01-09|||Fix all output_dir in test_trainer.py to use tmp_dir (#35266)
2025-01-08|||Pipeline: simple API for assisted generation (#34504)
2025-01-08|||[`PixtralLarge`] Update Pixtral conversion script to support large format! (#34801)
2025-01-09|||[docs] Remove Hiera from AUDIO MODELS in docs (#35544)
2025-01-09|||ovewrite top_k when crate audio classification pipeline (#35541)
2025-01-08|||add code owners (#35528)
2025-01-08|||Add ViTPose (#30530)
2025-01-09|||fix: Qwen2-VL generate with inputs_embeds (#35466)
2025-01-09|||Update doc for `metric_for_best_model` when `save_strategy="best"`. (#35389)
2025-01-09|||Add: num_additional_image_tokens to models (#35052)
2025-01-08|||Enable auto task for timm models in pipeline (#35531)
2025-01-08|||Bump torch requirement to >= 2 (#35479)
2025-01-08|||Timm wrapper label names (#35553)
2025-01-08|||Update missing model error message (#35370)
2025-01-08|||Update doc and default value of TextNetImageProcessor (#35563)
2025-01-08|||Add support for modular with fast image processors (#35379)
2025-01-08|||[Docs] links to `logits-processor-zoo` (#35552)
2025-01-08|||Fix Qwen2VL processor to handle odd number of frames (#35431)
2025-01-08|||support chat generator as input of TextGenerationPipeline (#35551)
2025-01-08|||Pass correct `num_items_in_batch` value into the training_step function (#35438)
2025-01-08|||MODERNBERT_INPUTS_DOCSTRING: past_key_values are ignored (#35513)
2025-01-08|||VLMs: major clean up üßº  (#34502)
2025-01-08|||Add TextNet (#34979)
2025-01-07|||[docs] Remove sortish_sampler (#35539)
2025-01-07|||Correctly list the chat template file in the Tokenizer saved files list (#34974)
2025-01-07|||[Whisper] fix docstrings typo (#35338)
2025-01-07|||[Qwen2Audio] handle input ids expansion during processing (#35534)
2025-01-07|||Release GPU memory after Optuna trial (#35440)
2025-01-07|||Check whether rescale is requested before checking is_scaled_image (#35439)
2025-01-07|||Fix bug when requesting input normalization with EnCodec (#34756)
2025-01-07|||Add diffllama (#34083)
2025-01-07|||NPU support SDPA (#35165)
2025-01-07|||Replace tokenizer to processing_class in Seq2SeqTrainer (#35452)
2025-01-07|||ci: mark model_parallel tests as cuda specific (#35269)
2025-01-06|||Zamba new attention standard (#35375)
2025-01-06|||[Dinov2 with Registers] Some fixes (#35411)
2025-01-07|||added logic for deleting adapters once loaded (#34650)
2025-01-06|||Fixed typo in Llama configuration docstring (#35520)
2025-01-07|||üåê [i18n-KO] Remove duplicates in toctree (#35496)
2025-01-07|||[GGUF] Refactor and decouple gguf checkpoint loading logic (#34385)
2025-01-06|||Bump jinja2 from 3.1.4 to 3.1.5 in /examples/research_projects/decision_transformer (#35408)
2025-01-06|||Update llm_optims docs for `sdpa_kernel` (#35481)
2025-01-07|||üåê [i18n-KO] Translated `altclip.md` to Korean (#34594)
2025-01-06|||Add check for if num_items_in_batch is not None (#35102)
2025-01-06|||Add `position_ids` in `XLMRobertaXLForCausalLM.prepare_inputs_for_generation` (#35044)
2025-01-06|||Add French translation of task_summary and tasks_explained (#33407)
2025-01-06|||Idefics: fix docstring (#35079)
2025-01-06||| Fix Llava conversion for models that use safetensors to store weights (#35406)
2025-01-05|||Applies the rest of the init refactor except to modular files (#35238)
2025-01-03|||Add Gemma2 GGUF support (#34002)
2025-01-03|||Reuse "if not" logic in image_processing. (#35405)
2025-01-03|||Use `sdpa_kernel` in tests (#35472)
2025-01-03|||Change `is_soundfile_availble` to `is_soundfile_available` (#35030)
2025-01-02|||Fix paligemma warning message (#35486)
2025-01-02|||Fix docs typos. (#35465)
2025-01-02|||Fix new BNB test failures (#35345)
2025-01-02|||Reintroduce Python 3.9 support for ModernBERT (#35458)
2024-12-31|||Update translated docs for `sdpa_kernel` (#35461)
2024-12-31|||[i18n-ar] Translated file: `docs/source/ar/tasks/summarization.md` into Arabic (#35195)
2024-12-30|||[i18n-ar] Translated file: `docs/source/ar/tasks/question_answering.md` into Arabic (#35196)
2024-12-30|||Update docs for `sdpa_kernel` (#35410)
2024-12-29|||Add compute_loss_func to Seq2SeqTrainer (#35136)
2024-12-29|||Update perf_infer_gpu_one.md: fix a typo (#35441)
2024-12-27|||Fix `model_accepts_loss_kwargs` for timm model (#35257)
2024-12-27|||Fix f-string to show `ACCELERATE_MIN_VERSION` on error (#35189)
2024-12-27|||CLIP conversion script - Change fairseq to OpenAI (#35384)
2024-12-27|||Fix: Rename keyword argument in_channels to num_channels (#35289)
2024-12-26|||Drop inplace operation for loss computation with gradient accumulation (#35416)
2024-12-24|||[`GPTQ`, `CompressedTensors`] Fix unsafe imports and metada check (#34815)
2024-12-24|||Add DINOv2 with registers (#35348)
2024-12-24|||enable non-cuda awq model support without modify version (#35334)
2024-12-24|||Disable  `.github/workflows/self-comment-ci.yml` for now (#35366)
2024-12-23|||Add compile test for fast image processor (#35184)
2024-12-23|||Adding logger.info about update_torch_dtype in some quantizers (#35046)
2024-12-23|||bugfix Idefics3 processor - handle gracefully cases with text and no images (#35363)
2024-12-23|||HIGGS Quantization Support (#34997)
2024-12-23|||add bnb support for Ascend NPU (#31512)
2024-12-23|||Fix : VPTQ test (#35394)
2024-12-23|||Fix typing in docstring for `PaliGemmaProcessor` (#35278)
2024-12-23|||Scale loss before backward (#35207)
2024-12-23|||Deprecate _is_quantized_training_enabled (#34991)
2024-12-23|||uniformize kwargs for SAM (#34578)
2024-12-23|||Patch GPTNeoX to use adequate FA2 if position_ids is provided (#35318)
2024-12-23|||make LlamaModel._update_causal_mask torch compilable (#35187)
2024-12-23|||bitsandbytes: simplify 8bit dequantization (#35068)
2024-12-22|||Fix new FA2 if `is_causal` is passed explicitly (#35390)
2024-12-21|||owlvit/2 dynamic input resolution (#34764)
2024-12-20|||[docs] Follow up register_pipeline (#35310)
2024-12-20|||Improved Documentation Of Audio Classification (#35368)
2024-12-20|||Improve modular transformers documentation (#35322)
2024-12-20|||Make `test_generate_with_static_cache` even less flaky (#34995)
2024-12-20|||Use `weights_only=True` with `torch.load` for `transfo_xl` (#35241)
2024-12-20|||Update test fetcher when we want to test all (#35364)
2024-12-20|||update codecarbon (#35243)
2024-12-20|||bugfix: torch.export failure caused by `_make_causal_mask` (#35291)
2024-12-20|||Aurevoir PyTorch 1 (#35358)
2024-12-20|||fix zoedepth initialization error under deepspeed zero3 (#35011)
2024-12-20|||Add Tensor Parallel support for Qwen2VL (#35050)
2024-12-20|||Cleaner attention interfaces (#35342)
2024-12-20|||Implement AsyncTextIteratorStreamer for asynchronous streaming (#34931)
2024-12-20|||Reduce CircleCI usage (#35355)
2024-12-20|||FEAT : Adding VPTQ quantization method to HFQuantizer (#34770)
2024-12-20|||[`Mamba2`] Fix caching, slow path, and multi-gpu (#35154)
2024-12-20|||fix onnx export of speech foundation models (#34224)
2024-12-19|||[`docs`] Add link to ModernBERT Text Classification GLUE finetuning script (#35347)
2024-12-19|||Modernbert Release Fixes (#35344)
2024-12-19|||Fix some fa2 tests (#35340)
2024-12-19|||Add ModernBERT to Transformers (#35158)
2024-12-19|||PaliGemma: Make sure to add <eos> to suffix if <image> is present in `text` (#35201)
2024-12-19|||Update comment CI bot (#35323)
2024-12-19|||Fix documentation for ColPali (#35321)
2024-12-19|||Add the Bamba Model (#34982)
2024-12-18|||feat: add `benchmarks_entrypoint.py` (#34495)
2024-12-18|||üö®All attention refactorüö® (#35235)
2024-12-18|||[Whisper] fix docstrings typo (#35319)
2024-12-18|||change bnb tests (#34713)
2024-12-18|||[Whisper] üö® Fix whisper decoding üö® (#34135)
2024-12-18|||Trigger GitHub CI with a comment on PR (#35211)
2024-12-18|||[tests] make cuda-only tests device-agnostic   (#35222)
2024-12-18|||Fix loading with only state dict and low_cpu_mem_usage = True (#35217)
2024-12-17|||[docs] Improve register_pipeline (#35300)
2024-12-17|||Fixed typo in audio_classification.md (#35305)
2024-12-17|||Add Cohere2 docs details (#35294)
2024-12-18|||Fix remove unused parameter in docs (#35306)
2024-12-17|||Fix image preview in multi-GPU inference docs (#35303)
2024-12-17|||Fix typos in translated quicktour docs (#35302)
2024-12-17|||üö®üö®üö® Limit backtracking in Nougat regexp (#35264)
2024-12-17|||remove `benchmark` job in `push-important-models.yml` (#35292)
2024-12-17|||üö®üö®üö® Delete conversion scripts when making release wheels (#35296)
2024-12-17|||Support for SDPA for SAM models (#34110)
2024-12-17|||Add sdpa for Beit (#34941)
2024-12-17|||Add Falcon3 documentation (#35307)
2024-12-17|||Add ColPali to ü§ó transformers (#33736)
2024-12-17|||fix modular order (#35297)
2024-12-16|||Improved documentation of Automatic speech recognition (#35268)
2024-12-17|||Fix wrongs in quicktour[zh] (#35272)
2024-12-17|||Translating "translate perf_infer_gpu_multi.md" to Chinese (#35271)
2024-12-16|||Fix typos in Translated Audio Classification Docs (#35287)
2024-12-16|||[Whisper] patch float type on mps (#35295)
2024-12-16|||Delete redundancy for loop checks. (#35288)
2024-12-16|||Temporarily disable amd push ci (#35293)
2024-12-16|||Fix : model used to test ggml conversion of Falcon-7b is incorrect (#35083)
2024-12-16|||Blip: fix offloading and MP tests  (#35239)
2024-12-16|||Aggeregate test summary files in CircleCI workflow runs (#34989)
2024-12-15|||Fall back to slow image processor in ImageProcessingAuto when no fast processor available (#34785)
2024-12-14|||[i18n-Chinese] Translating perf_train_cpu.md to Chinese (#35242)
2024-12-13|||don't use no_sync when deepspeed doesn't support it for certain zero stages (#35157)
2024-12-13|||Fix FSDP no longer working (#35212)
2024-12-14|||Translating agents_advanced.md to Chinese (#35231)
2024-12-13|||Fixed typos in Audio Classification Documentation (#35263)
2024-12-13|||Update AMD docker image (rocm 6.1) (#35259)
2024-12-13|||Use `rsfE` with `pytest` (#35119)
2024-12-13|||[tests] fix "Tester object has no attribute '_testMethodName'" (#34910)
2024-12-13|||skip Fuyu from test_generate (#35246)
2024-12-13|||Add Cohere2 model (#35224)
2024-12-13|||Run model as compressed/uncompressed mode (#34719)
2024-12-13|||Fix typo in chat template example (#35250)
2024-12-12|||[Init refactor] Modular changes (#35240)
2024-12-12|||Change back to `Thread` for SF conversion (#35236)
2024-12-12|||Refactoring `AssistedCandidateGenerator` for Improved Modularity and Reusability (#35009)
2024-12-12|||Support Python 3.10+ Union style in chat template type hints parsing (#35103)
2024-12-12|||Fix type hints for apply_chat_template (#35216)
2024-12-12|||Fixed typo of 'indentifier' in audio_utils.py (#35226)
2024-12-12|||docs: clarify initializer_range parameter description in Idefics3VisionConfig (#35215)
2024-12-11|||Fix seamless TTS generate (#34968)
2024-12-11|||Fix CI (#35208)
2024-12-11|||Cleanup: continue the init refactor (#35170)
2024-12-11|||Add TimmWrapper (#34564)
2024-12-11|||[PEFT] Better Trainer error when prompt learning with loading best model at the end (#35087)
2024-12-11|||üßπ Remove deprecated RotaryEmbedding parts in the Attention layers (#34858)
2024-12-11|||BLIP: enable device map (#34850)
2024-12-11|||[i18n-<languageCode>] Translating agents.md to Chinese  (#35139)
2024-12-10|||Update data collator docstrings to accurately reference Nvidia tensor core compute capability version (#35188)
2024-12-10|||[docs] Fix FlashAttention link (#35171)
2024-12-11|||[i18n-<languageCode>] Translating Benchmarks.md to Chinese (#35137)
2024-12-10|||Only import torch.distributed if it is available (#35133)
2024-12-10|||Multiple typo fixes in NLP, Audio docs (#35181)
2024-12-10|||[i18n-ar] Translated file : `docs/source/ar/community.md` into Arabic (#33027)
2024-12-10|||Fixing GGUF support for StableLm (#35060)
2024-12-10|||Fix DBRX LayerNorm init method (#35177)
2024-12-10|||Remove unnecessary masked_fill in deberta models (#35182)
2024-12-10|||Support BatchNorm in Hubert pos_conv_emb as in fairseq (#34389)
2024-12-10|||Fix file path for shard_num 1 with mllama converter (#35053)
2024-12-10|||Assisted decoding multi-gpu (#35116)
2024-12-10|||Fix `num_items_in_batch` not being an integer (#35115)
2024-12-09|||[CI] Fix bnb quantization tests with accelerate>=1.2.0 (#35172)
2024-12-09|||Fixed typo of 'avilable' in prompts.py (#35145)
2024-12-10|||Super tiny fix logging message (#35132)
2024-12-09|||Cleanup: continue the init refactor (#35167)
2024-12-09|||Fix typo in EETQ Tests (#35160)
2024-12-09|||Option to set 'non_blocking' for to(device) in BatchEncoding and BatchFeature (#34883)
2024-12-09|||Corrected typo in agent system prompts (#35143)
2024-12-09|||[I-JEPA] Update docs (#35148)
2024-12-09|||Fix GA loss bugs and add unit test (#35121)
2024-12-06|||Update I-JEPA checkpoints path (#35120)
2024-12-06|||Add feature dim attributes to BitLinear for easier PEFT integration (#34946)
2024-12-06|||Add Aria (#34157)
2024-12-06|||Fix private forked repo. CI (#35114)
2024-12-05|||[docs] top_p, top_k, temperature docstrings (#35065)
2024-12-05|||[docs] Update Python version in translations (#35096)
2024-12-05|||Dev version
2024-12-05|||Fix signatures for processing kwargs (#35105)
2024-12-05|||Adaptive dynamic number of speculative tokens (#34156)
2024-12-05|||Fix flaky Hub CI (`test_trainer.py`) (#35062)
2024-12-05|||[`trainer`] fix the GA `model_accepts_loss_kwargs` (#34915)
2024-12-05|||BLIP: this is correct now (#35081)
2024-12-05|||Add I-JEPA (#33125)
2024-12-05|||Deprecate quanto and switch to optimum-quanto (#35001)
2024-12-05|||Fix `tie_word_embeddings` handling for GGUF models (#35085)
2024-12-05|||Update Mistral conversion script (#34829)
2024-12-05|||[`tokenizers`] bump to 0.21 (#34972)
2024-12-05|||[Whisper] Fix whisper tokenizer (#34537)
2024-12-05|||Informative (#35059)
2024-12-04|||[docs] Increase visibility of torch_dtype="auto" (#35067)
2024-12-04|||[docs] add a comment that offloading requires CUDA GPU (#35055)
2024-12-04|||Support for easier multimodal use of modular (#35056)
2024-12-04|||[`GPTNeoX`] Flex Attention + Refactor (#34896)
2024-12-04|||Add Pytorch Tensor Parallel support for Qwen2, Qwen2Moe, Starcoder2 (#35007)
2024-12-04|||Fix `pad_token_tensor` is None in warning (#34005)
2024-12-04|||[docs] use device-agnostic API instead of hard-coded cuda (#35048)
2024-12-04|||[docs] use device-agnostic instead of `cuda` (#35047)
2024-12-04|||Translate community.md into Chinese (#35013)
2024-12-04|||[docs] fix example code bug (#35054)
2024-12-03|||fix speecht5 failure issue in test_peft_gradient_checkpointing_enable‚Ä¶ (#34454)
2024-12-03|||Fix `BertGeneration` (#35043)
2024-12-03|||Add token cost + runtime monitoring to Agent and HfEngine children (#34548)
2024-12-03|||Automatic compilation in generate: do not rely on inner function (#34923)
2024-12-03|||Translate bertlogy.md into Chinese (#34908)
2024-12-03|||[docs] add the missing import for Image and bug fix (#34776)
2024-12-02|||[i18n-ar] Translated file : `docs/source/ar/notebooks.md` into Arabic (#33049)
2024-12-02|||add docstring example for compute_loss_func (#35020)
2024-12-02|||Multiple typo fixes in Tutorials docs (#35035)
2024-12-02|||Fix `test_eager_matches_sdpa_inference` for `XPU` backend (#34889)
2024-12-02|||Add type hints for forward functions in Gemma2 (#35034)
2024-12-02|||Typo in warning switching to optimum-quanto (#35028)
2024-12-02|||Optimize memory usage of mllama encoder (#34930)
2024-12-02|||fix variable undefined bug when return_tensors is not specified in llava processing (#34953)
2024-12-02|||Only cast `cu_seqlens` when tracing (#35016)
2024-11-29|||Update `FillMaskPipeline.__call__` signature and docstring (#35006)
2024-11-29|||fix: double verbs (#35008)
2024-11-29|||Update timm version (#35005)
2024-11-29|||üö®üö®üö® Uniformize kwargs for TrOCR Processor (#34587)
2024-11-28|||Let server decide default repo visibility (#34999)
2024-11-28|||Fix docker CI : install autogptq from source (#35000)
2024-11-28|||Improve `.from_pretrained` type annotations (#34973)
2024-11-28|||Add optimized `PixtralImageProcessorFast` (#34836)
2024-11-28|||Fix `utils/check_bad_commit.py` (for auto ping in CI) (#34943)
2024-11-28|||Offloaded cache: fix generate (#34921)
2024-11-28|||Allow compressed-tensors quantized model to be trained (#34520)
2024-11-28|||Refine the code of Universal Assisted Generation (#34823)
2024-11-28|||üö®üö®üö® Changed DINOv2Config default patch size to 14 (#34568)
2024-11-28|||Fix `save_pretrained` for partially offloaded models (#34890)
2024-11-28|||[PEFT] Set eval mode when loading PEFT adapter (#34509)
2024-11-27|||Fixed typo in `VisitWebpageTool` (#34978)
2024-11-28|||Fix typo in code block in vipllava.md (#34957)
2024-11-27|||[i18n-zh]Translated perf_train_special.md into Chinese (#34948)
2024-11-27|||[docs] add explanation to `release_memory()` (#34911)
2024-11-28|||üåê [i18n-KO] Translated encoder-decoder.md to Korean (#34880)
2024-11-27|||Fix flaky test execution caused by `Thread` (#34966)
2024-11-27|||Avoid calling `get_max_length` (#34971)
2024-11-27|||Fix : Add PEFT from source to CI docker (#34969)
2024-11-27|||[`FlexAttention`] Update gemma2 (#34942)
2024-11-27|||[i18n-zh]Translated tiktoken.md into chinese (#34936)
2024-11-27|||docs: HUGGINGFACE_HUB_CACHE -> HF_HUB_CACHE (#34904)
2024-11-27|||[doc] use full path for run_qa.py  (#34914)
2024-11-27|||[docs] use device-agnostic API instead of cuda  (#34913)
2024-11-26|||[i18n-ar] Translated file : `docs/source/ar/benchmarks.md` into Arabic (#33023)
2024-11-27|||Update the Python version in the Chinese README to match the English README.  (#34870)
2024-11-26|||Fix torch.onnx.export of Qwen2-VL vision encoder (#34852)
2024-11-26|||Separate chat templates into a single file (#33957)
2024-11-26|||change apply_rotary_pos_emb of Glmmodel for GLM-Edge Series model (#34629)
2024-11-26|||Add Pytorch Tensor Parallel support for Mistral (#34927)
2024-11-26|||[Whisper] Fix whisper integration tests (#34111)
2024-11-26|||Skipping aqlm non working inference tests till fix merged (#34865)
2024-11-26|||VideoLLaVA: add default values (#34916)
2024-11-25|||Fix import structure for Fast Image processors (#34859)
2024-11-25|||making gpt2 fx traceable (#34633)
2024-11-25|||Updated documentation and added conversion utility (#34319)
2024-11-25|||Fix failling GGML test (#34871)
2024-11-25|||Upgrade torch version to 2.5 in dockerfile for quantization CI (#34924)
2024-11-25|||Fix `test_auto_backbone_timm_model_from_pretrained` (#34877)
2024-11-25|||fix static cache data type miss-match (#34799)
2024-11-25|||[AWQ, CI] Bump AWQ version used in docker image (#34922)
2024-11-25|||Fix : BitNet tests (#34895)
2024-11-25|||Rename OLMo November to OLMo2 (#34864)
2024-11-25|||Bump tornado from 6.4.1 to 6.4.2 in /examples/research_projects/lxmert (#34917)
2024-11-25|||Fix Qwen2 failing tests (#34819)
2024-11-25|||[`peft`] Given that `self.active_adapter` is deprecated, avoid using it (#34804)
2024-11-25|||Fix convert_tokens_to_string when decoder is None (#34569)
2024-11-25|||chore: fix some typos (#34891)
2024-11-25|||Bump tornado from 6.4.1 to 6.4.2 in /examples/research_projects/visual_bert (#34887)
2024-11-25|||prepare_fa2_from_position_ids function bugfix (#33269)
2024-11-25|||allow unused input parameters passthrough when chunking in asr pipelines (#33889)
2024-11-25|||Sum gathered input tokens (#34554)
2024-11-25|||üî¥ Mllama: fix base prefix (#34874)
2024-11-25|||[`Deberta/Deberta-v2`] Refactor code base to support compile, export, and fix LLM (#22105)
2024-11-25|||BLIP: fix generation after hub update (#34876)
2024-11-25|||Cache: init empty cache when `use_cache` (#34274)
2024-11-25|||Add safe_globals to resume training on PyTorch 2.6 (#34632)
2024-11-25|||Fix: Enable prefill phase key value caching of nemotron/minitron models (#34742)
2024-11-22|||Fix support for image processors modifications in modular (#34866)
2024-11-22|||Bitnet test fix to avoid using gated  model (#34863)
2024-11-22|||[CI] Skip EETQ tests while package is broken with latest transformers (#34854)
2024-11-22|||smol improvements to support more flexible usage (#34857)
2024-11-22|||Speculative decoding: Test the target distribution (to prevent issues like #32867) (#34553)
2024-11-22|||Auto compile when static cache (#34247)
2024-11-22|||Remove quantization related config from dequantized model (#34856)
2024-11-22|||Update checks for torch.distributed.tensor to require torch >= 2.5 (#34816)
2024-11-22|||Watermarking: fix order (#34849)
2024-11-21|||Refactor StarCoder2 using modular (#34015)
2024-11-21|||Fix heuristic scheduling for UAG (#34805)
2024-11-21|||Fix ds nvme (#34444)
2024-11-21|||Improve gguf tensor processing (#34515)
2024-11-21|||Add Nemotron GGUF Loading Support (#34725)
2024-11-21|||Change logging level from warning to info for `max_steps` overriding `num_train_epochs` (#34810)
2024-11-21|||VLMs: enable generation tests - last batch (#34484)
2024-11-20|||Fix CI slack reporting issue (#34833)
2024-11-20|||Fix CI by tweaking torchao tests (#34832)
2024-11-20|||Fix hyperparameter search when optuna+deepseed (#34642)
2024-11-20|||Torchao weights only + prequantized compability (#34355)
2024-11-20|||Fix: take into account meta device (#34134)
2024-11-20|||fix(DPT,Depth-Anything) `torch.export` (#34103)
2024-11-20|||Fix the memory usage issue of logits in generate() (#34813)
2024-11-20|||Fix low memory beam search (#34746)
2024-11-20|||LLaVA OV: fix unpadding precision (#34779)
2024-11-20|||Translate attention.md into Chinese (#34716)
2024-11-19|||Added image-text-to-text pipeline to task guide (#34783)
2024-11-19|||Fix `check_training_gradient_checkpointing` (#34806)
2024-11-19|||Run `test_medium_seamless_m4t_pt` in `subprocess` to avoid many failures (#34812)
2024-11-19|||Add Image Processor Fast Deformable DETR (#34353)
2024-11-19|||Add support for OpenAI api "image_url" input in chat for image-text-to-text pipeline (#34562)
2024-11-19|||Bump aiohttp from 3.10.2 to 3.10.11 in /examples/research_projects/decision_transformer (#34792)
2024-11-19|||fix crash in tiiuae/falcon-11B-vlm image-to-text generation (#34728)
2024-11-20|||Fix post process function called in the instance segmentation example of mask2former (#34588)
2024-11-20|||Add do_convert_rgb to vit (#34523)
2024-11-19|||Feature: print tokens per second during training (#34507)
2024-11-19|||üö®üö®üö® fix(Mask2Former): torch export üö®üö®üö® (#34393)
2024-11-19|||MLU devices : Checks if mlu is available via an cndev-based check which won't trigger the drivers and leave mlu (#34326)
2024-11-19|||Modular fix (#34802)
2024-11-19|||Fix cache_utils for optimum.quanto kvcache quantization  (#34750)
2024-11-19|||Gemma capping (#34282)
2024-11-19|||Self-speculation (Layer-Skip Llama) (#34240)
2024-11-19|||fix cpu bnb path (#34647)
2024-11-19|||Fix: siglip image processor rgb_convert is not being applied correctly. (#34301)
2024-11-19|||Support gradient checkpointing in Qwen2VL ViT (#34724)
2024-11-19|||feat: allow to use hf-hub models for timm backbone (#34729)
2024-11-19|||Trainer hyperparameter search kwargs docs update (#34459)
2024-11-19|||protect tensor parallel usage (#34800)
2024-11-18|||Fix Whisper CI (#34617)
2024-11-18|||Allow handling files as args for a tool created with Tool.from_space (#34687)
2024-11-18|||Simplify Tensor Parallel implementation with PyTorch TP (#34184)
2024-11-19|||fix: Wrong task mentioned in docs (#34757)
2024-11-19|||Fix callback key name (#34762)
2024-11-19|||fix: Update pixel_values parameter in hf_model input (#34782)
2024-11-19|||[tests] add XPU part to testing (#34778)
2024-11-19|||[docs] add XPU besides CUDA, MPS etc. (#34777)
2024-11-19|||[docs] make `empty_cache` device-agnostic (#34774)
2024-11-18|||make sure to disable gradients for integer tensor (#32943)
2024-11-18|||Fix skip of test_training_gradient_checkpointing (#34723)
2024-11-18|||fix a typo bug where 'id2label' was incorrectly written as 'i2label' when reading config (#34637)
2024-11-18|||Fix broken link (#34618)
2024-11-18|||VLMs: `patch_size` -> `num_image_tokens` in processing (#33424)
2024-11-18|||Add OLMo November 2024 (#34551)
2024-11-15|||üßº remove v4.44 deprecations (#34245)
2024-11-15|||Remove FSDP wrapping from sub-models. (#34452)
2024-11-15|||FSDP grad accum fix (#34645)
2024-11-15|||add xpu path for awq (#34712)
2024-11-15|||fix(wandb): pass fake dataset to avoid exception in trainer (see #34455) (#34720)
2024-11-15|||Update llava.md (#34749)
2024-11-15|||Retain newlines in chat template when `continue_final_message=True` (#34253)
2024-11-14|||[docs] add xpu device check  (#34684)
2024-11-14|||Fix example in EsmConfig docstring (#34653)
2024-11-13|||[docs] Broken link in generation_strategies (#34717)
2024-11-14|||üåê [i18n-KO] Translated marian.md to Korean (#34698)
2024-11-11|||Agents: Small fixes in streaming to gradio + add tests (#34549)
2024-11-11|||[i18n-ar] Translated file : `docs/source/ar/torchscript.md` into Arabic (#33079)
2024-11-11|||[docs] update not-working model revision (#34682)
2024-11-10|||Agents: turn any Space into a Tool with `Tool.from_space()` (#34561)
2024-11-10|||Update llm_engine.py (#33332)
2024-11-09|||[i18n-ar] Translated file : `docs/source/ar/trainer.md` into Arabic (#33080)
2024-11-08|||üåê [i18n-KO] Translated bert.md to Korean  (#34627)
2024-11-08|||üåê [i18n-KO] Translated `timesformer.md` to Korean (#33972)
2024-11-07|||fix(dvclive): pass fake dataset to avoid exception in trainer init (#34455)
2024-11-06|||üåê [i18n-KO] Translated `convbert.md` to Korean (#34599)
2024-11-06|||Fix `use_parallel_residual` and `qkv_bias` for StableLM GGUF config extraction (#34450)
2024-11-05|||Fix torchvision interpolation CI (#34539)
2024-11-05|||Changing __repr__ in torchao to show quantized Linear (#34202)
2024-11-05|||Remove `@slow` for `test_eager_matches_sdpa_inference` (#34558)
2024-11-05|||Fix  #34494 assistant tokens when truncated (#34531)
2024-11-05|||Revert "Fix Whisper CI" (#34605)
2024-11-05|||Remove unused test_dataset (#34516)
2024-11-05|||DistilBERT is ExecuTorch compatible (#34475)
2024-11-05|||Load sub-configs from composite configs (#34410)
2024-11-05|||FIX: Broken repr of TorchAoConfig (#34560)
2024-11-05|||Skip DeepSpeed ZeRO Stage 3 model initialization when bnb (#34395)
2024-11-04|||Fix Whisper CI (#34541)
2024-11-05|||fix TrainerState doc because num_input_tokens_seen is unused by defau‚Ä¶ (#34593)
2024-11-05|||üåê [i18n-KO] Update README_ko.md (#33098)
2024-11-05|||üåê [i18n-KO] Translated perf_train_special.md to Korean (#34590)
2024-11-04|||[i18n-HI] Translated TFLite page to Hindi (#34572)
2024-11-05|||Add text support to the Trainer's TensorBoard integration (#34418)
2024-11-04|||MPS: `isin_mps_friendly` can support 0D tensors (#34538)
2024-11-04|||VLM: special multimodal Tokenizer (#34461)
2024-11-04|||Update trainer for easier handling of accumulate, compile fixes, and proper reporting (#34511)
2024-11-01|||[i18n-HI] Translated accelerate page to Hindi (#34443)
2024-11-01|||Large modular logic refactoring (#34487)
2024-11-01|||:red_circle: :red_circle:  fix `query_pre_attn_scalar` different of `num_heads` in default gemma2 config (#34540)
2024-11-01|||BLIP: enable generation tests (#34174)
2024-11-01|||Blip: get/set input embeddings correctly (#34152)
2024-11-01|||[i18n-ar] Translated file : `docs/source/ar/multilingual.md` into Arabic (#33048)
2024-11-01|||update doc (#34478)
2024-10-31|||[CLIPSeg] Make interpolate_pos_encoding default to True (#34419)
2024-10-31|||Add image text to text pipeline (#34170)
2024-10-31|||Bug Fix for issue #34294 (#34295)
2024-10-31|||make `test_eager_matches_sdpa_inference `less flaky (#34512)
2024-10-31|||feat: add benchmarks pg indexes (#34536)
2024-10-31|||fix(DPT,Depth-Anything) Address expected_slice errors inside inference tests (#34518)
2024-10-31|||Qwen2VL: skip base `input_ids`-`inputs_embeds` equivalence check (#34535)
2024-10-31|||avoid calling `gc.collect` and `cuda.empty_cache` (#34514)
2024-10-31|||Fix step shifting when accumulate gradient (#33673)
2024-10-31|||Fix: img size mismatch caused by incorrect unpadding in LLaVA-Next (#34522)
2024-10-31|||enable QA bf16 pipeline (#34483)
2024-10-31|||UPDATE Documentation for #TRANSLATING.md Documentation into Multiple Languages.(Changes made) (#34226)
2024-10-30|||Add Image Processor Fast RT-DETR (#34354)
2024-10-30|||Fix super tiny extra space typo (#34440)
2024-10-30|||Add GGUF for Mamba (#34200)
2024-10-30|||Use torch 2.5 in scheduled CI (#34465)
2024-10-30|||fix pixtral processor (#34486)
2024-10-30|||Tests: move `generate` tests to the right mixin and delete redundant tests (#34464)
2024-10-30|||VLMs: fix number of image tokens (#34332)
2024-10-30|||Mllama: update docs (#34334)
2024-10-30|||Fix format mistake in string repr of tokenizer objects (#34493)
2024-10-30|||Roberta is ExecuTorch compatible (#34425)
2024-10-29|||Un-deprecate timeout arg in pipelines (#34382)
2024-10-29|||fix incorrect warning (#34416)
2024-10-29|||Fix performance in get_imports regexp (#34298)
2024-10-29|||Bump werkzeug from 3.0.3 to 3.0.6 in /examples/research_projects/decision_transformer (#34420)
2024-10-29|||Adding `optimizer_cls_and_kwargs` to `Trainer.__init__` (#34358)
2024-10-29|||Albert is ExecuTorch compatible (#34476)
2024-10-29|||MobileBERT is ExecuTorch compatible (#34473)
2024-10-29|||Bug fix for drop path decay rate in swin transformer (#34291)
2024-10-29|||fix-qwen2vl-no-position_ids (#33487)
2024-10-29|||manual `head_dim` for `mixtral` model (#34281)
2024-10-29|||Bert is ExecuTorch compatible (#34424)
2024-10-29|||Fix regression loading dtype (#34409)
2024-10-29|||Fixes for Modular Converter on Windows (#34266)
2024-10-29|||Fix perplexity computation in perplexity.md (#34387)
2024-10-29|||Simplify running tests in a subprocess (#34213)
2024-10-29|||üö®üö®üö® [SuperPoint] Fix keypoint coordinate output and add post processing (#33200)
2024-10-29|||use a tinymodel to test generation config which aviod timeout (#34482)
2024-10-29|||Fix CI (#34458)
2024-10-29|||Generation: fix test (#34369)
2024-10-29|||LLaVA: latency issues (#34460)
2024-10-28|||Add `post_process_depth_estimation` for GLPN (#34413)
2024-10-28|||feat: run benchmarks on A100 (#34287)
2024-10-29|||enable average tokens across devices (#34373)
2024-10-28|||[i18n-ar] Translated file : `docs/source/ar/fast_tokenizers.md` into Arabic (#33034)
2024-10-28|||Apply linting to the important code blocks to make it readable (#34449)
2024-10-29|||üåê [i18n-KO] Translated `model_doc/barthez.md` to Korean (#33980)
2024-10-28|||[docs] update input documentation for MAMBA2 and MISTRAL models to include cache_position and attention_mask details (#34322)
2024-10-29|||New option called `"best"` for `args.save_strategy`. (#31817)
2024-10-28|||exclude fsdp from delay_optimizer_creation (#34140)
2024-10-28|||Fix batch size handling in prediction_loop for DataLoaderShard (#34343)
2024-10-28|||Tiny update after #34383 (#34404)
2024-10-28|||pin `tensorflow_probability<0.22` in docker files (#34381)
2024-10-28|||Fix pix2struct (#34374)
2024-10-25|||[docs] Cache implementations (#34325)
2024-10-25|||Fix typos in agents_advanced.md (#34405)
2024-10-25|||Avoid check expected exception when it is on CUDA (#34408)
2024-10-25|||Fix bnb training test failure (#34414)
2024-10-25|||Tests: upgrade `test_eager_matches_sdpa_generate` (#34386)
2024-10-25|||SynthID: better example (#34372)
2024-10-25|||no filter (#34391)
2024-10-25|||Fix right padding in LLaVA models (#34305)
2024-10-25|||Fix onnx non-expotable inplace aten op (#34376)
2024-10-24|||Use non nested images and batched text Idefics2/3  (#34222)
2024-10-24|||Fix glm  (#34388)
2024-10-24|||[auto. ping] Avoid sending empty info + add more team members (#34383)
2024-10-24|||Correct the new defaults (#34377)
2024-10-24|||Fix `torch.fx` issue related to the new `loss_kwargs` keyword argument (#34380)
2024-10-24|||[PEFT] Add warning for missing key in LoRA adapter (#34068)
2024-10-24|||Ignore unsupported kwarg in ProcessorMixin call (#34285)
2024-10-24|||refactor: remove redundant if-condition and improve type correctness for `convert_tokens_to_ids` (#34030)
2024-10-24|||Add code sample docstrings and checkpoint reference for GLM models (#34360)
2024-10-24|||Fix pil_torch_interpolation_mapping import in image_processing_detr_fast (#34375)
2024-10-24|||Add T5 GGUF loading support (#33389)
2024-10-24|||add code generation to natural language processing section (#34333)
2024-10-24|||Zamba is an LM (#34342)
2024-10-24|||CI: fix failures (#34371)
2024-10-24|||translated gguf.md into chinese (#34163)
2024-10-24|||v4.47.0.dev0
2024-10-24|||Drop support for Python 3.8 (#34314)
2024-10-24|||Better defaults (#34026)
2024-10-24|||Remove graph breaks for torch.compile() in flash_attention_forward when Lllama Model is padding free tuned (#33932)
2024-10-23|||Add SynthID (watermerking by Google DeepMind) (#34350)
2024-10-23|||Fix red CI: benchmark script (#34351)
2024-10-23|||skip `test_pipeline_depth_estimation` temporarily (#34316)
2024-10-23|||Enable Gradient Accumulation fix across all models + trainer fully in forward() (#34283)
2024-10-23|||Support boolean tool args (#34208)
2024-10-23|||Added Deberta model type support (#34308)
2024-10-23|||[docs] Fix Korean toctree (#34324)
2024-10-22|||Example doc for token classification of Llama and Dependent/Copied Models (#34139)
2024-10-23|||üåê [i18n-KO] Translated `model_doc/bartpho.md` to Korean (#33981)
2024-10-23|||üåê [i18n-KO] Translated `bert japanese.md` to Korean (#33890)
2024-10-23|||üåê [i18n-KO] Translated `executorch.md` to Korean (#33888)
2024-10-23|||[docs] fix typo  (#34235)
2024-10-23|||fix error in _get_eval_sampler when group_by_length enabled (#34237)
2024-10-22|||Fix continue_final_message for image-text-to-text chat templates (#34236)
2024-10-22|||Feature: Add `MLFLOW_MAX_LOG_PARAMS` to `MLflowCallback` (#34279)
2024-10-22|||Add option for running ffmpeg_microphone_live as a background process (#32838)
2024-10-22|||Olmo is ExecuTorch Compatible (#34181)
2024-10-22|||Qwen2.5 is ExecuTorch Compatible (#34102)
2024-10-22|||Add post_process_depth_estimation to image processors and support ZoeDepth's inference intricacies (#32550)
2024-10-22|||Fix: tensor of examples of the same length triggers invalid stacking (#34166)
2024-10-22|||Fix FA2 attention for models supporting sliding window (#34093)
2024-10-22|||[RT-DETR] Fix onnx inference bug for Optype (Where) (#33877)
2024-10-22|||Update PR templates (#34065)
2024-10-22|||Sync video classification pipeline with huggingface_hub spec (#34288)
2024-10-22|||Fix Korean doc _toctree.yml (#34293)
2024-10-22|||[docs] Fix GenerationConfig params (#34299)
2024-10-22|||T5 compile compatibilty (#34089)
2024-10-22|||VLM: add more modularity (#34175)
2024-10-22|||Attn implementation for composite models (#32238)
2024-10-21|||Fix method name which changes in tutorial (#34252)
2024-10-21|||Add a doc section on writing generation prompts (#34248)
2024-10-21|||Add DetrImageProcessorFast (#34063)
2024-10-21|||Change Paligemma import logging to work with modular  (#34211)
2024-10-21|||Generation tests: don't rely on main input name (#34228)
2024-10-18|||Only cast logits to float when computing loss (#34147)
2024-10-18|||Fix UDOP dtype issue (#34180)
2024-10-18|||add Glm (#33823)
2024-10-18|||Informative 2 (#34154)
2024-10-18|||Fix broken test decorator `require_torch_up_to_2_accelerators` (#34201)
2024-10-18|||BLIP: fix input expansion logic (#34225)
2024-10-17|||Fix-red-ci (#34230)
2024-10-17|||Enable users to use their own loss functions + deal with prefetching for grad accum (#34198)
2024-10-17|||Support Llama 3.2 conversion (text models) (#33778)
2024-10-17|||Fix Gradient Accumulation issue (#34191)
2024-10-17|||Generate: visit non-llm `prepare_inputs_for_generation` (#34199)
2024-10-17|||Fix bus error when using GPT2 on M1 macs (#34031)
2024-10-17|||Llama3 and Llama2 are ExecuTorch compatible (#34101)
2024-10-17|||removes decord  (#33987)
2024-10-17|||Fix for tokenizer.apply_chat_template with continue_final_message=True (#34214)
2024-10-17|||fix(Wav2Vec2ForCTC): torch export (#34023)
2024-10-17|||Ping team members for new failed tests in daily CI (#34171)
2024-10-17|||Fix warning message for fp32_cpu_offloading in bitsandbytes configs (#34079)
2024-10-17|||Update `trainer._get_eval_sampler()` to support `group_by_length` arg (#33514)
2024-10-16|||Revert "Fix FSDP resume Initialization issue" (#34193)
2024-10-16|||Avoid using torch's Tensor or PIL's Image in chat template utils if not available (#34165)
2024-10-16|||Fix wrong name for llava onevision and qwen2_vl in tokenization auto (#34177)
2024-10-16|||Revert `accelerate` error caused by `46d09af` (#34197)
2024-10-16|||[fix] fix token healing tests and usage errors (#33931)
2024-10-16|||Moshi integration (#33624)
2024-10-16|||IDEFICS: support inputs embeds (#34043)
2024-10-16|||üåê [i18n-KO] Translated `blip-2.md` to Korean (#33516)
2024-10-16|||üåê [i18n-KO] Translated `trainer_utils.md` to Korean (#33817)
2024-10-16|||üåê [i18n-KO] Translated `gemma2.md` to Korean (#33937)
2024-10-16|||üåê [i18n-KO] Translated `vivit.md` to Korean (#33935)
2024-10-15|||[feat] LlavaNext add feature size check to avoid CUDA Runtime Error (#33608)
2024-10-15|||Fix optuna ddp hp search (#34073)
2024-10-15|||Add support for inheritance from class with different suffix in modular (#34077)
2024-10-15|||Generate: move `logits` to same device as `input_ids` (#34076)
2024-10-15|||Fix default behaviour in TextClassificationPipeline for regression problem type (#34066)
2024-10-15|||Fix FSDP resume Initialization issue (#34032)
2024-10-15||| Add sdpa for Vivit (#33757)
2024-10-15|||Idefics: enable generation tests (#34062)
2024-10-15|||Update README.md with Enterprise Hub (#34150)
2024-10-14|||Add documentation for docker (#33156)
2024-10-14|||Specify that users should be careful with their own files (#34153)
2024-10-14|||Fixed error message in mllama (#34106)
2024-10-14|||Add GGUF for starcoder2 (#34094)
2024-10-14|||Fix a typo (#34148)
2024-10-14|||Mistral-related models for QnA (#34045)
2024-10-12|||Generate: Fix modern llm `generate` calls with `synced_gpus` (#34095)
2024-10-11|||fix(ci): benchmarks dashboard was failing due to missing quotations (#34100)
2024-10-11|||refactor: benchmarks (#33896)
2024-10-11|||Avoid many test failures for `LlavaNextVideoForConditionalGeneration` (#34070)
2024-10-11|||Generate: move `prepare_inputs_for_generation` in encoder-decoder llms (#34048)
2024-10-11|||Fix flaky tests (#34069)
2024-10-11|||Fix NaNs in cost_matrix for mask2former (#34074)
2024-10-11|||avoid many failures for ImageGPT (#34071)
2024-10-11|||Fix PushToHubMixin when pusing to a PR revision (#34090)
2024-10-11|||Fix failing conversion (#34010)
2024-10-11|||Fix DAC slow tests (#34088)
2024-10-11|||Fix flax failures (#33912)
2024-10-11|||Tests: upcast `logits` to `float()` (#34042)
2024-10-11|||Update SSH workflow file (#34084)
2024-10-11|||Idefics: fix position ids (#33907)
2024-10-11|||Generate using exported model and enable gemma2-2b in ExecuTorch (#33707)
2024-10-10|||Default `synced_gpus` to `True` when using `FullyShardedDataParallel` (#33483)
2024-10-10|||Small Fix to modular converter (#34051)
2024-10-10|||provide trust_remote_code for search feat extractor in model config (#34036)
2024-10-10|||Update Blip2 `is_pipeline_test_to_skip` method signature (#34067)
2024-10-10|||[TESTS] ASR pipeline (#33925)
2024-10-10|||Fix data_seed unused (#33731)
2024-10-10|||[Docs] Update compressed_tensors.md (#33961)
2024-10-10|||check if eigenvalues of covariance matrix are complex.  (#34037)
2024-10-10|||Universal Assisted Generation: Assisted generation with any assistant model (by Intel Labs) (#33383)
2024-10-10|||Specifying torch dtype in Qwen2VLForConditionalGeneration (#33953)
2024-10-10|||Sync QuestionAnsweringPipeline (#34039)
2024-10-10|||Add gguf support for gpt2 (#34044)
2024-10-10|||Fix pipelines tests (#34049)
2024-10-10|||HfArgumentParser: allow for hyhenated field names in long-options (#33990)
2024-10-10|||Phi3: fix attn for sliding window (#33586)
2024-10-10|||add sdpa to OPT (#33298)
2024-10-10|||Add Translate docs into Arabic - section files CONCEPTUAL GUIDES (#33982)
2024-10-10|||üåê [i18n-KO] Translated `generation_utils.md` to Korean (#33818)
2024-10-10|||üåê [i18n-KO] Translated `main_classes/callback.md` to Korean (#33572)
2024-10-10|||üåê [i18n-KO] Translated `text_generation.md` to Korean (#33777)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/patchtst.md` to Korean (#33589)
2024-10-10|||üåê [i18n-KO] Translated `main_classes/data_collator.md` to Korean (#33954)
2024-10-10|||üåê [i18n-KO] Translated `modeling_utils.md` to Korean (#33808)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/graphormer.md` to Korean (#33569)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/informer.md` to Korean (#33585)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/time_series_transformer.md` to Korean (#33596)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/trajectory_transformer.md` to Korean (#33597)
2024-10-10|||üåê [i18n-KO] Translated `main_classes/model.md` to Korean (#33606)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/mamba2.md` to Korean (#33629)
2024-10-10|||üåê [i18n-KO] Translated `main_classes/keras_callbacks.md` to Korean (#33955)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/deberta.md` to Korean (#33967)
2024-10-10|||üåê [i18n-KO] Translated `model_doc/bart.md` to Korean (#33893)
2024-10-09|||FEAT : Adding BitNet quantization method to HFQuantizer (#33410)
2024-10-09|||Make `pipeline` able to load `processor` (#32514)
2024-10-09|||Fix PIL dep for tests (#34028)
2024-10-09|||Mllama: fix tests (#34000)
2024-10-09|||Generate: remove most decoder-only LLMs `prepare_inputs_for_generation` (#33870)
2024-10-09|||Fix Failed tests with mobile bert resize tokens embedding (#33950)
2024-10-09|||Add gguf support for StableLM (#33793)
2024-10-09|||[`Patch helper`] update to not have to checkout main (#34006)
2024-10-09|||üåê [i18n-KO] Translated `modular_transformers.md` to Korean (#33772)
2024-10-09|||üåê [i18n-KO] Translated `image_processing_utils.md` to Korean (#33804)
2024-10-09|||üåê [i18n-KO] Translated output.md to Korean (#33607)
2024-10-09|||üåê [i18n-KO] Translated `blip.md` to Korean (#33515)
2024-10-09|||üåê [i18n-KO] Translated `biogpt.md` to Korean (#33773)
2024-10-09|||üåê [i18n-KO] Translated `openai-gpt.md` to Korean (#33801)
2024-10-09|||üåê [i18n-KO] Translated `file_utils.md` to Korean (#33803)
2024-10-09|||üåê [i18n-KO] Translated `swin.md` to Korean (#33510)
2024-10-09|||üåê [i18n-KO] Translated `tokenization_utils.md` to Korean (#33813)
2024-10-09|||üåê [i18n-KO] Translated `main_classes/onnx.md` to Korean (#33601)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/deberta-v2.md` to Korean (#33968)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/dbrx.md` to Korean  (#33951)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/cohere.md` to Korean (#33885)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/mistral.md` to Korean (#33648)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/llama3.md` to Korean (#33635)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/paligemma.md` to Korean (#33612)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/clip.md` to Korean (#33610)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/patchtsmixer.md` to Korean (#33587)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/autoformer.md` to Korean (#33574)
2024-10-09|||üåê [i18n-KO] Translated `model_doc/mamba.md` to Korean (#33626)
2024-10-09|||üåê [i18n-KO] Translated `main_classes/configuration.md` to Korean  (#33952)
2024-10-09|||üåê [i18n-KO] Translated `main_classes/quantization.md` to Korean (#33959)
2024-10-09|||üåê [i18n-KO] Translated `rag.md` to Korean (#33989)
2024-10-09|||üåê [i18n-KO] Translated `gpt_neox_japanese.md` to Korean (#33894)
2024-10-09|||üåê [i18n-KO] Translated `bertweet.md` to Korean (#33891)
2024-10-09|||üåê [i18n-KO] Translated `feature_extractor.md` to Korean (#33775)
2024-10-08|||Fix `trainer_seq2seq.py`'s `__init__` type annotations (#34021)
2024-10-08|||Remove `decoder_config=None` (#34014)
2024-10-08|||fix awq tests due to ipex backend (#34011)
2024-10-08|||Fix typing issue (#34012)
2024-10-08|||Fixup DeepSpeed things (#34007)
2024-10-08|||Improve modular converter (#33991)
2024-10-08|||BatchFeature.to() supports non-tensor keys (#33918)
2024-10-08|||Image pipelines spec compliance (#33899)
2024-10-08|||Add auto model for image-text-to-text (#32472)
2024-10-08|||Processors: don't default padding side (#33942)
2024-10-08|||Add support for __all__ and potentilly deleting functions (#33859)
2024-10-08|||Cache: slight change in naming (#32421)
2024-10-08|||üåê [i18n-KO] Translated `gemma.md` to Korean (#33936)
2024-10-08|||üåê [i18n-KO] Translated `vit.md` to Korean (#33884)
2024-10-08|||üåê [i18n-KO] Translated `swin2sr.md` to Korean (#33795)
2024-10-08|||üåê [i18n-KO] Translated `auto.md` to Korean (#33590)
2024-10-08|||üåê [i18n-KO] Translated `logging.md` to Korean (#33543)
2024-10-08|||üåê [i18n-KO] Translated `chameleon.md` to Korean (#33799)
2024-10-08|||üåê [i18n-KO] Translated `trainer.md` to Korean (#33797)
2024-10-08|||üåê [i18n-KO] Translated `pipelines_utils.md` to Korean (#33809)
2024-10-08|||üåê [i18n-KO] Translated `time_series_utils.md` to Korean (#33806)
2024-10-08|||üåê [i18n-KO] Translated `esm.md` to Korean (#33796)
2024-10-08|||üåê [i18n-KO] Translated `audio_utils.md` to Korean (#33802)
2024-10-08|||üåê [i18n-KO] Translated `swinv2.md` to Korean (#33566)
2024-10-08|||üåê [i18n-KO] Translated `gguf.md` to Korean (#33764)
2024-10-07|||Fix undefined default_config in configuration_utils.py (#33934)
2024-10-07|||[`pytes collection`] Fix flax test collection (#34004)
2024-10-07|||Enable customized optimizer for DeepSpeed (#32049)
2024-10-07|||properly fix and RUN_SLOW (#33965)
2024-10-07|||Fix Tensor + Embedding error in some cases when using SiglipVisionModel (#33994)
2024-10-07|||[`Red CIs`] Fix hub failures (#34001)
2024-10-07|||[Docs] Add Developer Guide: How to Hack Any Transformers Model (#33979)
2024-10-07|||[Docs] Improve VLM docs (#33393)
2024-10-07|||Flash-attn performance: remove cuda sync during inference (#33570)
2024-10-07|||Add position ids in forward pass to opt model (#33121)
2024-10-06|||[WIP] Add Tokenizer for MyT5 Model (#31286)
2024-10-05|||[`TF`] Fix Tensorflow XLA Generation on limited seq_len models (#33903)
2024-10-05|||Bug fix gguf qwen2moe (#33940)
2024-10-05|||add test for Jamba with new model jamba-tiny-dev (#33863)
2024-10-05|||Updating `char_to_token` documentation to note behaviour when `trim_offsets` is True (#33919)
2024-10-05|||Paligemma: fix static cache test (#33941)
2024-10-04|||Cache: revert DynamicCache init for BC (#33861)
2024-10-04|||fix red check-copies (#33964)
2024-10-04|||Add Zamba (#30950)
2024-10-04|||PhiMoE (#33363)
2024-10-04|||hot fix `self.position_embeddings->self.position_embedding` (#33958)
2024-10-04|||Fix attn mask ignore logic in training-time trace (#32613)
2024-10-04|||Removed unnecessary transpose in Switch Transformer Routing (#33582)
2024-10-04|||üî¥ üö®  Resizing tokens embeddings: initialize from old embeddings' normal distribution. (#33325)
2024-10-04|||Enables CPU AWQ model with IPEX version. (#33460)
2024-10-04|||Add a section on writing tool templates to the chat template docs (#33924)
2024-10-04|||[`PR run-slow`]  (#33939)
2024-10-04|||Ignore keys on `validate_rope` (#33753)
2024-10-04|||[i18n-ru] Fixes typo in the README_ru.md (#33882)
2024-10-04|||[Doc]: Broken link in Kubernetes doc (#33879)
2024-10-04|||Fix distil whisper segment computation (#33920)
2024-10-03|||Minor error condition bug fix (#33781)
2024-10-03|||Remove `logits.float()` (#33902)
2024-10-03|||Uniformize kwargs for Idefics/2 processors (#32568)
2024-10-03|||Config: lower `save_pretrained` exception to warning (#33906)
2024-10-03|||Add support for `weights_only` flag when loading state_dict (#32481)
2024-10-03|||add setter for trainer processor (#33911)
2024-10-03|||[PEFT] Support low_cpu_mem_usage option for PEFT loading adapters (#33725)
2024-10-03|||[Tests] Diverse Whisper fixes (#33665)
2024-10-03|||Fix: use unidic-lite instead of ipadic as the tokenizer dictionary for Japanese (#33372)
2024-10-03|||Generate tests: modality-agnostic input preparation (#33685)
2024-10-03|||Add `SplinterTokenizer` unit test (#32652)
2024-10-03|||Fix module initialization for root module under Zero3 (#33632)
2024-10-03|||Migrate the CI runners to the new clusters (#33849)
2024-10-03|||VLM Generate: tag `test_static_cache_matches_dynamic` as flaky (#33630)
2024-10-03|||Update an keyerror on _save_check_point prevent confusion of missing ‚Ä¶ (#33832)
2024-10-03|||Fix dt proj bias reassigned (#33314)
2024-10-02|||uniformize processor Mllama (#33876)
2024-10-02|||rename all test_processing_*.py to test_processor_*.py (#33878)
2024-10-02|||Handle Trainer `tokenizer` kwarg deprecation with decorator (#33887)
2024-10-02|||Optim deformable detr (#33600)
2024-10-02|||[Quantization] Switch to optimum-quanto  (#31732)
2024-10-02|||Trainer - deprecate tokenizer for processing_class (#32385)
2024-10-02|||Add sdpa for DistilBert (#33724)
2024-10-02|||Fix kwargs passed by AutoQuantizationConfig.from_pretrained (#33798)
2024-10-02|||Allow for nightly packages of `compressed_tensors` (#33828)
2024-10-02|||Add falcon gguf (#33437)
2024-10-02|||populate quantization_config for kv-cache-scheme only configs (#33874)
2024-10-02|||Don't run reminder bot for now (#33883)
2024-10-02|||Uniformize model processors (#31368)
2024-10-02|||Fix: typo  (#33880)
2024-10-01|||Add support for custom inputs and batched inputs in ProcessorTesterMixin (#33711)
2024-10-01|||Repo consistency fix after #33339 (#33873)
2024-10-02|||[Fix] ViViT interpolate_pos_encoding (#33815)
2024-10-01|||Move weight initilization deformabledetr (#33339)
2024-10-01|||Make ASR pipeline compliant with Hub spec + add tests (#33769)
2024-10-01|||fix: repair depth estimation multiprocessing (#33759)
2024-10-01|||Avoid using context that is not accessable from external contributors (#33866)
2024-10-01|||Add include_loss_for_metrics (#33088)
2024-10-01|||Validate the eval dataset in advance. (#33743)
2024-10-01|||Raise `accelerate` dependency error in case of defaulting `low_cpu_mem_usage=True` (#33830)
2024-10-01|||This PR contains additional changes for #33143 (#33581)
2024-10-01|||Fix device mismatch errors (#33851)
2024-10-01|||Workaround for bark issue in pipelines (#33824)
2024-10-01|||add attention weight up-cast to float32 in chameleon (#33822)
2024-10-01|||fix: skip dropout in eval for flash_attn in various models (#33844)
2024-10-01|||Refactor image features selection in LlaVa (#33696)
2024-10-01|||Generate: move llama `prepare_inputs_for_generation` to `GenerationMixin` (#33677)
2024-10-01|||post reminder comment only once (#33848)
2024-10-01|||fix check for hidden size in text model for deepspeed zero3 auto entries (#33829)
2024-10-01|||Fix passing str dtype to static cache (#33741)
2024-10-01|||Fix Mamba slow path bug with dtype mismatch. (#32691)
2024-09-30|||Bump torch from 1.13.1 to 2.2.0 in /examples/research_projects/lxmert (#33821)
2024-10-01|||minor typo fix (#33784)
2024-09-30|||Fix link in gguf.md (#33768)
2024-09-30|||Fixes for issue #33763 in idefics2 model (#33766)
2024-09-30|||Fix ViT-MAE decoder interpolate (#33330)
2024-09-30|||[`modular`] fixes!  (#33820)
2024-09-30|||Add Slow CI reminder bot (#33506)
2024-09-30|||Hqq serialization (#33141)
2024-09-30|||Fix typo in documentation  (#33805)
2024-09-30|||Enable non-safetensor ser/deser for TorchAoConfig quantized model üî¥  (#33456)
2024-09-27|||Fix typing in `load_balancing_loss_func` function of `modeling_mixtral.py`. (#33641)
2024-09-27|||Make audio classification pipeline spec-compliant and add test (#33730)
2024-09-27|||Model addition timeline (#33762)
2024-09-27|||Cleanup return_text and return_full_text options in TextGenerationPipeline (#33542)
2024-09-27|||remove warning v2 (#33761)
2024-09-27|||Bump torch from 1.13.1 to 2.2.0 in /examples/flax/vision (#33748)
2024-09-27|||Add gguf support for bloom (#33473)
2024-09-27|||Paligemma support for multi-image (#33447)
2024-09-27|||Make siglip examples clearer and error free (#33667)
2024-09-27|||[`MllamaImageProcessing`] Update doc (#33747)
2024-09-27|||[`clean_up_tokenization_spaces`] Pl bart was failing, updating (#33735)
2024-09-27|||Doc and config mismatch for DeBERTa (#33713)
2024-09-27|||Update Albumentations Versions (#33704)
2024-09-27|||fix trainer tr_loss add error (#33651)
2024-09-27|||Fix modular model converter unable to generate Processor classes (#33737)
2024-09-26|||fix: add docstring for `image_size` in Convnextv2 config (#33734)
2024-09-26|||clean_up_tokenization_spaces=False if unset (#31938)
2024-09-26|||Generate: `can_generate()` recursive check (#33718)
2024-09-26|||Fix position embeddings singular/plural (#33678)
2024-09-26|||Fix docs and docstrings Omdet-Turbo (#33726)
2024-09-26|||fix: use correct var names for check_tokenizers script (#33702)
2024-09-26|||[`MllamaProcessor`] Update errors and API with multiple image (#33715)
2024-09-26|||Uniformize kwargs for chameleon processor (#32181)
2024-09-25|||Add Idefics 3! (#32473)
2024-09-25|||Dev release
2024-09-25|||adding positional encoder changes and tests (#32600)
2024-09-25|||Add MLLama (#33703)
2024-09-25|||Add OmDet-Turbo (#31843)
2024-09-26|||Corrected max number for bf16 in transformer/docs (#33658)
2024-09-25|||Add AdEMAMix optimizer (#33682)
2024-09-25|||Add SDPA support for M2M100 (#33309)
2024-09-25|||Fix Megatron-LM tokenizer path (#33344)
2024-09-25|||HFQuantizer implementation for compressed-tensors library (#31704)
2024-09-25|||fix code quality after merge
2024-09-25|||[Pixtral] Improve docs, rename model (#33491)
2024-09-25|||bump tokenizers, fix added tokens fast (#32535)
2024-09-25|||tests: fix pytorch tensor placement errors (#33485)
2024-09-25|||üö®üö® Setting default behavior of assisted decoding (#33657)
2024-09-24|||Uniformize kwargs for image-text-to-text processors (#32544)
2024-09-25|||Fix ByteLevel alphabet missing when Sequence pretokenizer is used (#33556)
2024-09-24|||Gemma2: fix config initialization (`cache_implementation`) (#33684)
2024-09-24|||Improve Error Messaging for Flash Attention 2 on CPU (#33655)
2024-09-24|||Generation tests: update imagegpt input name, remove unused functions (#33663)
2024-09-24|||Fixed docstring for cohere model regarding unavailability of prune_he‚Ä¶ (#33253)
2024-09-24|||Fix CIs post merging modular transformers (#33681)
2024-09-24|||Modular `transformers`: modularity and inheritance for new model additions (#33248)
2024-09-24|||uniformize git processor (#33668)
2024-09-24|||Fix error string after refactoring into get_chat_template (#33652)
2024-09-24|||Enable BNB multi-backend support (#31098)
2024-09-23|||Generation: deprecate `PreTrainedModel` inheriting from `GenerationMixin`  (#33203)
2024-09-23|||Uniformize kwargs for Udop processor and update docs (#33628)
2024-09-23|||Fix Llava conversion for LlavaQwen2ForCausalLM with Clip vision tower (#33613)
2024-09-23|||add back self.max_position_embeddings = config.max_position_embeddings (#33550)
2024-09-23|||handle dependency errors in check_imports (#33622)
2024-09-23|||Fix DPT /Dinov2 sdpa regression on main (#33660)
2024-09-23|||Clean up Unpack imports (#33631)
2024-09-21|||Sdpa dino v2 (#33403)
2024-09-21|||Pixtral update example checkpoint (#33633)
2024-09-20|||Granitemoe (#33207)
2024-09-21|||enable low-precision pipeline (#31625)
2024-09-21|||Fix typos (#33583)
2024-09-21|||Fix qwen2vl float16 inference bug (#33312)
2024-09-20|||Update daily ci to use new cluster (#33627)
2024-09-20|||Fix some missing tests in circleci (#33559)
2024-09-20|||Generate: assistant should sample when the main model samples (#33534)
2024-09-20|||Fix contrastive search to correctly handle input with padding (#33507)
2024-09-20|||Add support for args to ProcessorMixin for backward compatibility (#33479)
2024-09-20|||Fix missing test in `torch_job` (#33593)
2024-09-20|||VLM generate: tests can't generate image/video tokens (#33623)
2024-09-20|||Add sdpa for BioGpt (#33592)
2024-09-20|||Remove unnecessary CPM model tests (#33621)
2024-09-20|||Generate: remove flakyness in `test_generate_from_inputs_embeds_decoder_only` (#33602)
2024-09-20|||Update modeling_mamba2.py, fix pad size (#32599)
2024-09-20|||[tests] make more tests device-agnostic (#33580)
2024-09-20|||Allow CI could be run on private forked repositories (e.g. new model additions) (#33594)
2024-09-20|||Fix CircleCI nightly run (#33558)
2024-09-20|||Docs: add the ability to manually trigger jobs (#33598)
2024-09-20|||Fix Llama 3 TikToken conversion (#33538)
2024-09-20|||[tests] enable GemmaIntegrationTest on XPU  (#33555)
2024-09-20|||[tests] skip tests for xpu  (#33553)
2024-09-19|||Uniformize kwargs for Paligemma processor and update docs (#33571)
2024-09-19|||Cache: don't throw warnings on `gemma2` when instantiating a new cache (#33595)
2024-09-19|||[`Mamba2`] Move dt calculations to kernel (#33520)
2024-09-19|||change sequence_bias type of SequenceBiasLogitsProcessor to list, add‚Ä¶ (#33375)
2024-09-19|||Generate: check that `attention_mask` is 2D (#33575)
2024-09-19|||add uniform processors for altclip + chinese_clip (#31198)
2024-09-19|||fix tests with main revision and read token (#33560)
2024-09-19|||Cache: don't show warning in forward passes when `past_key_values` is None (#33541)
2024-09-19|||rag: fix CI (#33578)
2024-09-19|||VLMs: enable generation tests (#33533)
2024-09-19|||Load and save video-processor from separate folder (#33562)
2024-09-18|||Codec integration (#33565)
2024-09-18|||Fix bnb dequantization  (#33546)
2024-09-18|||Improve compiled RT-DETR inference speed  (#33412)
2024-09-18|||enforce original size to be a list (#33564)
2024-09-18|||Return attention mask in ASR pipeline to avoid warnings (#33509)
2024-09-18|||Pipeline: no side-effects on `model.config` and `model.generation_config` üî´  (#33480)
2024-09-19|||Added support for bfloat16 to zero-shot classification pipeline (#33554)
2024-09-18|||Fix tests in ASR pipeline (#33545)
2024-09-18|||fix the wandb logging issue (#33464)
2024-09-18|||[i18n-ur] Added README_ur.md file (#33461)
2024-09-18|||Fix missing head_dim in llama config from gguf model (#33526)
2024-09-18|||Chat template: save and load correctly for processors (#33462)
2024-09-18|||Fix for slow the bug tokenizer adding spaces to single id decodes (#32564)
2024-09-18|||Decorator for easier tool building (#33439)
2024-09-18|||Support LLaVa-OV-Chat (#33532)
2024-09-18|||fix patch_attention_mask incorrect setting which leads to the differe‚Ä¶ (#33499)
2024-09-17|||Add revision to trainer push_to_hub (#33482)
2024-09-17|||Uniformize kwargs for Pixtral processor (#33521)
2024-09-17|||Fix missing `sequences_scores` in the Whisper beam search output  (#32970)
2024-09-17|||fix to jamba config, asserting attention and expert offset (#33316)
2024-09-17|||CI Build image - move runners (#33530)
2024-09-18|||Add explicit example for RAG chat templating (#33503)
2024-09-17|||Update chameleon.md ‚Äî fix runtime type error (#33494)
2024-09-17|||idefics2 enable_input_require_grads not aligned with disable_input_re‚Ä¶ (#33194)
2024-09-17|||chore: migrate coverage cfg to pyproject.toml (#32650)
2024-09-17|||Fix number of patch check for different vision feature select strategy (#32494)
2024-09-17|||Fix parametrization-based weight norm (#33275)
2024-09-17|||Replace `accelerator.use_fp16` in examples (#33513)
2024-09-16|||Updated Trainer's liger-kernel integration to call correct patching API (#33502)
2024-09-17|||Fix: Qwen2-VL training on video datasets (#33307)
2024-09-16|||[Whisper test] Fix some failing tests (#33450)
2024-09-16|||[i18n-ar] Add File : `docs/source/ar/_toctree.yml`  (#32696)
2024-09-16|||`Agents, supercharged - Multi-agents, External tools, and more` docs typo fixed (#33478)
2024-09-16|||Uniformize kwargs for LLaVa processor and update docs (#32858)
2024-09-16|||Add keypoint-detection task guide (#33274)
2024-09-16|||Fix SSH workflow (#33451)
2024-09-16|||Cohere: update RoPE structure (#33408)
2024-09-14|||Add support for Pixtral (#33449)
2024-09-14|||chore: fix typo in comment in tokenization_utils_base.py (#33466)
2024-09-13|||Corrected `Agents and tools` documentation links typos (#33471)
2024-09-13|||Enable finetuning with torchao quantized model  (#33361)
2024-09-13|||Fix the initialization of the cache when we have multi gpu (#33303)
2024-09-13|||[Phi-3] Bug on stale kv cache  (#33129)
2024-09-13|||Mitigate a conflict when using sentencepiece (#33327)
2024-09-13|||Enable `padding_side` as call time kwargs (#33385)
2024-09-13|||add a callback hook right before the optimizer step (#33444)
2024-09-13|||Return image hidden states (#33426)
2024-09-13|||[docs] refine the doc for `train with a script` (#33423)
2024-09-12|||[whisper] Clarify error message when setting max_new_tokens (#33324)
2024-09-12|||Qwen2-VL: clean-up and add more tests (#33354)
2024-09-12|||Correct Whisper's beam search scores computation (#32336)
2024-09-12|||Allow send `SSH into runner` info. to DM (#33346)
2024-09-12|||Revive AMD scheduled CI (#33448)
2024-09-12|||Fix default revision for pipelines (#33395)
2024-09-12|||Clean-up deprecated code (#33446)
2024-09-12|||Fix flax whisper tokenizer bug (#33151)
2024-09-12|||Fix incomplete sentence in `Zero-shot object detection` documentation (#33430)
2024-09-12|||Docs - update formatting of llama3 model card (#33438)
2024-09-12|||Update stale.yml (#33434)
2024-09-12|||[docs] add the missing tokenizer when pushing models to huggingface hub (#33428)
2024-09-12|||[docs] add the missing huggingface hub username (#33431)
2024-09-11|||Fix: Cast prefetch_bucket_size to integer for deepspeed >= 0.15 (#33402)
2024-09-11|||Dynamic number of speculative tokens in order to accelerate speculative decoding (#33258)
2024-09-11|||Remove deprecated task in load_dataset (#33433)
2024-09-11|||Fix failing windows (#33436)
2024-09-11|||Fix `FbgemmFp8Linear` not preserving tensor shape (#33239)
2024-09-11|||use diff internal model in tests (#33387)
2024-09-10|||Make StaticCache configurable at model construct time (#32830)
2024-09-10|||Update WhisperTokenizer Doc: Timestamps and Previous Tokens Behaviour (#33390)
2024-09-10|||Bug Fix: Update hub.py to fix NoneType error (#33315)
2024-09-10|||Add support for GGUF Phi-3 (#31844)
2024-09-10|||fixed Mask2Former image processor segmentation maps handling (#33364)
2024-09-10|||VLM: fixes after refactor (#32907)
2024-09-10|||Import structure & first three model refactors (#31329)
2024-09-10|||Fix import of `FalconMambaForCausalLM` (#33381)
2024-09-09|||Remove repeated prepare_images in processor tests (#33163)
2024-09-09|||Adjust templates (#33384)
2024-09-09|||Compile compatibilty for decoder-only models (#32617)
2024-09-09|||Fixed Majority of the Typos in `transformers[en]` Documentation (#33350)
2024-09-09|||Add visit webpage tool (#33353)
2024-09-09|||schedulefree optimizers (#30079)
2024-09-09|||Fix quantized cache tests (#33351)
2024-09-06|||add sdpa mbart (#32033)
2024-09-07|||Update author for QLorA/PEFT community notebook (#33338)
2024-09-06|||Fix Prefill docs (#33352)
2024-09-06|||RoPE: fix BC warning (#33331)
2024-09-06|||red-ci on main, fix copies (#33356)
2024-09-06|||Support reading tiktoken tokenizer.model file (#31656)
2024-09-06|||support 3D attention mask in bert (#32105)
2024-09-06|||add self.head_dim for VisionAttention in Qwen2-VL (#33211)
2024-09-06|||Add validation for maximum sequence length in modeling_whisper.py (#33196)
2024-09-06|||support loading model without config.json file (#32356)
2024-09-06|||Load dynamic module (remote code) only once if code isn't change (#33162)
2024-09-06|||fix qwen2vl vision eager-attention (#33213)
2024-09-06|||[whisper] alternative fix for long-form timestamps (#32131)
2024-09-06|||Docs: add more cross-references to the KV cache docs (#33323)
2024-09-06|||Fix: StaticCache & `inputs_embeds` (#32932)
2024-09-06|||Add a community notebook for fine-tuning with QLoRA, PEFT, and MLflow (#33319)
2024-09-06|||simple align qwen2vl kv_seq_len calculation with qwen2 (#33161)
2024-09-05|||Add Qwen2Moe GGUF loading support  (#33264)
2024-09-05|||Update SECURITY.md (#32680)
2024-09-05|||üö® Fix `torch.jit.trace` for `interpolate_pos_encoding` in all vision models (#33226)
2024-09-05|||Add paper link (#33305)
2024-09-05|||Fix: Fix `FalconMamba` training issues due to incompatible kernels (#33195)
2024-09-05|||Llava Onevision: add model (#32673)
2024-09-04|||Add validate images and text inputs order util for processors and test_processing_utils (#33285)
2024-09-04|||Fix excessive CPU memory usage with FSDP and cpu_ram_efficient_loading (#33154)
2024-09-04|||[BUG] fix upper nltk version (#33301)
2024-09-04|||Add new documentation page for advanced agent usage (#33265)
2024-09-04|||Add a warning to the chat template docs about the tool_calls format (#33277)
2024-09-04|||Multi agents with manager (#32687)
2024-09-04|||[InstructBLIP] qformer_tokenizer is required input (#33222)
2024-09-04|||Bump cryptography from 42.0.0 to 43.0.1 in /examples/research_projects/decision_transformer (#33286)
2024-09-04|||Bugfix/alexsherstinsky/fix none check for attention factor in rope scaling 2024 08 28 0 (#33188)
2024-09-04|||wait 15m before SSH into runner workflow stops (#33300)
2024-09-04|||[fix] LlavaNextProcessor '_get_unpadded_features' method (#33263)
2024-09-04|||Config: unified logic to retrieve text config (#33219)
2024-09-04|||Cache docs: update (#32929)
2024-09-04|||Fix: multigpu training (#33271)
2024-09-03|||Add OLMoE (#32406)
2024-09-03|||Repo checks: check documented methods exist (#32320)
2024-09-03|||fix the parallel number of CI nodes when it is smaller than number of tests (#33276)
2024-09-03|||Only disallow DeepSpeed Zero-3 for auto bs finder (#31731)
2024-09-03|||Add sdpa support for Albert (#32092)
2024-09-03|||Bump opencv-python from 4.4.0.42 to 4.8.1.78 in /examples/research_projects/visual_bert (#33251)
2024-09-03|||Update chat template docs to remove Blenderbot (#33254)
2024-09-03|||üö® Support dequantization for most GGML types (#32625)
2024-09-03|||Fix Bark saving (#33266)
2024-09-03|||Fix: `num_logits_to_keep` in composite models (#33168)
2024-09-03|||remove torch input dependant control flow (#33245)
2024-09-03|||Fix: use `torch.from_numpy()` to create tensors for np.ndarrays (#33201)
2024-09-02|||Fixed typo repeated word in DETR docs (#33250)
2024-09-02|||remove to restriction for 4-bit model (#33122)
2024-09-02|||Generate: fix assistant in different device (#33257)
2024-09-02|||Add assistant prefill for chat templates and TextGenerationPipeline (#33198)
2024-09-02|||Bump opencv-python from 4.4.0.42 to 4.8.1.78 in /examples/research_projects/lxmert (#33227)
2024-09-02|||docs: Replace package abbreviations with full name(`bitsandbytes`) in docstrings (#33230)
2024-09-02|||Fix: Suppressed 'use_reentrant=False' warning (#33208)
2024-09-02|||Add duckduckgo search tool (#32882)
2024-09-02|||Add GraniteRMSNorm (#33177)
2024-09-01|||Add video text to text docs (#33164)
2024-08-31|||Generate: throw warning when `return_dict_in_generate` is False but should be True (#33146)
2024-08-30|||Test fetcher: missing return on filtered tests; don't write empty files (#33224)
2024-08-30|||Fix red amin (#33220)
2024-08-31|||üåê [i18n-KO] Translated `llm_optims.md` to Korean (#32325)
2024-08-30|||Create local Transformers Engine (#33218)
2024-08-30|||Refactor CI: more explicit (#30674)
2024-08-30|||Fix local repos with remote code not registering for pipelines (#33100)
2024-08-30|||Add warning for stop string edge case (#33169)
2024-08-30|||Add missing quotes in modeling_llava_next_video.py (#33214)
2024-08-30|||Bump torch from 1.13.1 to 2.2.0 in /examples/research_projects/decision_transformer (#33215)
2024-08-30|||Bump torch from 1.13.1 to 2.2.0 in /examples/research_projects/codeparrot (#33173)
2024-08-30|||Pipeline: fix bad generation kwargs docs (#33205)
2024-08-29|||use a single for loop (#33148)
2024-08-29|||Add a static cache that offloads to the CPU or other device (#32161)
2024-08-29|||Mamba2 conversion script for original models (#32580)
2024-08-29|||pass module to Params4bit.from_prequantized to ensure quant_state (#32524)
2024-08-28|||added quick clarification (#33166)
2024-08-28|||update push CI workflow files for security (#33142)
2024-08-28|||Fix spell mistakes (#33149)
2024-08-28|||Customise the separator used for splicing in DataCollatorWithFlattening (#33114)
2024-08-28|||Zero-shot pipelines: minor doc changes (#33127)
2024-08-28|||Fix import paths for test_module (#32888)
2024-08-28|||[RoBERTa-based] Add support for sdpa (#30510)
2024-08-28|||[whisper] pass attention_mask to generate_with_fallback() (#33145)
2024-08-28|||Fix: Jamba batched generation (#32914)
2024-08-28|||fix model name and copyright (#33152)
2024-08-27|||Granite language models (#31502)
2024-08-27|||üö® Add Blip2ForImageTextRetrieval (#29261)
2024-08-27|||Very small change to one of the function parameters (#32548)
2024-08-28|||üåê [i18n-KO] Translated `conversations.md` to Korean (#32468)
2024-08-27|||update torch req for 4-bit optimizer (#33144)
2024-08-27|||fix redundant checkpointing in example training scripts (#33131)
2024-08-27|||Llama: make slow tests green üü¢  (#33138)
2024-08-27|||Add a fix for custom code tokenizers in pipelines (#32300)
2024-08-27|||fix Idefics2VisionConfig type annotation (#33103)
2024-08-27|||Update stateful_callbacks state before saving checkpoint (#32115)
2024-08-27|||[docs] add quick usage snippet to Whisper. (#31289)
2024-08-27|||Log additional test metrics with the CometCallback (#33124)
2024-08-27|||Bump torch from 1.13.1 to 2.2.0 in /examples/research_projects/jax-projects/hybrid_clip (#33137)
2024-08-27|||CI: fix `efficientnet` pipeline timeout and prevent future similar issues due to large image size (#33123)
2024-08-27|||disable scheduled daily CI temporarily (#33136)
2024-08-27|||fix: multilingual midel convert to tflite get wrong token (#32079)
2024-08-27|||fix: Fixed CodeGenTokenizationTest::test_truncation failing test (#32850)
2024-08-26|||Fixup py 38 type hints for mps friendly (#33128)
2024-08-26|||quickfix documentation (#32566)
2024-08-26|||fix: Fixed `pydantic` required version in dockerfiles to make it compatible with DeepSpeed (#33105)
2024-08-26|||Add changes for uroman package to handle non-Roman characters (#32404)
2024-08-26|||mps: add `isin_mps_friendly`, a wrapper function for `torch.isin` (#33099)
2024-08-26|||Test: add higher `atol` in `test_forward_with_num_logits_to_keep` (#33093)
2024-08-26|||CI: add torchvision to the consistency image (#32941)
2024-08-26|||support qwen2-vl (#32318)
2024-08-26|||Updated the custom_models.md changed cross_entropy code (#33118)
2024-08-23|||Update Jinja docs with new functions and general cleanup (#33097)
2024-08-23|||added doctring to SchedulerType class (#32898)
2024-08-24|||DeviceGuard added to use Deformable Attention more safely on multi-GPU (#32910)
2024-08-23|||Enable some Jinja extensions and add datetime capabilities (#32684)
2024-08-23|||Integrate Liger (Linkedin GPU Efficient Runtime) Kernel to Trainer (#32860)
2024-08-23|||Forbid `PretrainedConfig` from saving `generate` parameters; Update deprecations in `generate`-related code üßπ  (#32659)
2024-08-23|||Reducing memory usage: removing useless logits computation in generate() (#31292)
2024-08-22|||docs: fix outdated link to TF32 explanation (#32947)
2024-08-22|||Generate: Deprecate returning legacy cache by default; Handle `use_cache=False` (#32863)
2024-08-22|||üåê [i18n-KO] Translated `knowledge_distillation_for_image_classification.md to Korean"  (#32334)
2024-08-23|||Fix regression on `Processor.save_pretrained` caused by #31691 (#32921)
2024-08-22|||[run_slow] idefics2 (#32840)
2024-08-22|||Gemma2: eager attention by default (#32865)
2024-08-22|||fix: (issue #32689) `AttributeError` raised when using `Trainer` with `eval_on_start=True` in Jupyter Notebook. (#32849)
2024-08-22|||Add chat_template for tokenizer extracted from GGUF model (#32908)
2024-08-22|||Improve greedy search memory usage (#32895)
2024-08-22|||Fix benchmark script (#32635)
2024-08-22|||Add SynCode to llm_tutorial (#32884)
2024-08-22|||FIX / Hub: Also catch for `exceptions.ConnectionError` (#31469)
2024-08-22|||CI: separate step to download nltk files (#32935)
2024-08-22|||FEAT / Trainer: Add adamw 4bit optimizer (#31865)
2024-08-22|||fix: no need to dtype A in jamba (#32924)
2024-08-22|||fix: Added missing `huggingface_hub` installation to workflows (#32891)
2024-08-22|||Jamba: update integration tests (#32250)
2024-08-21|||Update docker image building (#32918)
2024-08-22|||fix: [whisper] don't overwrite GenerationConfig's `return_timestamps` when `return_timestamps` is not passed to `generate` function (#31296)
2024-08-21|||[i18n-ar] add README_ar.md to README.md (#32583)
2024-08-20|||link for optimizer names (#32400)
2024-08-20|||Replace `tensor.norm()` with decomposed version for CLIP executorch export (#32887)
2024-08-20|||Bump nltk from 3.7 to 3.9 in /examples/research_projects/decision_transformer (#32903)
2024-08-20|||Fix: Mamba2 `norm_before_gate` usage (#32686)
2024-08-20|||fix: jamba cache fails to use torch.nn.module (#32894)
2024-08-20|||Fix repr for conv (#32897)
2024-08-20|||üö®üö®üö® Update min version of accelerate to 0.26.0 (#32627)
2024-08-20|||Allow-head-dim (#32857)
2024-08-19|||Add tip to clarify tool calling (#32883)
2024-08-19|||Docs: Fixed `whisper-large-v2` model link in docs (#32871)
2024-08-19|||Fix: Mamba2 generation mismatch between input_ids and inputs_embeds (#32694)
2024-08-19|||Mamba / FalconMamba: Fix mamba left padding (#32677)
2024-08-19|||Fix incorrect vocab size retrieval in GGUF config (#32551)
2024-08-19|||RT-DETR parameterized batchnorm freezing (#32631)
2024-08-19|||Support save/load ckpt for XLA FSDP (#32311)
2024-08-19|||Add __repr__ for Conv1D (#32425)
2024-08-19|||[tests] make `test_sdpa_can_compile_dynamic` device-agnostic (#32519)
2024-08-19|||support torch-speech (#32537)
2024-08-19|||Add Descript-Audio-Codec model (#31494)
2024-08-19|||Add Flax Dinov2 (#31960)
2024-08-17|||generate: missing `to` in DoLa body, causing exceptions in multi-gpu generation (#32856)
2024-08-16|||Make beam_constraints.Constraint.advance() docstring more accurate (#32674)
2024-08-16|||Reduce the error log when using core models that need their weights renamed, and provide a step forward (#32656)
2024-08-16|||fix multi-gpu with static cache (#32543)
2024-08-16|||Revert PR 32299, flag users when Zero-3 was missed (#32851)
2024-08-16|||improve _get_is_as_tensor_fns (#32596)
2024-08-16|||Fix AutoConfig and AutoModel support for Llava-Next-Video (#32844)
2024-08-16|||Cache: use `batch_size` instead of `max_batch_size` (#32657)
2024-08-16|||[tests] make test_sdpa_equivalence device-agnostic (#32520)
2024-08-16|||Generate: unify `LogitsWarper` and `LogitsProcessor` (#32626)
2024-08-16|||Use head_dim if in config for RoPE (#32495)
2024-08-16|||add back the position ids (#32554)
2024-08-16|||VLMs: small clean-up for cache class (#32417)
2024-08-16|||fix: update doc link for runhouse in README.md (#32664)
2024-08-15|||fix: Corrected ` falcon-mamba-7b` model checkpoint name (#32837)
2024-08-15|||reopen: llava-next fails to consider padding_side during Training (#32679)
2024-08-14|||Updated workflows to the latest versions (#32405)
2024-08-14|||Unpin deepspeed in Docker image/tests (#32572)
2024-08-14|||fix: Fixed unknown pytest config option `doctest_glob` (#32475)
2024-08-14|||Update the distributed CPU training on Kubernetes documentation (#32669)
2024-08-14|||Fix `JetMoeIntegrationTest` (#32332)
2024-08-14|||Add TorchAOHfQuantizer (#32306)
2024-08-14|||Update translation docs review (#32662)
2024-08-14|||fix: Fixed failing tests in `tests/utils/test_add_new_model_like.py` (#32678)
2024-08-14|||Support MUSA (Moore Threads GPU) backend in transformers (#31913)
2024-08-13|||Fix tests recurrent (#32651)
2024-08-14|||TF_Deberta supporting mixed precision (#32618)
2024-08-13|||Modify ProcessorTesterMixin for better generalization (#32637)
2024-08-13|||Fix: Fixed directory path for utils folder in `test_tokenization_utils.py` (#32601)
2024-08-13|||Add Depth Anything V2 Metric models (#32126)
2024-08-13|||Add support for GrokAdamW optimizer (#32521)
2024-08-13|||fix tensors on different devices in `WhisperGenerationMixin` (#32316)
2024-08-13|||Fix tests (#32649)
2024-08-13|||Automatically add `transformers` tag to the modelcard (#32623)
2024-08-13|||Expand inputs in processors for VLMs (#30962)
2024-08-13|||fix: Updated the `is_torch_mps_available()` function to include `min_version` argument (#32545)
2024-08-12|||"to be not" -> "not to be" (#32636)
2024-08-12|||Bump tensorflow from 2.11.1 to 2.12.1 in /examples/research_projects/decision_transformer (#32341)
2024-08-13|||fix: Fixed failing `test_find_base_model_checkpoint` (#32638)
2024-08-13|||üåê [i18n-KO] Translated `awq.md`to Korean (#32324)
2024-08-13|||üåê [i18n-KO] Translated `deepspeed.md` to Korean (#32431)
2024-08-12|||Cleanup tool calling documentation and rename doc (#32337)
2024-08-12|||Bump torch from 1.13.1 to 2.2.0 in /examples/research_projects/visual_bert (#32220)
2024-08-12|||Bump aiohttp from 3.9.4 to 3.10.2 in /examples/research_projects/decision_transformer (#32569)
2024-08-12|||Fix `.push_to_hub(..., create_pr=True, revision="my-branch")` when creating PR on not-owned repo (#32094)
2024-08-12|||fix: Fixed conditional check for `encodec` model names (#32581)
2024-08-12|||Fix sliding window attention used in Gemma2FlashAttention2 (#32522)
2024-08-12|||Fix: FA2 with packed training (#32487)
2024-08-12|||Add new model (#32615)
2024-08-10|||üåê [i18n-KO] Translated `agent.md` to Korean (#32351)
2024-08-09|||fix non contiguous tensor value error in save_pretrained (#32422)
2024-08-09|||fix slow integration gemma2 test (#32534)
2024-08-09|||Fix a bug in Qwen2Audio (#32552)
2024-08-09|||Gemma2: fix FA2 generation (#32553)
2024-08-08|||[docs] Translation guide (#32547)
2024-08-08|||Fix code example to load bigcode starcoder2 7b (#32474)
2024-08-08|||Fixed test `test_static_cache_exportability` with torch 2.4.0 (#32516)
2024-08-08|||Fix generate with `inputs_embeds` as input (#32493)
2024-08-09|||üåê [i18n-KO] Translated `bitsandbytes.md` to Korean (#32408)
2024-08-09|||üåê [i18n-KO] Translated `fsdp.md` to Korean (#32261)
2024-08-09|||üåê [i18n-KO] Translated `eetq.md` to Korean (#32352)
2024-08-09|||üåê [i18n-KO] Translated `trainer.md` to Korean (#32260)
2024-08-09|||üåê [i18n-KO] Translated `ko-llm_tutorial_optimization.md` to Korean (#32372)
2024-08-08|||filter flash_attn optional imports loading remote code (#30954)
2024-08-08|||Add Qwen2-Audio (#32137)
2024-08-08|||Fix add-new-model-like (#31773)
2024-08-08||| Uniformize kwargs for processors - GroundingDINO (#31964)
2024-08-08|||Change Phi3 `_supports_sdpa` to True (#32457)
2024-08-08|||Fix issue #32518: Update llm_tutorial.md (#32523)
2024-08-08|||Fix typo: depracted -> deprecated (#32489)
2024-08-07|||Fix link to autoclass_tutorial.md in i18n.md (#32501)
2024-08-08|||üåê [i18n-KO] Translated `chat_templating.md` to Korean (#32362)
2024-08-07|||Docs: Fixed WhisperModel.forward‚Äôs docstring link (#32498)
2024-08-07|||Fix references to model google mt5 small (#32497)
2024-08-08|||üåê [i18n-KO] Translated `image_feature_extraction.md` to Korean (#32239)
2024-08-08|||üåê [i18n-KO] Translated `quantization/quanto.md` to Korean (#32281)
2024-08-08|||üåê [i18n-KO] Translated `prompting.md` to Korean (#32294)
2024-08-08|||üåê [i18n-KO] Translated `gptq.md` to Korean (#32293)
2024-08-07|||Docs: alert for the possibility of manipulating logits (#32467)
2024-08-07|||fix broken link in docs (#32491)
2024-08-07|||Agents use grammar (#31735)
2024-08-07|||Fix typo in tokenization_utils_base.py (#32484)
2024-08-07|||enable xla fsdp (#32048)
2024-08-07|||Gemma2: add cache warning (#32279)
2024-08-07|||Cache: new Cache format in decoder-only models (#31421)
2024-08-07|||üåê [i18n-KO] Translated `image_to_image.md` to Korean (#32327)
2024-08-07|||üåê [i18n-KO] Translated `idefics.md` to Korean (#32258)
2024-08-07|||üåê [i18n-KO] Translated `mask_generation.md` to Korean (#32257)
2024-08-06|||Revert "fixes to properly shard FSDP across cpu and meta for cpu_effcient_loading for prequantized 4bit (#32276)" (#32477)
2024-08-06|||`is_torchdynamo_compiling` -- cast a wide exception net (#32476)
2024-08-06|||dev version 4.45.0
2024-08-06|||Documentation: BOS token_id deprecation change for NLLB (#32443)
2024-08-06|||Migrate import checks not need accelerate, and be more clear on min versions (#32292)
2024-08-06|||Add codestral mamba2 (#32080)
2024-08-06|||Generate: fix end to end compilation (#32465)
2024-08-06|||Add Nemotron HF Support (#31699)
2024-08-06|||Dependencies: fix typo (#32389)
2024-08-06|||Fix get large model config for Switch Transformer encoder only tester (#32438)
2024-08-06|||Update kwargs validation for `preprocess` with decorator (#32024)
2024-08-06|||add the missing flash attention test marker (#32419)
2024-08-06|||Llava: fix checkpoint_doc (#32458)
2024-08-06|||Cache: create docs (#32150)
2024-08-05|||Fix documentation links and code reference to model llava-next (#32434)
2024-08-05|||Respect the config's attn_implementation if set (#32383)
2024-08-05|||fix: Updated `test_embeded_special_tokens` for luke and mluke models (#32413)
2024-08-05|||Persist embedding type of BART and mBART models after resize (#32242)
2024-08-05|||Fix documentation references to google/bit-50 model (#32407)
2024-08-05|||add values for neftune (#32399)
2024-08-05|||#32184 save total_vocab_size (#32240)
2024-08-05|||Phi3 tests: fix typing for Python 3.8 (#32388)
2024-08-05|||fix: SeamlessM4TFeatureExtractor stride remainder (#32088)
2024-08-05|||Bump keras from 2.8.0 to 2.13.1 in /examples/research_projects/decision_transformer (#32393)
2024-08-03|||MixtralFlashAttention2: put "plus 1" inside parentheses when calculating rotary_seq_len, allowing None position_ids input. (#31500)
2024-08-03|||fix: (issue #32124) Exception raised when running `transformers/examples/flax/language-modeling/t5_tokenizer_model.py`. (#32157)
2024-08-02|||[generate] only require an attention mask for mps with torch<2.4 (#32367)
2024-08-02|||RoPE: Add numerical tests ‚ú®  (#32380)
2024-08-02|||Update docs (#32368)
2024-08-01|||Yell at the user if zero-3 init wasn't performed, but expected to have been done (#32299)
2024-08-01|||Fixed Hybrid Cache Shape Initialization. (#32163)
2024-08-01|||Docker: add `speech` dep to the consistency docker image (#32374)
2024-08-01|||Offloaded KV Cache (#31325)
2024-08-01|||Fix conflicting key in init kwargs in PreTrainedTokenizerBase (#31233)
2024-08-01|||Empty list in defaults for LLaMA special tokens during weights conversion (#32342)
2024-08-01|||update clean_up_tokenization_spaces warning (#32371)
2024-08-01|||Check device map for saving tokenizer config on TPU (fix for issue #31971) (#32043)
2024-08-01|||add missing attribute _supports_param_buffer_assignment for gpt-j. (#32359)
2024-08-01|||Remove size check between attn_weights and kv_seq_len for phi3 (#32339)
2024-08-01|||[whisper] compile compatibility with long-form decoding (#31772)
2024-08-01|||[enc-dec cache] fix bug in indexing (#32370)
2024-08-01|||LLaVa: add cache class attribute (#32278)
2024-08-01|||fix: warmup_steps check for training_args (#32236)
2024-08-01|||fix: Removed unnecessary `@staticmethod` decorator (#32361)
2024-07-31|||>3-5x faster torch.compile forward compilation for autoregressive decoder models (#32227)
2024-07-31|||Fix error when streaming to gradio with non-string tool arguments (#32360)
2024-07-31|||Gemma 2: support assisted generation (#32357)
2024-07-31|||[Idefics2] - Fix FA2 call for Perceiver layer (#32275)
2024-07-31|||Llama 3.1: Fix incorrect `inv_freq` assignment (#32330)
2024-07-31|||Gemma2 and flash-attention (#32188)
2024-07-31|||LLaVA-NeXT: fix anyres shapes (#32314)
2024-07-30|||Fix slow GemmaTokenizer and improve SPM slow -> fast conversion process (#32191)
2024-07-30|||Repo checks: skip docstring checks if not in the diff (#32328)
2024-07-30|||fixes #32329 : The Torch code is correct - to get an average of 10% o‚Ä¶ (#32335)
2024-07-30|||fixes to properly shard FSDP across cpu and meta for cpu_efficient_loading for prequantized 4bit (#32276)
2024-07-30|||fix: Added missing raise keyword for few exceptions (#32333)
2024-07-30|||Alternative agent plan (#32295)
2024-07-30|||Docs: formatting nits (#32247)
2024-07-30|||Fix M4T for ASR pipeline (#32296)
2024-07-30|||feat(ci): set `fetch-depth: 0` in trufflehog checkout step (#31663)
2024-07-30|||Cast epochs_trained to int when resuming training (#32286)
2024-07-30|||Fix GGUF dequantize for `gguf==0.9.1` (#32298)
2024-07-30|||Docs: fix GaLore optimizer code example (#32249)
2024-07-29|||use torch 2.4 in 2 CI jobs (#32302)
2024-07-29|||Add stream messages from agent run for gradio chatbot (#32142)
2024-07-29|||Make static cache compatible with torch.export (#32168)
2024-07-29|||[pipeline] fix padding for 1-d tensors (#31776)
2024-07-29|||Whisper tokenizer word level timestamps (#32197)
2024-07-29|||Generate: end-to-end compilation (#30788)
2024-07-29|||fix(docs): Fixed a link in docs (#32274)
2024-07-29|||make `p_mask` a numpy array before passing to `select_starts_ends` (#32076)
2024-07-29|||Repo: remove exceptions in `check_docstrings` (#32259)
2024-07-29|||fix: Fixed wrong argument passed to `convert_blip_checkpoint` function call (#32262)
2024-07-29|||Optimize t5 tokenize logic to avoid redundant calls (#32270)
2024-07-29|||Upload new model failure report to Hub (#32264)
2024-07-29|||üö® Bloom support for cache class (#31445)
2024-07-27|||Llama 3.1: replace for loop by tensor ops at inv_freq initialization (#32244)
2024-07-26|||More flexible trigger condition (#32251)
2024-07-26|||Flash-Attn: fix generation when no attention mask or no pading (#32241)
2024-07-26|||[tests] fix `static` cache implementation is not compatible with `attn_implementation==flash_attention_2` (#32039)
2024-07-26|||Add check for `target_sizes is None` in `post_process_image_guided_detection` for owlv2 (#31934)
2024-07-26|||Adds: extra_repr for RMSNorm layers in most models (#32204)
2024-07-26|||Refactor: Removed un-necessary `object` base class (#32230)
2024-07-26|||don't log base model architecture in wandb if log model is false (#32143)
2024-07-26|||Resize embeds with DeepSpeed  (#32214)
2024-07-26|||Llava: generate without images (#32183)
2024-07-26|||Generation: stop at `eos` for assisted decoding (#31301)
2024-07-25|||Fix code snippet for Grounding DINO (#32229)
2024-07-25|||Allow a specific microphone to be used by the ffmpeg audio pipeline utility functions. Default to using the currently active microphone on Mac (#31846)
2024-07-26|||translate philosophy.md to chinese (#32177)
2024-07-25|||Follow up for #31973 (#32025)
2024-07-25|||[warnings] fix E721 warnings (#32223)
2024-07-25|||[BigBird Pegasus] set _supports_param_buffer_assignment to False (#32222)
2024-07-25|||Update question_answering.py (#32208)
2024-07-25|||remove unnecessary guard code related with pytorch versions 1.4.2 ~ 1.7.0 (#32210)
2024-07-25|||[whisper] fix short-form output type (#32178)
2024-07-24|||fix: Replaced deprecated `unittest method` with the correct one (#32198)
2024-07-24|||:rotating_light: No more default chat templates (#31733)
2024-07-24|||Support dequantizing GGUF FP16 format (#31783)
2024-07-24|||Fix float8_e4m3fn in modeling_utils (#32193)
2024-07-24|||Fix resize embedding with Deepspeed (#32192)
2024-07-24|||let's not warn when someone is running a forward  (#32176)
2024-07-24|||RoPE: relaxed rope validation (#32182)
2024-07-24|||Remove conversational pipeline tests (#32099)
2024-07-24|||Update qwen2.md (#32108)
2024-07-24|||fix: default value reflects the runtime environment variables rather than the ones present at import time. (#32153)
2024-07-24|||adds: extra_repr() to MambaRMSNorm to include hidden size / size of weights in the layer (#32171)
2024-07-24|||[docs] change temperature to a positive value (#32077)
2024-07-23|||fix: Fixed an if condition that is always evaluating to true (#32160)
2024-07-23|||fix (#32162)
2024-07-23|||Llama 3.1 conversion
2024-07-23|||Dev version: v4.44.0.dev0
2024-07-23|||Updated `ruff` to the latest version (#31926)
2024-07-23|||Enhancing SFT Training Efficiency Using Packing and FlashAttention2 with Position IDs (#31629)
2024-07-23|||Added additional kwarg for successful running of optuna hyperparameter search (#31924)
2024-07-23|||feat(cache): StaticCache uses index_copy_ to avoid useless copy (#31857)
2024-07-23|||Fix typing to be compatible with later py versions (#32155)
2024-07-23|||Revert "Incorrect Whisper long-form decoding timestamps " (#32148)
2024-07-23|||Rename Phi-3 rope scaling type (#31436)
2024-07-23|||Added mamba.py backend (#30139)
2024-07-23|||Fix video batching to videollava (#32139)
2024-07-23|||Fix flash attention speed issue (#32028)
2024-07-23|||gguf conversion add_prefix_space=None for llama3 (#31937)
2024-07-23|||Llama: RoPE refactor (#32135)
2024-07-23|||Modify resize_token_embeddings to ensure output type is same as input (#31979)
2024-07-23|||Disable quick init for TapasPreTrainedModel (#32149)
2024-07-23|||Add YaRN and Dynamic-YaRN RoPE Scaling Methods (#30910)
2024-07-23|||Add method to retrieve used chat template (#32032)
2024-07-23|||Fix mask creations of `GPTNeoX` and `GPT2` (#31944)
2024-07-23|||[modelling] remove un-necessary transpose for fa2 attention (#31749)
2024-07-23|||Remove `trust_remote_code` when loading Libri Dummy (#31748)
2024-07-23|||LLaVaNeXT: pad on right if training (#32134)
2024-07-23|||Add llama3-llava-next-8b to llava_next conversion script (#31395)
2024-07-22|||Add new quant method (#32047)
2024-07-22|||set warning level to info for special tokens have been added (#32138)
2024-07-22|||Don't default to other weights file when use_safetensors=True (#31874)
2024-07-22|||Return assistant generated tokens mask in apply_chat_template  (#30650)
2024-07-22|||[RoBERTa] Minor clarifications to model doc (#31949)
2024-07-22|||fix: Fixed raising `TypeError` instead of `ValueError` for invalid type (#32111)
2024-07-23|||Update `ko/_toctree.yml` and remove `custom_tools.md` to reflect latest changes (#31969)
2024-07-22|||Fix failing test with race condition (#32140)
2024-07-22|||[generate] fix eos/pad id check on mps devices (#31695)
2024-07-22|||Mention model_info.id instead of model_info.modelId (#32106)
2024-07-22|||fix: Replaced deprecated `mktemp()` function (#32123)
2024-07-22|||Generate: store special token tensors under a unique variable name (#31980)
2024-07-22|||Fix shard order (#32023)
2024-07-22|||Agents planning (#31702)
2024-07-19|||Fix tests after `huggingface_hub` 0.24 (#32054)
2024-07-19|||Chameleon: not supported with fast load (#32091)
2024-07-19|||Disable quick init for deepspeed (#32066)
2024-07-19|||Support generating with fallback for short form audio in Whisper (#30984)
2024-07-19|||Add image-text-to-text task guide (#31777)
2024-07-19|||Fixes to chameleon docs (#32078)
2024-07-19|||Fix progress callback deepcopy (#32070)
2024-07-19|||VideoLLaVa: fix chat format in docs (#32083)
2024-07-19|||[mistral] Fix FA2 attention reshape for Mistral Nemo (#32065)
2024-07-19|||Incorrect Whisper long-form decoding timestamps  (#32003)
2024-07-19|||[Chameleon, Hiera] Improve docs (#32038)
2024-07-19|||Llava: add default chat templates (#31691)
2024-07-19|||docs: Fixed 2 links in the docs along with some minor fixes (#32058)
2024-07-18|||fix: Removed `duplicate entries` in a dictionary (#32041)
2024-07-18|||Add torch.compile Support For Mamba (#31247)
2024-07-18|||[mistral] Support passing `head_dim` through config (and do not require `head_dim * num_heads == hidden_size`) (#32050)
2024-07-18|||Bump scikit-learn from 1.1.2 to 1.5.0 in /examples/research_projects/codeparrot/examples (#32052)
2024-07-18|||Bump scikit-learn from 1.0.2 to 1.5.0 in /examples/research_projects/decision_transformer (#31458)
2024-07-18|||Chameleon: minor fixes after shipping (#32037)
2024-07-18|||unpin `numpy<2.0` (#32018)
2024-07-18|||Add `sdpa` and  FA2 for CLIP (#31940)
2024-07-17|||Add language to word timestamps for Whisper (#31572)
2024-07-17|||Pass missing arguments to `SeamlessM4Tv2ConformerEncoderLayer.forward()` when gradient checkpointing is enabled (#31945)
2024-07-17|||doc: fix broken BEiT and DiNAT model links on Backbone page (#32029)
2024-07-17|||Fix typo in classification function selection logic to improve code consistency (#32031)
2024-07-17|||Fixed `log messages` that are resulting in TypeError due to too many arguments (#32017)
2024-07-17|||Fix tests skip (#32012)
2024-07-17|||Chameleon: add model (#31534)
2024-07-16|||SpeechEncoderDecoder doesn't support param buffer assignments (#32009)
2024-07-16|||Fix if else and *actually* enable superfast init (#32007)
2024-07-16|||Fix gather when collecting 'num_input_tokens_seen' (#31974)
2024-07-16|||Bug report update -- round 2 (#32006)
2024-07-16|||fix: Fixed incorrect dictionary assignment in `src/transformers/__init__.py` (#31993)
2024-07-17|||add flash-attn deterministic option to flash-attn>=2.4.1 (#31961)
2024-07-16|||Bug report update (#31983)
2024-07-16|||Tests: remove cuda versions when the result is the same üßπüßπ (#31955)
2024-07-16|||Fix bad test about slower init (#32002)
2024-07-16|||[tests] fix deepspeed zero3 config for `test_stage3_nvme_offload` (#31881)
2024-07-16|||Speedup model init on CPU (by 10x+ for llama-3-8B as one example) (#31771)
2024-07-16|||Cambricon MLUs support SDPA and flash_attn (#31102)
2024-07-16|||Fix the incorrect permutation of gguf (#31788)
2024-07-15|||Generate: doc nits (#31982)
2024-07-15|||Masking: remove flakiness from test (#31939)
2024-07-15|||Avoid race condition (#31973)
2024-07-15|||Notify new docker images built for circleci (#31701)
2024-07-15|||fix: Fixed the arguments in `create_repo()` function call (#31947)
2024-07-15|||Generate: handle `logits_warper` update in models with custom generate fn (#31957)
2024-07-15|||fix: Removed a wrong key-word argument in `sigmoid_focal_loss()` function call (#31951)
2024-07-14|||Whisper: move to tensor cpu before converting to np array at decode time (#31954)
2024-07-14|||Generate: v4.42 deprecations üßπüßπ (#31956)
2024-07-14|||Generate: remove deprecated code due to `Cache` and `cache_position` being default (#31898)
2024-07-14|||Fix `GenerationMixin.generate` compatibility with pytorch profiler (#31935)
2024-07-12|||fix prompt strip to support tensors and np arrays (#27818)
2024-07-12|||Docker: TF pin on the consistency job (#31928)
2024-07-12|||[Bug Fix] fix qa pipeline tensor to numpy (#31585)
2024-07-12|||Adding hiera (#30356)
2024-07-11|||Allow `Trainer.get_optimizer_cls_and_kwargs` to be overridden (#31875)
2024-07-11|||üö® fix(SigLip): remove spurious exclusion of first vision output token (#30952)
2024-07-11|||Generate: fix `SlidingWindowCache.reset()` (#31917)
2024-07-11|||Refactor flash attention implementation in transformers (#31446)
2024-07-11|||Fix fx tests with inputs_embeds (#31862)
2024-07-11|||Add warning message for beta and gamma parameters (#31654)
2024-07-11|||add gather_use_object arguments II (#31799)
2024-07-11|||fix: Fixed the `1st argument` name in classmethods (#31907)
2024-07-11|||Fix missing methods for Fuyu (#31880)
2024-07-11|||[`Gemma2`] Support FA2 softcapping (#31887)
2024-07-11|||[`ConvertSlow`] make sure the order is preserved for addedtokens (#31902)
2024-07-11|||Processor accepts any kwargs (#31889)
2024-07-11|||Fixes to alternating SWA layers in Gemma2 (#31775)
2024-07-11|||InstructBlipVideo: Update docstring (#31886)
2024-07-11|||Add a condition for nested_detach (#31855)
2024-07-10|||Modify `warnings` in a `with` block to  avoid flaky tests (#31893)
2024-07-10|||[RT-DETR] Add resources (#31815)
2024-07-10|||Push sharded checkpoint to hub when `push_to_hub=True` in `TrainingArguments` (#31808)
2024-07-10|||fix: Removed `duplicate` field definitions in some classes (#31888)
2024-07-10|||Fix failed tests in #31851 (#31879)
2024-07-10|||Fix file type checks in data splits for contrastive training example script (#31720)
2024-07-10|||remove duplicate words in msg (#31876)
2024-07-10|||Add conversion for interleave llava (#31858)
2024-07-09|||add warning when using gradient_checkpointing with FSDP full shard (#31578)
2024-07-09|||Bump certifi from 2023.7.22 to 2024.7.4 in /examples/research_projects/visual_bert (#31872)
2024-07-09|||Revert "Fix `_init_weights` for `ResNetPreTrainedModel`" (#31868)
2024-07-09|||Add return type annotation to PreTrainedModel.from_pretrained (#31869)
2024-07-09|||Bump zipp from 3.7.0 to 3.19.1 in /examples/research_projects/decision_transformer (#31871)
2024-07-09|||Update depth estimation task guide (#31860)
2024-07-09|||Fix `_init_weights` for `ResNetPreTrainedModel` (#31851)
2024-07-09|||Generate: Add new decoding strategy "DoLa" in `.generate()` (#29619)
2024-07-09|||docs: typo in tf qa example (#31864)
2024-07-09|||Test loading generation config with safetensor weights (#31550)
2024-07-09|||save_pretrained: use tqdm when saving checkpoint shards from offloaded params (#31856)
2024-07-09|||chore: remove duplicate words (#31853)
2024-07-09|||[Grounding DINO] Add processor to auto mapping (#31845)
2024-07-09|||FX symbolic_trace: do not test decoder_inputs_embeds (#31840)
2024-07-09|||Deprecate `vocab_size` in other two VLMs (#31681)
2024-07-08|||Mamba & RecurrentGemma: enable strict signature (#31549)
2024-07-08|||Fix incorrect accelerator device handling for MPS in `TrainingArguments` (#31812)
2024-07-08|||Avoid failure `TFBlipModelTest::test_pipeline_image_to_text` (#31827)
2024-07-08|||transformers.fx.symbolic_trace supports inputs_embeds (#31574)
2024-07-08|||Fix typos (#31819)
2024-07-08|||Bump certifi from 2023.7.22 to 2024.7.4 in /examples/research_projects/lxmert (#31838)
2024-07-08|||Bump transformers from 4.26.1 to 4.38.0 in /examples/tensorflow/language-modeling-tpu (#31837)
2024-07-08|||Add FA2 and `sdpa` support for SigLIP (#31499)
2024-07-08|||Bump certifi from 2023.7.22 to 2024.7.4 in /examples/research_projects/decision_transformer (#31813)
2024-07-08|||Fix Seq2SeqTrainer crash when BatchEncoding data is None (#31418)
2024-07-08|||Add ZoeDepth (#30136)
2024-07-05|||Depth Anything: update conversion script for V2 (#31522)
2024-07-06|||Fix Wav2Vec2 Fairseq conversion (weight norm state dict keys) (#31714)
2024-07-05|||Fix galore lr display with schedulers (#31710)
2024-07-06|||Allow FP16 or other precision inference for Pipelines (#31342)
2024-07-05|||Repeating an important warning in the chat template docs (#31796)
2024-07-05|||Add training support for SigLIP (#31495)
2024-07-05|||Code agent: allow function persistence between steps (#31769)
2024-07-05|||Fix gemma tests (#31794)
2024-07-05|||Update CometCallback to allow reusing of the running experiment (#31366)
2024-07-05|||Exclude torch.compile time from metrics computation (#31443)
2024-07-05|||Make tensor device correct when ACCELERATE_TORCH_DEVICE is defined (#31751)
2024-07-05|||Fix serialization for offloaded model (#31727)
2024-07-04|||Fix ClapProcessor to merge feature_extractor output into the returned BatchEncoding (#31767)
2024-07-05|||Add torch_empty_cache_steps to TrainingArguments (#31546)
2024-07-04|||Fix Gemma2 types (#31779)
2024-07-04|||`pytest_num_workers=4` for some CircleCI jobs (#31764)
2024-07-03|||Fix RT-DETR weights initialization (#31724)
2024-07-03|||Fix RT-DETR cache for generate_anchors (#31671)
2024-07-03|||[fix bug] logits's shape different from label's shape in preprocess_logits_for_metrics (#31447)
2024-07-03|||Add ignore_errors=True to trainer.py rmtree in _inner_training_loop (#31668)
2024-07-03|||Gemma 2: Update slow tests (#31759)
2024-07-03|||handle (processor_class, None) returned by ModelPatterns (#31753)
2024-07-03|||Adds final answer tool for all agents (#31703)
2024-07-03|||Requires for torch.tensor before casting (#31755)
2024-07-03|||fix assisted decoding (#31401)
2024-07-02|||Fix documentation for Gemma2. (#31682)
2024-07-02|||Make tool JSON schemas consistent (#31756)
2024-07-02|||üö®üö® TextGenerationPipeline: rely on the tokenizer default kwargs (#31747)
2024-07-02|||[whisper] static kv cache (#31166)
2024-07-02|||Fix mistral ONNX export (#31696)
2024-07-02|||Move some test files (`tets/test_xxx_utils.py`) to `tests/utils` (#31730)
2024-07-02|||remove incorrect urls pointing to the llava repository (#31107)
2024-07-01|||dependencies: `keras-nlp<0.14` pin (#31684)
2024-06-28|||Add French version of run scripts tutorial (#31483)
2024-06-28|||Gemma capping is a must for big models (#31698)
2024-06-28|||add gather_use_object arguments (#31514)
2024-06-28|||Fix return_dict in encodec (#31646)
2024-06-28|||Fix Gemma2 4d attention mask (#31674)
2024-06-27|||don't zero out the attention_mask when using sliding window with flash attention (#31670)
2024-06-27|||[HybridCache] Fix `get_seq_length` method (#31661)
2024-06-27|||[docs] Llama3 (#31662)
2024-06-28|||Fix float out of range in owlvit and owlv2 when using FP16 or lower precision (#31657)
2024-06-27|||Fix post gemma merge (#31660)
2024-06-27|||v4.43.0.dev0
2024-06-27|||Add gemma 2 (#31659)
2024-06-27|||Remove deprecated config attribute in VLMs (#31655)
2024-06-27|||change anchor_image_size None for compatibility (#31640)
2024-06-27|||[QoL] Allow dtype str for torch_dtype arg of from_pretrained (#31590)
2024-06-27|||[`Llama`] Conversion: fix and simplify the script! (#31591)
2024-06-27|||Fix ONNX exports for Optimum compatible models (#31311)
2024-06-27|||Generation: past kv can be None (#31051)
2024-06-26|||Skip tests properly (#31308)
2024-06-27|||Fix dtype casting in swinv2 and swinv2sr to allow non-FP32 inference (#31589)
2024-06-26|||Generate: fix assisted generation with `past_key_values` passed as kwargs (#31644)
2024-06-26|||Fix paligemma detection inference (#31587)
2024-06-26|||Add LLaVa NeXT Video (#31252)
2024-06-26|||Fix RT-DETR inference with float16 and bfloat16 (#31639)
2024-06-26|||Llama et al. / FSDP : Fix breaking change in 4.40 for FSDP (#31161)
2024-06-26|||Update RT-DETR code snippet (#31631)
2024-06-26|||Fix llama gguf converter (#31575)
2024-06-26|||[`GPT-NeoX`] Add SDPA support (#31031)
2024-06-26|||Removed unnecessary `self.projection` call in `VivitTubeletEmbeddings` (#31632)
2024-06-26|||docs: move translations to `i18n` (#31584)
2024-06-25|||Add ViTImageProcessorFast to tests (#31424)
2024-06-25|||Improve error message for mismatched copies in code blocks  (#31535)
2024-06-25|||add preprocessing_num_workers to run_classification.py (#31586)
2024-06-25|||Add video modality for InstrucBLIP (#30182)
2024-06-25|||fix output data type of image classification (#31444)
2024-06-25|||Siglip: add `_no_split_module` (#31566)
2024-06-24|||Added version constraint on numpy for version <2.0 (#31569)
2024-06-24|||Fix is_torch_xpu_available for torch < 2.3 (#31573)
2024-06-24|||Fix doc typo in `TrainingArguments` (#31503)
2024-06-24|||Add Jinja as a requirement with the right version cutoff (#31536)
2024-06-24|||Fix bug about add_special_tokens and so on (#31496)
2024-06-24|||Fix the error caused by incorrect use of logger in pipeline (#31565)
2024-06-24|||Update git templates (#31539)
2024-06-24|||chore: fix typos (#31559)
2024-06-24|||Add implementation of `spectrogram_batch` (#27159)
2024-06-24|||Correct @is_flaky test decoration (#31480)
2024-06-23|||Update mask_generation.md (#31543)
2024-06-22|||New model support RTDETR (#29077)
2024-06-21|||Removed torch.cuda.empty_cache from train loop. (#31530)
2024-06-21|||SPLIT PR:  add user defined symbols and control symbols (#31305)
2024-06-21|||Deprecate legacy cache + use cache position (#31491)
2024-06-20|||Bump urllib3 from 1.26.18 to 1.26.19 in /examples/research_projects/lxmert (#31524)
2024-06-20|||Revive Nightly/Past CI (#31159)
2024-06-20|||unskip 2 tests in cohere (#31517)
2024-06-20|||RWKV: enable generation tests (#31490)
2024-06-20|||Fix mismatched ` in doc & other common typos (#31516)
2024-06-20|||GGUF: Fix llama 3 GGUF (#31358)
2024-06-20|||Fix a teeny-tiny typo in `tokenization_utils_base.py`'s docstring (#31510)
2024-06-19|||Add valid columns check in _remove_unused_columns method (#31466)
2024-06-19|||Consider inheritance in type checking for tensors (#31378)
2024-06-19|||Fix `wandb` integration with `SetFit` model (#30021)
2024-06-19|||Fix typo: pas_token_id (#30894)
2024-06-19|||auto-detect device when no device is passed to pipeline (#31398)
2024-06-19|||Add docs on zeroshot image classification prompt templates (#31343)
2024-06-19|||Update object_detection.md (#31488)
2024-06-19|||Mamba: add generative tests (#31478)
2024-06-19|||Docs  / AQLM: Clarify `torch.compile` support for AQLM (#31473)
2024-06-19|||[tests] rename `test_config_object` to `test_ds_config_object` (#31403)
2024-06-19|||Use self.config_tester.run_common_tests() (#31431)
2024-06-19|||Fix autocast incompatibility in RecurrentGemma (#30832)
2024-06-19|||[`GPT2`] Add SDPA support (#31172)
2024-06-18|||Update perf_train_gpu_many.md (#31451)
2024-06-18|||Give more useful `metric_for_best_model` errors (#31450)
2024-06-18|||Fix documentation typos (#31476)
2024-06-18|||Bump urllib3 from 1.26.18 to 1.26.19 in /examples/research_projects/visual_bert (#31472)
2024-06-18|||Improve `PreTrainedTokenizerFast` loading time when there are many added tokens (#31404)
2024-06-18|||Update chat template docs and bump Jinja version (#31455)
2024-06-18|||Fix single letter stop strings (#31448)
2024-06-18|||Make "tool_use" the default chat template key when tools are passed (#31429)
2024-06-18|||Donut: fix `generate` call from local path (#31470)
2024-06-18|||Bump urllib3 from 1.26.18 to 1.26.19 in /examples/research_projects/decision_transformer (#31459)
2024-06-18|||Agents: Improve python interpreter (#31409)
2024-06-18|||Fix typing errors in `Qwen2ForTokenClassification` (#31440)
2024-06-18|||simple fix (#31456)
2024-06-17|||üö® Remove dataset with restrictive license (#31452)
2024-06-17|||Pass datasets trust_remote_code (#31406)
2024-06-17|||Support multiple validation datasets when `dataloader_persistent_workers=True` (#30627)
2024-06-17|||Bump idna from 2.8 to 3.7 in /examples/research_projects/visual_bert (#30201)
2024-06-17|||[tests] make `TestDeepSpeedModelZoo` device-agnostic (#31402)
2024-06-17|||Bump idna from 2.8 to 3.7 in /examples/research_projects/lxmert (#30200)
2024-06-17|||Bump idna from 3.3 to 3.7 in /examples/research_projects/decision_transformer (#30203)
2024-06-17|||Generate: fix `tokenizer` being popped twice (#31427)
2024-06-17|||Rename misnamed image processor test files (#31430)
2024-06-17|||Fix Bark logits processors device misplacement (#31416)
2024-06-17|||Musicgen special tokens in tensors (#31420)
2024-06-14|||xpu: support xpu backend from stock pytorch (>=2.4) (#31238)
2024-06-14|||Remove empty create_and_test_config_common_properties tests (#31359)
2024-06-14|||Install the tensorflow example requirements in docker (#31428)
2024-06-14|||Remove duplicate image processor in auto map (#31383)
2024-06-14|||Change potential `inputs_embeds` padding `logger.warning` to `logger.warning_once` (#31411)
2024-06-14|||Fix SpeechT5 `decoder_attention_mask` shape (#28071)
2024-06-14|||Set seed for M4T retain grad test (#31419)
2024-06-14|||Fix MusicGen SDPA (#31208)
2024-06-14|||Pin datasets<2.20.0 for examples (#31417)
2024-06-14|||Support Clip QKV for MPT (#31307)
2024-06-13|||Temporarily pin datasets upper version to fix CI (#31407)
2024-06-13|||Add missing French translation of tutoriel_pipeline.md (#31396)
2024-06-13|||add initial design for uniform processors + align model (#31197)
2024-06-13|||Make chat templates part of ProcessorMixin (#30744)
2024-06-13|||[QoL fix] [Image processing] Add warning on assumption of channel dim and avoid infering when inputs are PIL.Image (#31364)
2024-06-12|||feat(ci): add trufflehog secrets detection (#31344)
2024-06-12|||Change JSON serialization to custom json.dumps (#31100)
2024-06-12|||Bump jupyter-core from 4.6.3 to 4.11.2 in /examples/research_projects/visual_bert (#31386)
2024-06-12|||Use huggingface_hub helper function to split state dict (#31091)
2024-06-12|||Update comment in modeling_utils.py (#31299)
2024-06-12|||README underline between badges fix  (#31376)
2024-06-12|||backbone_utils - fix relative import (#31382)
2024-06-12|||docs: fix broken link (#31370)
2024-06-12|||[Bug Fix] Renamed loss to losses to suppress UnboundLocalError (#31365)
2024-06-12|||Fix idefics cache (#31377)
2024-06-12|||Add support to declare imports for code agent (#31355)
2024-06-11|||Add french translation of AutoBackbone (#31300)
2024-06-11|||Fast image processor (#28847)
2024-06-11|||Chat Template support for function calling and RAG (#30621)
2024-06-11|||Bump jupyter-core from 4.6.3 to 4.11.2 in /examples/research_projects/lxmert (#31360)
2024-06-11|||Fix gradio tool demos (#31230)
2024-06-10|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/pplm (#31352)
2024-06-10|||Bump tornado from 6.3.3 to 6.4.1 in /examples/research_projects/lxmert (#31353)
2024-06-10|||üö® FLAVA: Remove double softmax (#31322)
2024-06-10|||Fix Cohere CI (#31263)
2024-06-10|||Improve error msg when using bitsandbytes (#31350)
2024-06-10|||Decorators for deprecation and named arguments validation (#30799)
2024-06-10|||docs/zh: fix style (#31334)
2024-06-10|||Fix paligemma inverted mask (#31207)
2024-06-10|||docs: fix style (#31340)
2024-06-10|||Use unused prepare_img() function in dinov2 conversion script (#31335)
2024-06-07|||Rename test_model_common_attributes -> test_model_get_set_embeddings (#31321)
2024-06-07|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/adversarial (#31320)
2024-06-07|||interpolation added for TVP. (#30863)
2024-06-07|||Bump pillow from 10.2.0 to 10.3.0 in /examples/research_projects/decision_transformer (#31319)
2024-06-07|||Remove ConversationalPipeline and Conversation object (#31165)
2024-06-07|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/bert-loses-patience (#31291)
2024-06-07|||Bump aiohttp from 3.9.0 to 3.9.4 in /examples/research_projects/decision_transformer (#31317)
2024-06-07|||Bump tornado from 6.3.3 to 6.4.1 in /examples/research_projects/visual_bert (#31298)
2024-06-07|||Implement JSON dump conversion for torch_dtype in TrainingArguments (#31224)
2024-06-07|||Extend save_pretrained to offloaded models (#27412)
2024-06-07|||Fix jetmoe model (#31279)
2024-06-07|||Fixed Wav2Vec2ProcessorWithLM decoding error (#31188)
2024-06-06|||Enable HF pretrained backbones (#31145)
2024-06-07|||Update text-to-speech.md (#31269)
2024-06-06|||Fix SwinLayer / DonutSwinLayer / ClapAudioLayer attention mask device (#31295)
2024-06-06|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/bertabs (#31290)
2024-06-06|||Pipeline VQA: Add support for list of images and questions as pipeline input (#31217)
2024-06-06|||Bump transformers from 4.19.0 to 4.38.0 in /examples/research_projects/codeparrot (#31285)
2024-06-06|||Mark MobileNetV1ModelTest::test_batching_equivalence as flaky (#31258)
2024-06-06|||Enable dynamic resolution input for Beit (#31053)
2024-06-06|||fix accelerate tests for roberta xl (#31288)
2024-06-06|||Fix _save_tpu: use _maybe_convert_to_cpu instead of to cpu. (#31264)
2024-06-06|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/bertology (#31256)
2024-06-06|||fix: `str` should be used not `int` when setting env variables (#31272)
2024-06-06|||Switch from `cached_download` to `hf_hub_download` in remaining occurrences (#31284)
2024-06-06|||Generation: fix handling of special tokens (#31254)
2024-06-06|||Make mamba use cache (#31116)
2024-06-06|||fix loading special_tokens_map_file (#31012)
2024-06-06|||[`SwitchTransformer`] Significant performance improvement on MoE blocks (#31173)
2024-06-06|||no need for explicit EXTRA_TOKENS in processing_paligemma.py (#31022)
2024-06-05|||Skip failing JetMOE generation tests (#31266)
2024-06-05|||Reduce by 2 the memory requirement in `generate()` üî•üî•üî• (#30536)
2024-06-05|||Add condition to `benchmark` job in `push-important-models.yml` (#31259)
2024-06-05|||Fix circular reference issue in CLIPTokenizerFast (#31075)
2024-06-05|||Add missing Flaubert tokenizer tests (#30492)
2024-06-05|||enable deterministic mode for npu (#31253)
2024-06-05|||doc: add info about wav2vec2 bert in older wav2vec2 models. (#31120)
2024-06-05|||Bump transformers from 3.5.1 to 4.38.0 in /examples/research_projects/deebert (#31244)
2024-06-05|||Early labels validation (#31240)
2024-06-05|||Benchmark GitHub Actions workflow (#31163)
2024-06-04|||Fixing `name 'torch' is not defined` in `bitsandbytes` integration (#31243)
2024-06-05|||Specify dtype=torch.bool to avoid xla error (#31191)
2024-06-04|||Bump transformers from 4.26.0 to 4.38.0 in /examples/research_projects/vqgan-clip (#31242)
2024-06-04|||Upload (daily) CI results to Hub (#31168)
2024-06-04|||Move out common backbone config param validation (#31144)
2024-06-04|||Blip: Deprecate `BlipModel` (#31235)
2024-06-04|||Fix `MistralIntegrationTest` (#31231)
2024-06-04|||add no split modules for xlmrobertaxl (#31223)
2024-06-04|||Add new line switch before logging ***** Running {description} ***** (#31225)
2024-06-04|||Fix pipeline tests - torch imports (#31227)
2024-06-04|||fix bf16 issue in text classification pipeline (#30996)
2024-06-04|||Add dynamic resolution input/interpolate position embedding to deit (#31131)
2024-06-04|||Video-LLaVa: handle any number of frames (#31221)
2024-06-04|||fix(PatchTST): Wrong dropout used for PretainHead (#31117)
2024-06-04|||Fix sentence fragment within test comments (#31218)
2024-06-04|||Pass device in Logits Processor's init (#29804)
2024-06-03|||[docs] Spanish translation of tokenizer_summary.md (#31154)
2024-06-03|||Fix GPU OOM for `mistral.py::Mask4DTestHard` (#31212)
2024-06-03|||Set greater_is_better to False if metric_for_best_model ends with "loss" (#31142)
2024-06-03|||Cohere: Fix copied from (#31213)
2024-06-03|||Wrong translation FR : Contents = Contenu (#31186)
2024-06-03|||Rename sanity_evaluation to eval_on_start (#31192)
2024-06-03|||Fix typo in utils (#31169)
2024-06-04|||fix the get_size_with_aspect_ratio in max_size situation (#30902)
2024-06-03|||Add Qwen2 GGUF loading support (#31175)
2024-06-03|||Fix `test_compile_static_cache` (#30991)
2024-06-03|||üö® [Mistral and friends] Update MLP (#31057)
2024-06-03|||SlidingWindowCache: reduce differences to other Cache classes (#30970)
2024-06-03|||Ignore non-causal mask in more cases with SDPA (#30138)
2024-06-03|||Fix Cannot convert [array()] to EagerTensor of dtype int64 (#31109)
2024-06-03|||[`GemmaModel`] fix small typo (#31202)
2024-06-03|||Token healing (#30081)
2024-06-03|||Remove copied froms for deprecated models (#31153)
2024-06-03|||Fix typo: use_safetenstors to use_safetensors (#31184)
2024-05-31|||Diff converter v2 (#30868)
2024-05-31|||Added description of quantization_config (#31133)
2024-05-31|||Instance segmentation examples (#31084)
2024-05-31|||Add streaming, various fixes (#30838)
2024-05-31|||[trainer] add sanity evaluation option  (#31146)
2024-05-31|||Quantization: Enhance bnb error message (#31160)
2024-05-31|||Update sam.md (#31130)
2024-05-31|||Fix quantized cache output (#31143)
2024-05-31|||pytest -rsfE (#31140)
2024-05-31|||helper (#31152)
2024-05-30|||Workflow: Remove `IS_GITHUB_CI` (#31147)
2024-05-30|||Docs / Quantization: Replace all occurences of `load_in_8bit` with bnb config (#31136)
2024-05-30|||fix get_scheduler when name is warmup_stable_decay (#31128)
2024-05-30|||FIX / Quantization: Add extra validation for bnb config (#31135)
2024-05-29|||Cleanup docker build (#31119)
2024-05-29|||Add on_optimizer_step to callback options (#31095)
2024-05-29|||Add VLM generation default contributor (#31115)
2024-05-29|||FIX / Docs: Fix GPTQ expected number of bits (#31111)
2024-05-29|||Fix nightly circleci (#31114)
2024-05-29|||Rm maintainer + migrate (#31089)
2024-05-29|||Fix faulty rstrip in module loading (#31108)
2024-05-29|||Fix env.py in cases where torch is not present (#31113)
2024-05-29|||Improve `transformers-cli env` reporting (#31003)
2024-05-29|||Use `HF_HUB_OFFLINE` + fix has_file in offline mode (#31016)
2024-05-29|||FEAT: Add mistral v3 conversion script (#30981)
2024-05-29|||Quantized KV cache: update quanto (#31052)
2024-05-28|||Deprecate low use models (#30781)
2024-05-28|||Docs / Quantization: Redirect deleted page (#31063)
2024-05-28|||TST: Fix instruct-blip tests (#31088)
2024-05-28|||Fix DeepSpeed compatibility with weight_norm (#30881) (#31018)
2024-05-28|||Fix PretrainedConfig docstring with deprecated resume_download (#31014)
2024-05-28|||skip `test_multi_gpu_data_parallel_forward` for `vit` and `deit` (#31086)
2024-05-28|||FIX / OPT: Fix OPT multi-GPU training for `OPTForQuestionAnswering` (#31092)
2024-05-28|||FIX: Add `accelerate` as a hard requirement (#31090)
2024-05-28|||Render chat template tojson filter as unicode (#31041)
2024-05-28|||Docs / PEFT: Add PEFT API documentation (#31078)
2024-05-28|||Watermark: fix tests (#30961)
2024-05-28|||Fix failing tokenizer tests (#31083)
2024-05-28|||[SuperPoint, PaliGemma] Update docs (#31025)
2024-05-28|||Fix typo in trainer.py (#31048)
2024-05-28|||Fix OWLv2 post_process_object_detection for multiple images (#31082)
2024-05-28|||Remove float64 cast for OwlVit and OwlV2 to support MPS device (#31071)
2024-05-28|||fix from_pretrained in offline mode when model is preloaded in cache (#31010)
2024-05-28|||Remove redundant backend checks in training_args.py (#30999)
2024-05-28|||Update quicktour.md to fix broken link to Glossary (#31072)
2024-05-28|||fix "piano" typo (#31027)
2024-05-28|||Remove `ninja` from docker image build (#31080)
2024-05-28|||use `@main` (#31065)
2024-05-27|||skip `test_model_parallelism` for 2 model test classes (#31067)
2024-05-27|||Fix pad_to_max_length Whisper (#30787)
2024-05-27|||Fix quanto tests (#31062)
2024-05-27|||Update feature request label in template (#30940)
2024-05-27|||Follow up: Fix link in dbrx.md (#30514)
2024-05-27|||unpin uv (#31055)
2024-05-27|||Redirect transformers_agents doc to agents (#31054)
2024-05-24|||Paligemma- fix devices and dtype assignments (#31008)
2024-05-24|||Add split special tokens (#30772)
2024-05-24|||added interpolation for vitmae model in pytorch as well as tf. (#30732)
2024-05-24|||save the list of new model failures (#31013)
2024-05-24|||Quantization / TST: Fix remaining quantization tests (#31000)
2024-05-24|||Fix resume_download future warning (#31007)
2024-05-24|||allow multi-gpu (#31011)
2024-05-24|||FIX / TST: Fix expected results on Mistral AWQ test  (#30971)
2024-05-24|||[tests] make `test_model_parallelism` device-agnostic   (#30844)
2024-05-24|||Perceiver interpolate position embedding (#30979)
2024-05-24|||pin `uv==0.1.45` (#31006)
2024-05-24|||Do not trigger autoconversion if local_files_only (#31004)
2024-05-24|||Fix training speed regression introduced by "optimize VRAM for calculating pos_bias in LayoutLM v2, v3 (#26139)" (#30988)
2024-05-24|||add prefix space ignored in llama #29625 (#30964)
2024-05-23|||Bugfix: WandbCallback uploads initial model checkpoint (#30897)
2024-05-23|||Remove deprecated properties in tokenization_nllb.py and tokenization_nllb_fast.py (#29834)
2024-05-23|||[Port] TensorFlow implementation of Mistral (#29708)
2024-05-23|||Update 4 `MptIntegrationTests` expected outputs (#30989)
2024-05-23|||Add a check that warmup_setps is either 0 or >= 1 (#30764)
2024-05-23|||[tests] add `torch.use_deterministic_algorithms` for XPU (#30774)
2024-05-23|||Fix accelerate failing tests (#30836)
2024-05-23|||FIX / Docs: Minor changes in quantization docs (#30985)
2024-05-23|||Finish adding support for torch.compile dynamic shapes (#30919)
2024-05-23|||test_custom_4d_attention_mask skip with sliding window attn (#30833)
2024-05-23|||Docs / Quantization: refactor quantization documentation (#30942)
2024-05-23|||Quantized KV Cache (#30483)
2024-05-23|||Bump requests from 2.31.0 to 2.32.2 in /examples/research_projects/visual_bert (#30983)
2024-05-23|||Push ci image (#30982)
2024-05-23|||Using assistant in AutomaticSpeechRecognitionPipeline with different encoder size (#30637)
2024-05-22|||Update object detection with latest resize and pad strategies (#30955)
2024-05-22|||Paligemma causal attention mask (#30967)
2024-05-22|||Fix link in Pipeline documentation (#30948)
2024-05-22|||[Whisper] Strip prompt before finding common subsequence (#27836)
2024-05-22|||Generation: get special tokens from model config (#30899)
2024-05-22|||legacy to init the slow tokenizer when converting from slow was wrong (#30972)
2024-05-22|||Finally fix the missing new model failure CI report (#30968)
2024-05-22|||üö® out_indices always a list (#30941)
2024-05-22|||Paligemma - fix slow tests, add bf16 and f16 slow tests (#30851)
2024-05-22|||[whisper] only trigger forced ids warning once (#30966)
2024-05-22|||Avoid extra chunk in speech recognition (#29539)
2024-05-22|||[doc] Add references to the fine-tuning blog and distil-whisper to Whisper. (#30938)
2024-05-22|||Fix low cpu mem usage tests (#30808)
2024-05-22|||Update video-llava docs (#30935)
2024-05-22|||Bump requests from 2.31.0 to 2.32.2 in /examples/research_projects/lxmert (#30956)
2024-05-22|||Update build ci image [push-ci-image] (#30933)
2024-05-22|||update ruff version (#30932)
2024-05-21|||üö® [Idefics2] Update ignore index (#30898)
2024-05-22|||Fix inhomogeneous shape error in example (#30434)
2024-05-21|||Fix swin embeddings interpolation (#30936)
2024-05-21|||TST / Workflows: Get slack notifications for docker image build (#30891)
2024-05-21|||[Benchmark] Reuse `optimum-benchmark` (#30615)
2024-05-21|||fix: center_crop occasionally outputs off-by-one dimension matrix (#30934)
2024-05-21|||Enforce saving at end of training if saving option chosen (#30160)
2024-05-21|||CI:  AMD MI300 tests fix (#30797)
2024-05-21|||PaliGemma - fix processor with no input text (#30916)
2024-05-21|||Bump requests from 2.31.0 to 2.32.0 in /examples/research_projects/decision_transformer (#30925)
2024-05-21|||FEAT / Trainer: LOMO optimizer support (#30178)
2024-05-21|||FIX / TST: Fix expected results on Mistral slow test (A10) (#30909)
2024-05-20|||[docs] Spanish translation of model_memory_anatomy.md (#30885)
2024-05-20|||Add torch.compile for Mistral (#30642)
2024-05-20|||Introduce configured_state arg for accelerator_config (#29781)
2024-05-20|||`tokenizer_class = "AutoTokenizer"` Llava Family (#30912)
2024-05-20|||Fix a shape annotation and typos in `mamba` slow forward (#30691)
2024-05-20|||Add AutoFeatureExtractor support to Wav2Vec2ProcessorWithLM (#28706)
2024-05-20|||fix for custom pipeline configuration  (#29004)
2024-05-20|||separate kwargs in processor (similar to #30193) (#30905)
2024-05-20|||Fix num_hidden_layers in initialization of new model in Mamba (#30403)
2024-05-20|||add return_token_timestamps to WhisperProcessor (#30812)
2024-05-20|||DeformableDETR two stage support bfloat16  (#30907)
2024-05-20|||LLaVa-Next: Update docs with batched inference (#30857)
2024-05-20|||Add support for torch.compile dynamic shapes (#30560)
2024-05-20|||FIX / Quantization: Fix Dockerfile build (#30890)
2024-05-20|||Add TokenClassification for Mistral, Mixtral and Qwen2 (#29878)
2024-05-17|||Enable dynamic resolution input for Swin Transformer and variants (#30656)
2024-05-17|||v4.42.dev.0
2024-05-17|||Add fixed resize and pad strategy for object detection (#30742)
2024-05-17|||update release script (#30880)
2024-05-17|||Support arbitrary processor (#30875)
2024-05-17|||[whisper] fix multilingual fine-tuning (#30865)
2024-05-17|||Fix dependencies for image classification example (#30842)
2024-05-17|||Enable device map (#30870)
2024-05-17|||Remove deprecated logic and warnings (#30743)
2024-05-17|||TEST: Add llama logits tests (#30835)
2024-05-16|||Fix VideoLlava imports (#30867)
2024-05-16|||TST / Quantization: Reverting to torch==2.2.1 (#30866)
2024-05-16|||Docs: update example with assisted generation + sample (#30853)
2024-05-16|||Video-LLaVa: Fix docs (#30855)
2024-05-16|||Make `Gemma` work with `torch.compile` (#30775)
2024-05-16|||Disable the FA backend for SDPA on AMD GPUs (#30850)
2024-05-16|||Cache: add new flag to distinguish models that `Cache` but not static cache (#30800)
2024-05-16|||[Idefics2] Improve docs, add resources (#30717)
2024-05-16|||add sdpa to ViT [follow up of #29325] (#30555)
2024-05-16|||[LLaVa-NeXT] Small fixes (#30841)
2024-05-15|||Fix llama model sdpa attention forward function masking bug when output_attentions=True (#30652)
2024-05-15|||Use `torch 2.3` for CI (#30837)
2024-05-15|||FEAT / Bitsandbytes: Add `dequantize` API for bitsandbytes quantized models (#30806)
2024-05-15|||Deprecate models script - correctly set the model name for the doc file (#30785)
2024-05-15|||Better llava next. (#29850)
2024-05-15|||Update ds_config_zero3.json (#30829)
2024-05-15|||Missing `Optional` in typing. (#30821)
2024-05-15|||Jamba - Skip 4d custom attention mask test (#30826)
2024-05-15|||Loading GGUF files support (#30391)
2024-05-15|||Add Video Llava  (#29733)
2024-05-15|||Remove unused module DETR based models (#30823)
2024-05-15|||Support mixed-language batches in `WhisperGenerationMixin` (#29688)
2024-05-14|||Add missing dependencies in image classification example (#30820)
2024-05-14|||Add support for custom checkpoints in MusicGen (#30011)
2024-05-14|||Add PaliGemma (#30814)
2024-05-14|||Added the necessay import of module (#30804)
2024-05-14|||Add JetMoE model (#30005)
2024-05-14|||[T5] Adding `model_parallel = False` to `T5ForTokenClassification` and `MT5ForTokenClassification` (#30763)
2024-05-14|||Deprecate TF weight conversion since we have full Safetensors support now (#30786)
2024-05-14|||CI: more models wo cache support (#30780)
2024-05-14|||Add Watermarking LogitsProcessor and WatermarkDetector (#29676)
2024-05-14|||PEFT: Access active_adapters as a property in Trainer (#30790)
2024-05-14|||Fix cache type in Idefics2 (#30729)
2024-05-13|||Fix OWLv2 Doc (#30794)
2024-05-13|||CI: update to ROCm 6.0.2 and test MI300 (#30266)
2024-05-13|||skip low_cpu_mem_usage tests (#30782)
2024-05-13|||Deprecate models script (#30184)
2024-05-13|||Save other CI jobs' result (torch/tf pipeline, example, deepspeed etc) (#30699)
2024-05-13|||Generate: assistant should be greedy in assisted decoding (#30778)
2024-05-13|||Port IDEFICS to tensorflow (#26870)
2024-05-13|||Generate: remove near-duplicate sample/greedy copy (#30773)
2024-05-13|||[Object detection pipeline] Lower threshold (#30710)
2024-05-13|||enable Pipeline to get device from model  (#30534)
2024-05-13|||Qwen: incorrect setup flag (#30776)
2024-05-13|||Generation / FIX: Fix multi-device generation (#30746)
2024-05-13|||Llama: fix custom 4D masks, v2 (#30348)
2024-05-13|||[GroundingDino] Adding ms_deform_attn kernels (#30768)
2024-05-13|||Support for Falcon2-11B (#30771)
2024-05-13|||Blip dynamic input resolution (#30722)
2024-05-13|||Workflow: Replace `actions/post-slack` with centrally defined workflow (#30737)
2024-05-13|||[awq] replace scale when we have GELU (#30074)
2024-05-10|||hqq - fix weight check in check_quantized_param (#30748)
2024-05-10|||[docs] Update link in es/pipeline_webserver.md (#30745)
2024-05-10|||PEFT / Trainer: Make use of `model.active_adapters()` instead of deprecated `model.active_adapter` whenever possible (#30738)
2024-05-10|||mlp_only_layers is more flexible than decoder_sparse_step (#30552)
2024-05-10|||Update llama3.md, fix typo (#30739)
2024-05-09|||[docs] Update es/pipeline_tutorial.md (#30684)
2024-05-09|||Update CodeLlama references (#30218)
2024-05-09|||Generate: consistently handle special tokens as tensors (#30624)
2024-05-09|||KV cache is no longer a model attribute (#30730)
2024-05-09|||Fix image post-processing for OWLv2 (#30686)
2024-05-09|||Generate: add `min_p` sampling (#30639)
2024-05-09|||Removal of deprecated maps (#30576)
2024-05-09|||Enable dynamic resolution for vivit (#30630)
2024-05-09|||Add dynamic resolution input/interpolate position embedding to SigLIP (#30719)
2024-05-08|||Cache: models return input cache type (#30716)
2024-05-08|||Immutability for data collators (#30603)
2024-05-08|||Update object detection guide (#30683)
2024-05-08|||Add installation of examples requirements in CI (#30708)
2024-05-08|||Llava: remove dummy labels (#30706)
2024-05-08|||[BitsandBytes] Verify if GPU is available (#30533)
2024-05-08|||Add examples for detection models finetuning (#30422)
2024-05-08|||Patch CLIP image preprocessor (#30698)
2024-05-07|||Pin deepspeed (#30701)
2024-05-07|||Add safetensors to model not found error msg for default use_safetensors value (#30602)
2024-05-07|||Rename artifact name `prev_ci_results` to `ci_results` (#30697)
2024-05-07|||Update `workflow_id` in `utils/get_previous_daily_ci.py` (#30695)
2024-05-07|||Separate tokenizer tests (#30675)
2024-05-07|||Bump tqdm from 4.48.2 to 4.66.3 in /examples/research_projects/lxmert (#30644)
2024-05-07|||Reboot Agents (#30387)
2024-05-07|||Bump tqdm from 4.48.2 to 4.66.3 in /examples/research_projects/visual_bert (#30645)
2024-05-07|||Bump tqdm from 4.63.0 to 4.66.3 in /examples/research_projects/decision_transformer (#30646)
2024-05-07|||Updated docs of `forward` in `Idefics2ForConditionalGeneration` with correct `ignore_index` value (#30678)
2024-05-07|||Word-level timestamps broken for short-form audio (#30325)
2024-05-07|||Fix `cache_position` initialisation for generation with `use_cache=False` (#30485)
2024-05-07|||Adding _tie_weights() to prediction heads to support low_cpu_mem_usage=True (#29024)
2024-05-07|||Bump werkzeug from 3.0.1 to 3.0.3 in /examples/research_projects/decision_transformer (#30679)
2024-05-07|||Bump jinja2 from 3.1.3 to 3.1.4 in /examples/research_projects/decision_transformer (#30680)
2024-05-07|||top-k instead of top-p in MixtralConfig docstring (#30687)
2024-05-06|||Respect `resume_download` deprecation  (#30620)
2024-05-06|||Fix typo: llama3.md (#30653)
2024-05-06|||Trainer - add cache clearing and the option for batched eval metrics computation (#28769)
2024-05-06|||Trainer._load_from_checkpoint - support loading multiple Peft adapters (#30505)
2024-05-06|||Fix llava next tie_word_embeddings config  (#30640)
2024-05-06|||Quantization / HQQ: Fix HQQ tests on our runner (#30668)
2024-05-06|||Hotfix-change-ci (#30669)
2024-05-06|||Check if the current compiled version of pytorch supports MPS (#30664)
2024-05-06|||[`CI update`] Try to use dockers and no cache (#29202)
2024-05-03|||Avoid duplication in PR slow CI model list (#30634)
2024-05-03|||Prevent `TextGenerationPipeline._sanitize_parameters` from overriding previously provided parameters (#30362)
2024-05-03|||HQQ: PEFT support for HQQ (#30632)
2024-05-03|||Fix W&B run name (#30462)
2024-05-03|||add mlp bias for llama models (#30031)
2024-05-03|||Fix CI after #30410 (#30612)
2024-05-02|||Add HQQ quantization support (#29637)
2024-05-03|||Output `None` as attention when layer is skipped (#30597)
2024-05-02|||Fix FX tracing issues for Llama (#30619)
2024-05-02|||Generate: fix `SinkCache` on Llama models (#30581)
2024-05-02|||Docs: add missing `StoppingCriteria` autodocs (#30617)
2024-05-02|||Docs: fix `generate`-related rendering issues (#30600)
2024-05-02|||phi3 chat_template does not support system role (#30606)
2024-05-02|||Use `contiguous()` in clip checkpoint conversion script (#30613)
2024-05-02|||fix:missing `output_router_logits` in SwitchTransformers (#30573)
2024-05-02|||Fix copies for DBRX - neuron fix (#30610)
2024-05-02|||üö® Update image_processing_vitmatte.py (#30566)
2024-05-02|||Fix memory leak with CTC training script on Chinese languages (#30358)
2024-05-02|||Fix for Neuron (#30259)
2024-05-02|||Fix: failing CI after #30568 (#30599)
2024-05-01|||Bump torch from 1.9.0+cpu to 1.13.1 in /examples/flax/vision (#21168)
2024-05-01|||Bump pillow from 10.0.1 to 10.2.0 in /examples/research_projects/decision_transformer (#28655)
2024-05-01|||Bump torch from 1.9.0+cpu to 1.13.1 in /examples/research_projects/jax-projects/hybrid_clip (#21167)
2024-05-01|||Bump torch from 1.11.0 to 1.13.1 in /examples/research_projects/decision_transformer (#21171)
2024-05-01|||Fix llava half precision and autocast issues (#29721)
2024-05-01|||Generate: remove deprecated public decoding functions and streamline logic üßº  (#29956)
2024-05-01|||Improve object detection task guideline (#29967)
2024-05-01|||Fix image segmentation example - don't reopen image (#30481)
2024-05-01|||Bump torch from 1.6.0 to 1.13.1 in /examples/research_projects/visual_bert (#21172)
2024-05-01|||Bump torch from 1.11.0 to 1.13.1 in /examples/research_projects/codeparrot (#21170)
2024-05-01|||Bump torch from 1.6.0 to 1.13.1 in /examples/research_projects/lxmert (#21174)
2024-05-01|||Bump pyarrow from 1.0.1 to 15.0.0 in /examples/research_projects/lxmert (#30584)
2024-05-01|||Bump pyarrow from 1.0.1 to 15.0.0 in /examples/research_projects/visual_bert (#30583)
2024-05-01|||Bump pyarrow from 7.0.0 to 15.0.0 in /examples/research_projects/decision_transformer (#30582)
2024-05-01|||Bump gitpython from 3.1.32 to 3.1.41 in /examples/research_projects/distillation (#30586)
2024-05-01|||Bump grpcio from 1.44.0 to 1.53.2 in /examples/research_projects/decision_transformer (#30585)
2024-05-01|||Bump gitpython from 3.1.32 to 3.1.41 in /examples/research_projects/decision_transformer (#30587)
2024-05-01|||Gemma: update activation warning (#29995)
2024-05-01|||Fix canonical model --model_type in examples (#30480)
2024-05-01|||remove jax example (#30498)
2024-05-01|||Fix QA example (#30580)
2024-05-01|||Refactor default chat template warnings (#30551)
2024-05-01|||Fix Marian model conversion (#30173)
2024-05-01|||Encoder-decoder models: move embedding scale to nn.Module (#30410)
2024-05-01|||Use text config's vocab size in testing models (#30568)
2024-04-30|||Remove `use_square_size` after loading (#30567)
2024-04-30|||General PR slow CI (#30540)
2024-05-01|||Fix generation doctests (#30263)
2024-04-30|||Add chat templating support for KeyDataset in text-generation pipeline (#30558)
2024-05-01|||BlipModel: get_multimodal_features method (#30438)
2024-04-30|||Fix seq2seq collator padding (#30556)
2024-04-30|||DBRX: make fixup (#30578)
2024-04-30|||Generate: update links on LLM tutorial doc (#30550)
2024-04-30|||Cache: Static cache as a standalone object (#30476)
2024-04-30|||Enable multi-device for more models (#30409)
2024-04-30|||Pass `use_cache` in kwargs for GPTNeoX (#30538)
2024-04-29|||Include safetensors as part of `_load_best_model` (#30553)
2024-04-29|||Reenable SDPA's FA2 During Training with torch.compile (#30442)
2024-04-29|||Fix repo. fetch/checkout in PR slow CI job (#30537)
2024-04-29|||Update runner tag for PR slow CI (#30535)
2024-04-29|||Fix broken link to Transformers notebooks (#30512)
2024-04-29|||Pass attn_implementation when using AutoXXX.from_config (#30507)
2024-04-29|||Allow boolean FSDP options in fsdp_config (#30439)
2024-04-26|||Fix link in dbrx.md (#30509)
2024-04-26|||[SegGPT] Fix seggpt image processor (#29550)
2024-04-26|||load_image - decode b64encode and encodebytes strings (#30192)
2024-04-26|||Fix GroundingDINO, DPR after BERT SDPA update (#30506)
2024-04-26|||[examples] update whisper fine-tuning (#29938)
2024-04-26|||[`DETR`] Remove timm hardcoded logic in modeling files (#29038)
2024-04-26|||Remove skipping logic now that set_epoch exists (#30501)
2024-04-26|||[`BERT`] Add support for sdpa (#28802)
2024-04-26|||Use the Keras set_random_seed in tests (#30504)
2024-04-26|||Update `dtype_byte_size` to handle torch.float8_e4m3fn/float8_e5m2 types (#30488)
2024-04-26|||Fix the `bitsandbytes` error formatting ("Some modules are dispatched on ...") (#30494)
2024-04-26|||FEAT: PEFT support for EETQ (#30449)
2024-04-25|||[docs] Spanish translation of pipeline_tutorial.md (#30252)
2024-04-25|||Quantization: `HfQuantizer` quant method update (#30484)
2024-04-25|||Add sidebar tutorial for chat models (#30401)
2024-04-26|||Do not use deprecated `SourceFileLoader.load_module()` in dynamic module loading (#30370)
2024-04-25|||Fix Llava for 0-embeddings (#30473)
2024-04-25|||Introduce Stateful Callbacks (#29666)
2024-04-25|||Make accelerate install non-torch dependent (#30463)
2024-04-25||| Fix Issue #29817 Video Classification Task Guide Using Undeclared Variables (#30457)
2024-04-25|||Add WSD scheduler (#30231)
2024-04-25|||üö® Add training compatibility for Musicgen-like models (#29802)
2024-04-25|||Prevent crash with `WandbCallback` with third parties (#30477)
2024-04-25|||Don't run fp16 MusicGen tests on CPU (#30466)
2024-04-25|||Fix SigLip classification doctest (#30475)
2024-04-25|||Script for finding candidate models for deprecation (#29686)
2024-04-25|||[fix codellama conversion]  (#30472)
2024-04-25|||FIX / Workflow: Fix SSH workflow bug (#30474)
2024-04-25|||FIX / Workflow: Change tailscale trigger condition (#30471)
2024-04-25|||Workflow / ENH: Add SSH into our runners workflow (#30425)
2024-04-24|||consistent job / pytest report / artifact name correspondence (#30392)
2024-04-24|||Non blocking support to torch DL's (#30465)
2024-04-24|||Enable fp16 on CPU (#30459)
2024-04-24|||Neuron: When save_safetensor=False, no need to move model to CPU (#29703)
2024-04-24|||[`research_project`] Most of the security issues come from this requirement.txt (#29977)
2024-04-24|||Fix wrong indent in `utils/check_if_new_model_added.py` (#30456)
2024-04-24|||Phi-3 (#30423)
2024-04-24|||Add `paths` filter to avoid the chance of being triggered (#30453)
2024-04-24|||[SegGPT] Fix loss calculation (#30421)
2024-04-24|||fix jamba slow foward for multi-gpu (#30418)
2024-04-24|||fix uncaught init of linear layer in clip's/siglip's for image classification models (#30435)
2024-04-24|||[tests] make test device-agnostic (#30444)
2024-04-24|||[`Llava`] + CIs fix red cis and llava integration tests (#30440)
2024-04-24|||Fix YOLOS image processor resizing (#30436)
2024-04-24|||Add llama3 (#30334)
2024-04-24|||New model PR needs green (slow tests) CI (#30341)
2024-04-24|||Remove mentions of models in the READMEs and link to the documentation page in which they are featured. (#30420)
2024-04-24|||Remove add-new-model in favor of add-new-model-like (#30424)
2024-04-24|||Remove task guides auto-update in favor of links towards task pages (#30429)
2024-04-23|||[`LlamaTokenizerFast`] Refactor default llama (#28881)
2024-04-23|||Fix use_cache for xla fsdp (#30353)
2024-04-23|||Rename torch.run to torchrun (#30405)
2024-04-23|||Remove old TF port docs (#30426)
2024-04-23|||Fix LayoutLMv2 init issue and doctest (#30278)
2024-04-23|||FIX: re-add bnb on docker image (#30427)
2024-04-23|||Make EosTokenCriteria compatible with mps (#30376)
2024-04-23|||fix for itemsize => element_size() for torch backwards compat (#30133)
2024-04-23|||Fix on "cache position" for assisted generation (#30068)
2024-04-23|||Jax: scipy version pin (#30402)
2024-04-23|||[tests] add `require_torch_sdpa` for test that needs sdpa support (#30408)
2024-04-23|||fix: link to HF repo/tree/revision when a file is missing (#30406)
2024-04-23|||remove redundant logging from longformer (#30365)
2024-04-23|||[Grounding DINO] Add support for cross-attention in GroundingDinoMultiHeadAttention (#30364)
2024-04-23|||Add inputs embeds in generation (#30269)
2024-04-23|||show `-rs` to show skip reasons (#30318)
2024-04-22|||[docs] LLM inference (#29791)
2024-04-23|||[FEAT]: EETQ quantizer support (#30262)
2024-04-22|||Add sdpa and fa2 the Wav2vec2 family.  (#30121)
2024-04-22|||FIX / PEFT: Pass device correctly to peft (#30397)
2024-04-22|||Fix DETA save_pretrained (#30326)
2024-04-22|||Jamba: fix left-padding test (#30389)
2024-04-23|||Fix layerwise GaLore optimizer hard to converge with warmup scheduler  (#30372)
2024-04-22|||Terminator strings for generate() (#28932)
2024-04-22|||Update docstrings for text generation pipeline (#30343)
2024-04-22|||`Llama` family, fix `use_cache=False` generation (#30380)
2024-04-22|||Add FSDP config for CPU RAM efficient loading through accelerate (#30002)
2024-04-22|||GenerationConfig: warn if pad token is negative (#30187)
2024-04-22|||Enable multi-device for more models (#30379)
2024-04-22|||Nits for model docs (#29795)
2024-04-19|||[Grounding DINO] Add resources (#30232)
2024-04-19|||Add TF swiftformer (#23342)
2024-04-20|||Fix config + attn_implementation in AutoModelForCausalLM.from_pretrained (#30299)
2024-04-19|||Do not remove half seq length in generation tests (#30016)
2024-04-19|||Update unwrap from accelerate (#29933)
2024-04-19|||Restore casting of masked_spec_embed (#30336)
2024-04-19|||Deprecate default chat templates (#30346)
2024-04-19|||Transformers Metadata (#30344)
2024-04-19|||parallel job limit for doctest (#30342)
2024-04-19|||[Whisper] Fix slow tests (#30152)
2024-04-19|||Pipeline: fix `pad_token_id` again (#30338)
2024-04-19|||[Feature Extractors] Fix kwargs to pre-trained (#30260)
2024-04-19|||feat: Upgrade Weights & Biases callback (#30135)
2024-04-19|||Enable multi-device for some models (#30207)
2024-04-19|||[UDOP] Add special tokens to tokenizer (#29594)
2024-04-18|||Fix `AssertionError` in clip conversion script (#30321)
2024-04-18|||Avoid `jnp` import in `utils/generic.py`  (#30322)
2024-04-18|||üö®üö®üö®Deprecate `evaluation_strategy` to `eval_strategy`üö®üö®üö® (#30190)
2024-04-18|||Fix test transposing image with EXIF Orientation tag (#30319)
2024-04-18|||disable use_cache if using gradient checkpointing (#30320)
2024-04-18|||fix Parameter dtype in audio models (#30310)
2024-04-18|||Fix: remove `pad token id` in pipeline forward arguments  (#30285)
2024-04-18|||Fix missing `prev_ci_results` (#30313)
2024-04-18|||Dev version
2024-04-18|||FIX: Fixes unexpected behaviour for Llava / LLama & AWQ Fused modules + revert #30070 at the same time (#30317)
2024-04-18|||Add DBRX Model (#29921)
2024-04-18|||Do not drop mask with SDPA for more cases (#30311)
2024-04-18|||Revert "Re-enable SDPA's FA2 path (#30070)" (#30314)
2024-04-18|||Fix RecurrentGemma device_map (#30273)
2024-04-18|||Add atol for sliding window test (#30303)
2024-04-18|||Add jamba (#29943)
2024-04-18|||Fix all torch pipeline failures except one (#30290)
2024-04-18|||Fix donut token2json multiline (#30300)
2024-04-18|||Add Flash Attention 2 to M2M100 model (#30256)
2024-04-17|||Fix quality Olmo + SDPA (#30302)
2024-04-17|||Re-enable SDPA's FA2 path (#30070)
2024-04-17|||Add OLMo model family (#29890)
2024-04-17|||Upgrading to tokenizers 0.19.0 (#30289)
2024-04-17|||Add strategy to store results in evaluation loop (#30267)
2024-04-17|||Add token type ids to CodeGenTokenizer (#29265)
2024-04-17|||FIX: Fix push important models CI (#30291)
2024-04-17|||Fix `Fatal Python error: Bus error` in `ZeroShotAudioClassificationPipelineTests` (#30283)
2024-04-17|||Fix test `ExamplesTests::test_run_translation` (#30281)
2024-04-17|||Enable fx tracing for Mistral (#30209)
2024-04-17|||Configuring Translation Pipelines documents update #27753 (#29986)
2024-04-17|||FIX / AWQ: Fix failing exllama test (#30288)
2024-04-17|||Fix SpeechT5 forward docstrings (#30287)
2024-04-17|||Fix SDPA sliding window compatibility (#30127)
2024-04-16|||Fix test fetcher (doctest) + `Idefics2`'s doc example (#30274)
2024-04-16|||fix: Fixed a `raise` statement (#30275)
2024-04-16|||BLIP - fix pt-tf equivalence test (#30258)
2024-04-16|||Raise relevent err when wrong type is passed in as the accelerator_config (#29997)
2024-04-16|||add `push_to_hub` to pipeline (#29172)
2024-04-16|||Workflow: Update tailscale to release version (#30268)
2024-04-16|||Allow for str versions of dicts based on typing (#30227)
2024-04-16|||FIX: Fix 8-bit serialization tests (#30051)
2024-04-16|||FIX: Fix corner-case issue with the important models workflow (#30212)
2024-04-16|||More fixes for doctest (#30265)
2024-04-16|||Update `ko/_toctree.yml`  (#30062)
2024-04-15|||Remove incorrect arg in codellama doctest (#30257)
2024-04-15|||[Docs] Update recurrent_gemma.md for some minor nits (#30238)
2024-04-15|||Add Idefics2 (#30253)
2024-04-15|||[tests] add the missing `require_torch_multi_gpu` flag (#30250)
2024-04-15|||update github actions packages' version to suppress warnings (#30249)
2024-04-15|||round epoch only in console (#30237)
2024-04-15|||Fix doctest more (for `docs/source/en`) (#30247)
2024-04-15|||Separate out kwargs in processor (#30193)
2024-04-15|||fix: Fixed `type annotation` for compatability with python 3.8 (#30243)
2024-04-15|||Refactor doctest (#30210)
2024-04-15|||fix: Replaced deprecated `typing.Text`  with `str` (#30230)
2024-04-15|||Set pad_token in run_glue_no_trainer.py #28534 (#30234)
2024-04-15|||fix: Replace deprecated `assertEquals` with `assertEqual` (#30241)
2024-04-15|||Add test for parse_json_file and change typing to os.PathLike (#30183)
2024-04-12|||Fixed config.json download to go to user-supplied cache directory (#30189)
2024-04-12|||Fix/Update for doctest (#30216)
2024-04-12|||Update modeling_bark.py (#30221)
2024-04-12|||Fix `RecurrentGemmaIntegrationTest.test_2b_sample` (#30222)
2024-04-12|||fix fuyu doctest (#30215)
2024-04-12|||fix typo (#30220)
2024-04-12|||fix: Replaced deprecated `logger.warn` with `logger.warning` (#30197)
2024-04-12|||Fix pipeline logger.warning_once bug (#30195)
2024-04-12|||ENH: [`CI`] Add new workflow to run slow tests of important models on push main if they are modified (#29235)
2024-04-11|||Docs PR template (#30171)
2024-04-11|||Falcon: make activation, ffn_hidden_size configurable (#30134)
2024-04-11|||Update output of SuperPointForKeypointDetection (#29809)
2024-04-11|||[Processor classes] Update docs (#29698)
2024-04-11|||fix: Fixed `ruff` configuration to avoid deprecated configuration warning (#30179)
2024-04-11|||chore: remove repetitive words (#30174)
2024-04-11|||Guard XLA version imports (#30167)
2024-04-11|||Fix Llava chat template examples (#30130)
2024-04-11|||Adding grounding dino (#26087)
2024-04-10|||Fixed typo in comments/documentation for Pipelines documentation (#30170)
2024-04-10|||Update config class check in auto factory (#29854)
2024-04-10|||FIX / bnb: fix torch compatiblity issue with `itemize` (#30162)
2024-04-10|||Fix natten install in docker (#30161)
2024-04-10|||Fixing a bug when MlFlow try to log a torch.tensor (#29932)
2024-04-10|||Add recurrent gemma (#30143)
2024-04-10|||Fix typing annotation in hf_argparser (#30156)
2024-04-10|||Fix accelerate kwargs for versions <0.28.0 (#30086)
2024-04-10|||[UDOP] Improve docs, add resources (#29571)
2024-04-10|||[UDOP] Fix tests (#29573)
2024-04-10|||Add str to TrainingArguments report_to type hint (#30078)
2024-04-10|||[tests] make 2 tests device-agnostic  (#30008)
2024-04-10|||[CI] Quantization workflow fix (#30158)
2024-04-10|||Fix and simplify semantic-segmentation example (#30145)
2024-04-10|||Fix length related warnings in speculative decoding (#29585)
2024-04-09|||[CI] Fix setup (#30147)
2024-04-09|||[docs] Fix image segmentation guide (#30132)
2024-04-09|||Fix quantization tests (#29914)
2024-04-09|||Send headers when converting safetensors (#30144)
2024-04-09|||Fix slow tests for important models to be compatible with A10 runners (#29905)
2024-04-09|||[Trainer] Undo #29896 (#30129)
2024-04-09|||[Trainer] Fix default data collator (#30142)
2024-04-09|||Revert workaround for TF safetensors loading (#30128)
2024-04-09|||Fix docs Pop2Piano (#30140)
2024-04-09|||Add datasets.Dataset to Trainer's train_dataset and eval_dataset type hints (#30077)
2024-04-09|||Fix failing DeepSpeed model zoo tests (#30112)
2024-04-08|||[`StableLm`] Add QK normalization and Parallel Residual Support (#29745)
2024-04-08|||Adding `mps` as device for `Pipeline` class (#30080)
2024-04-08|||Fix typo at ImportError (#30090)
2024-04-08|||Make vitdet jit trace complient (#30065)
2024-04-08|||Trainer / Core : Do not change init signature order (#30126)
2024-04-08|||Fix falcon with SDPA, alibi but no passed mask (#30123)
2024-04-08|||fix learning rate display in trainer when using galore optimizer (#30085)
2024-04-08|||Accept token in trainer.push_to_hub() (#30093)
2024-04-08|||[#29174] ImportError Fix: Trainer with PyTorch requires accelerate>=0.20.1 Fix (#29888)
2024-04-08|||Patch fix - don't use safetensors for TF models (#30118)
2024-04-08|||fixing issue 30034 - adding data format for run_ner.py (#30088)
2024-04-08|||[tests] add `require_bitsandbytes` marker (#30116)
2024-04-08|||updated examples/pytorch/language-modeling scripts and requirements.txt to require datasets>=2.14.0 (#30120)
2024-04-08|||Make MLFlow version detection more robust and handles mlflow-skinny (#29957)
2024-04-08|||Change log level to warning for num_train_epochs override (#30014)
2024-04-08|||[Whisper] Computing features on GPU in batch mode for whisper feature extractor.    (#29900)
2024-04-08|||doc: Correct spelling mistake (#30107)
2024-04-05|||Fix whisper kwargs and generation config (#30018)
2024-04-05|||Fix auto tests (#30067)
2024-04-05|||Add docstrings and types for MambaCache (#30023)
2024-04-05|||Refactor daily CI workflow (#30012)
2024-04-05|||Fix `torch.fx` symbolic tracing for LLama (#30047)
2024-04-05|||[test fetcher] Always include the directly related test files (#30050)
2024-04-05|||Update quantizer_bnb_4bit.py: In the ValueError string there should be "....you need to set `llm_int8_enable_fp32_cpu_offload=True`...." instead of "`load_in_8bit_fp32_cpu_offload=True`". (#30013)
2024-04-05|||[bnb] Fix offload test (#30039)
2024-04-05|||[Trainer] Allow passing image processor (#29896)
2024-04-05|||Fix mixtral ONNX Exporter Issue. (#29858)
2024-04-05|||if output is tuple like facebook/hf-seamless-m4t-medium, waveform is ‚Ä¶ (#29722)
2024-04-05|||skip `test_encode_decode_fast_slow_all_tokens` for now (#30044)
2024-04-05|||Add `whisper` to `IMPORTANT_MODELS` (#30046)
2024-04-04|||Refactor Cohere Model (#30027)
2024-04-04|||[`ProcessingIdefics`] Attention mask bug with padding (#29449)
2024-04-04|||Add a converter from mamba_ssm -> huggingface mamba (#29705)
2024-04-03|||Enable multi-device for efficientnet (#29989)
2024-04-03|||Make clearer about zero_init requirements (#29879)
2024-04-03|||[`Main CIs`] Fix the red cis  (#30022)
2024-04-03|||Superpoint imports fix (#29898)
2024-04-03|||[docs] Fix audio file (#30006)
2024-04-03|||Fix vipllava for generation (#29874)
2024-04-03|||Fix probability computation in `WhisperNoSpeechDetection` when recomputing scores (#29248)
2024-04-03|||Fix `kwargs` handling in `generate_with_fallback` (#29225)
2024-04-03|||Fix Qwen2Tokenizer (#29929)
2024-04-03|||Fix Swinv2ForImageClassification NaN output (#29981)
2024-04-03|||Make EncodecModel.decode ONNX exportable (#29913)
2024-04-03|||Update `tests/utils/tiny_model_summary.json` (#29941)
2024-04-02|||Fix `remove_columns` in `text-classification` example (#29351)
2024-04-02|||Generate: fix logits processors doctests (#29718)
2024-04-02|||Hard error when ignoring tensors. (#27484) (#29906)
2024-04-02|||Fix `skip_special_tokens` for `Wav2Vec2CTCTokenizer._decode` (#29311)
2024-04-02|||[Docs] Make an ordered list prettier in add_tensorflow_model.md (#29949)
2024-04-02|||Add Flash Attention 2 support to Musicgen and Musicgen Melody (#29939)
2024-04-02|||Adding FlaxNoRepeatNGramLogitsProcessor (#29677)
2024-04-02|||[bnb] Fix bug in `_replace_with_bnb_linear` (#29958)
2024-04-02|||Fix 29807 sinusoidal positional encodings in Flaubert, Informer and XLM (#29904)
2024-04-02|||[`generate`] fix breaking change for patch (#29976)
2024-04-01|||[docs] Big model loading (#29920)
2024-04-01|||Generate: move misplaced test (#29902)
2024-04-01|||[tests] fix the wrong output in `ImageToTextPipelineTests.test_conditional_generation_llava` (#29975)
2024-04-01|||Fix copies main ci (#29979)
2024-04-01|||Fix FA2 tests (#29909)
2024-03-30|||Rework tests to compare trainer checkpoint args (#29883)
2024-03-31|||[`BC`] Fix BC for AWQ quant (#29965)
2024-03-31|||Update model card and link of blog post. (#29928)
2024-03-31|||Reset alarm signal when the function is ended (#29706)
2024-03-30|||fix: get mlflow version from mlflow-skinny (#29918)
2024-03-30|||Add warning message for `run_qa.py` (#29867)
2024-03-30|||Fix rope theta for OpenLlama (#29893)
2024-03-29|||Super tiny fix 12 typos about "with with" (#29926)
2024-03-29|||Mark `test_eager_matches_sdpa_generate` flaky for some models (#29479)
2024-03-28|||Update installs in image classification doc (#29947)
2024-03-29|||[`LlamaSlowConverter`] Slow to Fast better support (#29797)
2024-03-28|||Fix doc issue #29758 in DebertaV2Config class (#29842)
2024-03-28|||[`BC`] Fix BC for other libraries (#29934)
2024-03-28|||Allow GradientAccumulationPlugin to be configured from AcceleratorConfig (#29589)
2024-03-28|||[ `TokenizationLlama`] fix the way we convert tokens to strings to keep leading spaces üö® breaking fix (#29453)
2024-03-28|||[`Mamba`] from pretrained issue with `self.embeddings` (#29851)
2024-03-28|||RoPE models: add numerical sanity-check test for RoPE scaling (#29808)
2024-03-28|||add functions to inspect model and optimizer status to trainer.py (#29838)
2024-03-28|||Safe import of LRScheduler (#29919)
2024-03-28|||Add beam search visualizer to the doc (#29876)
2024-03-28|||Tests: replace `torch.testing.assert_allclose` by `torch.testing.assert_close` (#29915)
2024-03-28|||[doc] fix some typos and add `xpu` to the testing documentation (#29894)
2024-03-28|||Adding Flash Attention 2 Support for GPT2 (#29226)
2024-03-28|||[`pipeline`]. Zero shot add doc warning (#29845)
2024-03-28|||[`GptNeox`] don't gather on pkv when using the trainer (#29892)
2024-03-28|||[`make fix-copies`] update and help (#29924)
2024-03-28|||Fix typo in T5Block error message (#29881)
2024-03-27|||MixtralSparseMoeBlock: add gate jitter (#29865)
2024-03-27|||add Cambricon MLUs support (#29627)
2024-03-27|||Move `eos_token_id` to stopping criteria (#29459)
2024-03-27|||fix fuyu device_map compatibility (#29880)
2024-03-27|||Reimplement "Automatic safetensors conversion when lacking these files" (#29846)
2024-03-27|||Fix 29807, sinusoidal positional encodings overwritten by post_init() (#29813)
2024-03-27|||Mamba `slow_forward` gradient fix (#29563)
2024-03-27|||Add Qwen2MoE (#29377)
2024-03-27|||Support `num_attention_heads` != `num_key_value_heads` in Flax Llama Implementation (#29557)
2024-03-26|||Set custom_container in build docs workflows (#29855)
2024-03-26|||Disable AMD memory benchmarks (#29871)
2024-03-26|||Add `cosine_with_min_lr` scheduler in Trainer (#29341)
2024-03-26|||Allow `bos_token_id is None` during the generation with `inputs_embeds` (#29772)
2024-03-26|||[docs] Indent ordered list in add_new_model.md (#29796)
2024-03-26|||Fix header in IFE task guide (#29859)
2024-03-26|||Replace 'decord' with 'av' in VideoClassificationPipeline (#29747)
2024-03-26|||Add warnings if training args differ from checkpoint trainer state (#29255)
2024-03-25|||remove quotes in code example (#29812)
2024-03-25|||[`revert commit`] revert  00a09ed448082da3d6d35fb23a37b7d04f7b4dcd
2024-03-25|||fix üò≠
2024-03-25|||Populate torch_dtype from model to pipeline (#28940)
2024-03-25|||Fix the behavior of collecting 'num_input_tokens_seen' (#29099)
2024-03-25|||Remove static pretrained maps from the library's internals (#29112)
2024-03-23|||model_summary.md - Restore link to Harvard's Annotated Transformer. (#29702)
2024-03-24|||[DOCS] Fix typo for llava next docs (#29829)
2024-03-22|||[`SuperPoint`] Fix doc example (#29816)
2024-03-22|||Complete security policy with mentions of remote code (#29707)
2024-03-22|||[`cleanup`] vestiges of causal mask (#29806)
2024-03-22|||replaced concatenation to f-strings to improve readability and unify ‚Ä¶ (#29785)
2024-03-22|||Generate: remove unused attributes in `AssistedCandidateGenerator` (#29787)
2024-03-22|||rm input dtype change in CPU (#28631)
2024-03-22|||Correct llava mask & fix missing setter for `vocab_size` (#29389)
2024-03-22|||Enable AMD docker build CI (#29803)
2024-03-22|||Fix type hint for train_dataset param of Trainer.__init__() to allow IterableDataset.  Issue 29678 (#29738)
2024-03-22|||[`quality`] update quality check to make sure we check imports üòà  (#29771)
2024-03-21|||Change in-place operations to out-of-place in LogitsProcessors (#29680)
2024-03-21|||Prepend `bos token` to Blip generations (#29642)
2024-03-21|||Llama: always convert the causal mask in the SDPA code path (#29663)
2024-03-21|||Generate: remove legacy generation mixin imports (#29782)
2024-03-21|||Add support for `torch_dtype` in the run_mlm example (#29776)
2024-03-21|||Add deterministic config to `set_seed` (#29778)
2024-03-21|||Silence deprecations and use the DataLoaderConfig (#29779)
2024-03-21|||Cast bfloat16 to float32 for Numpy conversions (#29755)
2024-03-21|||[`LlavaNext`] Fix llava next unsafe imports (#29773)
2024-03-21|||Fix docker image build for `Latest PyTorch + TensorFlow [dev]` (#29764)
2024-03-21|||fix issue with logit processor during beam search in Flax (#29636)
2024-03-21|||Allow `-OO` mode for `docstring_decorator` (#29689)
2024-03-21|||OWL-ViT box_predictor inefficiency issue (#29712)
2024-03-21|||Fixed typo in quantization_config.py (#29766)
2024-03-21|||[docs] Remove redundant `-`  and `the` from custom_tools.md (#29767)
2024-03-21|||[`BC 4.37 -> 4.38`] for Llama family, memory and speed  (#29753)
2024-03-20|||[`BitsAndBytesConfig`] Warning for unused `kwargs` & safety checkers for `load_in_4bit` and `load_in_8bit` (#29761)
2024-03-20|||Fix docker image build (#29762)
2024-03-20|||Update test reqs to include sentencepiece (#29756)
2024-03-20|||Add LLaVa-1.6, bis (#29586)
2024-03-20|||Add correct batched handling for apply_chat_template (#29222)
2024-03-20|||SuperPointModel -> SuperPointForKeypointDetection (#29757)
2024-03-20|||v4.40.0.dev.0
2024-03-20|||Support sharded safetensors in TF (#29350)
2024-03-20|||fix jinja2 package version check (#29754)
2024-03-20|||Update Mamba types and pass through use_cache attr to MambaModel (#29605)
2024-03-20|||[Tests] Remove unused code (#29737)
2024-03-20|||fix galore layerwise with frozen params (#29743)
2024-03-20|||fixed the issue of DPO trainer that using one node and mutiple GPUs and set the device_map='auto' (#29695)
2024-03-20|||Larger runner on CircleCI (#29750)
2024-03-20|||Tests: Musicgen tests + `make fix-copies` (#29734)
2024-03-19|||Fix `check_copies` not capturing the diff in model/paper title and link (#29724)
2024-03-19|||Llama: partial 4d masks (#29731)
2024-03-19|||Clean-up generation tests after moving methods to private (#29582)
2024-03-19|||Implementation of SuperPoint and AutoModelForKeypointDetection (#28966)
2024-03-20|||[`GemmaConverter`] use user_defined_symbols (#29473)
2024-03-20|||[`Gemma`]  final fixes to the modeling (#29729)
2024-03-19|||[tests] add more tests to `NOT_DEVICE_TESTS`  (#29670)
2024-03-19|||FEAT / Optim: Add GaLore optimizer (#29588)
2024-03-19|||Use logging.warning instead of warnings.warn in pipeline.__call__ (#29717)
2024-03-18|||Update the pipeline tutorial to include `gradio.Interface.from_pipeline` (#29684)
2024-03-18|||FIX [`bnb`] Make `unexpected_keys` optional (#29420)
2024-03-18|||Fix `filter_models` (#29710)
2024-03-18|||Add MusicGen Melody (#28819)
2024-03-18|||CI / generate: batch size computation compatible with all models (#29671)
2024-03-15|||[docs] Spanish translation of attention.md (#29681)
2024-03-15|||Revert "Fix wrong condition used in `filter_models`" (#29682)
2024-03-15|||[FIX] Fix speech2test modeling tests (#29672)
2024-03-15|||Generate: replace breaks by a loop condition (#29662)
2024-03-15|||[Quantization] Quanto quantizer (#29023)
2024-03-15|||Rename `glue` to `nyu-mll/glue` (#29679)
2024-03-15|||fix: typos (#29653)
2024-03-15|||Fix wrong condition used in `filter_models` (#29673)
2024-03-15|||[tests] ensure device-required software is available in the testing environment before testing     (#29477)
2024-03-15|||Fix AutoformerForPrediction example code (#29639)
2024-03-15|||[tests] remove deprecated tests for model loading (#29450)
2024-03-15|||Cohere Model Release (#29622)
2024-03-15|||Pipeline: use tokenizer pad token at generation time if the model pad token is unset. (#29614)
2024-03-15|||Trainer: fail early in the presence of an unsavable `generation_config` (#29675)
2024-03-15|||Extend import utils to cover "editable" torch versions (#29000)
2024-03-15|||Inaccurate code example within inline code-documentation (#29661)
2024-03-14|||Allow apply_chat_template to pass kwargs to the template and support a dict of templates (#29658)
2024-03-14|||Generate: handle `cache_position` update in `generate` (#29467)
2024-03-14|||Fix PVT v2 tests (#29660)
2024-03-14|||Add `dataset_revision` argument to `RagConfig` (#29610)
2024-03-14|||Fix TPU checkpointing inside Trainer (#29657)
2024-03-14|||[`PEFT`] Fix `save_pretrained` to make sure adapters weights are also saved on TPU (#29388)
2024-03-14|||Add newly added PVTv2 model to all README files. (#29647)
2024-03-13|||[docs] Remove broken ChatML format link from chat_templating.md (#29643)
2024-03-13|||Add PvT-v2 Model (#26812)
2024-03-13|||Fix `multi_gpu_data_parallel_forward` for `MusicgenTest` (#29632)
2024-03-13|||Fix batching tests for new models (Mamba and SegGPT) (#29633)
2024-03-13|||Refactor TFP call to just sigmoid() (#29641)
2024-03-14|||[tests] make `test_trainer_log_level_replica` to run on accelerators with more than 2 devices (#29609)
2024-03-13|||[`Mask2Former`] Move normalization for numerical stability (#29542)
2024-03-13|||Add support for FSDP+QLoRA and DeepSpeed ZeRO3+QLoRA (#29587)
2024-03-13|||[docs] Spanish translate chat_templating.md & yml addition (#29559)
2024-03-13|||[PyTorch/XLA] Fix extra TPU compilations introduced by recent changes (#29158)
2024-03-13|||Llama: allow custom 4d masks (#29618)
2024-03-13|||[`MaskFormer`, `Mask2Former`] Use einsum where possible (#29544)
2024-03-13|||Fix minor typo: infenrece => inference (#29621)
2024-03-13|||[generate] deprecate forced ids processor (#29487)
2024-03-13|||Adds pretrained IDs directly in the tests (#29534)
2024-03-13|||Warn about tool use (#29628)
2024-03-13|||[Whisper] Deprecate forced ids for v4.39 (#29485)
2024-03-13|||Core: Fix copies on main (#29624)
2024-03-13|||[Flash Attention 2] Add flash attention 2 for GPT-J (#28295)
2024-03-12|||[`Gemma`] Supports converting directly in half-precision (#29529)
2024-03-12|||Examples: check `max_position_embeddings` in the translation example (#29600)
2024-03-12|||Fix: handle logging of scalars in Weights & Biases summary (#29612)
2024-03-12|||Add tests for batching support (#29297)
2024-03-12|||Fix typo ; Update quantization.md (#29615)
2024-03-12|||Update flava tests (#29611)
2024-03-12|||Set env var to hold Keras at Keras 2 (#29598)
2024-03-12|||Update legacy Repository usage in various example files (#29085)
2024-03-12|||Implemented add_pooling_layer arg to TFBertModel (#29603)
2024-03-12|||Fix typo (determine) (#29606)
2024-03-12|||Stop passing None to compile() in TF examples (#29597)
2024-03-12|||Fix minor typo: softare => software (#29602)
2024-03-12|||Fix Fuyu doc typos (#29601)
2024-03-11|||Experimental loading of MLX files (#29511)
2024-03-12|||Tiny improvement for doc (#29581)
2024-03-11|||Fixed broken link (#29558)
2024-03-11|||Add missing localized READMEs to the copies check (#29575)
2024-03-12|||fix error: TypeError: Object of type Tensor is not JSON serializable ‚Ä¶ (#29568)
2024-03-11|||Don't use a subset in test fetcher if on `main` branch (#28816)
2024-03-11||| [Docs] Fix FastSpeech2Conformer model doc links (#29574)
2024-03-11|||Make torch xla available on GPU (#29334)
2024-03-11|||Bark model Flash Attention 2 Enabling to pass on check_device_map parameter to super() (#29357)
2024-03-11|||Add Fill-in-the-middle training objective example - PyTorch (#27464)
2024-03-11|||[`Docs`] fixed minor typo (#29555)
2024-03-11|||[`Mamba doc`] Post merge updates  (#29472)
2024-03-09|||feat: use `warning_advice` for tensorflow warning (#29540)
2024-03-08|||Fix eval thread fork bomb (#29538)
2024-03-08|||[tests] use the correct `n_gpu` in `TrainerIntegrationTest::test_train_and_eval_dataloaders` for XPU (#29307)
2024-03-08|||Fix WhisperNoSpeechDetection when input is full silence  (#29065)
2024-03-08|||fix typos in FSDP config parsing logic in `TrainingArguments` (#29189)
2024-03-08|||Make sliding window size inclusive in eager attention (#29519)
2024-03-08|||StableLM: Fix dropout argument type error (#29236)
2024-03-08|||[tests] use `torch_device` instead of `auto` for model testing  (#29531)
2024-03-08|||Typo fix in error message (#29535)
2024-03-08|||fix image-to-text batch incorrect output issue (#29342)
2024-03-08|||[tests] add the missing `require_sacremoses` decorator  (#29504)
2024-03-08|||Generate: left-padding test, revisited (#29515)
2024-03-08|||Typo in mlx tensor support (#29509)
2024-03-07|||Fix `VisionEncoderDecoder` Positional Arg (#29497)
2024-03-07|||Set `inputs` as kwarg in `TextClassificationPipeline` (#29495)
2024-03-07|||test_generation_config_is_loaded_with_model  - fall back to pytorch model for now (#29521)
2024-03-07|||Add support for metadata format MLX (#29335)
2024-03-07|||Flava multimodal add attention mask (#29446)
2024-03-07|||fix: Avoid error when fsdp_config is missing xla_fsdp_v2 (#29480)
2024-03-07|||Revert "Automatic safetensors conversion when lacking these files (#2‚Ä¶ (#29507)
2024-03-07|||v4.39 deprecations üßº  (#29492)
2024-03-07|||Enable BLIP for auto VQA (#29499)
2024-03-07|||Fix: Disable torch.autocast in RotaryEmbedding of Gemma and LLaMa for MPS device (#29439)
2024-03-06|||Substantially reduce memory usage in _update_causal_mask for large batches by using .expand instead of .repeat [needs tests+sanity check] (#29413)
2024-03-06|||Fix `TextGenerationPipeline.__call__` docstring (#29491)
2024-03-06|||added the max_matching_ngram_size to GenerationConfig (#29131)
2024-03-06|||Generate: torch.compile-ready generation config preparation (#29443)
2024-03-06|||Fix test failure on DeepSpeed (#29444)
2024-03-06|||Avoid dummy token in PLD to optimize performance (#29445)
2024-03-06|||Generate: get generation mode from the generation config instance üßº (#29441)
2024-03-06|||Generate: add tests for caches with `pad_to_multiple_of`  (#29462)
2024-03-06|||Fix TrainingArguments regression with torch <2.0.0 for dataloader_prefetch_factor (#29447)
2024-03-06|||[`docs`] Add starcoder2 docs (#29454)
2024-03-06|||[`Docs` / `Awq`] Add docs on exllamav2 + AWQ (#29474)
2024-03-06|||[FIX] `offload_weight()` takes from 3 to 4 positional arguments but 5 were given (#29457)
2024-03-06|||üåê [i18n-KO] Translated generation_strategies.md to Korean (#29086)
2024-03-06|||[i18n-zh] Translate add_new_pipeline.md into Chinese (#29432)
2024-03-05|||Automatic safetensors conversion when lacking these files (#29390)
2024-03-05|||Update pytest `import_path` location  (#29154)
2024-03-05|||Fix bug with passing capture_* args to neptune callback (#29041)
2024-03-05|||[`Add Mamba`] Adds support for the `Mamba` models (#28094)
2024-03-05|||Generate: inner decoding methods are no longer public (#29437)
2024-03-05|||[`Udop imports`] Processor tests were not run. (#29456)
2024-03-05|||Revert-commit 0d52f9f582efb82a12e8d9162b43a01b1aa0200f (#29455)
2024-03-05|||more fix
2024-03-05|||[`UdopTokenizer`] Fix post merge imports (#29451)
2024-03-05|||[tests] enable test_pipeline_accelerate_top_p on XPU    (#29309)
2024-03-05|||[docs] Update starcoder2 paper link (#29418)
2024-03-05|||Fix max length for BLIP generation (#29296)
2024-03-05|||Exllama kernels support for AWQ models (#28634)
2024-03-05|||FIX [`Generation`] Fix some issues when running the MaxLength criteria on CPU (#29317)
2024-03-04|||[Docs] Spanish Translation -Torchscript md & Trainer md (#29310)
2024-03-04|||Add UDOP (#22940)
2024-03-04|||DeformableDETR support bfloat16 (#29232)
2024-03-04|||Avoid edge case in audio utils (#28836)
2024-03-04|||Fix grad_norm unserializable tensor log failure (#29212)
2024-03-04|||üö® Fully revert atomic checkpointing üö® (#29370)
2024-03-04|||Fix OneFormer `post_process_instance_segmentation` for panoptic tasks (#29304)
2024-03-04|||Fix: Fixed the previous tracking URI setting logic to prevent clashes with original MLflow code. (#29096)
2024-03-04|||Convert SlimSAM checkpoints (#28379)
2024-03-04|||Workaround for #27758 to avoid ZeroDivisionError (#28756)
2024-03-04|||Add mlx support to BatchEncoding.convert_to_tensors (#29406)
2024-03-04|||[Mixtral] Fixes attention masking in the loss (#29363)
2024-03-04|||update path to hub files in the error message (#29369)
2024-03-04|||[tests] enable automatic speech recognition pipeline tests on XPU  (#29308)
2024-03-01|||Correct zero division error in inverse sqrt scheduler (#28982)
2024-03-01|||Fix deprecated arg issue (#29372)
2024-03-01|||Fix llama + gemma accelete tests (#29380)
2024-03-01|||Support subfolder with `AutoProcessor` (#29169)
2024-03-01|||[`YOLOS`] Fix - return padded annotations (#29300)
2024-03-01|||üö®üö®[Whisper Tok] Update integration test (#29368)
2024-03-01|||[`Llama + AWQ`] fix `prepare_inputs_for_generation`  ü´† (#29381)
2024-03-01|||FIX [`quantization` / `ESM`] Fix ESM 8bit / 4bit with bitsandbytes (#29329)
2024-03-01|||Fix Base Model Name of LlamaForQuestionAnswering (#29258)
2024-03-01|||Expose `offload_buffers` parameter of `accelerate` to `PreTrainedModel.from_pretrained` method (#28755)
2024-02-29|||Fix @require_read_token in tests (#29367)
2024-02-29|||Patch YOLOS and others (#29353)
2024-02-29|||Avoid using uncessary `get_values(MODEL_MAPPING)` (#29362)
2024-02-29|||FIX [`CI`] `require_read_token` in the llama FA2 test (#29361)
2024-02-29|||FIX [`CI`]: Fix failing tests for peft integration (#29330)
2024-02-29|||FIX [`CI` / `starcoder2`] Change starcoder2 path to correct one for slow tests (#29359)
2024-02-29|||[i18n-zh] Sync source/zh/index.md (#29331)
2024-02-28|||Better SDPA unmasking implementation (#29318)
2024-02-28|||[CI] Quantization workflow (#29046)
2024-02-28|||check if position_ids exists before using it (#29306)
2024-02-29|||RoPE loses precision for Llama / Gemma + Gemma logits.float() (#29285)
2024-02-28|||Idefics: generate fix (#29320)
2024-02-28|||Disable Mixtral `output_router_logits` during inference (#29249)
2024-02-28|||[`Llama ROPE`] Fix torch export but also slow downs in forward (#29198)
2024-02-28|||[`T5 and Llama Tokenizer`] remove warning (#29346)
2024-02-28|||[`require_read_token`] fix typo (#29345)
2024-02-28|||Remove numpy usage from owlvit (#29326)
2024-02-28|||FIX [`Gemma` / `CI`] Make sure our runners have access to the model (#29242)
2024-02-27|||simplify get_class_in_module and fix for paths containing a dot (#29262)
2024-02-28|||Starcoder2 model - bis (#29215)
2024-02-28|||[i18n-zh] Translate fsdp.md into Chinese (#29305)
2024-02-27|||Fix a few typos in `GenerationMixin`'s docstring (#29277)
2024-02-27|||Token level timestamps for long-form generation in Whisper (#29148)
2024-02-27|||Add compatibility with skip_memory_metrics for mps device (#29264)
2024-02-27|||Use torch 2.2 for deepspeed CI (#29246)
2024-02-27|||[tests] enable benchmark unit tests on XPU  (#29284)
2024-02-27|||Fix `attn_implementation` documentation (#29295)
2024-02-27|||Image Feature Extraction docs (#28973)
2024-02-27|||Cleaner Cache `dtype` and `device` extraction for CUDA graph generation for quantizers compatibility (#29079)
2024-02-27|||Add generate kwargs to VQA pipeline (#29134)
2024-02-27|||GenerationConfig validate both constraints and force_words_ids (#29163)
2024-02-26|||Adding SegGPT (#27735)
2024-02-26|||Fixed Deformable Detr typo when loading cuda kernels for MSDA (#29294)
2024-02-27|||[i18n-zh] Translated task/asr.md into Chinese (#29233)
2024-02-26|||[i18n-vi] Translate README.md to Vietnamese (#29229)
2024-02-27|||üåê [i18n-ZH] Translate chat_templating.md into Chinese (#28790)
2024-02-27|||[i18n-zh] Translated torchscript.md into Chinese (#29234)
2024-02-26|||[docs] Spanish translation of tasks_explained.md (#29224)
2024-02-26|||Track each row separately for stopping criteria (#29116)
2024-02-26|||Generate: v4.38 removals and related updates (#29171)
2024-02-26|||Use `torch.bool` instead of `torch.int64` for non-persistant causal mask buffer (#29241)
2024-02-26|||Add feature extraction mapping for automatic metadata update (#28944)
2024-02-26|||Add `non_device_test` pytest mark to filter out non-device tests (#29213)
2024-02-26|||Use `DS_DISABLE_NINJA=1` (#29290)
2024-02-26|||Cache `is_vision_available` result (#29280)
2024-02-23|||Use torch 2.2 for daily CI (model tests) (#29208)
2024-02-23|||Allow remote code repo names to contain "." (#29175)
2024-02-23|||[`Doc`] update model doc qwen2 (#29238)
2024-02-23|||Improve _update_causal_mask performance (#29210)
2024-02-23|||Fix missing translation in README_ru (#29054)
2024-02-23|||fix(mlflow): check mlflow version to use the synchronous flag (#29195)
2024-02-22|||Fix `torch.compile` with `fullgraph=True` when `attention_mask` input is used (#29211)
2024-02-22|||[Mistral, Mixtral] Improve docs (#29084)
2024-02-22|||[Gemma] Fix eager attention (#29187)
2024-02-21|||Add training version check for AQLM quantizer. (#29142)
2024-02-21|||FIX [`Gemma`] Fix bad rebase with transformers main (#29170)
2024-02-21|||[ `gemma`] Adds support for Gemma üíé (#29167)
2024-02-21|||[`Maskformer`] safely get backbone config (#29166)
2024-02-21|||support SDPA Attention in stablelm (#29106)
2024-02-21|||`torch.compile` compatibility with `generate` + static cache (#29114)
2024-02-21|||üö® Llama: update rope scaling to match static cache changes (#29143)
2024-02-21|||v4.39.dev.0
2024-02-20|||[`pipeline`] Add pool option to image feature extraction pipeline (#28985)
2024-02-20|||Fix drop path being ignored in DINOv2 (#29147)
2024-02-20|||Added image_captioning version in es and included in toctree file (#29104)
2024-02-20|||Generate: missing generation config eos token setting in encoder-decoder tests (#29146)
2024-02-20|||Raise unused kwargs image processor (#29063)
2024-02-20|||[Phi] Add support for sdpa (#29108)
2024-02-20|||Save (circleci) cache at the end of a job (#29141)
2024-02-20|||Add support for fine-tuning CLIP-like models using contrastive-image-text example (#29070)
2024-02-20|||Revert low cpu mem tie weights (#29135)
2024-02-20|||[`Core tokenization`]  `add_dummy_prefix_space` option to help with latest issues (#28010)
2024-02-20|||FIX [`PEFT` / `Trainer` ] Handle better peft + quantized compiled models (#29055)
2024-02-20|||[`cuda kernels`] only compile them when initializing (#29133)
2024-02-20|||Generate: unset GenerationConfig parameters do not raise warning (#29119)
2024-02-20|||Llama: fix batched generation (#29109)
2024-02-20|||FIX [`bnb` / `tests`] Propagate the changes from #29092 to 4-bit tests (#29122)
2024-02-20|||Abstract image processor arg checks. (#28843)
2024-02-20|||FEAT [`Trainer` / `bnb`]: Add RMSProp from `bitsandbytes` to HF `Trainer` (#29082)
2024-02-20|||Move misplaced line (#29117)
2024-02-20|||[`gradient_checkpointing`] default to use it for torch 2.3 (#28538)
2024-02-20|||Fixed nll with label_smoothing to just nll (#28708)
2024-02-19|||storing & logging gradient norm in trainer (#27326)
2024-02-19|||Fix two tiny typos in `pipelines/base.py::Pipeline::_sanitize_parameters()`'s docstring (#29102)
2024-02-19|||Bnb test fix for different hardwares (#29066)
2024-02-19|||ENH: added new output_logits option to generate function (#28667)
2024-02-19|||[Docs] Add resources (#28705)
2024-02-19|||change version (#29097)
2024-02-19|||Fix a typo in `examples/pytorch/text-classification/run_classification.py` (#29072)
2024-02-19|||Fix the `bert-base-cased` tokenizer configuration test (#29105)
2024-02-19|||fix the post-processing link (#29091)
2024-02-19|||FIX [`bnb` / `tests`]: Fix currently failing bnb tests (#29092)
2024-02-19|||[`Awq`] Add peft support for AWQ (#28987)
2024-02-16|||[Docs] Spanish translation of task_summary.md (#28844)
2024-02-16|||Add chat support to text generation pipeline (#28945)
2024-02-16|||Fix trainer test wrt DeepSpeed + auto_find_bs (#29061)
2024-02-16|||Feature: Option to set the tracking URI for MLflowCallback. (#29032)
2024-02-16|||Honor trust_remote_code for custom tokenizers (#28854)
2024-02-16|||`auto_find_batch_size` isn't yet supported with DeepSpeed/FSDP. Raise error accrodingly. (#29058)
2024-02-16|||fix failing trainer ds tests (#29057)
2024-02-16|||fix num_assistant_tokens with heuristic schedule (#28759)
2024-02-16|||Support : Leverage Accelerate for object detection/segmentation models  (#28312)
2024-02-16|||Fix max_length criteria when using inputs_embeds (#28994)
2024-02-16|||Update important model list (#29019)
2024-02-16|||Update all references to canonical models (#29001)
2024-02-15|||add test marker to run all tests with @require_bitsandbytes (#28278)
2024-02-15|||Fix a tiny typo in `generation/utils.py::GenerateEncoderDecoderOutput`'s docstring (#29044)
2024-02-15|||Removed obsolete attribute setting for AQLM quantization. (#29034)
2024-02-15|||Patch to skip failing `test_save_load_low_cpu_mem_usage` tests (#29043)
2024-02-15|||FIX: Fix error with `logger.warning` + inline with recent refactor (#29039)
2024-02-15|||Fix copies between DETR and DETA (#29037)
2024-02-15|||DeformableDetrModel support fp16 (#29013)
2024-02-15|||Add cuda_custom_kernel in DETA (#28989)
2024-02-15|||Fix static generation when compiling!  (#28937)
2024-02-15|||[`CLeanup`] Revert SDPA attention changes that got in the static kv cache PR (#29027)
2024-02-14|||FIX [`Trainer` / tags]: Fix trainer + tags when users do not pass `"tags"` to `trainer.push_to_hub()` (#29009)
2024-02-14|||[TPU] Support PyTorch/XLA FSDP via SPMD (#28949)
2024-02-14|||Backbone kwargs in config (#28784)
2024-02-15|||Add tie_weights() to LM heads and set bias in set_output_embeddings() (#28948)
2024-02-14|||Mask Generation Task Guide (#28897)
2024-02-14|||Fix flaky test vision encoder-decoder generate (#28923)
2024-02-14|||Introduce AcceleratorConfig dataclass (#28664)
2024-02-14|||Set the dataset format used by `test_trainer` to float32 (#28920)
2024-02-14|||[`Doc`] Fix docbuilder - make `BackboneMixin` and `BackboneConfigMixin` importable from `utils`.  (#29002)
2024-02-14|||AQLM quantizer support (#28928)
2024-02-14|||Add SiglipForImageClassification and CLIPForImageClassification (#28952)
2024-02-14|||Add `StableLM` (#28810)
2024-02-14|||ENH [`AutoQuantizer`]: enhance trainer + not supported quant methods (#28991)
2024-02-14|||ENH: Do not pass warning message in case `quantization_config` is in config but not passed as an arg (#28988)
2024-02-13|||[`DETR`] Update the processing to adapt masks & bboxes to reflect padding (#28363)
2024-02-13|||Update configuration_llama.py: fixed broken link (#28946)
2024-02-13|||Static Cache: load models with MQA or GQA (#28975)
2024-02-13|||Add sudachi_projection option to BertJapaneseTokenizer (#28503)
2024-02-13|||[`NllbTokenizer`] refactor with added tokens decoder (#27717)
2024-02-12|||[i18n-de] Translate CONTRIBUTING.md to German (#28954)
2024-02-12|||[Docs] Add video section (#28958)
2024-02-12|||[Docs] Add language identifiers to fenced code blocks (#28955)
2024-02-12|||Clean up staging tmp checkpoint directory (#28848)
2024-02-12|||Always initialize tied output_embeddings if it has a bias term (#28947)
2024-02-12|||Updated requirements for image-classification samples: datasets>=2.14.0 (#28974)
2024-02-12|||Tests: tag `test_save_load_fast_init_from_base` as flaky (#28930)
2024-02-12|||[`pipelines`] updated docstring with vqa alias (#28951)
2024-02-12|||Convert `torch_dtype` as `str` to actual torch data type (i.e. "float16" ‚Ä¶to `torch.float16`) (#28208)
2024-02-12|||[Docs] Update README and default pipelines (#28864)
2024-02-12|||[Nougat] Fix pipeline (#28242)
2024-02-09|||[i18n-de] Translate README.md to German (#28933)
2024-02-09|||Fix type annotations on neftune_noise_alpha and fsdp_config TrainingArguments parameters (#28942)
2024-02-10|||Fix a wrong link to CONTRIBUTING.md section in PR template (#28941)
2024-02-09|||Fix max_position_embeddings default value for llama2 to 4096 #28241 (#28754)
2024-02-08|||[Docs] Fix broken links and syntax issues (#28918)
2024-02-08|||Support batched input for decoder start ids (#28887)
2024-02-08|||pass kwargs in stopping criteria list (#28927)
2024-02-08|||fix: torch.int32 instead of torch.torch.int32 (#28883)
2024-02-08|||Remove dead TF loading code (#28926)
2024-02-08|||[`Core generation`] Adds support for static KV cache (#27931)
2024-02-08|||Fix utf-8 yaml load for marian conversion to pytorch in Windows (#28618)
2024-02-08|||[Docs] Revert translation of '@slow' decorator (#28912)
2024-02-08|||[Docs] Fix placement of tilde character (#28913)
2024-02-08|||Add npu device for pipeline (#28885)
2024-02-07|||Update the cache number (#28905)
2024-02-07|||‚ö†Ô∏è Raise `Exception` when trying to generate 0 tokens ‚ö†Ô∏è (#28621)
2024-02-07|||Fix Keras scheduler import so it works for older versions of Keras (#28895)
2024-02-07|||fix Starcoder FA2 implementation (#28891)
2024-02-07|||fix: Fixed the documentation for `logging_first_step` by removing "evaluate" (#28884)
2024-02-06|||[Docs] Add missing language options and fix broken links (#28852)
2024-02-06|||Hotfix - make `torchaudio` get the correct version in `torch_and_flax_job` (#28899)
2024-02-06|||[Docs] Fix backticks in inline code and documentation links (#28875)
2024-02-06|||Explicit server error on gated model (#28894)
2024-02-06|||unpin torch (#28892)
2024-02-06|||Revert "[WIP] Hard error when ignoring tensors." (#28898)
2024-02-06|||Fix `FastSpeech2ConformerModelTest` and skip it on CPU (#28888)
2024-02-06|||Raise error when using `save_only_model` with `load_best_model_at_end` for DeepSpeed/FSDP (#28866)
2024-02-06|||Fix LongT5ForConditionalGeneration initialization of lm_head (#28873)
2024-02-06|||[Docs] Update project names and links in awesome-transformers (#28878)
2024-02-06|||Bump cryptography from 41.0.2 to 42.0.0 in /examples/research_projects/decision_transformer (#28879)
2024-02-06|||Adds LlamaForQuestionAnswering class in modeling_llama.py along with AutoModel Support  (#28777)
2024-02-05|||Do not use mtime for checkpoint rotation. (#28862)
2024-02-05|||ClearMLCallback enhancements: support multiple runs and handle logging better (#28559)
2024-02-05|||Image Feature Extraction pipeline (#28216)
2024-02-05|||Correct wav2vec2-bert inputs_to_logits_ratio (#28821)
2024-02-05|||[`Doc`] update contribution guidelines (#28858)
2024-02-05|||[WIP] Hard error when ignoring tensors. (#27484)
2024-02-05|||Ability to override clean_code_for_run (#28783)
2024-02-04|||[Docs] Fix bad doc: replace save with logging (#28855)
2024-02-05|||Support custom scheduler in deepspeed training (#26831)
2024-02-05|||Bump dash from 2.3.0 to 2.15.0 in /examples/research_projects/decision_transformer (#28845)
2024-02-02|||Mark `test_encoder_decoder_model_generate` for `vision_encoder_deocder` as flaky (#28842)
2024-02-02|||Reduce GPU memory usage when using FSDP+PEFT (#28830)
2024-02-02|||Use `-v` for `pytest` on CircleCI  (#28840)
2024-02-02|||fix / skip (for now) some tests before switch to torch 2.2 (#28838)
2024-02-02|||Fix issues caused by natten (#28834)
2024-02-02|||Add missing None check for hf_quantizer (#28804)
2024-02-02|||Explicitly check if token ID's are None in TFBertTokenizer constructor (#28824)
2024-02-02|||[Docs] Fix spelling and grammar mistakes (#28825)
2024-02-01|||[docs] HfQuantizer (#28820)
2024-02-01|||[docs] Backbone (#28739)
2024-02-01|||Add models from deit (#28302)
2024-02-02|||[docs] fix some bugs about parameter description (#28806)
2024-02-02|||enable graident checkpointing in DetaObjectDetection and add tests in Swin/Donut_Swin (#28615)
2024-02-01|||Add tip on setting tokenizer attributes (#28764)
2024-02-01|||Fix symbolic_trace with kv cache (#28724)
2024-02-01|||Make `is_torch_bf16_available_on_device` more strict (#28796)
2024-02-01|||Adding [T5/MT5/UMT5]ForTokenClassification (#28443)
2024-02-01|||[docs] Correct the statement in the docstirng of compute_transition_scores in generation/utils.py (#28786)
2024-01-31|||Split daily CI using 2 level matrix (#28773)
2024-01-31|||Add artifact name in job step to maintain job / artifact correspondence (#28682)
2024-01-31|||DeepSpeed: hardcode `torch.arange` dtype on `float` usage to avoid incorrect initialization (#28760)
2024-01-31|||Flax mistral (#26943)
2024-01-31|||Wrap Keras methods to support BatchEncoding (#28734)
2024-01-31|||canonical repos moves (#28795)
2024-01-31|||Resolve DeepSpeed cannot resume training with PeftModel (#28746)
2024-01-31|||[Whisper] Refactor forced_decoder_ids & prompt ids (#28687)
2024-01-31|||[`HFQuantizer`] Remove `check_packages_compatibility` logic (#28789)
2024-01-30|||don't initialize the output embeddings if we're going to tie them to input embeddings (#28192)
2024-01-31|||Prevent MLflow exception from disrupting training (#28779)
2024-01-31|||[`bnb`] Fix bnb slow tests (#28788)
2024-01-30|||Pin Torch to <2.2.0 (#28785)
2024-01-30|||Add tf_keras imports to prepare for Keras 3 (#28588)
2024-01-30|||Task-specific pipeline init args (#28439)
2024-01-30|||[`Backbone`] Use `load_backbone` instead of `AutoBackbone.from_config` (#28661)
2024-01-30|||Further pin pytest version (in a temporary way) (#28780)
2024-01-30|||Fix transformers.utils.fx compatibility with torch<2.0 (#28774)
2024-01-30|||Use Conv1d for TDNN (#25728)
2024-01-30|||[`HfQuantizer`] Move it to "Developper guides" (#28768)
2024-01-30|||`HfQuantizer` class for quantization-related stuff in `modeling_utils.py` (#26610)
2024-01-30|||Move CLIP _no_split_modules to CLIPPreTrainedModel (#27841)
2024-01-30|||Don't allow passing `load_in_8bit` and `load_in_4bit` at the same time (#28266)
2024-01-29|||Add French translation: french README.md (#28696)
2024-01-29|||Support saving only PEFT adapter in checkpoints when using PEFT + FSDP (#28297)
2024-01-29|||[Whisper] Make tokenizer normalization public (#28136)
2024-01-29|||Fix typo of `Block`. (#28727)
2024-01-29|||Mark test_constrained_beam_search_generate as flaky (#28757)
2024-01-29|||Pin pytest version <8.0.0 (#28758)
2024-01-29|||small doc update for CamemBERT (#28644)
2024-01-29|||Enable Gradient Checkpointing in Deformable DETR (#28686)
2024-01-29|||PatchtTST and PatchTSMixer fixes (#28083)
2024-01-29|||[Docs] Fix Typo in English & Japanese CLIP Model Documentation (TMBD -> TMDB) (#28751)
2024-01-29|||Fix input data file extension in examples (#28741)
2024-01-29|||Fix `DepthEstimationPipeline`'s docstring (#28733)
2024-01-29|||Add serialization logic to pytree types (#27871)
2024-01-28|||[`Siglip`] protect from imports if sentencepiece not installed (#28737)
2024-01-27|||Generate: deprecate old src imports (#28607)
2024-01-27|||Falcon: removed unused function (#28605)
2024-01-26|||[Flax] Update no init test for Flax v0.7.1 (#28735)
2024-01-26|||[docs] Fix datasets in guides (#28715)
2024-01-26|||Unpin pydantic (#28728)
2024-01-27|||fix: suppress `GatedRepoError` to use cache file (fix #28558). (#28566)
2024-01-26|||Stop confusing the TF compiler with ModelOutput objects (#28712)
2024-01-26|||Fix `weights_only` (#28725)
2024-01-26|||Initialize _tqdm_active with hf_hub_utils.are_progress_bars_disabled(‚Ä¶ (#28717)
2024-01-26|||[`docs`] Update preprocessing.md (#28719)
2024-01-26|||fix: corrected misleading log message in save_pretrained function (#28699)
2024-01-26|||support PeftMixedModel signature inspect (#28321)
2024-01-26|||Fix duplicate & unnecessary flash attention warnings (#28557)
2024-01-26|||Don't fail when `LocalEntryNotFoundError` during `processor_config.json` loading (#28709)
2024-01-25|||[`docs`] Improve visualization for vertical parallelism (#28583)
2024-01-25|||[`Vilt`] align input and model dtype in the ViltPatchEmbeddings forward pass  (#28633)
2024-01-25|||Update question_answering.md (#28694)
2024-01-25|||Improve Backbone API docs (#28666)
2024-01-25|||[`chore`] Add missing space in warning (#28695)
2024-01-25|||Add Depth Anything (#28654)
2024-01-24|||[docs] Fix doc format (#28684)
2024-01-25|||improve efficient training on CPU documentation (#28646)
2024-01-24|||Improved type hinting for all attention parameters (#28479)
2024-01-24|||[docs] DeepSpeed (#28542)
2024-01-24|||Add back in generation types (#28681)
2024-01-24|||Use save_safetensor to disable safe serialization for XLA (#28669)
2024-01-24||| Exclude the load balancing loss of padding tokens in Mixtral-8x7B (#28517)
2024-01-23|||Update README_es.md (#28612)
2024-01-24|||fix a hidden bug of `GenerationConfig`, now the `generation_config.json` can be loaded successfully (#28604)
2024-01-23|||Remove deprecated eager_serving fn (#28665)
2024-01-23|||Support single token decode for `CodeGenTokenizer` (#28628)
2024-01-23|||add dataloader prefetch factor in training args and trainer (#28498)
2024-01-23|||Fix windows err with checkpoint race conditions (#28637)
2024-01-23|||`tensor_size` - fix copy/paste error msg typo (#28660)
2024-01-23|||Enable instantiating model with pretrained backbone weights (#28214)
2024-01-23|||Enable safetensors conversion from PyTorch to other frameworks without the torch requirement (#27599)
2024-01-23|||integrations: fix DVCLiveCallback model logging (#28653)
2024-01-23|||get default device through `PartialState().default_device` as it has been officially released (#27256)
2024-01-22|||Fix phi model doc checkpoint (#28581)
2024-01-22|||[`SigLIP`] Only import tokenizer if sentencepiece available (#28636)
2024-01-22|||Update image_processing_deformable_detr.py (#28561)
2024-01-22|||[`GPTNeoX`] Fix GPTNeoX + Flash Attention 2 issue (#28645)
2024-01-22|||[`Llava`] Update convert_llava_weights_to_hf.py script (#28617)
2024-01-22|||Fix lr_scheduler in no_trainer training scripts (#27872)
2024-01-22|||Add config tip to custom model docs (#28601)
2024-01-22|||Avoid root logger's level being changed (#28638)
2024-01-22|||Add missing key to TFLayoutLM signature (#28640)
2024-01-22|||Fix id2label assignment in run_classification.py (#28590)
2024-01-21|||[`GPTNeoX`] Fix BC issue with 4.36 (#28602)
2024-01-19|||Fix auxiliary loss related code in transformers (#28406)
2024-01-19|||RWKV: raise informative exception when attempting to manipulate `past_key_values` (#28600)
2024-01-19|||Fix `_speculative_sampling` implementation (#28508)
2024-01-19|||Allow add_tokens for ESM (#28535)
2024-01-19|||[`Llava`] Fix convert_llava_weights_to_hf.py script (#28570)
2024-01-19|||[SigLIP] Don't pad by default (#28578)
2024-01-19|||Fix wrong xpu device in DistributedType.MULTI_XPU mode (#28386)
2024-01-19|||[Whisper] Finalize batched SOTA long-form generation (#27658)
2024-01-19|||feat: Sequential beam search (#26304)
2024-01-19|||Add w2v2bert to pipeline (#28585)
2024-01-19|||v4.38.dev.0
2024-01-19|||Don't save `processor_config.json` if a processor has no extra attribute  (#28584)
2024-01-18|||Making CTC training example more general (#28582)
2024-01-18|||[Whisper] Fix audio classification with weighted layer sum (#28563)
2024-01-18|||[Whisper Tok] Move token ids to CPU when computing offsets (#28485)
2024-01-18|||[ASR Pipe] Update init to set model type and subsequently call parent init method (#28486)
2024-01-18|||Fix the documentation checkpoint for xlm-roberta-xl (#28567)
2024-01-18|||Use `LoggingLevel` context manager in 3 tests (#28575)
2024-01-18|||Add new meta w2v2-conformer BERT-like model (#28165)
2024-01-18|||chore: Fix multiple typos (#28574)
2024-01-18|||[`Core Tokenization`] Support a fix for spm fast models (#26678)
2024-01-18|||Use `weights_only` only if torch >= 1.13 (#28506)
2024-01-18|||Save `Processor` (#27761)
2024-01-17|||Fix Switch Transformers When sparse_step = 1 (#28564)
2024-01-18|||Allow to train dinov2 with different dtypes like bf16 (#28504)
2024-01-17|||Fix SDPA tests (#28552)
2024-01-17|||Add qwen2 (#28436)
2024-01-17|||Fixes default value of `softmax_scale` in `PhiFlashAttention2`. (#28537)
2024-01-17|||symbolic_trace: add past_key_values, llama, sdpa support (#28447)
2024-01-17|||[Makefile] Exclude research projects from format (#28551)
2024-01-16|||Config: warning when saving generation kwargs in the model config (#28514)
2024-01-17|||Add is_model_supported for fx (#28521)
2024-01-16|||Clearer error for SDPA when explicitely requested (#28006)
2024-01-16|||[`SpeechT5Tokenization`]  Add copied from and fix the `convert_tokens_to_string` to match the fast decoding scheme (#28522)
2024-01-16|||[`TokenizationRoformerFast`]  Fix the save and loading (#28527)
2024-01-16|||[ `TokenizationUtils`] Fix `add_special_tokens` when the token is already there (#28520)
2024-01-16|||Fix/speecht5 bug (#28481)
2024-01-16|||Fix mismatching loading in from_pretrained with/without accelerate (#28414)
2024-01-16|||Improving Training Performance and Scalability Documentation (#28497)
2024-01-16|||Remove `task` arg in `load_dataset` in image-classification example (#28408)
2024-01-15|||SiLU activation wrapper for safe importing (#28509)
2024-01-15|||improve dev setup comments and hints (#28495)
2024-01-15|||fix: sampling in flax keeps EOS (#28378)
2024-01-15|||Generate: consolidate output classes (#28494)
2024-01-15|||Add a use_safetensors arg to TFPreTrainedModel.from_pretrained() (#28511)
2024-01-15|||Fixed minor typos (#28489)
2024-01-15|||[GPTQ] Fix test (#28018)
2024-01-15|||Tokenizer kwargs in textgeneration pipe (#28362)
2024-01-15|||Add the XPU device check for pipeline mode (#28326)
2024-01-15|||[`core`/ FEAT] Add the possibility to push custom tags using `PreTrainedModel` itself (#28405)
2024-01-15|||Don't set `finetuned_from` if it is a local path  (#28482)
2024-01-15|||[`chore`] Update warning text, a word was missing (#28017)
2024-01-15|||Fix paths to AI Sweden Models reference and model loading (#28423)
2024-01-13|||Generate: fix candidate device placement (#28493)
2024-01-13|||Adding Prompt lookup decoding (#27775)
2024-01-12|||Change progress logging to once across all nodes (#28373)
2024-01-12|||Fix docstrings and update docstring checker error message (#28460)
2024-01-12|||TF: purge `TFTrainer` (#28483)
2024-01-12|||Generate: refuse to save bad generation config files (#28477)
2024-01-12|||Docs: add model paths (#28475)
2024-01-12|||Generate: deprecate old public functions (#28478)
2024-01-12|||Fix torch.ones usage in xlnet (#28471)
2024-01-12|||Bump jinja2 from 2.11.3 to 3.1.3 in /examples/research_projects/decision_transformer (#28457)
2024-01-12|||[`Mixtral` / `Awq`] Add mixtral fused modules for Awq  (#28240)
2024-01-12|||Update metadata loading for oneformer (#28398)
2024-01-12|||Mark two logger tests as flaky (#28458)
2024-01-12|||[`Awq`] Add llava fused modules support (#28239)
2024-01-12|||Fix broken link on page (#28451)
2024-01-11|||Fix docstring checker issues with PIL enums (#28450)
2024-01-12|||Doc (#28431)
2024-01-11|||Byebye torch 1.10 (#28207)
2024-01-11|||Fix load balancing loss func for mixtral (#28256)
2024-01-11|||Correctly resolve trust_remote_code=None for AutoTokenizer (#28419)
2024-01-11|||[Phi] Extend implementation to use GQA/MQA. (#28163)
2024-01-11|||Optionally preprocess segmentation maps for MobileViT (#28420)
2024-01-11|||Set `cache_dir` for `evaluate.load()` in example scripts (#28422)
2024-01-11|||Fix docker file (#28452)
2024-01-11|||Use python 3.10 for docbuild (#28399)
2024-01-11|||Optimize the speed of the truncate_sequences function. (#28263)
2024-01-11|||Enable multi-label image classification in pipeline (#28433)
2024-01-11|||Assitant model may on a different device (#27995)
2024-01-10|||[Whisper] Fix slow test (#28407)
2024-01-10|||[docstring] Fix docstring for ErnieConfig, ErnieMConfig (#27029)
2024-01-10|||Fix load correct tokenizer in Mixtral model documentation (#28437)
2024-01-10|||Fix for checkpoint rename race condition (#28364)
2024-01-10|||update docs to add the `phi-2` example (#28392)
2024-01-10|||CI: limit natten version (#28432)
2024-01-10|||Fix number of models in README.md (#28430)
2024-01-10|||Support `DeepSpeed` when using auto find batch size (#28088)
2024-01-10|||Skip now failing test in the Trainer tests (#28421)
2024-01-10|||[BUG] BarkEosPrioritizerLogitsProcessor eos_token_id use list, tensor size mismatch (#28201)
2024-01-10|||Bump fonttools from 4.31.1 to 4.43.0 in /examples/research_projects/decision_transformer (#28417)
2024-01-10|||Use mmap option to load_state_dict (#28331)
2024-01-10|||Fix `_merge_input_ids_with_image_features` for llava model (#28333)
2024-01-09|||Fix initialization for missing parameters in `from_pretrained` under ZeRO-3 (#28245)
2024-01-09|||fix auxiliary loss training in DetrSegmentation (#28354)
2024-01-09|||[SDPA] Make sure attn mask creation is always done on CPU (#28400)
2024-01-09|||update warning for image processor loading (#28209)
2024-01-08|||Add SigLIP (#26522)
2024-01-08|||Add segmentation map processing to SAM Image Processor (#27463)
2024-01-08|||Remove shell=True from subprocess.Popen to Mitigate Security Risk (#28299)
2024-01-08|||[AttentionMaskConverter] fix sdpa unmask unattended (#28369)
2024-01-08|||Bugfix / ffmpeg input device (mic) not working on Windows (#27051)
2024-01-08|||remove two deprecated function (#28220)
2024-01-08|||Fix building alibi tensor when num_heads is not a power of 2 (#28380)
2024-01-08|||Enhancing Code Readability and Maintainability with Simplified Activation Function Selection. (#28349)
2024-01-07|||[Phi2] Add support for phi2 models (#28211)
2024-01-05|||chore: Fix typo s/exclusivelly/exclusively/ (#28361)
2024-01-05|||Update VITS modeling to enable ONNX export (#28141)
2024-01-05||| fix FA2 when using quantization for remaining models (#28341)
2024-01-05|||[DETA] Improvement and Sync from DETA especially for training (#27990)
2024-01-05|||Fix pos_mask application and update tests accordingly (#27892)
2024-01-05|||Don't check the device when device_map=auto (#28351)
2024-01-04|||README: install transformers from conda-forge channel (#28313)
2024-01-04|||Fix error in M4T feature extractor (#28340)
2024-01-04|||enable training mask2former and maskformer for transformers trainer (#28277)
2024-01-03|||[docs] Sort es/toctree.yml | Translate performance.md (#28262)
2024-01-04|||Translate contributing.md into Chinese (#28243)
2024-01-03|||Remove token_type_ids from model_input_names (like #24788) (#28325)
2024-01-03|||Add FastSpeech2Conformer (#23439)
2024-01-03|||fix documentation for zero_shot_object_detection (#28267)
2024-01-03|||Bump tj-actions/changed-files from 22.2 to 41 in /.github/workflows (#28311)
2024-01-02|||Remove fast tokenization warning in Data Collators (#28213)
2024-01-02|||[Whisper] Fix errors with MPS backend introduced by new code on word-level timestamps computation (#28288)
2024-01-02|||fix bug:divide by zero in _maybe_log_save_evaluate() (#28251)
2024-01-02|||Fix trainer saving safetensors: metadata is None (#28219)
2024-01-02|||Update docs around mixing hf scheduler with deepspeed optimizer (#28223)
2023-12-26|||small typo (#28229)
2023-12-26|||fix FA2 when using quantization (#28203)
2023-12-25|||[`Awq`] Enable the possibility to skip quantization for some target modules (#27950)
2023-12-22|||[`Llava`] Fix llava index errors (#28032)
2023-12-22|||update the logger message with accordant weights_file_name (#28181)
2023-12-22|||Fixing visualization code for object detection to support both types of bounding box.  (#27842)
2023-12-22|||[Whisper] Fix word-level timestamps with bs>1 or num_beams>1 (#28114)
2023-12-22|||Drop `feature_extractor_type` when loading an image processor file (#28195)
2023-12-22|||Fix the check of models supporting FA/SDPA not run (#28202)
2023-12-22|||Bug: `training_args.py` fix missing import with accelerate with version `accelerate==0.20.1` (#28171)
2023-12-22|||Add Swinv2 backbone (#27742)
2023-12-22|||Fix: [SeamlessM4T - S2TT] Bug in batch loading of audio in torch.Tensor format in the SeamlessM4TFeatureExtractor class (#27914)
2023-12-22|||Fix ONNX export for causal LM sequence classifiers by removing reverse indexing (#28144)
2023-12-22|||Update `docs/source/en/perf_infer_gpu_one.md` (#28198)
2023-12-22|||[`Docs`]¬†Add 4-bit serialization docs (#28182)
2023-12-21|||Update YOLOS slow test values (#28187)
2023-12-21|||Fix slow backbone tests - out_indices must match stage name ordering (#28186)
2023-12-21|||Even more TF test fixes (#28146)
2023-12-21|||[`Mixtral` & `Mistral`] Add support for sdpa (#28133)
2023-12-21|||[Whisper] Use torch for stft if available (#26119)
2023-12-21|||Fix `input_embeds` docstring in encoder-decoder architectures (#28168)
2023-12-21|||[bnb] Let's make serialization of 4bit models possible  (#26037)
2023-12-21|||disable test_retain_grad_hidden_states_attentions on SeamlessM4TModelWithTextInputTest (#28169)
2023-12-20|||Fix yolos resizing (#27663)
2023-12-20|||Generate: fix speculative decoding (#28166)
2023-12-20|||[docs] Trainer docs (#28145)
2023-12-20|||Align backbone stage selection with out_indices & out_features (#27606)
2023-12-20|||Update FA2 exception msg to point to hub discussions (#28161)
2023-12-20|||Avoid unnecessary warnings when loading `CLIPConfig` (#28108)
2023-12-20|||Fix weights not properly initialized due to shape mismatch (#28122)
2023-12-20|||move code to Trainer.evaluate to enable use of that function with multiple datasets (#27844)
2023-12-20|||[gpt-neox] Add attention_bias config to support model trained without attention biases (#28126)
2023-12-20|||Fix FA2 integration (#28142)
2023-12-19|||Remove deprecated CPU dockerfiles (#28149)
2023-12-19|||[docs] Fix mistral link in mixtral.md (#28143)
2023-12-19|||Update modeling_utils.py (#28127)
2023-12-19|||[`Mixtral`] Fix loss + nits (#28115)
2023-12-19|||Generate: speculative decoding (#27979)
2023-12-19|||Update split string in doctest to reflect #28087 (#28135)
2023-12-19|||When save a model on TPU, make a copy to be moved to CPU (#27993)
2023-12-18|||[Doc] Fix token link in What ü§ó Transformers can do (#28123)
2023-12-18|||Fix a typo in tokenizer documentation (#28118)
2023-12-18|||[docs] General doc fixes (#28087)
2023-12-18|||Fix indentation error - semantic_segmentation.md (#28117)
2023-12-18|||More TF fixes (#28081)
2023-12-18|||Remove warning if `DISABLE_TELEMETRY` is used (#28113)
2023-12-18|||Disable jitter noise during evaluation in SwitchTransformers (#28077)
2023-12-18|||fix ConversationalPipeline docstring (#28091)
2023-12-18|||in peft finetune, only the trainable parameters need to be saved (#27825)
2023-12-18|||Spelling correction (#28110)
2023-12-18|||[`Llava` / `Vip-Llava`] Add SDPA into llava (#28107)
2023-12-17|||Fix the deprecation warning of _torch_pytree._register_pytree_node (#27803)
2023-12-17|||4D `attention_mask` support (#27539)
2023-12-16|||fix resuming from ckpt when using FSDP with FULL_STATE_DICT (#27891)
2023-12-15|||[docs] MPS (#28016)
2023-12-15|||[docs] Trainer (#27986)
2023-12-15|||Fix Vip-llava docs (#28085)
2023-12-16|||Fix wrong examples in llava usage. (#28020)
2023-12-16|||Fix `low_cpu_mem_usage` Flag Conflict with DeepSpeed Zero 3 in `from_pretrained` for Models with `keep_in_fp32_modules`" (#27762)
2023-12-15|||Update fixtures-image-utils (#28080)
2023-12-16|||Fix bug for checkpoint saving on multi node training setting (#28078)
2023-12-15|||make torch.load a bit safer (#27282)
2023-12-15|||Make GPT2 traceable in meta state (#28054)
2023-12-15|||[LLaVa] Add past_key_values to _skip_keys_device_placement to fix multi-GPU dispatch (#28051)
2023-12-15|||Skip M4T `test_retain_grad_hidden_states_attentions`  (#28060)
2023-12-15|||[`Mixtral`]¬†update conversion script to reflect new changes (#28068)
2023-12-15|||doc: Correct spelling mistake (#28064)
2023-12-15|||Remove SpeechT5 deprecated argument (#28062)
2023-12-15|||[Flax LLaMA] Fix attn dropout (#28059)
2023-12-15|||[Flax BERT] Update deprecated 'split' method (#28012)
2023-12-15|||[`Modeling` / `Mixtral`] Fix GC + PEFT issues with Mixtral (#28061)
2023-12-15|||[`FA-2`] Fix fa-2 issue when passing `config` to `from_pretrained` (#28043)
2023-12-14|||Remove warning when Annotion enum is created (#28048)
2023-12-14|||Replace build() with build_in_name_scope() for some TF tests (#28046)
2023-12-14|||Proper build() methods for TF (#27794)
2023-12-14|||[Seamless] Fix links in docs (#27905)
2023-12-14|||Generate: Mistral/Mixtral FA2 cache fix when going beyond the context window (#28037)
2023-12-14|||Fixed spelling error in T5 tokenizer warning message (s/thouroughly/t‚Ä¶ (#28014)
2023-12-14|||Fix languages covered by M4Tv2 (#28019)
2023-12-14|||SeamlessM4T: `test_retain_grad_hidden_states_attentions` is flaky (#28035)
2023-12-14|||Generate: assisted decoding now uses `generate` for the assistant (#28030)
2023-12-14|||Fix AMD push CI not triggered (#28029)
2023-12-14|||[`core` / `modeling`] Fix training bug with PEFT + GC (#28031)
2023-12-14|||[`SeamlessM4TTokenizer`]  Safe import (#28026)
2023-12-14|||well well well (#28011)
2023-12-13|||add `modules_in_block_to_quantize` arg in GPTQconfig (#27956)
2023-12-13|||Add model_docs from cpmant.md to derformable_detr.md (#27884)
2023-12-13|||Dev version
2023-12-13|||[Doc] Spanish translation of glossary.md (#27958)
2023-12-13|||Fix bug with rotating checkpoints (#28009)
2023-12-13|||[`CI slow`] Fix expected values (#27999)
2023-12-13|||Fix PatchTSMixer slow tests (#27997)
2023-12-13|||Adds VIP-llava to transformers (#27932)
2023-12-13|||[`Whisper`] raise better errors (#27971)
2023-12-13|||[`Tokenizer Serialization`] Fix the broken serialisation  (#27099)
2023-12-12|||fix typo in dvclive callback (#27983)
2023-12-12|||[doc] fix typo (#27981)
2023-12-12|||Fix SDPA correctness following torch==2.1.2 regression (#27973)
2023-12-12|||Better key error for AutoConfig (#27976)
2023-12-12|||Fix link in README.md of Image Captioning (#27969)
2023-12-12|||Hot-fix-mixstral-loss (#27948)
2023-12-12|||Generate: `assisted_decoding` now accepts arbitrary candidate generators (#27750)
2023-12-11|||fixed typos (issue 27919) (#27920)
2023-12-12|||Support PeftModel signature inspect (#27865)
2023-12-11|||[docs] Fused AWQ modules (#27896)
2023-12-11|||Update bounding box format everywhere (#27944)
2023-12-11|||[`Mixtral`] Change mistral op order (#27955)
2023-12-11|||fix no sequence length models error (#27522)
2023-12-11|||Fix for stochastic depth decay rule in the TimeSformer implementation (#27875)
2023-12-12|||fix bug in mask2former: cost matrix is infeasible (#27897)
2023-12-11|||Fix a couple of typos and add an illustrative test (#26941)
2023-12-11|||Add deepspeed test to amd scheduled CI (#27633)
2023-12-11|||Fix AMD scheduled CI not triggered (#27951)
2023-12-11|||In PreTrainedTokenizerBase add missing word in error message (#27949)
2023-12-11|||Fix parameter count in readme for mixtral 45b (#27945)
2023-12-11|||Update import message (#27946)
2023-12-11|||Fix test for auto_find_batch_size on multi-GPU (#27947)
2023-12-11|||Docs for AutoBackbone & Backbone (#27456)
2023-12-11|||use logger.warning_once to avoid massive outputs (#27428)
2023-12-11|||Fix PatchTSMixer Docstrings (#27943)
2023-12-11|||[`Add Mixtral`] Adds support for the Mixtral MoE (#27942)
2023-12-11|||[`from_pretrained`] Make from_pretrained fast again (#27709)
2023-12-11|||Fix SDPA dispatch & make SDPA CI compatible with torch<2.1.1 (#27940)
2023-12-11|||[LLaVa] Some improvements (#27895)
2023-12-11|||Fix `SeamlessM4Tv2ModelIntegrationTest` (#27911)
2023-12-11|||Skip `UnivNetModelTest::test_multi_gpu_data_parallel_forward` (#27912)
2023-12-11|||[BEiT] Fix test (#27934)
2023-12-11|||[DETA] fix backbone freeze/unfreeze function (#27843)
2023-12-09|||Fix typo (#27918)
2023-12-09|||[integration] Update Ray Tune integration for Ray 2.7 (#26499)
2023-12-09|||[CLAP] Replace hard-coded batch size to enable dynamic ONNX export (#27790)
2023-12-08|||F.scaled_dot_product_attention support (#26572)
2023-12-08|||Generate: SinkCache can handle iterative prompts (#27907)
2023-12-09|||fix typo in image_processing_blip.py Wwhether -> Whether (#27899)
2023-12-08|||[Doc] Spanish translation of pad_truncation.md (#27890)
2023-12-08|||Allow `resume_from_checkpoint` to handle `auto_find_batch_size` (#27568)
2023-12-08|||fix llava (#27909)
2023-12-08|||Llama conversion script: adjustments for Llama Guard (#27910)
2023-12-08|||Fix 2 tests in `FillMaskPipelineTests` (#27889)
2023-12-08|||Fix `notification_service.py` (#27903)
2023-12-08|||mark `test_initialization` as flaky in 2 model tests (#27906)
2023-12-08|||Fix CLAP converting script (#27153)
2023-12-08|||Fix remaining issues in beam score calculation (#27808)
2023-12-08|||Fix beam score calculation issue for Tensorflow version (#27814)
2023-12-08|||fix: non-atomic checkpoint save (#27820)
2023-12-08|||Added passing parameters to "reduce_lr_on_plateau" scheduler (#27860)
2023-12-08|||Fix: Raise informative exception when `prefix_allowed_tokens_fn` return empty set of tokens (#27797)
2023-12-08|||[‚ö†Ô∏è removed a default argument] Make `AttentionMaskConverter` compatible with `torch.compile(..., fullgraph=True)` (#27868)
2023-12-08|||Generate: New `Cache` abstraction and Attention Sinks support (#26681)
2023-12-08|||Translate `model_doc` files from `clip` to `cpm`  to JP (#27774)
2023-12-07|||Updates the distributed CPU training documentation to add instructions for running on a Kubernetes cluster (#27780)
2023-12-07|||[docs] Custom semantic segmentation dataset (#27859)
2023-12-07|||Generate: All logits processors are documented and have examples (#27796)
2023-12-07|||Fix TF loading PT safetensors when weights are tied (#27490)
2023-12-07|||Show new failing tests in a more clear way in slack report (#27881)
2023-12-07|||Fix device of masks in tests (#27887)
2023-12-07|||update version of warning notification for `get_default_device` to v4.38 (#27848)
2023-12-07|||update `create_model_card` to properly save peft details when using Trainer with PEFT (#27754)
2023-12-07|||Allow `# Ignore copy` (#27328)
2023-12-07|||[`Llava`]¬†Add Llava to transformers (#27662)
2023-12-07|||fix: fix gradient accumulate step for learning rate (#27667)
2023-12-07|||[`FA-2`] Add Flash Attention to `Phi` (#27661)
2023-12-07|||[i18n-fr] Translate autoclass tutorial to French (#27659)
2023-12-07|||Fix bug of _prepare_4d_attention_mask (#27847)
2023-12-07|||Add Llama Flax Implementation (#24587)
2023-12-07|||Fix beam score calculation issue for JAX version (#27816)
2023-12-07|||Translating en/model_doc folder docs to Japanese(from `blip` to `clap`) üáØüáµ (#27673)
2023-12-06|||[`Flash Attention 2`] Add flash attention 2 for GPT-Neo-X (#26463)
2023-12-06|||Avoid class attribute `_keep_in_fp32_modules` being modified (#27867)
2023-12-06|||removed the delete doc workflows (#27852)
2023-12-05|||Update CUDA versions for DeepSpeed (#27853)
2023-12-05|||[`Docs`] Update broken image on fused modules (#27856)
2023-12-05|||Documentation: Spanish translation of perplexity.mdx (#27807)
2023-12-05|||fix(whisper): mutable generation config (#27833)
2023-12-05|||Update `VitDetModelTester.get_config` to use `pretrain_image_size` (#27831)
2023-12-05|||‚ö†Ô∏è [VitDet] Fix test (#27832)
2023-12-05|||[Time series] Add PatchTSMixer (#26247)
2023-12-05|||Move tensors to same device to enable IDEFICS naive MP training (#27746)
2023-12-05|||[`ClipVision`] `accelerate` support for clip-vision (#27851)
2023-12-05|||Generate: Update VisionEncoderDecoder test value (#27850)
2023-12-05|||Faster generation using AWQ + Fused modules (#27411)
2023-12-05|||Make image processors more general (#27690)
2023-12-05|||pin `ruff==0.1.5` (#27849)
2023-12-05|||Translate `en/tasks` folder docs to Japanese üáØüáµ (#27098)
2023-12-05|||translate internal folder files to chinese (#27638)
2023-12-04|||[Seamless v2] Add FE to auto mapping (#27829)
2023-12-04|||Disallow `pickle.load` unless `TRUST_REMOTE_CODE=True` (#27776)
2023-12-04|||restructure AMD scheduled CI (#27743)
2023-12-04|||single word should be set to False (#27738)
2023-12-04|||[Hot-Fix][XLA] Re-enable broken _tpu_save for XLATensors (#27799)
2023-12-04|||Flash Attention 2 support for RoCm (#27611)
2023-12-04|||Added test cases for rembert refering to albert and reformer test_tok‚Ä¶ (#27637)
2023-12-04|||[Whisper] Fix doctest in timestamp logits processor (#27795)
2023-12-04|||[Seamless v1] Link to v2 docs (#27827)
2023-12-04|||Keypoints 0.0 are confusing ../transformers/models/detr/image_processing_detr.py which are fixed (#26250)
2023-12-04|||Fix `Owlv2ModelIntegrationTest::test_inference_object_detection` (#27793)
2023-12-04|||Fix `TvpModelIntegrationTests` (#27792)
2023-12-04|||[`ModelOnTheFlyConversionTester`] Mark as slow for now (#27823)
2023-12-04|||Add `persistent_workers` parameter to `TrainingArguments` (#27189)
2023-12-04|||Fix typo in max_length deprecation warnings (#27788)
2023-12-04|||Improve forward signature test (#27729)
2023-12-03|||[JAX] Replace uses of jax.devices("cpu") with jax.local_devices(backend="cpu") (#27593)
2023-12-01|||[MusicGen] Fix audio channel attribute (#27440)
2023-12-01|||Better error message for bitsandbytes import  (#27764)
2023-12-01|||Make using safetensors files automated. (#27571)
2023-12-01|||Fixes for PatchTST Config (#27777)
2023-12-01|||[i18n-fr] Translate installation to French (#27657)
2023-12-01|||[SeamlessM4Tv2] Fix links in README (#27782)
2023-12-01|||Fix unsupported setting of self._n_gpu in training_args on XPU devices (#27716)
2023-11-30|||Add SeamlessM4T v2 (#27779)
2023-11-30|||Generate: `GenerationConfig` throws an exception when `generate` args are passed (#27757)
2023-11-30|||uses dvclive_test mode in examples/pytorch/test_accelerate_examples.py (#27763)
2023-11-30|||Remove `check_runner_status.yml` (#27767)
2023-11-29|||Fix precision errors from casting rotary parameters to FP16 with AMP (#27700)
2023-11-29|||[Time series] Add patchtst (#27581)
2023-11-28|||[docs] Quantization (#27641)
2023-11-28|||Docs: Fix broken cross-references, i.e. `~transformer.` -> `~transformers.` (#27740)
2023-11-28|||CLVP Fixes (#27547)
2023-11-28|||Trigger corresponding pipeline tests if `tests/utils/tiny_model_summary.json` is modified (#27693)
2023-11-28|||Enforce pin memory disabling when using cpu only (#27745)
2023-11-28|||Add madlad-400 MT models (#27471)
2023-11-28|||Log a warning in `TransfoXLTokenizer.__init__` (#27721)
2023-11-28|||Update tiny model creation script (#27674)
2023-11-28|||Add BeitBackbone (#25952)
2023-11-28|||Fix AMD Push CI not triggered (#27732)
2023-11-28|||Fixed passing scheduler-specific kwargs via TrainingArguments lr_scheduler_kwargs (#27595)
2023-11-28|||Translate  `en/model_doc` to JP (#27264)
2023-11-28|||translation main-class files to chinese (#27588)
2023-11-27|||Update chat template warnings/guides (#27634)
2023-11-28|||docs: replace torch.distributed.run by torchrun (#27528)
2023-11-27|||Fix owlv2 code snippet (#27698)
2023-11-27|||Modify group_sub_entities in TokenClassification Pipeline to support label with "-" (#27325)
2023-11-27|||Update forward signature test for vision models (#27681)
2023-11-27|||fix assisted decoding assistant model inputs (#27503)
2023-11-27|||Fix oneformer instance segmentation RuntimeError (#27725)
2023-11-27|||Fix mistral generate for long prompt / response (#27548)
2023-11-27|||Reorder the code on the Hub to explicit that sharing on the Hub isn't a requirement (#27691)
2023-11-27|||fix warning (#27689)
2023-11-27|||Fix Past CI (#27696)
2023-11-26|||Fix sliding_window hasattr in Mistral (#27041)
2023-11-24|||Fix `TVPModelTest` (#27695)
2023-11-24|||Successfully Resolved The ZeroDivisionError Exception. (#27524)
2023-11-24|||Reflect RoCm support in the documentation (#27636)
2023-11-24|||[`DocString`] Support a revision in the docstring `add_code_sample_docstrings` to facilitate integrations (#27645)
2023-11-24|||Fix semantic error in evaluation section (#27675)
2023-11-24|||Docs/Add conversion code to the musicgen docs (#27665)
2023-11-24|||Fix typo in warning message (#27055)
2023-11-24|||Deprecate `TransfoXL` (#27607)
2023-11-24|||Skip pipeline tests for 2 models for now (#27687)
2023-11-24|||Refactoring Trainer, adds `save_only_model` arg and simplifying FSDP integration (#27652)
2023-11-23|||Update tiny model summary file (#27388)
2023-11-23|||[DPT, Dinov2] Add resources (#27655)
2023-11-23|||Update TVP arxiv link (#27672)
2023-11-23|||Extended semantic segmentation to image segmentation (#27039)
2023-11-23|||[`FA2`] Add flash attention for opt (#26414)
2023-11-23|||update d_kv'annotation in mt5'configuration (#27585)
2023-11-23|||update Openai API call method (#27628)
2023-11-22|||Add UnivNet Vocoder Model for Tortoise TTS Diffusers Integration (#24799)
2023-11-22|||[Whisper] Add sequential longform decoding (#27492)
2023-11-22|||Fix `max_steps` documentation regarding the end-of-training condition (#27624)
2023-11-22|||Simplify the implementation of jitter noise in moe models (#27643)
2023-11-22|||[`dependency`] update pillow pins (#27409)
2023-11-22|||Fix `resize_token_embeddings` (#26861) (#26865)
2023-11-21|||Harmonize HF environment variables + other cleaning (#27564)
2023-11-21|||Explicitely specify `use_cache=True` in Flash Attention tests (#27635)
2023-11-22|||TVP model (#25856)
2023-11-22|||remove the deprecated method `init_git_repo` (#27617)
2023-11-21|||Fix tracing dinov2 (#27561)
2023-11-21|||Fix flash attention bugs with Mistral and Falcon (#27625)
2023-11-21|||Add RoCm scheduled CI & upgrade RoCm CI to PyTorch 2.1 (#26940)
2023-11-21|||Idefics: Fix information leak with cross attention gate in modeling (#26839)
2023-11-21|||Generate: Update docs regarding reusing `past_key_values` in `generate` (#27612)
2023-11-21|||[ConvNext] Improve backbone (#27621)
2023-11-21|||[`core` / `gradient_checkpointing`] add support for old GC method (#27610)
2023-11-21|||dvclive callback: warn instead of fail when logging non-scalars (#27608)
2023-11-20|||Fix torch.fx import issue for torch 1.12 (#27570)
2023-11-21|||Update Korean tutorial for using LLMs, and refactor the nested conditional statements in hr_argparser.py (#27489)
2023-11-21|||[Whisper] Add `large-v3` version support (#27336)
2023-11-20|||timm to pytorch conversion for vit model fix (#26908)
2023-11-20|||[`FA-2`] Add fa2 support for `from_config` (#26914)
2023-11-20|||[ examples] fix loading jsonl with load dataset in run translation example (#26924)
2023-11-20|||docs: fix 404 link (#27529)
2023-11-20|||Add `convert_hf_to_openai.py` script to Whisper documentation resources (#27590)
2023-11-20|||Fix idx2sym not loaded from pretrained vocab file in Transformer XL (#27589)
2023-11-19|||Adding leaky relu in dict ACT2CLS (#27574)
2023-11-18|||Fix broken distilbert url (#27579)
2023-11-18|||translate deepspeed.md to chinese (#27495)
2023-11-18|||Broken links fixed related to datasets docs (#27569)
2023-11-17|||fixed broken link (#27560)
2023-11-17|||Generate: update compute transition scores doctest (#27558)
2023-11-17|||Generate: fix flaky tests (#27543)
2023-11-17|||Fix AMD CI not showing GPU (#27555)
2023-11-17|||Skip some fuyu tests (#27553)
2023-11-16|||translate Trainer.md to chinese (#27527)
2023-11-16|||Updated albert.md doc for ALBERT model (#27223)
2023-11-16|||Generate: improve assisted generation tests (#27540)
2023-11-16|||[`Styling`] stylify using ruff (#27144)
2023-11-16|||Disable docker image build job `latest-pytorch-amd` for now (#27541)
2023-11-16|||Raise error when quantizing a quantized model (#27500)
2023-11-16|||Set `usedforsecurity=False` in hashlib methods (FIPS compliance) (#27483)
2023-11-16|||Revert "add attention_mask and position_ids in assisted model" (#27523)
2023-11-16|||Update the TF pin for 2.15 (#27375)
2023-11-16|||docs: add docs for map, and add num procs to load_dataset (#27520)
2023-11-16|||[`pytest`] Avoid flash attn test marker warning (#27509)
2023-11-16|||Support ONNX export for causal LM sequence classifiers (#27450)
2023-11-16|||translate model.md to chinese (#27518)
2023-11-15|||Fix offload disk for loading derivated model checkpoint into base model (#27253)
2023-11-16|||Fix bug for T5x to PyTorch convert script with varying encoder and decoder layers (#27448)
2023-11-15|||Incorrect setting for num_beams in translation and summarization examples (#27519)
2023-11-15|||Fixing the failure of models without max_position_embeddings attribute. (#27499)
2023-11-16|||Translating `en/model_doc` docs to Japanese. (#27401)
2023-11-15|||Fix wav2vec2 params (#27515)
2023-11-15|||[ `PretrainedConfig`] Improve messaging  (#27438)
2023-11-15|||üö®üö® Fix beam score calculation issue for decoder-only models (#27351)
2023-11-15|||[`tokenizers`] update `tokenizers` version pin (#27494)
2023-11-15|||Make some jobs run on the GitHub Actions runners (#27512)
2023-11-15|||[`CircleCI`] skip test_assisted_decoding_sample for everyone (#27511)
2023-11-15|||Update spelling mistake (#27506)
2023-11-15|||[Table Transformer] Add Transformers-native checkpoints (#26928)
2023-11-15|||[Fuyu] Add tests (#27001)
2023-11-15|||[`CI-test_torch`] skip test_tf_from_pt_safetensors and `test_assisted_decoding_sample`  (#27508)
2023-11-14|||Track the number of tokens seen to metrics (#27274)
2023-11-14|||Update processor mapping for hub snippets (#27477)
2023-11-14|||Have seq2seq just use gather (#27025)
2023-11-14|||Minor type annotation fix (#27276)
2023-11-14|||Generate: `GenerationConfig.from_pretrained` can return unused kwargs (#27488)
2023-11-14|||Update and reorder docs for chat templates (#27443)
2023-11-14|||Generate: fix `ExponentialDecayLengthPenalty` doctest (#27485)
2023-11-14|||translate hpo_train.md and perf_hardware.md to chinese (#27431)
2023-11-14|||Revert "[time series] Add PatchTST (#25927)" (#27486)
2023-11-14|||[Whisper] Fix pipeline test (#27442)
2023-11-14|||Clap processor: remove wasteful np.stack operations (#27454)
2023-11-14|||Add speecht5 batch generation and fix wrong attention mask when padding (#25943)
2023-11-14|||Fix M4T weights tying (#27395)
2023-11-14|||[`CI-test_torch`] skip `test_tf_from_pt_safetensors` for 4 models (#27481)
2023-11-14|||[`Peft`] `modules_to_save` support for peft integration (#27466)
2023-11-14|||Fix FA2 import + deprecation cycle  (#27330)
2023-11-13|||[time series] Add PatchTST (#25927)
2023-11-13|||Fixed typo in pipelines.md documentation (#27455)
2023-11-13|||Perf torch compile (#27422)
2023-11-13|||[`AWQ` ] Addresses TODO for awq tests (#27467)
2023-11-13|||Fix Falcon tokenizer loading in pipeline (#27316)
2023-11-13|||Add version check for Jinja (#27403)
2023-11-13|||Add DINOv2 depth estimation (#26092)
2023-11-13|||Install `python-Levenshtein` for `nougat` in CI image (#27465)
2023-11-13|||Fix docstring for `gradient_checkpointing_kwargs` (#27470)
2023-11-13|||OWLv2: bug fix in post_process_object_detection() when using cuda device (#27468)
2023-11-13|||Fix `from_pt` flag when loading with `safetensors` (#27394)
2023-11-13|||Default to msgpack for safetensors (#27460)
2023-11-13|||[`Llama + Mistral`] Add attention dropout (#27315)
2023-11-13|||Remove-auth-token (#27060)
2023-11-13|||Fixed typo in error message (#27461)
2023-11-13|||Fix some Wav2Vec2 related models' doctest (#27462)
2023-11-13|||Fix line ending in `utils/not_doctested.txt` (#27459)
2023-11-10|||Make `examples_torch_job` faster (#27437)
2023-11-10|||Normalize floating point cast (#27249)
2023-11-10|||Add Phi-1 and Phi-1_5 (#26170)
2023-11-10|||At most 2 GPUs for CI (#27435)
2023-11-10|||[`AttentionMaskConverter`] ]Fix-mask-inf (#27114)
2023-11-10|||Add CLVP (#24745)
2023-11-10|||update Bark FA2 docs (#27400)
2023-11-10|||[`Quantization`] Add str to enum conversion for AWQ (#27320)
2023-11-10|||add attention_mask and position_ids in assisted model (#26892)
2023-11-09|||Run all tests if `circleci/create_circleci_config.py` is modified (#27413)
2023-11-09|||Fix `Owlv2` checkpoint name and a default value in `Owlv2VisionConfig` (#27402)
2023-11-09|||remove failing tests and clean FE files (#27414)
2023-11-09|||Fix RequestCounter to make it more future-proof (#27406)
2023-11-09|||Final fix of the accelerate installation issue (#27408)
2023-11-09|||Use editable install for git deps (#27404)
2023-11-09|||Fix fuyu checkpoint repo in `FuyuConfig` (#27399)
2023-11-09|||use `pytest.mark` directly (#27390)
2023-11-09|||Adds dvclive callback (#27352)
2023-11-09|||device-agnostic deepspeed testing (#27342)
2023-11-09|||Skip failing cache call tests (#27393)
2023-11-09|||Put doctest options back to `pyproject.toml` (#27366)
2023-11-09|||Change thresh in test (#27378)
2023-11-09|||[`CodeLlamaTokenizer`] Nit, update __init__ to make sure the AddedTokens are not normalized because they are special (#27359)
2023-11-09|||Smangrul/fix failing ds ci tests (#27358)
2023-11-08|||translate debugging.md to chinese (#27374)
2023-11-08|||Update deprecated `torch.range` in `test_modeling_ibert.py` (#27355)
2023-11-08|||Add Flash Attention 2 support to Bark (#27364)
2023-11-08|||translate big_models.md and performance.md to chinese (#27334)
2023-11-08|||Fix tiny model script: not using `from_pt=True` (#27372)
2023-11-08|||[Flax Whisper] large-v3 compatibility (#27360)
2023-11-08|||Remove unused param from example script tests (#27354)
2023-11-08|||Translate index.md to Turkish (#27093)
2023-11-08|||MusicGen Update (#27084)
2023-11-08|||Fix `Kosmos-2` device issue (#27346)
2023-11-08|||Fix example tests from failing (#27353)
2023-11-08|||moving example of benchmarking to legacy dir (#27337)
2023-11-08|||Add numpy alternative to FE using torchaudio (#26339)
2023-11-07|||translate model_sharing.md and llm_tutorial.md to chinese (#27283)
2023-11-08|||translate the en tokenizer_summary.md to Chinese (#27291)
2023-11-08|||Allow scheduler parameters (#26480)
2023-11-07|||FIx Bark batching feature (#27271)
2023-11-07|||[`Whisper`]  Nit converting the tokenizer (#27349)
2023-11-07|||Remove padding_masks from `gpt_bigcode`. (#27348)
2023-11-07|||Resolve AttributeError by utilizing device calculation at the start of the forward function (#27347)
2023-11-07|||Remove a redundant variable. (#27288)
2023-11-07|||[`Whisper`]  Add conversion script for the tokenizer  (#27338)
2023-11-07|||[`FA2`] Add flash attention for `GPT-Neo` (#26486)
2023-11-07|||Fix Whisper Conversion Script: Correct decoder_attention_heads and _download function (#26834)
2023-11-07|||Generate: skip tests on unsupported models instead of passing (#27265)
2023-11-07|||Fix autoawq docker image (#27339)
2023-11-07|||[Whisper] Block language/task args for English-only (#27322)
2023-11-06|||[docs] fixed links with 404 (#27327)
2023-11-06|||Fix `Kosmos2Processor` batch mode (#27323)
2023-11-06|||Fix VideoMAEforPretrained dtype error (#27296)
2023-11-06|||Update sequence_classification.md (#27281)
2023-11-06|||[`PretrainedTokenizer`] add some of the most important functions to the doc (#27313)
2023-11-06|||enable memory tracker metrics for npu (#27280)
2023-11-06|||Remove an unexpected argument for FlaxResNetBasicLayerCollection (#27272)
2023-11-06|||Update doctest workflow file (#27306)
2023-11-06|||Fix daily CI image build (#27307)
2023-11-06|||Fix tokenizer export for LLamaTokenizerFast (#27222)
2023-11-03|||translate run_scripts.md to chinese (#27246)
2023-11-03|||translate autoclass_tutorial to chinese (#27269)
2023-11-03|||[`FA2`] Add flash attention for for `DistilBert` (#26489)
2023-11-03|||[Docs] Model_doc structure/clarity improvements (#26876)
2023-11-03|||[`Docs` / `SAM` ] Reflect correct changes to run inference without OOM  (#27268)
2023-11-03|||Fix switch transformer mixed precision issue (#27220)
2023-11-03|||Update the ConversationalPipeline docstring for chat templates (#27250)
2023-11-03|||[docs] Custom model doc update (#27213)
2023-11-03|||Avoid many failing tests in doctesting (#27262)
2023-11-03|||[`PEFT` / `Tests` ] Fix peft integration failing tests (#27258)
2023-11-03|||Refactor: Use Llama RoPE implementation for Falcon (#26933)
2023-11-03|||Fuyu protection (#27248)
2023-11-02|||Fixed base model class name extraction from PeftModels (#27162)
2023-11-02|||Removed the redundant SiLUActivation class. (#27136)
2023-11-02|||translate peft.md to chinese (#27215)
2023-11-02|||Dev version
2023-11-02|||Enrich TTS pipeline parameters naming (#26473)
2023-11-02|||Remove redundant code from T5 encoder mask creation (#27216)
2023-11-02|||Generate: return `past_key_values` (#25086)
2023-11-02|||fix-deprecated-exllama-arg (#27243)
2023-11-02|||Fixing m4t. (#27240)
2023-11-02|||Fix safetensors failing tests (#27231)
2023-11-02|||Wrap `_prepare_4d_causal_attention_mask` as a leaf function (#27236)
2023-11-02|||Fuyu: improve image processing (#27007)
2023-11-02|||[`core` / `Quantization`] Fix for 8bit serialization tests (#27234)
2023-11-02|||Reproducible checkpoint for npu (#27208)
2023-11-02|||support bf16 (#25879)
2023-11-01|||[Whisper, Bart, MBart] Add Flash Attention 2 (#27203)
2023-11-01|||Enable split_batches through TrainingArguments (#26798)
2023-11-01|||Fix CPU offload + disk offload tests (#27204)
2023-11-01|||Add exllamav2 better (#27111)
2023-11-01|||Translate task summary to chinese  (#27180)
2023-11-01|||improving TimmBackbone to support FrozenBatchNorm2d (#27160)
2023-11-01|||Fix docstring in get_oneformer_resize_output_image_size func (#27207)
2023-11-02|||Add TensorFlow implementation of ConvNeXTv2  (#25558)
2023-11-01|||[WhisperForCausalLM] Add WhisperForCausalLM for speculative decoding (#27195)
2023-11-01|||Added cache_block_outputs option to enable GPTQ for non-regular models (#27032)
2023-11-01|||added unsqueeze_dim to apply_rotary_pos_emb (#27117)
2023-11-01|||Fixing docstring in get_resize_output_image_size function (#27191)
2023-11-01|||Fix the typos and grammar mistakes in CONTRIBUTING.md. (#27193)
2023-11-01|||Fix docstring get maskformer resize output image size (#27196)
2023-11-01|||[`core` / `Quantization` ] AWQ integration (#27045)
2023-11-01|||device agnostic fsdp testing (#27120)
2023-11-01|||üåê [i18n-ZH] Translate tflite.md into Chinese (#27134)
2023-10-31|||Safetensors serialization by default (#27064)
2023-11-01|||Unify warning styles for better readability (#27184)
2023-11-01|||device agnostic models testing (#27146)
2023-10-31|||[docs] Update CPU/GPU inference docs (#26881)
2023-10-31|||translate traning.md to chinese (#27122)
2023-10-31|||Fix dropout in `StarCoder` (#27182)
2023-10-31|||[`Quantization` / `tests` ] Fix bnb MPT test (#27178)
2023-10-31|||Backward compatibility fix for the Conversation class (#27176)
2023-10-31|||[FEAT] Add Neftune into transformers Trainer (#27141)
2023-10-31|||device agnostic pipelines testing (#27129)
2023-10-31|||Shorten the conversation tests for speed + fixing position overflows (#26960)
2023-10-31|||Trigger CI if `tiny_model_summary.json` is modified (#27175)
2023-10-31|||Add support for loading GPTQ models on CPU (#26719)
2023-10-31|||fix: Fix typical_p behaviour broken in recent change (#27165)
2023-10-31|||Add flash attention for `gpt_bigcode` (#26479)
2023-10-31|||Disable CI runner check (#27170)
2023-10-31|||[doctring] Fix docstring for BlipTextConfig, BlipVisionConfig (#27173)
2023-10-31|||[docstring] Fix docstring for AltCLIPTextConfig, AltCLIPVisionConfig and AltCLIPConfig (#27128)
2023-10-31|||Remove broken links to s-JoL/Open-Llama (#27164)
2023-10-31|||deprecate function `get_default_device` in `tools/base.py` (#26774)
2023-10-30|||[KOSMOS-2] Update docs (#27157)
2023-10-30|||Fix import of torch.utils.checkpoint (#27155)
2023-10-31|||Fix: typos in README.md (#27154)
2023-10-30|||[`core`/ `GC` / `tests`] Stronger GC tests (#27124)
2023-10-31|||Device agnostic trainer testing (#27131)
2023-10-30|||Translating `en/main_classes` folder docs to Japanese üáØüáµ (#26894)
2023-10-30|||üåê [i18n-ZH] Translate serialization.md into Chinese (#27076)
2023-10-30|||Remove some Kosmos-2 `copied from` (#27149)
2023-10-30|||make tests of pytorch_example device agnostic (#27081)
2023-10-30|||[`tests` / `Quantization`] Fix bnb test (#27145)
2023-10-30|||Fix some tests using `"common_voice"` (#27147)
2023-10-30|||Add `Kosmos-2` model (#24709)
2023-10-30|||remove the obsolete code related to fairscale FSDP (#26651)
2023-10-30|||[`Trainer` / `GC`] Add `gradient_checkpointing_kwargs` in trainer and training arguments (#27068)
2023-10-30|||Fix data2vec-audio note about attention mask (#27116)
2023-10-30|||[`FA2`/ `Mistral`] Revert previous behavior with right padding + forward (#27125)
2023-10-30|||Fix slack report failing for doctest (#27042)
2023-10-29|||[Typo fix] flag config in WANDB (#27130)
2023-10-27|||Fix docstring and type hint for resize (#27104)
2023-10-27|||translate transformers_agents.md to Chinese (#27046)
2023-10-28|||Added Telugu [te] translation for README.md in main (#27077)
2023-10-27|||[Attention Mask] Refactor all encoder-decoder attention mask (#27086)
2023-10-27|||fix detr device map (#27089)
2023-10-27|||[`core`/ `gradient_checkpointing`] Refactor GC - part 2 (#27073)
2023-10-27|||Fix no split modules underlying modules (#27090)
2023-10-27|||Provide alternative when warning on use_auth_token (#27105)
2023-10-27|||Add early stopping for Bark generation via logits processor (#26675)
2023-10-27|||Revert "add exllamav2 arg" (#27102)
2023-10-27|||[`T5Tokenizer`]  Fix fast and extra tokens (#27085)
2023-10-27|||Added huggingface emoji instead of the markdown format (#27091)
2023-10-26|||Save TB logs as part of push_to_hub (#27022)
2023-10-26|||Correct docstrings and a typo in comments (#27047)
2023-10-26|||add exllamav2 arg (#26437)
2023-10-26|||[Llama FA2] Re-add _expand_attention_mask and clean a couple things (#27074)
2023-10-26|||Add-support for commit description (#26704)
2023-10-26|||Create SECURITY.md
2023-10-26|||Remove unneeded prints in modeling_gpt_neox.py (#27080)
2023-10-26|||Bump`flash_attn` version to `2.1` (#27079)
2023-10-26|||Bring back `set_epoch` for Accelerate-based dataloaders (#26850)
2023-10-26|||Bump urllib3 from 1.26.17 to 1.26.18 in /examples/research_projects/lxmert (#26888)
2023-10-26|||Bump werkzeug from 2.2.3 to 3.0.1 in /examples/research_projects/decision_transformer (#27072)
2023-10-25|||Handle unsharded Llama2 model types in conversion script (#27069)
2023-10-25|||Hindi translation of pipeline_tutorial.md (#26837)
2023-10-26|||üåê [i18n-ZH] Translate custom_models.md into Chinese (#27065)
2023-10-25|||[`docs`] Add `MaskGenerationPipeline` in docs (#27063)
2023-10-25|||[DOCS] minor fixes in README.md (#27048)
2023-10-26|||[docstring] fix incorrect llama docstring: encoder -> decoder (#27071)
2023-10-25|||Fix TypicalLogitsWarper tensor OOB indexing edge case (#26579)
2023-10-25|||[`core`] Refactor of `gradient_checkpointing` (#27020)
2023-10-25|||Skip-test (#27062)
2023-10-24|||Fix RoPE config validation for FalconConfig + various config typos (#26929)
2023-10-25|||Add a default decoder_attention_mask for EncoderDecoderModel during training (#26752)
2023-10-24|||[docs] Performance docs refactor p.2 (#26791)
2023-10-24|||Fix config silent copy in from_pretrained (#27043)
2023-10-24|||Device agnostic testing (#25870)
2023-10-24|||Add fuyu device map (#26949)
2023-10-24|||add info on TRL docs (#27024)
2023-10-24|||Safe import of rgb_to_id from FE modules (#27037)
2023-10-24|||[`TFxxxxForSequenceClassifciation`] Fix the eager mode after #25085 (#25751)
2023-10-24|||Normalize only if needed (#26049)
2023-10-24|||Add descriptive docstring to WhisperTimeStampLogitsProcessor (#25642)
2023-10-24|||Add `default_to_square_for_size` to `CLIPImageProcessor` (#26965)
2023-10-24|||Register ModelOutput as supported torch pytree nodes (#26618)
2023-10-24|||Fix key dtype in GPTJ and CodeGen (#26836)
2023-10-23|||üåê [i18n-ZH] Translate create_a_model.md into Chinese (#27026)
2023-10-24|||Fix little typo (#27028)
2023-10-23|||Bugfix device map detr model (#26849)
2023-10-24|||translate `preprocessing.md` to Chinese (#26955)
2023-10-23|||üåê [i18n-ZH] Translate multilingual into Chinese (#26935)
2023-10-23|||Remove ambiguous `padding_mask` and instead use a 2D->4D Attn Mask Mapper (#26792)
2023-10-23|||Translate `pipeline_tutorial.md` to chinese (#26954)
2023-10-23|||Remove token_type_ids from default TF GPT-2 signature (#26962)
2023-10-23|||small typos found (#26988)
2023-10-23|||[`SeamlessM4T`] fix copies with NLLB MoE int8  (#27018)
2023-10-23|||[`NLLB-MoE`] Fix NLLB MoE 4bit inference (#27012)
2023-10-23|||Add Seamless M4T model (#25693)
2023-10-23|||Change default `max_shard_size` to smaller value (#26942)
2023-10-23|||Nits in Llama2 docstring (#26996)
2023-10-23|||skip two tests (#27013)
2023-10-23|||python falcon doc-string example typo (#26995)
2023-10-23|||Limit to inferior fsspec version (#27010)
2023-10-23|||fix logit-to-multi-hot conversion in example (#26936)
2023-10-21|||Added Telugu [te] translations (#26828)
2023-10-21|||Update README_hd.md (#26872)
2023-10-20|||Fix Fuyu image scaling bug (#26918)
2023-10-20|||fix set_transform link docs (#26856)
2023-10-20|||[docstring] Fix docstring for speech-to-text config (#26883)
2023-10-19|||Corrected modalities description in README_ru.md (#26913)
2023-10-19|||Generate: update basic llm tutorial (#26937)
2023-10-19|||[`FA-2` / `Mistral`] Supprot fa-2 + right padding + forward (#26912)
2023-10-19|||Pin Keras for now (#26904)
2023-10-19|||Fix license (#26931)
2023-10-19|||[docstring] Fix docstrings for `CodeGen` (#26821)
2023-10-19|||Fix and re-enable ConversationalPipeline tests (#26907)
2023-10-19|||[Docs] Make sure important decode and generate method are nicely displayed in Whisper docs (#26927)
2023-10-19|||[docstring] Fix docstring for `ChineseCLIP` (#26880)
2023-10-19|||[`FA-2`] Revert suggestion that broke FA2 fine-tuning with quantized models (#26916)
2023-10-19|||Add fuyu model (#26911)
2023-10-18|||[`FA-2`] Final fix for FA2 dtype (#26846)
2023-10-18|||[i18n-ZH] Translated fast_tokenizers.md to Chinese (#26910)
2023-10-18|||Refactor code part in documentation translated to japanese (#26900)
2023-10-18|||Add default template warning (#26637)
2023-10-18|||Emergency PR to skip conversational tests to fix CI (#26906)
2023-10-18|||[`Tokenizer`] Fix slow and fast serialization (#26570)
2023-10-18|||Fix Seq2seqTrainer decoder attention mask  (#26841)
2023-10-18|||Knowledge distillation for vision guide (#25619)
2023-10-18|||Bump urllib3 from 1.26.17 to 1.26.18 in /examples/research_projects/decision_transformer (#26889)
2023-10-18|||Bump urllib3 from 1.26.17 to 1.26.18 in /examples/research_projects/visual_bert (#26890)
2023-10-18|||Generate: improve docstrings for custom stopping criteria (#26863)
2023-10-17|||Fix TensorFlow pakage check (#26842)
2023-10-18|||Translating `en/internal` folder docs to Japanese üáØüáµ (#26747)
2023-10-17|||Fixed a typo in mistral.md (#26879)
2023-10-17|||[docstring] Fix docstring for LukeConfig (#26858)
2023-10-17|||üö® üö®  Raise error when no speaker embeddings in speecht5._generate_speech (#26418)
2023-10-17|||[`FA2`] Fix flash attention 2 fine-tuning with Falcon (#26852)
2023-10-17|||üö®üö® Generate: change order of ops in beam sample to avoid nans (#26843)
2023-10-17|||Update logits_process.py docstrings to clarify penalty and reward cases (attempt #2) (#26784)
2023-10-17|||fix: when window_size is passes as array (#26800)
2023-10-17|||Chore: Typo fixed in multiple files of docs/source/en/model_doc (#26833)
2023-10-16|||Fix Mistral OOM again (#26847)
2023-10-16|||üö®üö®üö® [`Quantization`] Store the original dtype in the config as a private attribute üö®üö®üö® (#26761)
2023-10-16|||Conversation pipeline fixes (#26795)
2023-10-16|||[docstring] Fix bert generation tokenizer (#26820)
2023-10-16|||Better way to run AMD CI with different flavors (#26634)
2023-10-16|||Llama tokenizer: remove space in template comment (#26788)
2023-10-16|||Add LLM doc (#26058)
2023-10-16|||[OWL-ViT, OWLv2] Add resources (#26822)
2023-10-16|||fix resume_from_checkpoint bug (#26739)
2023-10-16|||Make fsdp ram efficient loading optional (#26631)
2023-10-16|||Image-to-Image Task Guide (#26595)
2023-10-16|||[docstring] Fix docstring for `CodeLlamaTokenizerFast` (#26666)
2023-10-16|||Add Japanese translation (#26799)
2023-10-16|||[docstring] Fix docstring for `CanineConfig` (#26771)
2023-10-16|||Fixed typos (#26810)
2023-10-13|||translation brazilian portuguese (#26769)
2023-10-14|||Add CLIP resources (#26534)
2023-10-13|||[`Flava`] Fix flava doc (#26789)
2023-10-13|||Fixed KeyError for Mistral (#26682)
2023-10-13|||Add OWLv2, bis (#26668)
2023-10-13|||Fix Falcon generation test (#26770)
2023-10-13|||Disable default system prompt for LLaMA (#26765)
2023-10-13|||[`core`] Fix fa-2 import (#26785)
2023-10-13|||[docstring] fix docstring `DPRConfig` (#26674)
2023-10-13|||Fix num. of minimal calls to the Hub with peft for pipeline  (#26385)
2023-10-13|||[docstring] Fix docstring for `RwkvConfig` (#26782)
2023-10-13|||Update expect outputs of `IdeficsProcessorTest.test_tokenizer_padding` (#26779)
2023-10-13|||üåê [i18n-KO] Translated `big_models.md` to Korean (#26245)
2023-10-12|||Skip `TrainerIntegrationFSDP::test_basic_run_with_cpu_offload` if `torch < 2.1` (#26764)
2023-10-12|||chore: fix typos (#26756)
2023-10-12|||Fix `PerceiverModelIntegrationTest::test_inference_masked_lm` (#26760)
2023-10-12|||[docstring] Fix docstring for 'BertGenerationConfig' (#26661)
2023-10-12|||[docstring] Update `GPT2` and  `Whisper` (#26642)
2023-10-12|||[docstring] Fix `UniSpeech`, `UniSpeechSat`, `Wav2Vec2ForCTC` (#26664)
2023-10-12|||[docs] LLM prompting guide (#26274)
2023-10-12|||Fix backward compatibility of Conversation (#26741)
2023-10-12|||Fix `MistralIntegrationTest` OOM (#26754)
2023-10-12|||Fix `PersimmonIntegrationTest` OOM (#26750)
2023-10-12|||Warnings controlled by logger level (#26527)
2023-10-12|||Add many missing spaces in adjacent strings (#26751)
2023-10-12|||Fix doctest for `Blip2ForConditionalGeneration` (#26737)
2023-10-12|||Translated the accelerate.md file of the documentation to Chinese (#26161)
2023-10-11|||add japanese documentation (#26138)
2023-10-11|||[docstring] Fix docstring for `CodeLlamaTokenizer` (#26709)
2023-10-12|||[docstring] Fix docstring for `LlamaTokenizer` and `LlamaTokenizerFast` (#26669)
2023-10-11|||Revert #20715 (#26734)
2023-10-11|||Update docker files to use `torch==2.1.0` (#26735)
2023-10-11|||Fix checkpoint path in `no_trainer` scripts (#26733)
2023-10-11|||Fix stale bot for locked issues (#26711)
2023-10-11|||fix the model card issue as `use_cuda_amp` is no more available (#26731)
2023-10-11|||[docstring] `SwinModel` docstring fix (#26679)
2023-10-11|||[Assistant Generation] Improve Encoder Decoder (#26701)
2023-10-11|||`Copied from` for test files (#26713)
2023-10-11|||Update docs to explain disabling callbacks using report_to (#26155)
2023-10-11|||In assisted decoding, pass model_kwargs to model's forward call (fix prepare_input_for_generation in all models) (#25242)
2023-10-11|||Make Whisper Encoder's sinusoidal PE non-trainable by default (#26032)
2023-10-10|||[JAX] Replace uses of `jnp.array` in types with `jnp.ndarray`. (#26703)
2023-10-10|||Fix source_prefix default value (#26654)
2023-10-10|||fix a typo in flax T5 attention - attention_mask variable is misnamed (#26663)
2023-10-10|||[docstring] Fix docstring for `LlamaConfig` (#26685)
2023-10-10|||Fix Typo: table in deepspeed.md (#26705)
2023-10-10|||Control first downsample stride in ResNet (#26374)
2023-10-09|||[docstring] Fix docstrings for `CLIP` (#26691)
2023-10-09|||Fix stale bot (#26692)
2023-10-09|||[docstring] Fix docstring for DonutImageProcessor (#26641)
2023-10-09|||[docstring] Fix docstring for `CLIPImageProcessor` (#26676)
2023-10-09|||[docstring] Fix docstring CLIP configs (#26677)
2023-10-09|||fix typos in idefics.md (#26648)
2023-10-09|||Avoid CI OOM (#26639)
2023-10-09|||fix links in README.md for the GPT, GPT-2, and Llama2 Models (#26640)
2023-10-09|||Fixed malapropism error (#26660)
2023-10-09|||[DINOv2] Convert more checkpoints (#26177)
2023-10-06|||docs(zh): review and punctuation & space fix (#26627)
2023-10-06|||[docstring] Fix docstring for `AlbertConfig` (#26636)
2023-10-06|||[`LlamaTokenizerFast`] Adds edge cases for the template processor    (#26606)
2023-10-06|||remove SharedDDP as it is deprecated (#25702)
2023-10-06|||Fix failing `MusicgenTest .test_pipeline_text_to_audio` (#26586)
2023-10-06|||fix RoPE t range issue for fp16 (#26602)
2023-10-06|||Update chat template docs with more tips on writing a template (#26625)
2023-10-06|||Remove unnecessary unsqueeze - squeeze in rotary positional embedding (#26162)
2023-10-06|||Update tokenization_code_llama_fast.py (#26576)
2023-10-06|||Fixed inconsistency in several fast tokenizers (#26561)
2023-10-06|||Remove unnecessary `view`s of `position_ids` (#26059)
2023-10-05|||Don't install `pytorch-quantization` in Doc Builder docker file (#26622)
2023-10-05|||[docs] Update to scripts building index.md (#26546)
2023-10-05|||Fix `transformers-pytorch-gpu` docker build (#26615)
2023-10-05|||Don't close ClearML task if it was created externally (#26614)
2023-10-05|||#26566 swin2 sr allow in out channels (#26568)
2023-10-05|||[`core`] fix silent bug `keep_in_fp32` modules (#26589)
2023-10-05|||Make `ModelOutput` serializable (#26493)
2023-10-05|||Fix failing tests on `main` due to torch 2.1 (#26607)
2023-10-05|||[Falcon] Set `use_cache=False` before creating `presents` which relies on `use_cache` (#26328)
2023-10-05|||[`GPTNeoX`] Faster rotary embedding for GPTNeoX (based on llama changes) (#25830)
2023-10-05|||[ `NougatProcessor`] Fix the default channel (#26608)
2023-10-05|||add zh translation for installation (#26084)
2023-10-04|||[Wav2Vec2] Fix tokenizer set lang (#26349)
2023-10-04|||Update mistral.md to update 404 link (#26590)
2023-10-04|||skip flaky hub tests (#26594)
2023-10-05|||Fix encoder->decoder typo bug in convert_t5x_checkpoint_to_pytorch.py (#26587)
2023-10-04|||Fix embarrassing typo in the doc chat template! (#26596)
2023-10-04|||Add # Copied from statements to audio feature extractors that use the floats_list function (#26581)
2023-10-04|||[Mistral] Update config docstring (#26593)
2023-10-04|||refactor: change default block_size (#26229)
2023-10-04|||Add add_generation_prompt argument to apply_chat_template (#26573)
2023-10-04|||Docstring check (#26052)
2023-10-04|||feat: add trainer label to wandb run upon initialization (#26466)
2023-10-04|||Extend Trainer to enable Ascend NPU to use the fused Adamw optimizer when training (#26194)
2023-10-04|||Bump pillow from 9.3.0 to 10.0.1 in /examples/research_projects/decision_transformer (#26580)
2023-10-04|||docs: feat: add clip notebook resources from OSSCA community (#26505)
2023-10-03|||[Tokenizers] Skip tests temporarily (#26574)
2023-10-04|||üåê [i18n-KO] Translated `semantic_segmentation.md` to Korean (#26515)
2023-10-03|||[Whisper] Allow basic text normalization (#26149)
2023-10-03|||v4.35.0.dev0
2023-10-03|||[`Nougat`] from transformers import * (#26562)
2023-10-03|||[`PEFT`] Final fixes (#26559)
2023-10-03|||[`Mistral`] Add Flash Attention-2 support for `mistral` (#26464)
2023-10-03|||Nit-added-tokens (#26538)
2023-10-03|||[Doctest] Add `configuration_encoder_decoder.py` (#26519)
2023-10-03|||[AMD] Add initial version for run_tests_multi_gpu (#26346)
2023-10-03|||[Wav2Vec2 and Co] Update init tests for PT 2.1 (#26494)
2023-10-03|||Add tokenizer kwargs to fill mask pipeline. (#26234)
2023-10-03|||[RFC, Logging] Change warning to info (#26545)
2023-10-03|||Bump urllib3 from 1.26.9 to 1.26.17 in /examples/research_projects/decision_transformer (#26554)
2023-10-03|||Bump urllib3 from 1.26.5 to 1.26.17 in /examples/research_projects/visual_bert (#26552)
2023-10-03|||Bump urllib3 from 1.26.5 to 1.26.17 in /examples/research_projects/lxmert (#26551)
2023-10-02|||[i18n-DE] contribute chapter (#26481)
2023-10-03|||üåê [i18n-KO] Translated `tokenizer_summary.md` to Korean (#26243)
2023-10-02|||add build_inputs_with_special_tokens to LlamaFast (#26297)
2023-10-02|||Code-llama-nit (#26300)
2023-10-02|||[Doctest] Add configuration_roformer.py  (#26530)
2023-10-02|||Remove-warns (#26483)
2023-10-02|||[`PEFT`] Protect `adapter_kwargs` check (#26537)
2023-10-02|||Fix model integration ci (#26322)
2023-10-02|||[`core`/  `auto` ] Fix bnb test with code revision + bug with code revision (#26431)
2023-10-02|||[`PEFT`] Pass token when calling `find_adapter_config` (#26488)
2023-10-02|||Fix broken link to video classification task (#26487)
2023-10-02|||Fix issue of canine forward requiring input_ids anyway (#26290)
2023-10-02|||Fix requests connection error during modelcard creation (#26518)
2023-10-02|||Fix num_heads in _upad_input (#26490)
2023-10-02|||Revert falcon exception (#26472)
2023-09-29|||[ASR Pipe] Improve docs and error messages (#26476)
2023-09-29|||[Flax Examples] Seq2Seq ASR Fine-Tuning Script (#21764)
2023-09-29|||Avoid all-zeor attnetion mask used in testing (#26469)
2023-09-29||| Skip 2 failing persimmon pipeline tests for now (#26485)
2023-09-29|||[docs] navigation improvement between text gen pipelines and text gen params (#26477)
2023-09-29|||[docs] Update offline mode docs (#26478)
2023-09-28|||[Whisper Tokenizer] Make decoding faster after adding timestamps (#26299)
2023-09-28|||Esm checkpointing (#26454)
2023-09-28|||fix_mbart_tied_weights (#26422)
2023-09-28|||Do not warn about unexpected decoder weights when loading T5EncoderModel and LongT5EncoderModel (#26211)
2023-09-28|||[`PEFT`]¬†introducing `adapter_kwargs` for loading adapters from different Hub location (`subfolder`, `revision`) than the base model (#26270)
2023-09-28|||[VITS] Fix speaker_embed device mismatch (#26115)
2023-09-28|||change mention of decoder_input_ids to input_ids and same with decode_inputs_embeds (#26406)
2023-09-28|||docs: change assert to raise and some small docs (#26232)
2023-09-28|||Fix `cos_sin` device issue in Falcon model (#26448)
2023-09-28|||optimize VRAM for calculating pos_bias in LayoutLM v2, v3 (#26139)
2023-09-28|||üåê [i18n-KO] Translated `perf_train_gpu_many.md` to Korean (#26244)
2023-09-28|||üåê [i18n-KO] Translated `debugging.md` to Korean (#26246)
2023-09-27|||[i18n-DE] Complete first toc chapter (#26311)
2023-09-27|||Update `runs-on` in workflow files (#26435)
2023-09-27|||Fix failing doctest (#26450)
2023-09-27|||[Mistral] Mistral-7B-v0.1 support (#26447)
2023-09-27|||[`PEFT`] Fix PEFT multi adapters support (#26407)
2023-09-27|||add bf16 mixed precision support for NPU (#26163)
2023-09-27|||[`FA` / `tests`] Add use_cache tests for FA models (#26415)
2023-09-27|||Fixing tokenizer when `transformers` is installed without `tokenizers` (#26236)
2023-09-27|||Update semantic_segmentation.md (#26419)
2023-09-27|||Fix padding for IDEFICS  (#26396)
2023-09-26|||Add torch `RMSProp` optimizer (#26425)
2023-09-26|||[InternLM] Add support for InternLM (#26302)
2023-09-26|||Fix DeepSpeed issue with Idefics (#26393)
2023-09-26|||added support for gradient checkpointing in ESM models (#26386)
2023-09-26|||Deleted duplicate sentence (#26394)
2023-09-26|||[ViTMatte] Add resources (#26317)
2023-09-26|||Add Nougat (#25942)
2023-09-26|||üåê [i18n-KO] Translated  `audio_classification.mdx` to Korean (#26200)
2023-09-25|||Add Russian localization for README (#26208)
2023-09-25|||Update tiny model information and pipeline tests (#26285)
2023-09-25|||[docs] removed MaskFormerSwin and TimmBackbone from the table on index.md (#26347)
2023-09-25|||Fix MusicGen logging error (#26370)
2023-09-25|||Update add_new_model.md (#26365)
2023-09-23|||Fixed unclosed p tags (#26240)
2023-09-23|||feat: adding num_proc to load_dataset (#26326)
2023-09-22|||Add image to image pipeline (#25393)
2023-09-22|||[TTA Pipeline] Fix MusicGen test (#26348)
2023-09-22|||[`core` ]¬†Integrate Flash attention 2 in most used models (#25598)
2023-09-22|||[doc] fixed indices in obj detection example (#26343)
2023-09-22|||Fix doctest CI (#26324)
2023-09-22|||Use CircleCI `store_test_results` (#26223)
2023-09-22|||[QUICK FIX LINK] Update trainer.py (#26293)
2023-09-21|||More error message fixup, plus some linebreaks! (#26296)
2023-09-21|||Porting the torchaudio kaldi fbank implementation to audio_utils (#26182)
2023-09-21|||update hf hub dependency to be compatible with the new tokenizers (#26301)
2023-09-21|||Fix FSMT weight sharing (#26292)
2023-09-21|||Keep relevant weights in fp32 when `model._keep_in_fp32_modules` is set even when `accelerate` is not installed (#26225)
2023-09-20|||add custom RMSNorm to `ALL_LAYERNORM_LAYERS` (#26227)
2023-09-20|||[`Trainer`] Refactor trainer + bnb logic (#26248)
2023-09-20|||include changes from llama (#26260)
2023-09-20|||add bbox input validation (#26294)
2023-09-20|||fix deepspeed available detection (#26252)
2023-09-20|||Rewrite for custom code warning messages (#26291)
2023-09-20|||Integrate AMD GPU in CI/CD environment (#26007)
2023-09-20|||Update bros checkpoint (#26277)
2023-09-20|||fix name error when accelerate is not available (#26278)
2023-09-20|||FSDP tests and checkpointing fixes (#26180)
2023-09-20|||[FIX] resize_token_embeddings (#26102)
2023-09-20|||DeepSpeed ZeRO-3 handling when resizing embedding layers (#26259)
2023-09-19|||Fix `Error` not captured in PR doctesting (#26215)
2023-09-19|||Add ViTMatte (#25843)
2023-09-19|||Fix gated repo tests (#26257)
2023-09-19|||Fix some docstring in image processors (#26235)
2023-09-19|||Fix the gitlab user mention in issue templates to the correct user (#26237)
2023-09-19|||[docs] Fix model reference in zero shot image classification example (#26206)
2023-09-19|||Update add_new_pipeline.md (#26197)
2023-09-19|||Update README.md (#26198)
2023-09-18|||[AutoBackbone] Add test (#26094)
2023-09-18|||Create the return value on device to avoid unnecessary copying from CPU (#26151)
2023-09-19|||üåê [i18n-KO] Translated `whisper.md` to Korean (#26002)
2023-09-18|||üö®üö® üö®üö® [`Tokenizer`] attemp to fix add_token issuesüö®üö® üö®üö®  (#23909)
2023-09-18|||[Check] Fix config docstring (#26222)
2023-09-18|||[Permisson] Style fix (#26228)
2023-09-18|||[Wav2Vec2-Conf / LLaMA] Style fix  (#26188)
2023-09-18|||refactor: change default block_size in block size > max position embeddings (#26069)
2023-09-18|||refactor decay_parameters production into its own function (#26152)
2023-09-18|||[FSMT] Fix non-shared weights (#26187)
2023-09-18|||Fix ConversationalPipeline tests (#26217)
2023-09-18|||moved `ctrl` to `Salesforce/ctrl` (#26183)
2023-09-18|||Remove `utils/documentation_tests.txt` (#26213)
2023-09-18|||No doctest for `convert_bros_to_pytorch.py` (#26212)
2023-09-15|||[PEFT] Allow PEFT model dict to be loaded (#25721)
2023-09-15|||[docs] IDEFICS guide and task guides restructure (#26035)
2023-09-15|||Fix pad to multiple of (#25732)
2023-09-15|||Update notebook.py to support multi eval datasets (#25796)
2023-09-15|||[Whisper] Check length of prompt + max new tokens (#26164)
2023-09-15|||Tweaks to Chat Templates docs (#26168)
2023-09-15|||[TTA Pipeline] Test MusicGen and VITS (#26146)
2023-09-14|||IDEFICS: allow interpolation of vision's pos embeddings (#26029)
2023-09-14|||[BLIP-2] Improve conversion script (#24854)
2023-09-15|||Add BROS (#23190)
2023-09-14|||[Whisper] Fix word-level timestamps for audio < 30 seconds (#25607)
2023-09-14|||[MusicGen] Add sampling rate to config (#26136)
2023-09-15|||Fix beam search when using model parallel (#24969)
2023-09-14|||[MusicGen] Add streamer to generate (#25320)
2023-09-14|||Overhaul Conversation class and prompt templating (#25323)
2023-09-14|||[`PEFT`] Fix PEFT + gradient checkpointing (#25846)
2023-09-14|||[Whisper Tokenizer] Encode timestamps (#26054)
2023-09-14|||Fix eval accumulation when `accelerate` > 0.20.3 (#26060)
2023-09-14|||Add missing Maskformer dataclass decorator, add dataclass check in ModelOutput for subclasses (#25638)
2023-09-14|||Flex xpu bug fix (#26135)
2023-09-13|||[docs] last hidden state vs hidden_states[-1] (#26142)
2023-09-13|||Update training_args.py - addition of self.distributed_state when using XPU (#25999)
2023-09-14|||Fix `beam_scores` shape when token scores shape changes after `logits_processor` (#25980)
2023-09-13|||Falcon: batched generation (#26137)
2023-09-13|||Fix `test_finetune_bert2bert` (#25984)
2023-09-13|||Generate: ignore warning when `generation_config.max_length` is set to `None` (#26147)
2023-09-14|||docs: feat: add llama2 notebook resources from OSSCA community (#26076)
2023-09-13|||[`RWKV`] Final fix RWMV 4bit (#26134)
2023-09-13|||Update spectrogram and waveform model mapping for TTS/A pipeline (#26114)
2023-09-13|||Add missing space in generation/utils.py (#26121)
2023-09-13|||[`core`] fix 4bit `num_parameters` (#26132)
2023-09-13|||Fix AutoTokenizer docstring typo (#26117)
2023-09-13|||fix the deepspeed tests (#26021)
2023-09-13|||safeguard torch distributed check (#26056)
2023-09-13|||Fix `MarianTokenizer` to remove metaspace character in `decode` (#26091)
2023-09-12|||Text2text pipeline: don't parameterize from the config (#26118)
2023-09-13|||chore: correct update_step and correct gradient_accumulation_steps (#26068)
2023-09-13|||enable optuna multi-objectives feature (#25969)
2023-09-13|||üåê [i18n-KO] Translated `contributing.md` to Korean (#25877)
2023-09-12|||[docs] Updates to TTS task guide with regards to the new TTS pipeline  (#26095)
2023-09-13|||üåê [i18n-KO] Translated `llama2.md` to Korean (#26047)
2023-09-12|||Fix ExponentialDecayLengthPenalty negative logits issue (#25594)
2023-09-12|||Update logits_process.py docstrings (#25971)
2023-09-12|||Generate: legacy mode is only triggered when `generation_config` is untouched (#25962)
2023-09-12|||[`core`] Import tensorflow inside relevant methods in `trainer_utils` (#26106)
2023-09-12|||[`Persimmon`] Add support for persimmon (#26042)
2023-09-12|||docs: add space to docs (#26067)
2023-09-11|||[Core] Add lazy import structure to imports (#26090)
2023-09-11|||docs: update link huggingface map (#26077)
2023-09-11|||only main process should call _save on deepspeed zero3 (#25959)
2023-09-08|||[`CITests`] skip failing tests until #26054 is merged (#26063)
2023-09-08|||[`CodeLlamaTokenizerFast`] Fix fix `set_infilling_processor` to properly reset (#26041)
2023-09-09|||üåê [i18n-KO] Translated `llama.md` to Korean (#26044)
2023-09-08|||Skip warning if tracing with dynamo (#25581)
2023-09-08|||Update missing docs on `activation_dropout` and fix DropOut docs for SEW-D (#26031)
2023-09-08|||Fix Dropout Implementation in Graphormer (#24817)
2023-09-08|||Try to fix training Loss inconsistent after resume from old checkpoint (#25872)
2023-09-08|||Punctuation fix (#26025)
2023-09-08|||Fix vilt config docstring parameter to match value in init (#26017)
2023-09-07|||Added HerBERT to README.md (#26020)
2023-09-07|||[VITS] Fix nightly tests (#25986)
2023-09-08|||Add `tgs` speed metrics (#25858)
2023-09-07|||Fix CircleCI config (#26023)
2023-09-07|||fix _resize_token_embeddings will set lm head size to 0 when enabled deepspeed zero3 (#26024)
2023-09-07|||Fix err with FSDP (#25991)
2023-09-06|||modify context length for GPTQ + version bump (#25899)
2023-09-06|||Remove Falcon from undocumented list (#26008)
2023-09-06|||üåê[i18n-KO] Translated `llm_tutorial.md` to Korean (#25791)
2023-09-06|||Fix small typo README.md (#25934)
2023-09-06|||TF-OPT attention mask fixes (#25238)
2023-09-06|||Falcon: fix revision propagation (#26006)
2023-09-06|||Update README.md (#26003)
2023-09-06|||save space when converting hf model to megatron model. (#25950)
2023-09-06|||Fix Mega chunking error when using decoder-only model (#25765)
2023-09-05|||[`VITS`]  tokenizer integration test: fix revision did not exist (#25996)
2023-09-05|||[`CI`]  Fix red CI and ERROR failed should show (#25995)
2023-09-06|||Add LLaMA resources (#25859)
2023-09-05|||[Wav2Vec2 Conformer] Fix inference float16 (#25985)
2023-09-05|||deepspeed resume from ckpt fixes and adding support for deepspeed optimizer and HF scheduler (#25863)
2023-09-05|||Add TFDebertaV2ForMultipleChoice (#25932)
2023-09-05|||PegasusX add _no_split_modules (#25933)
2023-09-05|||Patch with accelerate xpu (#25714)
2023-09-05|||Show failed tests on CircleCI layout in a better way (#25895)
2023-09-05|||Trainer: delegate default generation values to `generation_config` (#25987)
2023-09-05|||Update training_args.py to remove the runtime error (#25920)
2023-09-05|||Update RAG README.md with correct path to examples/seq2seq (#25953)
2023-09-05|||[doc] Always call it Agents for consistency (#25958)
2023-09-05|||Use main in conversion script (#25973)
2023-09-05|||fix typo (#25981)
2023-09-05|||Add `Pop2Piano` space demo. (#25975)
2023-09-05|||nn.Identity is not required to be compatible with PyTorch < 1.1.0 as the minimum PyTorch version we currently support is 1.10.0 (#25974)
2023-09-05|||Fix `test_load_img_url_timeout` (#25976)
2023-09-05|||Fix Detr CI (#25972)
2023-09-05|||Fix typo (#25966)
2023-09-04|||v4.34.dev.0
2023-09-04|||[`Falcon`] Remove SDPA for falcon to support earlier versions of PyTorch (< 2.0) (#25947)
2023-09-04|||Put Falcon back (#25960)
2023-09-04|||Add type hints for tf models final batch (#25883)
2023-09-04|||Fix smart check (#25955)
2023-09-04|||Fix failing test (#25963)
2023-09-04|||Add proper Falcon docs and conversion script (#25954)
2023-09-04|||[VITS] Fix init test (#25945)
2023-09-04|||Update README.md (#25922)
2023-09-04|||Import deepspeed utilities from integrations (#25919)
2023-09-04|||[VITS] Handle deprecated weight norm (#25946)
2023-09-04|||[MMS] Fix pip install in docs (#25949)
2023-09-04|||Update README.md (#25941)
2023-09-04|||Update autoclass_tutorial.md (#25929)
2023-09-04|||Update community.md (#25928)
2023-09-04|||Fix typos (#25936)
2023-09-04|||Skip offload tests for `ViTDet` (#25913)
2023-09-04|||CI: hotfix (skip VitsModelTest::test_initialization)
2023-09-01|||Update model_memory_anatomy.md (#25896)
2023-09-01|||Update-llama-code (#25826)
2023-09-01|||[VITS] Only trigger tokenizer warning for uroman (#25915)
2023-09-01|||[MMS] Update docs with HF TTS implementation (#25907)
2023-09-01|||[VITS] Add to TTA pipeline (#25906)
2023-09-01|||Revert frozen training arguments (#25903)
2023-09-01|||Remove broken docs for MusicGen (#25905)
2023-09-01|||Better error message for pipeline loading (#25912)
2023-09-01|||Falcon: Add RoPE scaling (#25878)
2023-09-01|||fix FSDP model resume optimizer & scheduler (#25852)
2023-09-01|||add VITS model (#24085)
2023-08-31|||remove torch_dtype override (#25894)
2023-08-31|||Smarter check for `is_tensor` (#25871)
2023-08-31|||Update `setup.py` (#25893)
2023-08-31|||Add type hints for tf models batch 1 (#25853)
2023-08-31|||[`InstructBlip`] FINAL Fix instructblip test (#25887)
2023-08-31|||Save image_processor while saving pipeline (ImageSegmentationPipeline) (#25884)
2023-08-31|||[`CodeLlama`] Fix CI  (#25890)
2023-08-31|||[`TokenizerFast`] `can_save_slow_tokenizer` as a property for when `vocab_file`'s folder was removed (#25626)
2023-08-31|||Modify efficient GPU training doc with now-available adamw_bnb_8bit optimizer (#25807)
2023-08-31|||fix ds z3 checkpointing when  `stage3_gather_16bit_weights_on_model_save=False` (#25817)
2023-08-31|||For xla tensors, use an alternative way to get a unique id (#25802)
2023-08-30|||[ViTDet] Fix doc tests (#25880)
2023-08-30|||Reduce CI output (#25876)
2023-08-30|||pin pandas==2.0.3 (#25875)
2023-08-30|||Docs: fix example failing doctest in `generation_strategies.md ` (#25874)
2023-08-30|||fix max_memory for bnb (#25842)
2023-08-30|||Fix imports (#25869)
2023-08-30|||Remote tools are turned off (#25867)
2023-08-30|||Add Blip2 model in VQA pipeline (#25532)
2023-08-30|||Add flax installation in daily doctest workflow (#25860)
2023-08-30|||minor typo fix in PeftAdapterMixin docs (#25829)
2023-08-30|||Update README.md (#25832)
2023-08-29|||Generate: models with custom `generate()` return `True` in `can_generate()` (#25838)
2023-08-29|||Update README.md (#25834)
2023-08-29|||Support loading base64 images in pipelines (#25633)
2023-08-29|||MaskFormer,Mask2former - reduce memory load (#25741)
2023-08-29|||[AutoTokenizer] Add data2vec to mapping (#25835)
2023-08-29|||update remaining `Pop2Piano` checkpoints (#25827)
2023-08-29|||ü§¶update warning to If you want to use the new behaviour, set `legacy=‚Ä¶ (#25833)
2023-08-30|||üåê¬†[i18n-KO] Translated¬†`community.md` to Korean (#25674)
2023-08-30|||üåê [i18n-KO] Translated `add_new_pipeline.md` to Korean (#25498)
2023-08-29|||Tests: detect lines removed from "utils/not_doctested.txt" and doctest ALL generation files (#25763)
2023-08-29|||Error with checking args.eval_accumulation_steps to gather tensors (#25819)
2023-08-29|||üåê [i18n-KO] `model_memory_anatomy.md` to Korean (#25755)
2023-08-29|||üåê [i18n-KO] Translated peft.md to Korean (#25706)
2023-08-29|||fix warning trigger for embed_positions when loading xglm (#25798)
2023-08-29|||[`LlamaTokenizer`] `tokenize` nits.  (#25793)
2023-08-29|||Minor wording changes for Code Llama (#25815)
2023-08-29|||fix register (#25779)
2023-08-29|||[`Docs`] More clarifications on BT + FA (#25823)
2023-08-29|||Resolving Attribute error when using the FSDP ram efficient feature (#25820)
2023-08-29|||[DINOv2] Add backbone class (#25520)
2023-08-29|||Add ViTDet (#25524)
2023-08-29|||fixing name position_embeddings to object_queries (#24652)
2023-08-29|||Fix incorrect Boolean value in deepspeed example (#25788)
2023-08-29|||Arde/fsdp activation checkpointing (#25771)
2023-08-28|||[idefics] fix vision's `hidden_act` (#25787)
2023-08-28|||Add type hints for several pytorch models (batch-4) (#25749)
2023-08-28|||Add type hints for pytorch models (final batch) (#25750)
2023-08-28|||Add type hints for several pytorch models (batch-2) (#25557)
2023-08-28|||[`LlamaFamiliy`] add a tip about dtype (#25794)
2023-08-26|||Add docstrings and fix VIVIT examples (#25628)
2023-08-25|||[idefics] small fixes (#25764)
2023-08-25|||[`CodeLlama`] Add support for `CodeLlama` (#25740)
2023-08-25|||fix a typo in docsting (#25759)
2023-08-25|||Correct attention mask dtype for Flax GPT2 (#25636)
2023-08-25|||üö®üö®üö® [`Refactor`] Move third-party related utility files into `integrations/` folder üö®üö®üö® (#25599)
2023-08-25|||Add type hints for several pytorch models (batch-3) (#25705)
2023-08-25|||Docs: fix indentation in `HammingDiversityLogitsProcessor` (#25756)
2023-08-25|||fix encoder hook (#25735)
2023-08-25|||[`Sentencepiece`] make sure `legacy` do not require `protobuf` (#25684)
2023-08-25|||[CLAP] Fix logit scales dtype for fp16 (#25754)
2023-08-25|||Generate: logits processors are doctested and fix broken doctests (#25692)
2023-08-25|||[DOCS] Add example for HammingDiversityLogitsProcessor (#25481)
2023-08-25|||Generate: add missing logits processors docs (#25653)
2023-08-25|||Add FlaxCLIPTextModelWithProjection (#25254)
2023-08-25|||fixed typo in speech encoder decoder doc (#25745)
2023-08-25|||[`PEFT`] Fix PeftConfig save pretrained when calling `add_adapter` (#25738)
2023-08-25|||üåê [i18n-KO] Translated `visual_question_answering.md` to Korean (#25679)
2023-08-24|||[ASR Pipe Test] Fix CTC timestamps error message (#25727)
2023-08-24|||[`from_pretrained`] Fix failing PEFT tests (#25733)
2023-08-24|||ImageProcessor - check if input pixel values between 0-255 (#25688)
2023-08-24|||[idefics] idefics-9b test use 4bit quant (#25734)
2023-08-24|||[`from_pretrained`]  Simpler code for peft (#25726)
2023-08-24|||Generate: nudge towards `do_sample=False` when `temperature=0.0` (#25722)
2023-08-24|||[`AutoGPTQ`] Add correct installation of GPTQ library + fix slow tests (#25713)
2023-08-24|||Fix number of minimal calls to the Hub with peft integration (#25715)
2023-08-24|||[`PEFT`] Fix peft version (#25710)
2023-08-24|||Fix failing `test_batch_generation`  for bloom (#25718)
2023-08-24|||docs: Resolve typos in warning text (#25711)
2023-08-24|||Update list of persons to tag (#25708)
2023-08-24|||[`LlamaTokenizer`] make unk_token_length a property (#25689)
2023-08-24|||fix ram efficient fsdp init (#25686)
2023-08-24|||Skip broken tests
2023-08-24|||Fix typo in `configuration_gpt2.py` (#25676)
2023-08-23|||Generate: general test for decoder-only generation from `inputs_embeds`  (#25687)
2023-08-24|||correct resume training steps number in progress bar (#25691)
2023-08-24|||[DOCS] Added docstring example for EpsilonLogitsWarper #24783 (#25378)
2023-08-23|||Fix `pad_token` check condition (#25685)
2023-08-23|||Sets the stalebot to 10 AM CEST (#25678)
2023-08-23|||‚ö†Ô∏è [CLAP] Fix dtype of logit scales in init (#25682)
2023-08-23|||Prevent Dynamo graph fragmentation in GPTNeoX with torch.baddbmm fix (#24941)
2023-08-23|||Remove `utils/documentation_tests.txt` (#25680)
2023-08-23|||fix wrong path in some doc (#25658)
2023-08-23|||[`GPTNeo`]  Add input_embeds functionality to gpt_neo Causal LM  (#25664)
2023-08-23|||[`SPM`] Patch `spm` Llama and T5 (#25656)
2023-08-23|||Add Llama2 resources (#25531)
2023-08-22|||Update doc toctree (#25661)
2023-08-22|||Add input_embeds functionality to gpt_neo Causal LM (#25659)
2023-08-22|||stringify config (#25637)
2023-08-22|||Adds `TRANSFORMERS_TEST_BACKEND` (#25655)
2023-08-22|||removing unnecesssary extra parameter (#25643)
2023-08-22|||Fix bloom add prefix space (#25652)
2023-08-22|||TF 2.14 compatibility (#25630)
2023-08-22|||Put IDEFICS in the right section of the doc (#25650)
2023-08-22|||Pass the proper token to PEFT integration in auto classes (#25649)
2023-08-22|||[MINOR:TYPO] (#25646)
2023-08-22|||[DOCS] MusicGen Docs Update (#25510)
2023-08-22|||Add Number Normalisation for SpeechT5 (#25447)
2023-08-22|||Support specifying revision in push_to_hub (#25578)
2023-08-21|||Add Pop2Piano (#21785)
2023-08-21|||fix documentation for CustomTrainer (#25635)
2023-08-21|||üö®üö®üö® changing default threshold and applying threshold before the rescale (#25608)
2023-08-21|||Skip doctest for some recent files (#25631)
2023-08-21|||fix ACT_FN (#25627)
2023-08-21|||correct TTS pipeline docstrings snippet (#25587)
2023-08-21|||Added paper links in logitprocess.py (#25482)
2023-08-21|||v4.33.0.dev0
2023-08-21|||Fix test_modeling_mpt typo in model id (#25606)
2023-08-21|||Run doctest for new files (#25588)
2023-08-21|||Fix PEFT integration failures on nightly CI (#25624)
2023-08-21|||Ignore all exceptions from signal in dynamic code (#25623)
2023-08-19|||Hotfix
2023-08-18|||reattach hooks when using `resize_token_embeddings` (#25596)
2023-08-18|||new model: IDEFICS via HuggingFaceM4 (#24796)
2023-08-19|||üåê [i18n-KO] Translated `perf_train_tpu_tf.md` to Korean (#25433)
2023-08-18|||Make TTS automodels importable (#25595)
2023-08-18|||[`PEFT`] Peft integration alternative design  (#25077)
2023-08-18|||[`TokenizerFast`] Fix setting prefix space in __init__ (#25563)
2023-08-18|||fix z3 init when using accelerate launcher (#25589)
2023-08-18|||[Time series Informer] fix dtype of cumsum (#25431)
2023-08-18|||[`Llama`] remove prompt and fix prefix finetuning (#25565)
2023-08-18|||[`split_special_tokens`] Add support for `split_special_tokens` argument to encode (#25081)
2023-08-18|||Replaces calls to `.cuda` with `.to(torch_device)` in tests (#25571)
2023-08-18|||Added missing parenthesis in call to is_fsdp_enabled (#25585)
2023-08-18|||[`Docs` / `BetterTransformer` ] Added more details about flash attention + SDPA (#25265)
2023-08-18|||Suggestions on Pipeline_webserver (#25570)
2023-08-17|||Fix typo in example code (#25583)
2023-08-17|||add warning for 8bit optimizers (#25575)
2023-08-17|||Skip `test_contrastive_generate` for `TFXLNet` (#25574)
2023-08-17|||Add Text-To-Speech pipeline (#24952)
2023-08-17|||add util for ram efficient loading of model when using fsdp (#25107)
2023-08-17|||Revert "change version (#25387)" (#25573)
2023-08-17|||[`Tests`] Fix failing 8bit test (#25564)
2023-08-17|||[`NllbMoe`] Update code to properly support loss computation (#25429)
2023-08-17|||Inconsistency in PreTrainedModel.resize_token_embeddings When ZeRO3 Is Enabled (#25394)
2023-08-17|||üö®üö®üö® [`SPM`] Finish fix spm models üö®üö®üö® (#25224)
2023-08-17|||[`SwitchTransformers`] Remove unused module (#25427)
2023-08-17|||[`resize_embedding`] Introduce `pad_to_multiple_of` and guidance (#25088)
2023-08-17|||Skip `test_beam_search_xla_generate_simple` for `T5` (#25566)
2023-08-17|||Adds `TRANSFORMERS_TEST_DEVICE` (#25506)
2023-08-17|||[`Docs`] Fix un-rendered images (#25561)
2023-08-17|||Skip `test_onnx_runtime_optimize` for now (#25560)
2023-08-17|||YOLOS - reset default return_pixel_mask value (#25559)
2023-08-17|||üö®üö®üö® Vivit update default rescale_factor value (#25547)
2023-08-17|||Fix `torch.fx` tests on nightly CI (#25549)
2023-08-17|||Fix MPT CI (#25548)
2023-08-17|||Add documentation to dynamic module utils (#25534)
2023-08-16|||Update trainer.py (#25553)
2023-08-17|||[i18n-KO] Translated docs: ko: pr_checks.md to Korean (#24987)
2023-08-17|||More utils doc (#25457)
2023-08-16|||[ASR Pipeline] Fix init with timestamps (#25438)
2023-08-16|||Input data format (#25464)
2023-08-16|||More frozen args (#25540)
2023-08-16|||Fix `MaskFormerModelIntegrationTest` OOM (#25544)
2023-08-16|||fix vit hybrid test (#25543)
2023-08-16|||Generate: fix default max length warning (#25539)
2023-08-16|||Document the test fetcher (#25521)
2023-08-16|||Marian: post-hack-fix correction (#25459)
2023-08-16|||Fix nested configs of Jukebox (#25533)
2023-08-16|||[TYPO] fix typo/format in quicktour.md (#25519)
2023-08-15|||Use dynamic past key-values shape in TF-Whisper (#25523)
2023-08-15|||Make training args fully immutable (#25435)
2023-08-15|||add __repr__  to the BitsAndBytesConfig class (#25517)
2023-08-15|||Bump tornado from 6.3.2 to 6.3.3 in /examples/research_projects/lxmert (#25511)
2023-08-15|||Bump tornado from 6.3.2 to 6.3.3 in /examples/research_projects/visual_bert (#25512)
2023-08-14|||Check for case where `auxiliary_head` is `None` in `UperNetPreTrainedModel` (#25514)
2023-08-14|||Conditional DETR type hint fix (#25505)
2023-08-14|||üö®üö®üö® Remove softmax for EfficientNetForImageClassification üö®üö®üö® (#25501)
2023-08-14|||fix gptq nits (#25500)
2023-08-14|||MaskFormer post_process_instance_segmentation bug fix convert out side of loop (#25497)
2023-08-14|||Set can_generate for SpeechT5ForTextToSpeech (#25493)
2023-08-14|||Add type hints to Blip2QFormer,  BigBirdForQA and ConditionalDetr family models (#25488)
2023-08-14|||Remove logging code in TF Longformer that fails to compile (#25496)
2023-08-14|||fix : escape key of start_token from special characters before search end_token in token2json function of DonutProcessor  (#25472)
2023-08-13|||Bump gitpython from 3.1.30 to 3.1.32 in /examples/research_projects/decision_transformer (#25467)
2023-08-13|||Bump gitpython from 3.1.30 to 3.1.32 in /examples/research_projects/distillation (#25468)
2023-08-13|||import required torch and numpy libraries (#25483)
2023-08-11|||Revert "Reuse the cache created for latest `main` on PRs/branches" (#25466)
2023-08-11|||Mark flaky tests (#25463)
2023-08-11|||Add input_data_format argument, image transforms (#25462)
2023-08-11|||Update run_translation.py broken link example Pytoch (#25461)
2023-08-11|||Reuse the cache created for latest `main` on PRs/branches if `setup.py` is not modified (#25445)
2023-08-11|||Switch Transformers: remove overwritten beam sample test (#25458)
2023-08-11|||Refactor image processor testers (#25450)
2023-08-11|||Fix for #25437 (#25454)
2023-08-10|||GPTQ integration (#25062)
2023-08-10|||docs: add LLaMA-Efficient-Tuning to awesome-transformers (#25441)
2023-08-10|||Fix issue with ratio evaluation steps and auto find batch size (#25436)
2023-08-10|||Add `examples`  to tests to run when `setup.py` is modified (#25437)
2023-08-10|||Fix rendering for `torch.compile()` docs (#25432)
2023-08-10|||Generate: Load generation config when `device_map` is passed (#25413)
2023-08-10|||[WavLM] Fix Arxiv link and authors (#25415)
2023-08-10|||Generation: strict generation config validation at save time (#25411)
2023-08-10|||Doc checks (#25408)
2023-08-10|||üåê [i18n-KO] Translated `philosophy.md` to Korean (#25010)
2023-08-10|||[DINOv2] Update pooler output (#25392)
2023-08-09|||Bark: flexible generation config overload (#25414)
2023-08-09|||Enable passing number of channels when inferring data format (#25412)
2023-08-10|||aligned sample_beam output selection with beam_search (#25375)
2023-08-09|||Update Bark generation configs and tests (#25409)
2023-08-10|||üåê [i18n-KO] Translated `model_summary.md` to Korean (#24625)
2023-08-10|||üåê [i18n-KO] Translated `add_new_model.md` to Korean (#24957)
2023-08-09|||VQA task guide (#25244)
2023-08-09|||Generate: lower severity of parameterization checks (#25407)
2023-08-09|||16059 - Add extra type hints for AltCLIPModel (#25399)
2023-08-09|||Generate: generation config validation fixes in docs (#25405)
2023-08-09|||Improve training args (#25401)
2023-08-09|||Generate: length validation (#25384)
2023-08-09|||Docs: introduction to generation with LLMs (#25240)
2023-08-09|||YOLOS - Revert default return_pixel_mask value (#25404)
2023-08-09|||Fix path for dynamic module creation (#25402)
2023-08-09|||rm useless condition since the previous condition contains it. (#25403)
2023-08-09|||16059 - Add missing type hints for ASTModel (#25364)
2023-08-09|||üåê [i18n-KO] Translated `perf_train_cpu_many.md` to Korean (#24923)
2023-08-08|||[DOCS] Add example for `TopPLogitsWarper`  (#25361)
2023-08-08|||change version (#25387)
2023-08-08|||Add copied from for image processor methods (#25121)
2023-08-08|||Use small config for `OneFormerModelTest.test_model_with_labels` (#25383)
2023-08-08|||Fix missing usage of `token` (#25382)
2023-08-08|||Generate: add config-level validation (#25381)
2023-08-08|||Fix `torch_job` worker(s) crashing (#25374)
2023-08-08|||üåê [i18n-KO] Translated `add_tensorflow_model.md` to Korean (#25017)
2023-08-08|||Enable tests to run on third-party devcies (#25327)
2023-08-08|||Fix `token` in example template (#25351)
2023-08-08|||Load state in else (#25318)
2023-08-08|||MaskFormer, Mask2Former - replace einsum for tracing (#25297)
2023-08-08|||[ASR Pipeline] Clarify return timestamps (#25344)
2023-08-08|||Add warning for missing attention mask when pad tokens are detected (#25345)
2023-08-08|||Fix `test_model_parallelism` (#25359)
2023-08-07|||Register ModelOutput subclasses as supported torch.utils._pytree nodes (#25358)
2023-08-08|||[DOCS] Add descriptive docstring to MinNewTokensLength (#25196)
2023-08-07|||Add mask2former fp16 support (#25093)
2023-08-07|||Docs: Added benchmarks for `torch.compile()`¬†for vision models (#24748)
2023-08-07|||[DOCS] Add `NoRepeatNGramLogitsProcessor` Example for `LogitsProcessor` class (#25186)
2023-08-07|||Adding more information in help parser on train_file and validation_file (#25324)
2023-08-07|||Migrate Trainer from `Repository` to `upload_folder` (#25095)
2023-08-07|||Fix more offload edge cases (#25342)
2023-08-07|||Generate: remove Marian hack (#25294)
2023-08-07|||Allow `trust_remote_code` in example scripts (#25248)
2023-08-07|||Loosen output shape restrictions on GPT-style models (#25188)
2023-08-07|||Generalize CFG to allow for positive prompts (#25339)
2023-08-07|||Update TF pin in docker image (#25343)
2023-08-07|||üåê [i18n-KO] Translated `perf_infer_gpu_one.md` to Korean (#24978)
2023-08-06|||add CFG for .generate() (#24654)
2023-08-05|||Remove jnp.DeviceArray since it is deprecated. (#24875)
2023-08-04|||[Whisper] Better error message for outdated generation config (#25298)
2023-08-04|||Document toc check and doctest check scripts (#25319)
2023-08-04|||Make `bark` could have tiny model (#25290)
2023-08-04|||Document check copies (#25291)
2023-08-04|||Deal with nested configs better in base class (#25237)
2023-08-04|||Add offline mode for agents (#25226)
2023-08-04|||Generate: get generation mode as an enum (#25292)
2023-08-04|||Give more memory in test_disk_offload (#25315)
2023-08-04|||Move usage of deprecated logging.warn to logging.warning (#25310)
2023-08-03|||Fix typo: Roberta -> RoBERTa (#25302)
2023-08-03|||[small] llama2.md typo (#25295)
2023-08-03|||[JAX] Bump min version (#25286)
2023-08-03|||Add timeout parameter to load_image function (#25184)
2023-08-03|||add generate method to SpeechT5ForTextToSpeech (#25233)
2023-08-03|||Update bark doc (#25234)
2023-08-03|||Docs: separate generate section (#25235)
2023-08-03|||Update InstructBLIP & Align values after rescale update (#25209)
2023-08-03|||Docs: Update list of `report_to` logging integrations in docstring (#25281)
2023-08-02|||CI with `pytest_num_workers=8` for torch/tf jobs (#25274)
2023-08-02|||CI with `num_hidden_layers=2` üöÄüöÄüöÄ (#25266)
2023-08-02|||[MMS] Fix mms (#25267)
2023-08-02|||recommend DeepSpeed's Argument Parsing documentation (#25268)
2023-08-02|||üåê [i18n-KO] Translated `perf_infer_gpu_many.md` to Korean (#24943)
2023-08-02|||Remove `pytest_options={"rA": None}` in CI (#25263)
2023-08-02|||Fix return_dict_in_generate bug in InstructBlip generate function (#25246)
2023-08-02|||[DOCS] Add example and modified docs of EtaLogitsWarper (#25125)
2023-08-02|||Fix some bugs for two stage training of deformable detr (#25045)
2023-08-02|||Update rescale tests - cast to float after rescaling to reflect #25229 (#25259)
2023-08-02|||resolving zero3 init when using accelerate config with Trainer (#25227)
2023-08-02|||Add `token` arugment in example scripts (#25172)
2023-08-02|||add pathname and line number to logging formatter in debug mode (#25203)
2023-08-02|||fix get_keys_to_not_convert() to return correct modules for full precision inference (#25105)
2023-08-02|||Fix set of model parallel in the Trainer when no GPUs are available (#25239)
2023-08-01|||Move rescale dtype recasting to match torchvision ToTensor (#25229)
2023-08-01|||[`Detr`] Fix detr BatchNorm replacement issue (#25230)
2023-08-01|||[`MPT`] Add  `require_bitsandbytes` on MPT integration tests (#25201)
2023-08-01|||[`Docs`/`quantization`] Clearer explanation on how things works under the hood. + remove outdated info (#25216)
2023-08-01|||[`Pix2Struct`] Fix pix2struct cross attention (#25200)
2023-08-01|||make build_mpt_alibi_tensor a method of MptModel so that deepspeed co‚Ä¶ (#25193)
2023-07-31|||Fix docker image build failure (#25214)
2023-07-31|||Update tiny model info. and pipeline testing (#25213)
2023-07-31|||[`pipeline`] revisit device check for pipeline (#25207)
2023-07-31|||[quantization.md] fix (#25190)
2023-07-31|||Fix `all_model_classes` in `FlaxBloomGenerationTest` (#25211)
2023-07-31|||[`PreTrainedModel`] Wrap `cuda` and `to` method correctly (#25206)
2023-07-31|||Better error message in `_prepare_output_docstrings` (#25202)
2023-07-31|||Musicgen: CFG is manually added  (#25173)
2023-07-28|||üö®üö®üö®  Fix rescale ViVit Efficientnet (#25174)
2023-07-28|||[MusicGen] Fix integration tests (#25169)
2023-07-28|||Fix beam search to sample at least 1 non eos token (#25103) (#25115)
2023-07-29|||üåê¬†[i18n-KO] Translated¬†`transformers_agents.md` to Korean (#24881)
2023-07-28|||[`InstructBlip`] Fix instructblip slow test (#25171)
2023-07-28|||[`Mpt`] Fix mpt slow test (#25170)
2023-07-28|||Update `use_auth_token` -> `token` in example scripts (#25167)
2023-07-28|||added compiled model support for inference (#25124)
2023-07-28|||make run_generation more generic for other devices (#25133)
2023-07-28|||Represent query_length in a different way to solve jit issue (#25164)
2023-07-28|||override .cuda() to check if model is already quantized (#25166)
2023-07-28|||Add test when downloading from gated repo (#25039)
2023-07-28|||Fix `.push_to_hub` and cleanup `get_full_repo_name` usage (#25120)
2023-07-27|||Add new model in doc table of content (#25148)
2023-07-27|||Add bloom flax (#25094)
2023-07-27|||More `token` things (#25146)
2023-07-27|||Add offload support to Bark (#25037)
2023-07-27|||[`MptConfig`] support from pretrained args (#25116)
2023-07-27|||üö®üö®üö®Change default from `adamw_hf` to `adamw_torch` üö®üö®üö® (#25109)
2023-07-27|||Clarify 4/8 bit loading log message (#25134)
2023-07-27|||[`T5/LlamaTokenizer`] default legacy to `None` to not always warn (#25131)
2023-07-27|||fix delete all checkpoints when save_total_limit is set to 1 (#25136)
2023-07-27|||fix deepspeed load best model at end when the model gets sharded (#25057)
2023-07-26|||Move center_crop to BaseImageProcessor (#25122)
2023-07-26|||MaskFormer - enable return_dict in order to compile (#25052)
2023-07-26|||Fix ViT docstring regarding default dropout values. (#25118)
2023-07-26|||Move common image processing methods to BaseImageProcessor (#25089)
2023-07-26|||Fix past CI after #24334 (#25113)
2023-07-26|||update `use_auth_token` -> `token` (#25083)
2023-07-26|||fix "UserWarning: Creating a tensor from a list of numpy.ndarrays is ‚Ä¶ (#24772)
2023-07-26|||Add descriptive docstring to TemperatureLogitsWarper (#24892)
2023-07-26|||Fix `PvtModelIntegrationTest::test_inference_fp16` (#25106)
2023-07-26|||üåê[i18n-KO] Translated pipeline_webserver.md to Korean (#24828)
2023-07-26|||documentation for llama2 models (#25102)
2023-07-25|||fix tied_params for meta tensor (#25101)
2023-07-25|||Bump certifi from 2022.12.7 to 2023.7.22 in /examples/research_projects/visual_bert (#25097)
2023-07-25|||Bump certifi from 2022.12.7 to 2023.7.22 in /examples/research_projects/decision_transformer (#25098)
2023-07-25|||Bump certifi from 2022.12.7 to 2023.7.22 in /examples/research_projects/lxmert (#25096)
2023-07-25|||Fix doctest (#25031)
2023-07-25|||[`T5`, `MT5`, `UMT5`] Add [T5, MT5, UMT5]ForSequenceClassification (#24726)
2023-07-25|||Hotfix for failing `MusicgenForConditionalGeneration` tests (#25091)
2023-07-25|||[ `PreTrainedTokenizerFast`] Keep properties from fast tokenizer (#25053)
2023-07-25|||Edit err message and comment in `test_model_is_small` (#25087)
2023-07-25|||[`TF`]  Also apply patch to support left padding (#25085)
2023-07-25|||[ `ForSequenceClassification`] Support `left` padding (#24979)
2023-07-25|||Allow generic composite models to pass more kwargs (#24927)
2023-07-25|||üåê [i18n-KO] Translated `perf_infer_cpu.md` to Korean (#24920)
2023-07-25|||[DOCS] add example NoBadWordsLogitsProcessor (#25046)
2023-07-25|||[`MPT`] Add MosaicML's `MPT` model to transformers (#24629)
2023-07-25|||Fix: repeat per sample for SAM image embeddings (#25074)
2023-07-25|||üåê [i18n-KO] Translated `hpo_train.md` to Korean (#24968)
2023-07-25|||[`generate`]  Only warn users if the `generation_config`'s `max_length` is set to the default value (#25030)
2023-07-25|||replace `per_gpu_eval_batch_size` with `per_device_eval_batch_size` in readme of multiple-choice task (#25078)
2023-07-25|||Fix broken link in README_hd.md (#25067)
2023-07-25|||Set `TF32` flag for PyTorch cuDNN backend (#25075)
2023-07-25|||fix: add TOC anchor link (#25066)
2023-07-25|||Fix last models for common tests that are too big. (#25058)
2023-07-25|||üåê [i18n-KO] Translated `perf_hardware.md` to Korean (#24966)
2023-07-25|||üåê [i18n-KO] Translated `<tf_xla>.md` to Korean (#24904)
2023-07-25|||[Docs] fix rope_scaling doc string (#25072)
2023-07-25|||Generate - add beam indices output in contrained beam search (#25042)
2023-07-25|||[`RWKV`] Add note in doc on `RwkvStoppingCriteria` (#25055)
2023-07-24|||Better error message when signal is not supported on OS (#25049)
2023-07-25|||üåê [i18n-KO] Translated `perf_train_cpu.md` to Korean (#24911)
2023-07-24|||[`8bit`] Fix 8bit corner case with Blip2 8bit (#25047)
2023-07-24|||compute_loss in trainer failing to label shift for PEFT model when label smoothing enabled. (#25044)
2023-07-24|||Pvt model (#24720)
2023-07-24|||Comment again print statement
2023-07-24|||Make more test models smaller (#25005)
2023-07-24|||Fix typo in LlamaTokenizerFast docstring example (#25018)
2023-07-24|||Add dispatch_batches to training arguments (#25038)
2023-07-24|||üåê [i18n-KO] Translated `testing.md` to Korean (#24900)
2023-07-24|||üåê[i18n-KO] Translated performance.md to Korean (#24883)
2023-07-24|||Better handling missing SYS in llama conversation tokenizer (#24997)
2023-07-24|||Support GatedRepoError + use raise from (#25034)
2023-07-24|||[docs] Performance docs tidy up, part 1  (#23963)
2023-07-24|||fix(integrations): store serialized `TrainingArgs` to `wandb.config` without sanitization. (#25035)
2023-07-24|||[`logging.py`] set default `stderr`  path if `None` (#25033)
2023-07-23|||[check_config_docstrings.py] improve diagnostics (#25012)
2023-07-22|||üåê [i18n-KO] Updated Korean `serialization.md` (#24686)
2023-07-21|||Move template doc file to md (#25004)
2023-07-21|||improve from_pretrained for zero3 multi gpus mode (#24964)
2023-07-21|||[`Llama`] remove persistent  `inv_freq` tensor (#24998)
2023-07-21|||[`bnb`] Add simple check for bnb import (#24995)
2023-07-21|||Fix `llama` tokenization doctest (#24990)
2023-07-21|||Use main_input_name for include_inputs_for_metrics (#24993)
2023-07-21|||Fix type annotation for deepspeed training arg (#24988)
2023-07-21|||Avoid importing all models when instantiating a pipeline (#24960)
2023-07-21|||Remove tokenizers from the doc table (#24963)
2023-07-21|||[`LlamaConfig`] Nit: pad token should be None by default (#24958)
2023-07-21|||Fix missing spaces in system prompt of Llama2 tokenizer (#24930)
2023-07-21|||fsdp fixes and enhancements (#24980)
2023-07-21|||üåê [i18n-KO] Fixed Korean and English `quicktour.md` (#24664)
2023-07-21|||fix: cast input pixels to appropriate dtype for image_to_text pipelines (#24947)
2023-07-21|||fix fsdp checkpointing issues (#24926)
2023-07-20|||Fallback for missing attribute `Parameter.ds_numel` (#24942)
2023-07-20|||Contrastive Search peak memory reduction (#24120)
2023-07-20|||Change logic for logging in the examples (#24956)
2023-07-20|||[`RWKV`] Add Gradient Checkpointing support for RWKV (#24955)
2023-07-20|||Bump aiohttp from 3.8.1 to 3.8.5 in /examples/research_projects/decision_transformer (#24954)
2023-07-20|||fix type annotations for arguments in training_args (#24550)
2023-07-20|||[DOCS] Example for `LogitsProcessor` class (#24848)
2023-07-20|||Fix `main_input_name` in `src/transformers/keras_callbacks.py` (#24916)
2023-07-20|||Update processing_vision_text_dual_encoder.py (#24950)
2023-07-20|||Bump pygments from 2.11.2 to 2.15.0 in /examples/research_projects/decision_transformer (#24949)
2023-07-20|||Generate: sequence bias can handle same terminations (#24822)
2023-07-20|||replace no_cuda with use_cpu in test_pytorch_examples (#24944)
2023-07-20|||Deprecate unused OpenLlama architecture (#24922)
2023-07-20|||Add multi-label text classification support to pytorch example (#24770)
2023-07-20|||üåê [i18n-KO] Translated`tasks/document_question_answering.md` to Korean (#24588)
2023-07-19|||[doc] `image_processing_vilt.py` wrong default documented (#24931)
2023-07-19|||[`Llama2`] replace `self.pretraining_tp` with `self.config.pretraining_tp` (#24906)
2023-07-19|||Fix minor llama2.md model doc typos (#24909)
2023-07-19|||fix typo in BARK_PRETRAINED_MODEL_ARCHIVE_LIST (#24902)
2023-07-19|||Fixed issue where ACCELERATE_USE_CPU="False" results in bool(True) (#24907)
2023-07-19|||Fix `test_model_parallelism` for `FalconModel` (#24914)
2023-07-19|||Update tested versions in READMEs (#24895)
2023-07-19|||Avoid some pipeline tasks to use `use_cache=True` (#24893)
2023-07-18|||Check for accelerate env var when doing CPU only (#24890)
2023-07-18|||Disable ipex env var if false (#24885)
2023-07-18|||[`Llama2`]  Add support for Llama 2 (#24891)
2023-07-18|||Separate CircleCI cache between `main` and `pull` (or other branches) (#24886)
2023-07-18|||check if eval dataset is dict (#24877)
2023-07-18|||[`Blip`] Fix blip output name (#24889)
2023-07-18|||[`InstructBlip`] Fix int8/fp4 issues (#24888)
2023-07-18|||Add DINOv2 (#24016)
2023-07-18|||Enable `ZeroShotAudioClassificationPipelineTests::test_small_model_pt` (#24882)
2023-07-18|||add ascend npu accelerator support (#24879)
2023-07-18|||Fix CircleCI cache (#24880)
2023-07-18|||[`Docs`] Clarify 4bit docs (#24878)
2023-07-17|||Remove `tests/onnx` (#24868)
2023-07-17|||Skip Add model like job (#24865)
2023-07-17|||Skip failing `ZeroShotAudioClassificationPipelineTests::test_small_model_pt` for now (#24867)
2023-07-17|||deprecate no_cuda (#24863)
2023-07-18|||Remove deprecated codes (#24837)
2023-07-17|||Make CLIP model could use new added tokens with meaningful pooling (#24777)
2023-07-18|||Replace assert statements with exceptions (#24856)
2023-07-17|||Fix the fetch of all example tests (#24864)
2023-07-17|||4.32.0.dev0
2023-07-17|||Fix token pass (#24862)
2023-07-17|||Add bark (#24086)
2023-07-17|||Add TAPEX to the list of deprecated models (#24859)
2023-07-17|||fix broken links in READMEs (#24861)
2023-07-17|||Fix comments for `_merge_heads` (#24855)
2023-07-17|||Fix `is_vision_available` (#24853)
2023-07-17|||Add Multimodal heading and Document question answering in task_summary.mdx (#23318)
2023-07-17|||Bump cryptography from 41.0.0 to 41.0.2 in /examples/research_projects/decision_transformer (#24833)
2023-07-17|||Remove unused code in GPT-Neo (#24826)
2023-07-17|||üåê¬†[i18n-KO] Translated¬†`custom_tools.mdx` to Korean  (#24580)
2023-07-17|||deprecate `sharded_ddp` training argument (#24825)
2023-07-15|||[üîó Docs] Fixed Incorrect Migration Link (#24793)
2023-07-14|||Check models used for common tests are small (#24824)
2023-07-14|||set correct model input names for gptsw3tokenizer (#24788)
2023-07-14|||Fixing double `use_auth_token.pop` (preventing private models from being visible). (#24812)
2023-07-13|||Copy code when using local trust remote code (#24785)
2023-07-13|||Run hub tests (#24807)
2023-07-13|||Use _BaseAutoModelClass's register method (#24810)
2023-07-13|||Update setup.py to be compatible with pipenv (#24789)
2023-07-13|||Remove Falcon docs for the release until TGI is ready (#24808)
2023-07-13|||Fix typo 'submosules' (#24809)
2023-07-13|||Add accelerate version in transformers-cli env (#24806)
2023-07-13|||Llama/GPTNeoX: add RoPE scaling  (#24653)
2023-07-13|||Deprecate models (#24787)
2023-07-13|||Skip torchscript tests for `MusicgenForConditionalGeneration` (#24782)
2023-07-13|||Fix MobileVitV2 doctest checkpoint (#24805)
2023-07-13|||Upgrade jax/jaxlib/flax pin versions (#24791)
2023-07-13|||[DOC] Clarify relationshi load_best_model_at_end and save_total_limit (#24614)
2023-07-13|||[fix] Change the condition of ValueError in "convert_checkpoint_from_transformers_to_megatron" (#24769)
2023-07-13|||Removing unnecessary `device=device` in modeling_llama.py (#24696)
2023-07-13|||Revert "Unpin protobuf in docker file (for daily CI)" (#24800)
2023-07-12|||Rm duplicate pad_across_processes (#24780)
2023-07-12|||Remove WWT from README (#24672)
2023-07-12|||gpt-bigcode: avoid `zero_` to support Core ML (#24755)
2023-07-12|||Fix pad across processes dim in trainer and not being able to set the timeout (#24775)
2023-07-12|||Update default values of bos/eos token ids in `CLIPTextConfig` (#24773)
2023-07-12|||Replacement of 20 asserts with exceptions (#24757)
2023-07-12|||Docs: Update logit processors __call__ docs (#24729)
2023-07-12|||Add MobileVitV2 to doctests (#24771)
2023-07-12|||Fix eval_accumulation_steps leading to incorrect metrics (#24756)
2023-07-11|||Unpin protobuf in docker file (for daily CI) (#24761)
2023-07-11|||Allow existing configs to be registered (#24760)
2023-07-11|||:bug: Handle empty gen_kwargs for seq2seq trainer prediction_step function (#24759)
2023-07-11|||Fix lr scheduler not being reset on reruns (#24758)
2023-07-11|||Skip some slow tests for doctesting in PRs (Circle)CI (#24753)
2023-07-11|||[InstructBLIP] Fix bos token of LLaMa checkpoints (#24492)
2023-07-11|||Fix non-deterministic Megatron-LM checkpoint name (#24674)
2023-07-11|||Skip keys not in the state dict when finding mismatched weights (#24749)
2023-07-11|||add gradient checkpointing for distilbert (#24719)
2023-07-11|||Docs: add `kwargs` type to fix formatting (#24733)
2023-07-11|||fix: Text splitting in the BasicTokenizer (#22280)
2023-07-11|||Fix typo in LocalAgent (#24736)
2023-07-11|||Add ViViT (#22518)
2023-07-11|||[Patch-t5-tokenizer] Patches the changes on T5 to make sure previous behaviour is still valide for beginning of words (#24622)
2023-07-11|||Falcon port (#24523)
2023-07-10|||add link to accelerate doc (#24601)
2023-07-10|||Docs: change some `input_ids` doc reference from `BertTokenizer` to `AutoTokenizer`  (#24730)
2023-07-10|||[`T5`] Adding model_parallel = False to `T5ForQuestionAnswering` and `MT5ForQuestionAnswering` (#24684)
2023-07-10|||Add Multi Resolution Analysis (MRA) (New PR) (#24513)
2023-07-07|||Enable `conversational` pipeline for `GPTSw3Tokenizer` (#24648)
2023-07-07|||Whisper: fix prompted max length (#24666)
2023-07-07|||Fix flaky `test_for_warning_if_padding_and_no_attention_mask` (#24706)
2023-07-07|||[`MT5`] Fix CONFIG_MAPPING issue leading it to load umt5 class (#24678)
2023-07-06|||Fix integration with Accelerate and failing test (#24691)
2023-07-06|||Avoid import `sentencepiece_model_pb2` in `utils.__init__.py` (#24689)
2023-07-06|||DeepSpeed/FSDP ckpt saving utils fixes and FSDP training args fixes (#24591)
2023-07-06|||Add dropouts to GPT-NeoX (#24680)
2023-07-06|||LlamaTokenizer should be picklable (#24681)
2023-07-05|||Add Nucleotide Transformer notebooks and restructure notebook list (#24669)
2023-07-05|||Fix model referenced and results in documentation. Model mentioned was inaccessible (#24609)
2023-07-05|||Unpin `huggingface_hub` (#24667)
2023-07-05|||Add `is_torch_mps_available` function to utils (#24660)
2023-07-05|||Fix `VisionTextDualEncoderIntegrationTest` (#24661)
2023-07-05|||Fix `EncodecModelTest::test_multi_gpu_data_parallel_forward` (#24663)
2023-07-04|||Make warning disappear for remote code in pipelines (#24603)
2023-07-04|||Add `finetuned_from` property in the autogenerated model card (#24528)
2023-07-04|||Update warning messages reffering to post_process_object_detection (#24649)
2023-07-04|||documentation_tests.txt - sort filenames alphabetically (#24647)
2023-07-04|||llama fp16 torch.max bug fix (#24561)
2023-07-04|||Fix audio feature extractor deps (#24636)
2023-07-04|||precompiled_charsmap checking before adding to the normalizers' list for XLNetTokenizerFast conversion. (#24618)
2023-07-03|||Generate: force cache with `inputs_embeds` forwarding (#24639)
2023-07-03|||Generate: multi-device support for contrastive search (#24635)
2023-07-03|||Fix loading dataset docs link in run_translation.py example (#24594)
2023-07-03|||Pin `Pillow` for now (#24633)
2023-07-03|||[Time-Series] Added blog-post to tips (#24482)
2023-07-03|||üåê [i18n-KO] Translated `perplexity.mdx` to Korean (#23850)
2023-07-03|||[`Umt5`]  Add google's umt5 to `transformers` (#24477)
2023-07-01|||fix pydantic install command
2023-07-01|||Limit Pydantic to V1 in dependencies (#24596)
2023-06-30|||Use protobuf 4 (#24599)
2023-06-30|||[several models] improve readability (#24585)
2023-06-30|||Speed up TF tests by reducing hidden layer counts (#24595)
2023-06-30|||Make (TF) CI faster (test only a subset of model classes) (#24592)
2023-06-30|||Show a warning for missing attention masks when pad_token_id is not None (#24510)
2023-06-30|||Udate link to RunHouse hardware setup documentation. (#24590)
2023-06-30|||‚ö†Ô∏è‚ö†Ô∏è[`T5Tokenize`] Fix T5 family tokenizers‚ö†Ô∏è‚ö†Ô∏è (#24565)
2023-06-30|||fix peft ckpts not being pushed to hub  (#24578)
2023-06-30|||Fix annotations (#24582)
2023-06-29|||Check all objects are equally in the main `__init__` file (#24573)
2023-06-29|||Fix ESM models buffers (#24576)
2023-06-29|||Removal of deprecated vision methods and specify deprecation versions (#24570)
2023-06-29|||Update some torchscript tests after #24505 (#24566)
2023-06-29|||Add Musicgen (#24109)
2023-06-29|||Revert "Fix typing annotations for FSDP and DeepSpeed in TrainingArguments" (#24574)
2023-06-29|||Docs: 4 bit doc corrections (#24572)
2023-06-29|||Fix annotations (#24571)
2023-06-29|||Fix Typo (#24559)
2023-06-29|||Update old existing feature extractor references (#24552)
2023-06-29|||Fixed OwlViTModel inplace operations (#24529)
2023-06-28|||Update masked_language_modeling.md (#24560)
2023-06-28|||Make PT/Flax tests could be run on GPU (#24557)
2023-06-28|||Update PT/Flax weight conversion after #24030 (#24556)
2023-06-28|||[`InstructBlip`] Add instruct blip int8 test (#24555)
2023-06-28|||Fix processor __init__ bug if image processor undefined (#24554)
2023-06-28|||[`gpt2-int8`] Add gpt2-xl int8 test (#24543)
2023-06-28|||Update `EncodecIntegrationTest` (#24553)
2023-06-28|||Update PT/TF weight conversion after #24030 (#24547)
2023-06-28|||Fix typing annotations for FSDP and DeepSpeed in TrainingArguments (#24549)
2023-06-28|||Allow for warn_only selection in enable_full_determinism (#24496)
2023-06-28|||Unpin DeepSpeed and require DS >= 0.9.3 (#24541)
2023-06-28|||‚ö†Ô∏è Time to say goodbye to py37 (#24091)
2023-06-28|||Add bitsandbytes support for gpt2 models (#24504)
2023-06-27|||Finishing tidying keys to ignore on load (#24535)
2023-06-28|||Fix Typo (#24530)
2023-06-27|||Allow backbones not in backbones_supported - Maskformer Mask2Former (#24532)
2023-06-27|||Clean load keys (#24505)
2023-06-27|||[Mask2Former] Remove SwinConfig (#24259)
2023-06-27|||Fix LR scheduler based on bs from auto bs finder (#24521)
2023-06-27|||Find module name in an OS-agnostic fashion (#24526)
2023-06-27|||Update `huggingface_hub` commit sha (#24527)
2023-06-27|||set model to training mode before accelerate.prepare (#24520)
2023-06-27|||[`T5`] Add T5ForQuestionAnswering and MT5ForQuestionAnswering (#24481)
2023-06-27|||Update hyperparameter_search.py (#24515)
2023-06-27|||use accelerate autocast in jit eval path, since mix precision logic is‚Ä¶ (#24460)
2023-06-27|||üåê [i18n-KO] Translated `tflite.mdx` to Korean (#24435)
2023-06-27|||Fix poor past ci (#24485)
2023-06-27|||Fix TypeError: Object of type int64 is not JSON serializable (#24340)
2023-06-27|||Generate: `min_tokens_to_keep` has to be `>= 1` (#24453)
2023-06-27|||Generate: `group_beam_search` requires `diversity_penalty>0.0` (#24456)
2023-06-27|||üö®üö® Fix group beam search (#24407)
2023-06-26|||Fix link in utils (#24501)
2023-06-26|||Compute `dropout_probability` only in training mode (SpeechT5) (#24498)
2023-06-27|||Fix 'local_rank' AttiributeError in Trainer class (#24297)
2023-06-26|||Compute `dropout_probability` only in training mode (#24486)
2023-06-26|||[`InstructBlip`] Add accelerate support for instructblip (#24488)
2023-06-26|||Add support for for loops in python interpreter (#24429)
2023-06-26|||Update token_classification.md (#24484)
2023-06-26|||Update `InstructBlipModelIntegrationTest` (#24490)
2023-06-26|||deepspeed z1/z2 state dict fix (#24489)
2023-06-26|||when resume from peft checkpoint, the model should be trainable (#24463)
2023-06-26|||[`pipeline`] Fix str device issue (#24396)
2023-06-26|||Update AlbertModel type annotation (#24450)
2023-06-26|||Fix tpu_metrics_debug (#24452)
2023-06-26|||add missing alignment_heads to Whisper integration test (#24487)
2023-06-26|||Add InstructBLIP (#23460)
2023-06-23|||Improved keras imports (#24448)
2023-06-23|||Update `JukeboxConfig.from_pretrained` (#24443)
2023-06-23|||Allow dict input for audio classification pipeline (#23445)
2023-06-23|||fixes issue when saving fsdp via accelerate's FSDP plugin (#24446)
2023-06-23|||Fix some `TFWhisperModelIntegrationTests` (#24428)
2023-06-23|||Fix typo (#24440)
2023-06-23|||Replace python random with torch.rand to enable dynamo.export (#24434)
2023-06-23|||fix the grad_acc issue at epoch boundaries (#24415)
2023-06-23|||[`Trainer`] Fix `.to` call on 4bit models (#24444)
2023-06-23|||[AutoModel] Add AutoModelForTextEncoding (#24305)
2023-06-22|||[llama] Fix comments in weights converter (#24436)
2023-06-22|||Save `site-packages` as cache in CircleCI job (#24424)
2023-06-22|||Clarify batch size displayed when using DataParallel (#24430)
2023-06-22|||Refactor hyperparameter search backends (#24384)
2023-06-22|||TF CI fix for Segformer (#24426)
2023-06-22|||Update RayTune doc link for Hyperparameter tuning (#24422)
2023-06-22|||Fix `save_cache` version in `config.yml` (#24419)
2023-06-22|||Revert "Fix gradient checkpointing + fp16 autocast for most models" (#24420)
2023-06-22|||[`bnb`]¬†Fix bnb serialization issue with new release (#24416)
2023-06-22|||Skip `test_conditional_generation_pt_pix2struct` in Past CI (torch < 1.11) (#24417)
2023-06-22|||TF safetensors reduced mem usage (#24404)
2023-06-22|||[ASR pipeline] Check for torchaudio (#23953)
2023-06-21|||Explicit arguments in `from_pretrained` (#24306)
2023-06-21|||Remove redundant code from TrainingArgs (#24401)
2023-06-21|||add word-level timestamps to Whisper (#23205)
2023-06-21|||Check auto mappings could be imported via `from transformers` (#24400)
2023-06-21|||Clean up dist import (#24402)
2023-06-21|||Fix gradient checkpointing + fp16 autocast for most models (#24247)
2023-06-21|||[Trainer] Fix optimizer step on PyTorch TPU (#24389)
2023-06-21|||fix type annotation for debug arg (#24033)
2023-06-21|||byebye Hub connection timeout - Recast (#24399)
2023-06-21|||Generate: add SequenceBiasLogitsProcessor (#24334)
2023-06-21|||Add `ffmpeg` for `doc_test_job` on CircleCI (#24397)
2023-06-20|||[docs] Fix NLLB-MoE links (#24388)
2023-06-20|||Update deprecated torch.ger (#24387)
2023-06-20|||Migrate doc files to Markdown. (#24376)
2023-06-20|||[Wav2Vec2 - MMS] Correct directly loading adapters weights (#24335)
2023-06-20|||[GPTNeoX] Nit in config (#24349)
2023-06-20|||[Whisper Docs] Nits (#24367)
2023-06-20|||Skip a tapas (tokenization) test in past CI (#24378)
2023-06-20|||Better test name and enable pipeline test for `pix2struct` (#24377)
2023-06-20|||style: add BitsAndBytesConfig __repr__ function (#24331)
2023-06-20|||[Tokenizer doc] Clarification about `add_prefix_space` (#24368)
2023-06-20|||Add a check in `ImageToTextPipeline._forward` (#24373)
2023-06-20|||Rename test to be more accurate (#24374)
2023-06-20|||Remove print statement
2023-06-20|||[Whisper] Make tests faster (#24105)
2023-06-20|||[modelcard] add audio classification to task list (#24363)
2023-06-20|||Update tiny models for pipeline testing. (#24364)
2023-06-20|||TensorFlow CI fixes (#24360)
2023-06-20|||Fix resuming PeftModel checkpoints in Trainer  (#24274)
2023-06-20|||Allow passing kwargs through to TFBertTokenizer (#24324)
2023-06-20|||Respect explicitly set framework parameter in pipeline (#24322)
2023-06-19|||Fix the order in `GPTNeo`'s docstring (#24358)
2023-06-19|||[Doc Fix] Fix model name path in the transformers doc for AutoClasses (#24329)
2023-06-19|||docs: add BentoML to awesome-transformers (#24344)
2023-06-19|||Fix link to documentation in Install from Source (#24336)
2023-06-19|||Fix ImageGPT doctest (#24353)
2023-06-19|||Make `AutoFormer` work with previous torch version (#24357)
2023-06-19|||Update MMS integration docs  (#24311)
2023-06-19|||Fix device issue in `SwitchTransformers` (#24352)
2023-06-19|||Fix `KerasMetricCallback`: pass `generate_kwargs` even if `use_xla_generation` is False (#24333)
2023-06-19|||Clean up disk sapce during docker image build for `transformers-pytorch-gpu` (#24346)
2023-06-19|||byebye Hub connection timeout (#24350)
2023-06-19|||pin `apex` to a speicifc commit (for DeepSpeed CI docker image) (#24351)
2023-06-19|||üåê [i18n-KO] Fixed `tutorial/preprocessing.mdx` (#24156)
2023-06-19|||error bug on saving distributed optim state when using data parallel (#24108)
2023-06-16|||Adding ddp_broadcast_buffers argument to Trainer (#24326)
2023-06-16|||Add test for proper TF input signatures (#24320)
2023-06-16|||Fix ImageGPT doc example (#24317)
2023-06-16|||Tied weights load (#24310)
2023-06-16|||Fix ner average grouping with no groups (#24319)
2023-06-16|||Big TF test cleanup (#24282)
2023-06-16|||Byebye pytorch 1.9 (#24080)
2023-06-16|||Fix functional TF Whisper and modernize tests (#24301)
2023-06-16|||[`SwitchTransformers`] Fix return values (#24300)
2023-06-15|||Update test versions on README.md (#24307)
2023-06-15|||Make `can_generate` as class method (#24299)
2023-06-15|||Beam search type (#24288)
2023-06-15|||Update tokenizer_summary.mdx (grammar) (#24286)
2023-06-15|||[Docs] Fix the paper URL for MMS model (#24302)
2023-06-15|||[EnCodec] Changes for 32kHz ckpt (#24296)
2023-06-15|||deepspeed init during eval fix (#24298)
2023-06-15|||Update README_zh-hans.md (#24181)
2023-06-15|||[Docs] Improve docs for MMS loading of other languages (#24292)
2023-06-15|||Fix image segmentation tool bug (#23897)
2023-06-15|||[fix] bug in BatchEncoding.__getitem__ (#24293)
2023-06-15|||Split common test from core tests (#24284)
2023-06-15|||remove unused is_decoder parameter in DetrAttention (#24226)
2023-06-15|||Fix LLaMa beam search when using parallelize (#24224)
2023-06-15|||Fix `check_config_attributes`: check all configuration classes (#24231)
2023-06-15|||Fix bug in slow tokenizer conversion, make it a lot faster (#24266)
2023-06-15|||Add MMS CTC Fine-Tuning (#24281)
2023-06-14|||[WIP] add EnCodec model (#23655)
2023-06-14|||Clean up old Accelerate checks (#24279)
2023-06-14|||Fix Debertav2 embed_proj (#24205)
2023-06-14|||`Pix2StructImageProcessor` requires `torch>=1.11.0` (#24270)
2023-06-14|||Update check of core deps (#24277)
2023-06-14|||Adapt Wav2Vec2 conversion for MMS lang identification (#24234)
2023-06-14|||TF: CTRL with native embedding layers (#23456)
2023-06-14|||Skip some `TQAPipelineTests` tests in past CI (#24267)
2023-06-14|||QA doc: import torch before it is used (#24228)
2023-06-14|||Fix URL in comment for contrastive loss function (#24271)
2023-06-14|||update FSDP save and load logic (#24249)
2023-06-14|||docs wrt using accelerate launcher with trainer (#24250)
2023-06-13|||Skip `GPT-J` fx tests for torch < 1.12 (#24256)
2023-06-13|||Stop storing references to bound methods via tf.function (#24146)
2023-06-13|||Fix how we detect the TF package (#24255)
2023-06-13|||Update urls in warnings for rich rendering (#24136)
2023-06-13|||Add `torch >=1.12` requirement for `Tapas` (#24251)
2023-06-13|||Generate: GenerationConfig can overwrite attributes at from_pretrained time (#24238)
2023-06-13|||TF: standardize `test_model_common_attributes` for language models (#23457)
2023-06-13|||[Time Series] use mean scaler when scaling is a boolean True (#24237)
2023-06-13|||Tied params cleanup (#24211)
2023-06-13|||deprecate `use_mps_device` (#24239)
2023-06-13|||fix overflow when training mDeberta in fp16 (#24116)
2023-06-13|||Safely import pytest in testing_utils.py (#24241)
2023-06-13|||Improving error message when using `use_safetensors=True`. (#24232)
2023-06-13|||Update `(TF)SamModelIntegrationTest` (#24199)
2023-06-13|||fix: TextIteratorStreamer cannot work with pipeline (#23641)
2023-06-12|||Fix README copies
2023-06-12|||Add the number of `model` test failures to slack CI report (#24207)
2023-06-12|||Finish dataloader integration (#24201)
2023-06-12|||Update `WhisperForAudioClassification` doc example (#24188)
2023-06-13|||Remove unnecessary aten::to overhead in llama (#24203)
2023-06-12|||Skip RWKV test in past CI (#24204)
2023-06-12|||Fix steps bugs in no trainer examples (#24197)
2023-06-12|||Fix `_load_pretrained_model` (#24200)
2023-06-12|||üö®üö®üö® Replace DataLoader logic for Accelerate in Trainer, remove unneeded tests üö®üö®üö® (#24028)
2023-06-13|||üåê [i18n-KO] Translated tasks_summary.mdx to Korean (#23977)
2023-06-12|||Generate: detect special architectures when loaded from PEFT (#24198)
2023-06-12|||typo: fix typos in CONTRIBUTING.md and deepspeed.mdx (#24184)
2023-06-12|||Update `GPTNeoXLanguageGenerationTest` (#24193)
2023-06-12|||Fix device issue in `OpenLlamaModelTest::test_model_parallelism` (#24195)
2023-06-12|||Generate: force caching on the main model, in assisted generation (#24177)
2023-06-12|||[i18n]Translated "attention.mdx" to korean (#23878)
2023-06-12|||Change ProgressCallback to use dynamic_ncols=True (#24101)
2023-06-12|||Fix push to hub (#24187)
2023-06-12|||Fix `Wav2Vec2` CI OOM  (#24190)
2023-06-10|||Avoid OOM in doctest CI (#24139)
2023-06-09|||[tests] fix bitsandbytes import issue (#24151)
2023-06-09|||Tool types (#24032)
2023-06-09|||Fix typo in streamers.py (#24144)
2023-06-09|||[documentation] grammatical fixes in image_classification.mdx (#24141)
2023-06-09|||Fix Pipeline CI OOM issue (#24124)
2023-06-09|||[BlenderBotSmall] Update doc example (#24092)
2023-06-09|||[lamaTokenizerFast] Update documentation (#24132)
2023-06-09|||[`SAM`] Fix sam slow test (#24140)
2023-06-09|||Fix XGLM OOM on CI (#24123)
2023-06-09|||Fix SAM OOM issue on CI (#24125)
2023-06-09|||Fix TF Rag OOM issue (#24122)
2023-06-09|||fix bugs with trainer (#24134)
2023-06-09|||Generate: PT's `top_p` enforces `min_tokens_to_keep` when it is `1` (#24111)
2023-06-09|||Correctly build models and import call_context for older TF versions (#24138)
2023-06-09|||[`bnb`] Fix bnb config json serialization (#24137)
2023-06-09|||PLAM => PaLM (#24129)
2023-06-09|||[Lllama] Update tokenization code to ensure parsing of the special tokens [core] (#24042)
2023-06-08|||Avoid `GPT-2` daily CI job OOM (in TF tests) (#24106)
2023-06-08|||Fix typo in Llama docstrings (#24020)
2023-06-08|||add trust_remote_code option to CLI download cmd (#24097)
2023-06-08|||[`GPT2`] Add correct keys on `_keys_to_ignore_on_load_unexpected` on all child classes of `GPT2PreTrainedModel` (#24113)
2023-06-08|||fix get_keys_to_not_convert function (#24095)
2023-06-08|||Update the pin on Accelerate (#24110)
2023-06-08|||[`Trainer`] Correct behavior of `_load_best_model` for PEFT models (#24103)
2023-06-08|||reset accelerate env variables after each test (#24107)
2023-06-08|||Fix a tiny typo in `WhisperForConditionalGeneration::generate` docstring (#24045)
2023-06-07|||v4.31.0.dev0
2023-06-07|||Add AzureOpenAiAgent (#24058)
2023-06-07|||Up pinned accelerate version (#24089)
2023-06-08|||fix accelerator prepare during eval only mode (#24014)
2023-06-07|||Do not prepare lr scheduler as it as the right number of steps (#24088)
2023-06-07|||fix executable batch size issue (#24067)
2023-06-07|||Update delete_doc_comment_trigger.yml (#24084)
2023-06-07|||Fix expected value in tests of the test fetcher (#24077)
2023-06-07|||[doc build] Use secrets (#24079)
2023-06-07|||Make the TF dummies even smaller (#24071)
2023-06-07|||Be nice to TF (#24076)
2023-06-07|||[`bnb`] Fix bnb skip modules (#24043)
2023-06-07|||Fix `is_optimum_neuron_available` (#23961)
2023-06-07|||[`Hub`] Add `safe_serialization` in push_to_hub (#24074)
2023-06-07|||Support PEFT models when saving the model using trainer (#24073)
2023-06-07|||Add support for non-rust implemented tokenization for `__getitem__` method. (#24039)
2023-06-07|||[Wav2Vec2] Fix torch srcipt (#24062)
2023-06-07|||Generate: increase left-padding test atol (#23448)
2023-06-06|||Remote code improvements (#23959)
2023-06-06|||Fix device placement for model-parallelism in generate for encoder/de‚Ä¶ (#24025)
2023-06-06|||bring back `filtered_test_list_cross_tests.txt` (#24055)
2023-06-06|||Use new parametrization based weight norm if available (#24030)
2023-06-06|||Move TF building to an actual build() method (#23760)
2023-06-06|||Oops, missed one (#24054)
2023-06-06|||Reduce memory usage in TF building (#24046)
2023-06-06|||Act on deprecations in Accelerate no_trainer examples (#24053)
2023-06-06|||Tiny fix for `check_self_hosted_runner.py` (#24052)
2023-06-06|||Add TimmBackbone model (#22619)
2023-06-06|||Modification of one text example file should trigger said test (#24051)
2023-06-06|||Prevent ZeroDivisionError on `trainer.evaluate` if model and dataset are tiny  (#24049)
2023-06-06|||Use TruncatedNormal from Keras initializers (#24036)
2023-06-06|||Fixing single candidate_label return. (#24023)
2023-06-06|||Add check for tied parameters (#24029)
2023-06-06|||üåê [i18n-KO] Translated `bertology.mdx` to Korean (#23968)
2023-06-06|||üåê [i18n-KO] Translated `language-modeling.mdx` (#23969)
2023-06-05|||Pin `deepspeed` to `0.9.2` for now (#24024)
2023-06-05|||Fix `MobileViTV2` checkpoint name (#24018)
2023-06-06|||üåê [i18n-KO] Translated `tasks_explained.mdx` to Korean (#23844)
2023-06-05|||TensorBoard callback no longer adds hparams (#23999)
2023-06-06|||Pix2Struct: fix wrong broadcast axis of attention mask in visual encoder (#23976)
2023-06-05|||expose safe_serialization argument in the pipeline API (#23775)
2023-06-05|||Auto tokenizer registration (#23965)
2023-06-05|||Update README.md (#24022)
2023-06-05|||Skip `test_multi_gpu_data_parallel_forward` for `MobileViTV2ModelTest` (#24017)
2023-06-05|||fix trainer slow tests related to hyperparam search (#24011)
2023-06-05|||Fix typo in doc comment of BitsAndBytesConfig (#23978)
2023-06-02|||Bump cryptography from 39.0.1 to 41.0.0 in /examples/research_projects/decision_transformer (#23964)
2023-06-02|||Added time-series blogs to the models (#23857)
2023-06-02|||Add an option to reduce compile() console spam (#23938)
2023-06-02|||[Whisper Tokenizer] Skip special tokens when decoding with timestamps (#23945)
2023-06-02|||Trainer: fixed evaluate raising `KeyError` for ReduceLROnPlateau (#23952)
2023-06-02|||üåê [i18n-KO] Translated object_detection.mdx to Korean (#23164)
2023-06-02|||add new mms functions to doc (#23954)
2023-06-02|||Add MobileViTv2 (#22820)
2023-06-02|||[MMS] Scaling Speech Technology to 1,000+ Languages | Add attention adapter to Wav2Vec2 (#23813)
2023-06-02|||Fix `ReduceLROnPlateau` object has no attribute 'get_last_lr' (#23944)
2023-06-01|||use _make_causal_mask in clip/vit models (#23942)
2023-06-01|||Modify device_map behavior when loading a model using from_pretrained (#23922)
2023-06-02|||#23675 Registering Malay language (#23689)
2023-06-01|||Revert "Update stale.yml to use HuggingFaceBot" (#23943)
2023-06-01|||Make TF ESM inv_freq non-trainable like PyTorch (#23940)
2023-06-01|||Update stale.yml to use HuggingFaceBot (#23941)
2023-06-01|||rename DocumentQuestionAnsweringTool parameter input to match docstring (#23939)
2023-06-01|||Pin rhoknp (#23937)
2023-06-01|||Fix doc string nits (#23929)
2023-06-01|||Effectively allow `encoder_outputs` input to be a tuple in pix2struct (#23932)
2023-06-01|||[Flax Whisper] Update decode docstring (#23908)
2023-05-31|||Skip device placement for past key values in decoder models (#23919)
2023-05-31|||[PushToHub] Make it possible to upload folders (#23920)
2023-05-31|||Update the update metadata job to use upload_folder (#23917)
2023-05-31|||Re-enable squad test (#23912)
2023-05-31|||remove the extra `accelerator.prepare`  (#23914)
2023-05-31|||Bug fix - flip_channel_order for channels first images (#23701)
2023-05-31|||Empty circleci config (#23913)
2023-05-31|||Raise error if loss can't be calculated - ViT MIM  (#23872)
2023-05-31|||add conditional statement for auxiliary loss calculation (#23899)
2023-05-31|||[`RWKV`] Fix RWKV 4bit (#23910)
2023-05-31|||Upgrade safetensors version (#23911)
2023-05-31|||fix: Replace `add_prefix_space` in `get_prompt_ids` with manual space for FastTokenizer compatibility (#23796)
2023-05-31|||Move import check to before state reset (#23906)
2023-05-31|||[`bnb`] add warning when no linear  (#23894)
2023-05-31|||Unpin numba (#23162)
2023-05-31|||ensure banned_mask and indices in same device (#23901)
2023-05-31|||Support shared tensors (#23871)
2023-05-31|||Fix Trainer when model is loaded on a different GPU (#23792)
2023-05-31|||fix(configuration_llama): add `keys_to_ignore_at_inference` to `LlamaConfig` (#23891)
2023-05-31|||Skip failing test for now
2023-05-31|||accelerate deepspeed and gradient accumulation integrate (#23236)
2023-05-31|||Add TensorFlow implementation of  EfficientFormer (#22620)
2023-05-31|||Fix last instances of kbit -> quantized (#23797)
2023-05-31|||Fix bug leading to missing token in GPTSanJapaneseTokenizer (#23883)
2023-05-31|||shift torch dynamo handling to accelerate (#23168)
2023-05-31|||move fsdp handling to accelerate (#23158)
2023-05-31|||üåê [i18n-KO] Translated `pad_truncation.mdx` to Korean (#23823)
2023-05-31|||Smangrul/accelerate ddp integrate (#23151)
2023-05-31|||Smangrul/accelerate mp integrate (#23148)
2023-05-30|||Adds AutoProcessor.from_pretrained support for MCTCTProcessor (#23856)
2023-05-30|||Editing issue with pickle def with lambda function (#23869)
2023-05-30|||[from_pretrained] imporve the error message when `_no_split_modules` is not defined (#23861)
2023-05-30|||#23388 Issue: Update RoBERTa configuration (#23863)
2023-05-30|||[LlamaTokenizerFast] nit update `post_processor` on the fly (#23855)
2023-05-30|||Update collating_graphormer.py (#23862)
2023-05-30|||Adds a FlyteCallback (#23759)
2023-05-30|||üåê [i18n-KO] Translated `troubleshooting.mdx` to Korean (#23166)
2023-05-30|||[i18n-KO] Translated video_classification.mdx to Korean (#23026)
2023-05-30|||üåê [i18n-KO] Translated `fast_tokenizers.mdx` to Korean (#22956)
2023-05-30|||fix Whisper tests on GPU (#23753)
2023-05-30|||TF SAM shape flexibility fixes (#23842)
2023-05-30|||add type hint in pipeline model argument (#23740)
2023-05-30|||[Time-Series] Autoformer model (#21891)
2023-05-26|||Enable code-specific revision for code on the Hub (#23799)
2023-05-26|||Log the right train_batch_size if using auto_find_batch_size and also log the adjusted value seperately. (#23800)
2023-05-26|||Fix no such file or directory error (#23783)
2023-05-26|||no_cuda does not take effect in non distributed environment (#23795)
2023-05-26|||Update trainer.mdx class_weights example (#23787)
2023-05-26|||Fix RWKV backward on GPU (#23774)
2023-05-26|||[OPT] Doc nit, using fast is fine (#23789)
2023-05-25|||[`Nllb-Moe`] Fix nllb moe accelerate issue (#23758)
2023-05-25|||Bump tornado from 6.0.4 to 6.3.2 in /examples/research_projects/visual_bert (#23767)
2023-05-25|||Bump tornado from 6.0.4 to 6.3.2 in /examples/research_projects/lxmert (#23766)
2023-05-26|||Fix is_ninja_available() (#23752)
2023-05-25|||[LongFormer] code nits, removed unused parameters  (#23749)
2023-05-25|||Revamp test selection for the example tests (#23737)
2023-05-25|||Fix psuh_to_hub in Trainer when nothing needs pushing (#23751)
2023-05-25|||Add LlamaIndex to awesome-transformers.md (#23484)
2023-05-25|||Fix `pip install --upgrade accelerate` command in modeling_utils.py (#23747)
2023-05-24|||Remove the last few TF serving sigs (#23738)
2023-05-24|||Enable prompts on the Hub (#23662)
2023-05-24|||Fix sagemaker DP/MP (#23681)
2023-05-24|||Fix the regex in `get_imports` to support multiline try blocks and excepts with specific exception types (#23725)
2023-05-24|||[Whisper] Reduce batch size in tests (#23736)
2023-05-24|||Overhaul TF serving signatures + dummy inputs (#23234)
2023-05-24|||fix: Whisper generate, move text_prompt_ids trim up for max_new_tokens calculation (#23724)
2023-05-25|||fix: delete duplicate sentences in `document_question_answering.mdx` (#23735)
2023-05-24|||TF SAM memory reduction (#23732)
2023-05-24|||Minor awesome-transformers.md fixes (#23453)
2023-05-24|||Better TF docstring types (#23477)
2023-05-24|||fix gptj could not jit.trace in GPU (#23317)
2023-05-24|||fix: use bool instead of uint8/byte in Deberta/DebertaV2/SEW-D to make it compatible with TensorRT (#23683)
2023-05-24|||Export to ONNX doc refocused on using optimum, added tflite (#23434)
2023-05-24|||Paged Optimizer + Lion Optimizer for Trainer (#23217)
2023-05-24|||4-bit QLoRA via bitsandbytes (4-bit base model + LoRA) (#23479)
2023-05-24|||add GPTJ/bloom/llama/opt into model list and enhance the jit support (#23291)
2023-05-24|||Fix some docs what layerdrop does (#23691)
2023-05-24|||fix: load_best_model_at_end error when load_in_8bit is True (#23443)
2023-05-23|||Skip `TFCvtModelTest::test_keras_fit_mixed_precision` for now (#23699)
2023-05-23|||is_batched fix for remaining 2-D numpy arrays (#23309)
2023-05-23|||[`Blip`] Fix blip doctest (#23698)
2023-05-23|||TF version compatibility fixes (#23663)
2023-05-23|||[`SAM`]¬†Fixes pipeline and adds a dummy pipeline test (#23684)
2023-05-23|||Fix a `BridgeTower` test (#23694)
2023-05-23|||üåê [i18n-KO] Translated `tasks/monocular_depth_estimation.mdx` to Korean (#23621)
2023-05-23|||Making `safetensors` a core dependency. (#23254)
2023-05-23|||Fix PyTorch SAM tests (#23682)
2023-05-23|||Fix typo in a parameter name for open llama model (#23637)
2023-05-23|||Add PerSAM [bis] (#23659)
2023-05-23|||Bump requests from 2.22.0 to 2.31.0 in /examples/research_projects/lxmert (#23668)
2023-05-23|||Bump requests from 2.22.0 to 2.31.0 in /examples/research_projects/visual_bert (#23670)
2023-05-23|||Bump requests from 2.27.1 to 2.31.0 in /examples/research_projects/decision_transformer (#23673)
2023-05-23|||small fix to remove unused eos in processor when it's not used. (#23408)
2023-05-22|||[image-to-text pipeline] Add conditional text support + GIT (#23362)
2023-05-22|||Update workflow files (#23658)
2023-05-22|||Update all no_trainer with skip_first_batches (#23664)
2023-05-22|||Fix SAM tests and use smaller checkpoints (#23656)
2023-05-22|||changing the requirements to a cpu torch version that works (#23483)
2023-05-22|||Fix wav2vec2 is_batched check to include 2-D numpy arrays (#23223)
2023-05-22|||Bugfix: LLaMA layer norm incorrectly changes input type and consumers lots of memory (#23535)
2023-05-22|||Muellerzr fix deepspeed (#23657)
2023-05-22|||Fix accelerate logger bug (#23650)
2023-05-22|||Fix tensor device while attention_mask is not None (#23538)
2023-05-22|||Remove erroneous `img` closing tag (#23646)
2023-05-22|||Debug example code for MegaForCausalLM (#23382)
2023-05-20|||Fix `tests/repo_utils/test_get_test_info.py` (#23485)
2023-05-19|||Fix confusing `transformers` installation in CI (#23465)
2023-05-19|||Fix DeepSpeed stuff in the nightly CI (#23478)
2023-05-19|||[`Blip`] Remove redundant shift right (#23153)
2023-05-19|||Fix: Change tensors to integers for torch.dynamo and torch.compile compatibility (#23475)
2023-05-19|||Fix PretrainedConfig `min_length` docstring (#23471)
2023-05-19|||Fix parallel mode check (#23409)
2023-05-19|||Fix `transformers`' DeepSpeed CI job (#23463)
2023-05-19|||Use config to set name and description if not present (#23473)
2023-05-19|||[`RWKV`] Rwkv fix for 8bit inference (#23468)
2023-05-19|||TF port of the Segment Anything Model (SAM) (#22970)
2023-05-19|||Remove .data usages in optimizations.py (#23417)
2023-05-19|||README: Fix affiliation for MEGA (#23394)
2023-05-19|||feat: Whisper prompting (#22496)
2023-05-18|||fix bug in group_texts function, that was inserting short batches (#23429)
2023-05-18|||Clean up CUDA kernels (#23455)
2023-05-18|||Add an option to log result from the Agent (#23454)
2023-05-18|||add cleanlab to awesome-transformers tools list (#23440)
2023-05-18|||Properly guard PyTorch stuff (#23452)
2023-05-18|||Update tiny models and pipeline tests (#23446)
2023-05-18|||Less flaky `test_assisted_decoding_matches_greedy_search` (#23451)
2023-05-18|||Make `RwkvModel` accept `attention_mask` but discard it internally (#23442)
2023-05-18|||Add local agent (#23438)
2023-05-18|||TF: GPT2 with native embedding layers (#23436)
2023-05-18|||Fix DecisionTransformerConfig doctring (#23450)
2023-05-18|||Fix (skip) a pipeline test for `RwkvModel` (#23444)
2023-05-18|||üåê [i18n-KO] Translated `tasks/zero_shot_object_detection.mdx` to Korean (#23430)
2023-05-18|||remove unnecessary print in gpt neox sequence classifier (#23433)
2023-05-18|||Generate: skip left-padding tests on old models (#23437)
2023-05-17|||Fix device issue in `SwiftFormerModelIntegrationTest::test_inference_image_classification_head` (#23435)
2023-05-17|||Remove hardcoded prints in Trainer (#23432)
2023-05-17|||Encoder-Decoder: add informative exception when the decoder is not compatible (#23426)
2023-05-17|||Update Bigbird Pegasus tests (#23431)
2023-05-17|||TF: embeddings out of bounds check factored into function (#23427)
2023-05-17|||Update error message when Accelerate isn't installed (#23373)
2023-05-17|||Small fixes and link in the README (#23428)
2023-05-17|||Top 100 (#22912)
2023-05-17|||Add Missing tokenization test [electra] (#22997)
2023-05-17|||[Reland] search model buffers for dtype as the last resort (#23319)
2023-05-17|||Return early once stop token is found. (#23421)
2023-05-17|||[`SAM`] fix sam slow test (#23376)
2023-05-17|||Update 3 docker files to use cu118 (#23406)
2023-05-17|||Use dict.items to avoid unnecessary lookups. (#23415)
2023-05-17|||Fix a typo in HfAgent docstring. (#23420)
2023-05-16|||Update `ConvNextV2ModelIntegrationTest::test_inference_image_classification_head` (#23402)
2023-05-16|||Run doctest (in PRs) only when some doc example(s) are modified (#23387)
2023-05-16|||Why crash the whole run when HFHub gives a 50x error? (#23320)
2023-05-16|||Fix smdistributed check (#23414)
2023-05-16|||Replace appends with list comprehension. (#23359)
2023-05-16|||Generate: add test to check KV format (#23403)
2023-05-16|||Build with non Python files (#23405)
2023-05-16|||Docs: add link to assisted generation blog post (#23397)
2023-05-16|||[AutoModel] fix `torch_dtype=auto` in `from_pretrained` (#23379)
2023-05-16|||Fix translation no_trainer (#23407)
2023-05-16|||Generate: faster `can_generate` check on TF and Flax (#23398)
2023-05-16|||[`Pix2Struct`] Add conditional generation on docstring example (#23399)
2023-05-16|||Minor fixes in transformers-tools (#23364)
2023-05-16|||üåê [i18n-KO] Translated `asr.mdx` to Korean (#23106)
2023-05-16|||Fix chat prompt in HFAgent (#23335)
2023-05-16|||OPT/BioGPT: Improved attention mask shape exception (#23270)
2023-05-16|||Update `test_batched_inference_image_captioning_conditioned` (#23391)
2023-05-16|||Fix `RwkvModel` (#23392)
2023-05-16|||Use `mkstemp` to replace deprecated `mktemp` (#23372)
2023-05-16|||Replace NumPy Operations with JAX NumPy Equivalents for JIT Compilation Compatibility (#23356)
2023-05-15|||Added type hints for `Graphormer` pytorch version (#23073)
2023-05-15|||Fix test typos - audio feature extractors (#23310)
2023-05-15|||Skip failing `AlignModelTest::test_multi_gpu_data_parallel_forward` (#23374)
2023-05-15|||[Bugfix] `OPTDecoderLayer` does not return attentions when `gradient_checkpointing` and `training` is enabled. (#23367)
2023-05-15|||Revert "Only add files with modification outside doc blocks" (#23371)
2023-05-15|||Fix `OwlViTForObjectDetection.image_guided_detection` doc example (#23370)
2023-05-15|||Fix `BigBirdForMaskedLM` doctest (#23369)
2023-05-15|||Fix some `is_xxx_available` (#23365)
2023-05-15|||Typo suggestion (#23360)
2023-05-15|||Fix issue introduced in PR #23163 (#23363)
2023-05-15|||Removing one of the twice defined position_embeddings in LongFormer (#23343)
2023-05-12|||Use cu118 with cudnn >= 8.6 in docker file (#23339)
2023-05-12|||replaced assert with raise ValueError for t5, switch_transformers, pix2struct, mt5, longt5, gptsan_japanese. (#23273)
2023-05-12|||Handle padding warning in generation when using `inputs_embeds` (#23131)
2023-05-12|||OR am I crazy? (#23295)
2023-05-12|||[docs] Fix Agents and Tools docstring (#23313)
2023-05-12|||Only add files with modification outside doc blocks (#23327)
2023-05-12|||Compute the mask in-place, with less memory reads, and on CUDA on `XLNetLMHeadModel` (#23332)
2023-05-12|||Fix docker image (caused by `tensorflow_text`) (#23321)
2023-05-12|||Add swiftformer (#22686)
2023-05-12|||Remove `LanguageIdentificationTool` in `__init__.py` as we don't have it yet (#23326)
2023-05-11|||Revert "search buffers for dtype" (#23308)
2023-05-11|||unpin tf prob (#23293)
2023-05-11|||Style
2023-05-11|||Fix image segmentation tool test (#23306)
2023-05-11|||Fix typo in gradio-tools docs (#23305)
2023-05-11|||Fix broken links in the agent docs (#23297)
2023-05-11|||Agents extras (#23301)
2023-05-11|||Add gradient_checkpointing parameter to FlaxWhisperEncoder (#23300)
2023-05-11|||Better check for packages availability (#23163)
2023-05-11|||skip `test_run_squad_no_trainer` for now (#23302)
2023-05-11|||Fix doctest files fetch issue (#23277)
2023-05-11|||Convert numpy arrays to lists before saving the evaluation metrics as json (#23268)
2023-05-11|||Update transformers_agents.mdx (#23289)
2023-05-11|||Update custom_tools.mdx: fix link (#23292)
2023-05-11|||Added missing " in CHAT_PROMPT_TEMPLATE (#23287)
2023-05-11|||Temporarily increase tol for PT-FLAX whisper tests (#23288)
2023-05-11|||`transformers-cli` -> `huggingface-cli` (#23276)
2023-05-11|||Add `top_k` argument to post-process of conditional/deformable-DETR (#22787)
2023-05-11|||Temporary tolerance fix for flaky whipser PT-TF equiv. test (#23257)
2023-05-11|||[`gpt`] Gpt2 fix half precision causal mask (#23256)
2023-05-10|||Bring back the PR `Refactor doctests + add CI` to `main` (#23271)
2023-05-10|||Remove missplaced test file (#23275)
2023-05-10|||Fix link displayed for custom tools (#23274)
2023-05-10|||chore: allow protobuf 3.20.3 requirement (#22759)
2023-05-10|||Render custom tool docs a bit better (#23269)
2023-05-10|||Fix new line bug in chat mode for agents (#23267)
2023-05-10|||Refine documentation for Tools (#23266)
2023-05-10|||pin `tensorflow-probability` in docker files (#23260)
2023-05-10|||Update Image segmentation description (#23261)
2023-05-10|||Metadata update (#23259)
2023-05-10|||Improve Docs of Custom Tools and Agents (#23255)
2023-05-10|||[docs] Audio task guides fixes (#23239)
2023-05-10|||CTC example: updated trainer parameters to save tokenizer (#23243)
2023-05-09|||Test composition (#23214)
2023-05-09|||Fix `from_config` (#23246)
2023-05-09|||Revert "[Doctests] Refactor doctests + add CI" (#23245)
2023-05-09|||v4.30.0.dev0
2023-05-10|||[Doctests] Refactor doctests + add CI (#22987)
2023-05-09|||Support ratios for `logging_steps`, `eval_steps`, and `save_steps` (#23235)
2023-05-09|||Proposed fix for TF example now running on safetensors. (#23208)
2023-05-09|||Add RWKV-4 (#22797)
2023-05-09|||Add Japanese translation to accelerate.mdx (#23232)
2023-05-09|||fix: Update run_qa.py to work with deepset/germanquad (#23225)
2023-05-09|||Fix typo ; Update output.mdx (#23227)
2023-05-09|||make opt checkpoint dir name correct (#21660)
2023-05-09|||audio_utils improvements (#21998)
2023-05-09|||[SAM] Add resources (#23224)
2023-05-08|||Pin tensorflow-probability (#23220)
2023-05-08|||docs: Fix broken link in 'How to add a model...'  (#23216)
2023-05-08|||New version of Accelerate for the Trainer (#23204)
2023-05-08|||Skip failing test
2023-05-08|||Fixing class embedding selection in owl-vit (#23157)
2023-05-08|||Generate: starcoder ü§ú ü§õ assisted generation (#23182)
2023-05-07|||Fix hf_argparser.parse_json_file to open file with utf-8 encoding, close file when finished (#23194)
2023-05-08|||fix random attention for pytorch's bigbird/pegasus_bigbird (#23056)
2023-05-08|||Update LLaMA docs with arxiv link (#23191)
2023-05-06|||search buffers for dtype (#23159)
2023-05-05|||Add FlaxWhisperForAudioClassification model (#23173)
2023-05-05|||Add `no_trainer` scripts to pre-train Vision Transformers (#23156)
2023-05-05|||fix: Passing language as acronym to Whisper generate (#23141)
2023-05-06|||üåê [i18n-KO] docs: ko: Translate `multiple_choice.mdx` (#23064)
2023-05-05|||fixed whisper positional encoding (#23167)
2023-05-05|||Add TrOCR resources (#23142)
2023-05-04|||Revert "Add FlaxWhisperForAudioClassification model" (#23154)
2023-05-04|||Generate: text generation pipeline no longer emits `max_length` warning when it is not set (#23139)
2023-05-04|||[docs] Text to speech task guide (#23107)
2023-05-04|||Add FlaxWhisperForAudioClassification model (#22883)
2023-05-04|||Pin urllib3
2023-05-04|||[`GPT-J`] Fix causal mask dtype (#23147)
2023-05-04|||GPTNeoXForQuestionAnswering (#23059)
2023-05-04|||gpt2 multi-gpu fix (#23149)
2023-05-04|||fix resume fsdp (#23111)
2023-05-04|||Remove typo in perf_train_gpu_many.mdx (#23144)
2023-05-04|||fix spelling error (#23143)
2023-05-04|||Add methods to update and verify out_features out_indices (#23031)
2023-05-03|||GPTNeoForQuestionAnswering (#23057)
2023-05-03|||Tidy Pytorch GLUE benchmark example (#23134)
2023-05-03|||Remove redundant print statements (#23133)
2023-05-03|||Enable to use custom tracer in FX `symbolic_trace` (#23105)
2023-05-03|||Add focalnet backbone (#23104)
2023-05-03|||[doc] Try a few ‚â† ways of linking to Papers, users, and org profiles (#22611)
2023-05-04|||docs: ko: update `_toctree.yml` (#23112)
2023-05-03|||Add support for beam search's num_return_sequencs flag in flax  (#23082)
2023-05-03|||Support union types `X | Y` syntax for `HfArgumentParser` for Python 3.10+ (#23126)
2023-05-03|||Fix ConvNext V2 paramater naming issue (#23122)
2023-05-03|||Add resources for LayoutLmV2 and reformat documentation resources (#23115)
2023-05-03|||Generate: better warnings with pipelines (#23128)
2023-05-03|||improve unclear documentation (#23123)
2023-05-03|||Generate: correct beam search length on score calculation for multi batch generation (#23127)
2023-05-03|||Generate: slow assisted generation test (#23125)
2023-05-03|||[`Doctest`]¬†Fix pix2struct doctest (#23121)
2023-05-02|||Pin numba for now (#23118)
2023-05-02|||Fixed default config for `Pix2Struct` model to set `Pix2StructTextModel` to `is_decoder=True` (#23051)
2023-05-02|||num_noise_spans should be <= num_items #22246 (#22938)
2023-05-02|||[ONNX] Sam fix (#23110)
2023-05-02|||[`Flava`] Fix flava `torch.distributed.nn.functional import all_gather` issue (#23108)
2023-05-02|||Fix check for backword_pos (#23075)
2023-05-02|||üåê [i18n-KO] Translated `torchscript.mdx` to Korean (#23060)
2023-05-02|||GPT2ForQuestionAnswering (#23030)
2023-05-02|||Save the tokenizer and image preprocessor after training a model with the contrastive image-text example (#23035)
2023-05-02|||added type hints for blip_text pytorch model (#23071)
2023-05-01|||Bump flask from 2.0.3 to 2.3.2 in /examples/research_projects/decision_transformer (#23094)
2023-05-02|||üåê [i18n-KO] Translated `tasks/zero_shot_image_classification.mdx` to Korean (#23065)
2023-05-02|||üåê [i18n-KO] Translated `tasks/question_answering.mdx` to Korean (#23012)
2023-05-01|||üåê [i18n-KO] Translated `tasks/image_classification.mdx` to Korean (#23048)
2023-05-01|||Depricate xpu_backend for ddp_backend (#23085)
2023-05-01|||Fix `convnext` __init__ (#23078)
2023-05-01|||Add `BioGPTForSequenceClassification` (#22253)
2023-05-01|||Fix string syntax error in logger warning message (additional comma) (#23083)
2023-05-01|||Fix grammar error in summarization pipeline (#23080)
2023-04-29|||Generate: prepare assisted generation for release (#23052)
2023-04-28|||extend the test files (#23043)
2023-04-28|||Fix model parallelism for `BridgeTower` (#23039)
2023-04-28|||üö®üö®üö® [`Blip`] remove labels masking (#23024)
2023-04-28|||add open-llama model with ckpt (#22795)
2023-04-28|||Skip pt/flax equivalence tests in pytorch `bigbird` test file (#23040)
2023-04-28|||Cuda rng_state_all is used when saving in distributed mode so same should also be used when loading (#23045)
2023-04-28|||[docs] Doc TOC updates (#23049)
2023-04-28|||üåê [i18n-KO] Translated `model_sharing.mdx` to Korean (#22991)
2023-04-28|||Add Trainer support for ReduceLROnPlateau (#23010)
2023-04-28|||Make `_test_xla_generate` less flaky (#22996)
2023-04-27|||Fix CLAP link across all READMEs (#23032)
2023-04-27|||Fix bigbird random attention (#21023)
2023-04-27|||Update `BridgeTowerModelTester` (#23029)
2023-04-27|||added GPTNeoForTokenClassification (#22908)
2023-04-27|||added GPTNeoXForTokenClassification (#23002)
2023-04-27|||[MEGA] nit size test (#23028)
2023-04-27|||Fix the expected error in `test_offline_mode_pipeline_exception` (#23022)
2023-04-27|||üåê [i18n-KO] Translated `multilingual.mdx` to Korean (#23008)
2023-04-27|||[`Pix2Struct`] Fix pix2struct doctest (#23023)
2023-04-27|||Add methods to PreTrainedModel to use PyTorch's BetterTransformer (#21259)
2023-04-26|||üö®üö®üö® Use default ignore index in Luke (#23014)
2023-04-26|||Bring back PartialState DeepSpeed (#22921)
2023-04-26|||Fix None value when adding info to auto_map (#22990)
2023-04-26|||[Llama Tokenizer] Fast llama template (#22959)
2023-04-26|||[`PEFT`] Add HFTracer support for PEFT (#23006)
2023-04-26|||üö®üö®üö® [`Pix2Struct`] Attempts to fix training issues üö®üö®üö® (#23004)
2023-04-26|||Add gradient checkpointing to Whisper Flax (#22954)
2023-04-26|||Remove a failing ONNX test (#23011)
2023-04-26|||Add TensorFlow Wav2Vec2 for sequence classification (#22073)
2023-04-26|||üåê [i18n-KO] Translated `token_classification.mdx` to Korean (#22945)
2023-04-26|||üåê [i18n-KO] Translated `tasks/image_captioning.mdx` to Korean (#22943)
2023-04-25|||Fix typo in mega.mdx (#22998)
2023-04-26|||üåê [i18n-KO] Translated `serialization.mdx` to Korean (#22806)
2023-04-25|||[`DocTest`] Fix correct checkpoint (#22988)
2023-04-25|||Avoid invalid escape sequences, use raw strings (#22936)
2023-04-25|||fixed small typo in code example (#22982)
2023-04-25|||Neptune fix bug init run (#22836)
2023-04-25|||[`SAM`]¬†Add sam doc (#22984)
2023-04-25|||üåê [i18n-KO] Fixed `tasks/masked_language_modeling.mdx` (#22965)
2023-04-25|||Fix `DeepSpeed` CI job link in Past CI (#22967)
2023-04-24|||Install `accelerete@main` in PyTorch Past CI jobs (#22963)
2023-04-24|||Generate: assisted generation with sample (take 2) (#22949)
2023-04-25|||üåê [i18n-KO] translate `create_a_model` doc to Korean (#22754)
2023-04-24|||Update feature selection in to_tf_dataset (#21935)
2023-04-24|||Fix TF example in quicktour (#22960)
2023-04-24|||fix ValueError message in LlamaAttention (#22966)
2023-04-24|||Reverting Deta cloning mecanism. (#22656)
2023-04-24|||üåê [i18n-KO] Translated `run_scripts.mdx` to Korean (#22793)
2023-04-24|||Prepare tests for hfh 0.14 (#22958)
2023-04-24|||[Fix Bugs] Fix keys in `_load_pretrained_model` (#22947)
2023-04-24|||Raise error if `stride` is too high in `TokenClassificationPipeline` (#22942)
2023-04-24|||Decorate `test_codegen_sample_max_time` as flaky (#22953)
2023-04-24|||Add an attribute to disable custom kernels in deformable detr in order to make the model ONNX exportable (#22918)
2023-04-24|||üåê [i18n-KO] Translated `tasks/summarization.mdx` to Korean (#22783)
2023-04-24|||üåê [i18n-KO] Translated `tasks/masked_language_modeling.mdx` to Korean (#22838)
2023-04-24|||Update tiny models and a few fixes (#22928)
2023-04-24|||Generate: Add exception path for Donut (#22955)
2023-04-24|||[CLAP] Doc nits  (#22957)
2023-04-24|||[i18n-KO] Translated `accelerate.mdx` to Korean (#22830)
2023-04-23|||Add FocalNet (#21532)
2023-04-22|||vilt_model (#22930)
2023-04-21|||Feature to convert videomae huge and small finetuned on kinetics and ssv2 added to the videomae to pytorch converter (#22788)
2023-04-21|||Small sam patch (#22920)
2023-04-21|||Fix a minor bug in CI slack report (#22906)
2023-04-21|||tests: Fix flaky test for NLLB-MoE (#22880)
2023-04-21|||ddp fixes for training (#22874)
2023-04-21|||[CI] clap patch fusion test values (#22922)
2023-04-21|||Hardcode GELU as the intermediate activation for ESM (#22892)
2023-04-21|||Remove broken test_data symlink in legacy s2s examples (#22876)
2023-04-21|||fix: GPTNeoX half inference error (#22888)
2023-04-21|||Expose AutoModelForMaskGeneration (#22910)
2023-04-21|||Make sam ONNX exportable (#22915)
2023-04-21|||Fix: Seq2SeqTrainingArgs overriding to_dict for GenerationConfig json support (#22919)
2023-04-21|||fix bug of CLAP dataloader  (#22674)
2023-04-21|||Update Swin MIM output class (#22893)
2023-04-21|||Fix `FillMaskPipelineTests` (#22894)
2023-04-21|||Add inputs_embeds functionality when generating with GPT-Neox  (#22916)
2023-04-21|||fix CLAP integration tests (#22834)
2023-04-21|||Fix Slack report for Nightly CI and Past CI (#22901)
2023-04-21|||Fix counting in Slack report for some jobs (#22913)
2023-04-21|||Moved labels to enable parallelism pipeline in Luke model (#22909)
2023-04-21|||Skip a failing test on main for now (#22911)
2023-04-21|||moved labels to the same device as logits for LILT model (#22898)
2023-04-20|||[tensorflow] Add support for the `is_symbolic_tensor` predicate (#22878)
2023-04-20|||Revert DeepSpeed stuff from accelerate integration (#22899)
2023-04-20|||Add `automatic-mask-generation` pipeline for Segment Anything Model (SAM) (#22840)
2023-04-20|||Pin flax & optax version (#22895)
2023-04-20|||Fix weight tying in TF-ESM (#22839)
2023-04-20|||Include decoder_attention_mask in T5 model inputs (#22835)
2023-04-20|||moved labels to the same device as logits for OTP, CODEGEN ,gptj and pixel2struct model (#22872)
2023-04-20|||[Examples/TensorFlow] minor refactoring to allow compatible datasets to work (#22879)
2023-04-20|||[`SAM`] Change to `facebook/sam-vit-base` (#22891)
2023-04-20|||fix warning function call creating logger error (max_length and max_new_tokens) (#22889)
2023-04-20|||Change schedule CI time (#22884)
2023-04-20|||Generation: only search for eos_token if set (#22875)
2023-04-20|||fix: Correct small typo in docstring (#22857)
2023-04-20|||Fix SAM example in documentation (#22887)
2023-04-20|||Patching clip model to create mask tensor on the device (#22711)
2023-04-20|||[`SAM`] Correct arxiv link (#22886)
2023-04-20|||XGLM: Fix left-padding (PT and TF) (#22828)
2023-04-19|||Add Segment Anything Model (SAM) (#22654)
2023-04-19|||Fix to removing ESM special tokens (#22870)
2023-04-19|||Fixup multigpu local_rank (#22869)
2023-04-19|||Remove some pipeline skip cases (#22865)
2023-04-19|||Show diff between 2 CI runs on Slack reports (#22798)
2023-04-19|||Remove 'main' from doc links (#22860)
2023-04-19|||use `accelerate@main` in CI (#22859)
2023-04-19|||feat(model parallelism): move labels to the same device as logits for M2M100 (#22850)
2023-04-19|||move preprocess_logits_for_metrics before _nested_gather in trainer.e‚Ä¶ (#22603)
2023-04-19|||fix SpeechT5 doc comments (#22854)
2023-04-18|||Make ClipSeg compatible with model parallelism (#22844)
2023-04-18|||Raise err if minimum Accelerate version isn't available (#22841)
2023-04-18|||Fix from_pretrained when model is instantiated on the meta device (#22837)
2023-04-18|||Use code on the Hub from another repo (#22814)
2023-04-18|||Update accelerate version + warning check fix (#22833)
2023-04-18|||Generate: Add assisted generation (#22211)
2023-04-18|||Fix `test_eos_token_id_int_and_list_top_k_top_sampling` (#22826)
2023-04-18|||Fix Past CI not running against the latest `main` (#22823)
2023-04-18|||üåê [i18n-KO] Fix anchor links for docs `auto_tutorial`, `training` (#22796)
2023-04-18|||TTS fine-tuning for SpeechT5 (#21824)
2023-04-17|||Mark auto models as important (#22815)
2023-04-17|||Introduce `PartialState` as the device handler in the `Trainer` (#22752)
2023-04-17|||Revert "Use code on the Hub from another repo" (#22813)
2023-04-17|||Simplify update metadata job (#22811)
2023-04-17|||Remove accelerate from tf test reqs (#22777)
2023-04-17|||Fix squeeze into torch 1.x compatible form in llama model (#22808)
2023-04-17|||Don't use `LayoutLMv2` and `LayoutLMv3` in some pipeline tests (#22774)
2023-04-17|||Use code on the Hub from another repo (#22698)
2023-04-18|||üåê [i18n-KO] Translated `tasks/translation.mdx` to Korean (#22805)
2023-04-17|||Fix sneaky torch dependency in TF example (#22804)
2023-04-17|||improve(llama): Faster apply_rotary_pos_emb (#22785)
2023-04-17|||[i18n-KO] fix: docs: ko: sagemaker anchors and  `_toctree.yml` (#22549)
2023-04-17|||üåê [i18n-KO] Translated `custom_models.mdx` to Korean (#22534)
2023-04-17|||Fix `test_word_time_stamp_integration` for `Wav2Vec2ProcessorWithLMTest` (#22800)
2023-04-15|||Generate: add CJK support to TextStreamer (#22664)
2023-04-14|||Move labels to the same device as logits for Whisper (#22779)
2023-04-14|||Indexing fix - CLIP checkpoint conversion (#22776)
2023-04-14|||Seq2SeqTrainer: Evict decoder_input_ids only when it is created from labels (#22772)
2023-04-14|||Fix word_ids hyperlink (#22765)
2023-04-14|||Tweak ESM tokenizer for Nucleotide Transformer (#22770)
2023-04-14|||[WIP]üåê [i18n-KO] Translated `tutorial/proprecssing.mdx` to Korean (#22578)
2023-04-14|||Fix failing torchscript tests for `CpmAnt` model  (#22766)
2023-04-14|||Fix a mistake in Llama weight converter log output. (#22764)
2023-04-14|||Generate: pin number of beams in BART test (#22763)
2023-04-14|||Pix2struct: doctest fix (#22761)
2023-04-14|||[Examples] TPU-based training of a language model using TensorFlow (#21657)
2023-04-14|||üåê [i18n-KO] Translated `sequence_classification.mdx` to Korean (#22655)
2023-04-13|||Fix `serving_output` for TF composite models (encoder-decoder like models) (#22743)
2023-04-13|||Revert (for now) the change on `Deta` in #22437 (#22750)
2023-04-13|||Generate: handle text conditioning with multimodal encoder-decoder models (#22748)
2023-04-14|||fix(llama): fix LlamaTokenzier (#22746)
2023-04-13|||[trainer] update url (#22747)
2023-04-13|||Remove `DS_BUILD_AIO=1` (#22741)
2023-04-13|||`DocumentQuestionAnsweringPipeline` only for fast ‚ö° tokenizers (#22745)
2023-04-14|||üåê [i18n-KO] Translated `training.mdx` to Korean (#22670)
2023-04-13|||Change `torch_dtype` to `str` when `saved_model=True` in `save_pretrained` for TF models (#22740)
2023-04-13|||[Pix2struct] Simplify generation (#22527)
2023-04-13|||Make vilt, switch_transformers compatible with model parallelism (#22703)
2023-04-13|||Indexing fix for gpt_bigcode (#22737)
2023-04-13|||[Doctest] Add configuration_mvp.py (#22735)
2023-04-13|||[Doctest] Add configuration_m2m_100.py (#22733)
2023-04-12|||v4.29.0.dev0
2023-04-12|||Fix docstrings for TF BLIP (#22618)
2023-04-12|||Update warning levels (#22727)
2023-04-12|||add fast support and option (#22724)
2023-04-12|||`torch.distributed` group initialization for `torch_neuron` disabled when `optimum-neuron` is installed (#22728)
2023-04-12|||[tests] switch to torchrun (#22712)
2023-04-12|||Modify pipeline_tutorial.mdx (#22726)
2023-04-12|||[`bnb`] Let's make serialization of int8 models possible (#22177)
2023-04-12|||add model resources for CPMAnt (new) (#20906)
2023-04-12|||Added parallel device usage for GPT-J (#22713)
2023-04-12|||remove wrong doc in readme (#22723)
2023-04-12|||Update input values for docstring (#22631)
2023-04-11|||Fix decorator order (#22708)
2023-04-11|||Replace -100s in predictions by the pad token (#22693)
2023-04-11|||Remove 2 failing ONNX conversion tests (#22660)
2023-04-11|||Clarify stride option (#22684)
2023-04-11|||Enable naive Pipeline Parallelism training for Gpt neox japanese and san japanese (#22702)
2023-04-11|||Make it easier to develop without a dev install (#22697)
2023-04-11|||Update some `MarkupLM` tests' expected values (#22667)
2023-04-10|||Model parallelism: Moving labels to same devices as the logits are (#22691)
2023-04-11|||add GPTNeoXForSequenceClassification (#22671)
2023-04-10|||use __func__ to check can_generate (#22643)
2023-04-10|||Fix quantization docs typo (#22666)
2023-04-10|||Make dynamic code work with offline mode (#22661)
2023-04-10|||(feat): Moving labels to same device as logits for Deit (#22679)
2023-04-10|||Model parallelism: Moving labels to the same device as logits for BridgeTower models (#22676)
2023-04-10|||Add GPTBigCode model (Optimized GPT2 with MQA from Santacoder & BigCode) (#22575)
2023-04-08|||moved labels to the same device as logits for BLOOM, GPT Neo, GPT NeoX, RoBERTa and VIT models (#22663)
2023-04-07|||Revert migration of setup to pyproject.toml (#22658)
2023-04-07|||Generate: add API warning to streamers (#22659)
2023-04-07|||[OPT] Fix default attention mask size (#22649)
2023-04-07|||[tokenization] do not push special file (#22657)
2023-04-07|||Small nit, (#22653)
2023-04-08|||üåê [i18n-KO] Translated `pipeline_tutorial.mdx` to Korean (#22508)
2023-04-07|||Fix `MegaModel` CI (#22652)
2023-04-07|||Fix typo (#22650)
2023-04-07|||Move labels to the same device as logits for LlamaForSequenceClassification and Blip2 (#22596)
2023-04-07|||üåê[i18n-KO] Translate `autoclass_tutorial` to Korean and Fix the typo of `quicktour` (#22533)
2023-04-07|||fix FSDP version related issues (#22489)
2023-04-06|||Update tiny model summary file for recent models (#22637)
2023-04-06|||[`Blip`] Fix slow tests and doctests with correct values (#22632)
2023-04-06|||LlamaTokenizerFast Fix (.., from_slow=True). (#22630)
2023-04-06|||[`bnb`] 8bit models should not be converted to `DDP` (#22628)
2023-04-06|||A script to add/update `pipeline_model_mapping` systematically (#22180)
2023-04-06|||update_pip_test_mapping (#22606)
2023-04-06|||docs: Fix broken link to generation strategies (#22623)
2023-04-06|||Make tiny model creation + pipeline testing more robust (#22500)
2023-04-06|||Backbone add mixin tests (#22542)
2023-04-06|||Seq2SeqTrainer: use unwrapped model to retrieve the generation config (#22584)
2023-04-06|||Revert error back into warning for byte fallback conversion. (#22607)
2023-04-06|||Adding Llama FastTokenizer support. (#22264)
2023-04-06|||feat(model parallelism): moving the labels to the same device as the logits for gpt2 and bart (#22591)
2023-04-05|||Use native TF checkpoints for the BLIP TF tests (#22593)
2023-04-05|||Add DePlot + MatCha on `transformers` (#22528)
2023-04-05|||Adding support for BPE merge creation from scores instead of ids. (#22582)
2023-04-05|||Fix a typo in one of the BLIP pretrained checkpoint names (#22588)
2023-04-05|||Sync preprocesses before loading the processor at run_speech_recognition_ctc.py (#21926)
2023-04-05|||docs: ko: complete `_toctree.yml` (#22581)
2023-04-05|||Add thousands separator in training summary (#22583)
2023-04-05|||Fix PT-TF equivalence test for GPT1 (#22586)
2023-04-05|||Tests: disable `accelerate_tests` mark warnings (#22585)
2023-04-05|||Move back doctest instructions to setup.cfg (#22587)
2023-04-05|||Generate: `TextIteratorStreamer` timeout (#22576)
2023-04-04|||Skip failing test
2023-04-04|||Fix inverted conditional in TF common test! (#22540)
2023-04-04|||fix `_no_split_modules` for Whisper model (#22486)
2023-04-04|||Flax Regnet (#21867)
2023-04-04|||corrected the code comment for the output of find_pruneable_heads_and_indices  (#22557)
2023-04-04|||Add TF port of BLIP (#22090)
2023-04-04|||Soft error whisper. (#22475)
2023-04-04|||Add id2label and label2id to model's config in run_xnil (#22558)
2023-04-04|||[`bnb`] Fix typo (#22556)
2023-04-04|||Remove hack for dynamic modules and use Python functions instead (#22537)
2023-04-04|||Implemented safetensors checkpoints save/load for Trainer (#22498)
2023-04-04|||üö®üö®üö® `[NLLB Tokenizer]` Fix the prefix tokens üö®üö®üö® (#22313)
2023-04-04|||[Roformer] Fixing a bug in RoFormerEncoder where it was ignoring the length of past_key_values when generating as a decoder (#22416)
2023-04-04|||Generate: Add text streamer decoding options (#22544)
2023-04-03|||Fix OPTForQuestionAnswering doc string (#22481)
2023-04-03|||Update test_image_processing_pix2struct.py (#22543)
2023-04-03|||Skip failing test
2023-04-04|||[setup] migrate setup script to `pyproject.toml` (#22539)
2023-04-03|||Generate: Enable easier TextStreamer customization (#22516)
2023-04-04|||[setup] drop deprecated `distutils` usage (#22531)
2023-04-03|||Fix missing metrics with multiple eval datasets (#22536)
2023-04-03|||[`T5`] Enable naive Pipeline Parallelism training for T5 (#22535)
2023-04-03|||[`Trainer`] Force `is_model_parallel` when model is loaded in multiple GPUs using `accelerate` (#22532)
2023-04-03|||[BLIP] fix cross attentions for BlipTextEncoder (#22515)
2023-04-03|||fix LayoutLMv3TokenizerFast subword label after 'ƒ†' token (#21695)
2023-04-03|||llama docs: fix conversion script url (#22514)
2023-04-03|||Fix convert_opt_original_pytorch_checkpoint_to_pytorch.py typo (#22526)
2023-04-03|||Generate: `TextIteratorStreamer` (streamer for gradio) (#22501)
2023-04-03|||added biogpt token classifier (#22447)
2023-04-03|||[WIP] docs: ko: sagemaker.mdx (#22509)
2023-04-03|||Fix llama tokenizer (#22402)
2023-04-03|||[Time-Series] fix past_observed_mask type (#22076)
2023-04-03|||Backbone add out indices (#22493)
2023-04-03|||Update convert_llama_weights_to_hf.py (#22525)
2023-03-31|||Test fetch v2 (#22367)
2023-03-31|||Update Neptune callback docstring (#22497)
2023-03-31|||Bump redis from 4.5.3 to 4.5.4 in /examples/research_projects/decision_transformer (#22494)
2023-03-31|||Making sure we can use safetensors to serialize all the time. (#22437)
2023-03-31|||Update `Wav2Vec2ProcessorWithLM` doc example (#22474)
2023-03-31|||Relax `eos_token_id < 0` checks in `generate()` from `ValueError` to warning (#22472)
2023-03-30|||(Re-)Enable Nightly + Past CI (#22393)
2023-03-30|||Docs fix: Multinomial sampling decoding needs "num_beams=1", since by default it is usually not 1. (#22473)
2023-03-30|||Llama: support for `max_position_embeddings` (#22471)
2023-03-30|||[NLLB-MoE] `model_type` update for auto mapping (#22470)
2023-03-30|||Guard imports of PreTrainedTokenizerFast on is_tokenizers_available (#22285)
2023-03-30|||üö®üö®üö®   Fix ordering of height, width for BLIP image processor (#22466)
2023-03-30|||Generate: basic token streaming (#22449)
2023-03-30|||Skip flaky NLLB Moe test for now (#22463)
2023-03-30|||Rescale image back if it was scaled during PIL conversion (#22458)
2023-03-30|||Move common properties to BackboneMixin (#21855)
2023-03-29|||Update: ignore padding support for TransfoXL training when n_clusters==0 (#22457)
2023-03-29|||Pin ruff (#22455)
2023-03-29|||Update release instructions (#22454)
2023-03-29|||Avoid using personal HF token in CI (#22453)
2023-03-29|||Update Neptune docs (#22452)
2023-03-29|||Revert "Fix --bf16 option support for Neuron after PR #22300" (#22451)
2023-03-29|||[`Pix2Struct`] Fix slow test (#22448)
2023-03-29|||Revert "Error (also in original) model, scaling only q matrix not qk.T dot product (qk.T/sqrt(dim_per_head))" (#22444)
2023-03-29|||Use real tokenizers if tiny version(s) creation has issue(s) (#22428)
2023-03-29|||Don't hard error when cache version can't be converted to int (#22427)
2023-03-29|||[`Generate`] Add conditional generation for multimodal models (#22424)
2023-03-29|||[`bnb`] fix bnb failing test (#22439)
2023-03-29|||Hyperparameter search reporting to W&B (#22440)
2023-03-29|||Add clean_up_tokenization_spaces to config (#22341)
2023-03-28|||MBart: Fix docs and doctests (#22422)
2023-03-28|||[performance] ensure `causal_mask` is created directly on device (#22378)
2023-03-28|||Fix bug in perplexity guide calculations and update perplexity numbers. Fixes #22348 (#22411)
2023-03-27|||Bump redis from 4.1.4 to 4.5.3 in /examples/research_projects/decision_transformer (#22410)
2023-03-28|||[neptune] fix checkpoint bug with relative out_dir (#22102)
2023-03-27|||[WIP]`NLLB-MoE` Adds the moe model (#22024)
2023-03-27|||Fix quality
2023-03-27|||Hardware Auto-Setup for Examples (#22319)
2023-03-27|||Trainer: missing None check (#22404)
2023-03-27|||Trainer: move Seq2SeqTrainer imports under the typing guard (#22401)
2023-03-27|||[Pix2Struct] Add support to resize embeddings (#22394)
2023-03-27|||Transformers env safetensors (#22400)
2023-03-27|||[`bnb`] Force `requires_grad` to be `False` (#22396)
2023-03-27|||Generate: support for left-padding on GPTNeoX and Llama (#22382)
2023-03-27|||Seq2seq trainer generation config arg (#22323)
2023-03-27|||Wav2Vec2ProcessorWithLM can return N best hypotheses now (#22235)
2023-03-27|||load_in_8bit now respects 'balanced' device maps in multi-gpu environments (#22377)
2023-03-27|||Adapt find_tied_parameters to handle breaking change in Accelerate (#22360)
2023-03-27|||Translated documentation in italian (#22388)
2023-03-27|||Changed world_size() to get_world_size() bugfix (#22381)
2023-03-27|||TensorFlow: additional missing `cmake` dependencies in CI (#22383)
2023-03-24|||[safetensors] don't use in `torch<1.10` (#22370)
2023-03-24|||Fix TF pipeline job
2023-03-24|||[Trainer] add disclaimer that full_determinism is slow (#22368)
2023-03-25|||Resnet flax (#21472)
2023-03-24|||TensorFlow: pin maximum version to 2.12 (#22364)
2023-03-24|||Improve error message (#22361)
2023-03-24|||Pin tensorflow-text to go with tensorflow (#22362)
2023-03-24|||Update docker files to use official torch 2.0.0 (#22357)
2023-03-24|||Add Mega: Moving Average Equipped Gated Attention (#21766)
2023-03-24|||Generate: Add GPTNeoX integration test (#22346)
2023-03-24|||Fix typo in Greedy Search Description (#22345)
2023-03-24|||[HFTracer] Make embeddings ops take on the dtype of the weight (#22347)
2023-03-23|||Automatically create/update tiny models (#22275)
2023-03-23|||Enable training Llama with model or pipeline parallelism (#22329)
2023-03-23|||Generate: add test for left-padding support (#22322)
2023-03-23|||Fix --bf16 option support for Neuron after PR #22300 (#22307)
2023-03-23|||Added type hints to TFDeiTModel (#22327)
2023-03-23|||Minor typo in pipeline FillMaskPipeline's documentation. (#22339)
2023-03-23|||Fix various imports (#22281)
2023-03-23|||Mention why one needs to specify max_steps in Trainer (#22333)
2023-03-23|||Fixed gradient checkpoint bug for TimeSeriesTransformer (#22272)
2023-03-23|||[`MBart`] Add `accelerate` support for MBart (#22309)
2023-03-22|||[gptj] support older pytorch version (#22325)
2023-03-22|||Really fix quality due to ruff release
2023-03-22|||Fix quality due to ruff release
2023-03-22|||[deepspeed zero3] need `generate(synced_gpus=True, ...)` (#22242)
2023-03-22|||Fix PipelineTests skip conditions (#22320)
2023-03-22|||Chunkable token classification pipeline (#21771)
2023-03-22|||docs: Resolve incorrect type typo in trainer methods (#22316)
2023-03-22|||Add Pix2Struct (#21400)
2023-03-22|||Beef up Llama tests (#22314)
2023-03-22|||Generate: Export TF generate with a TF tokenizer (#22310)
2023-03-22|||Enforce `max_memory` for device_map strategies (#22311)
2023-03-22|||Fixed bug to calculate correct xpath_sub_list in MarkupLMTokenizer (#22302)
2023-03-22|||Fix position embeddings for GPT-J and CodeGen (#22069)
2023-03-22|||fix: Allow only test_file in pytorch and flax summarization (#22293)
2023-03-22|||add low_cpu_mem_usage option in run_clm.py example which will benefit‚Ä¶ (#22288)
2023-03-22|||Enable traced model for text-generation task (#22265)
2023-03-22|||Add MaskedImageModelingOutput  (#22212)
2023-03-22|||Final update of doctest (#22299)
2023-03-21|||[deepspeed] offload + non-cpuadam optimizer exception doc (#22044)
2023-03-21|||Correct NATTEN function signatures and force new version (#22298)
2023-03-21|||Restore fp16 support on xla gpu device (#22300)
2023-03-21|||Time to Say Goodbye, torch 1.7 and 1.8 (#22291)
2023-03-21|||Add translation perf_infer_gpu_one for it (#22296)
2023-03-21|||fix more doctests (#22292)
2023-03-21|||More doctests (#22268)
2023-03-21|||Fix error in mixed precision training of `TFCvtModel` (#22267)
2023-03-21|||replace_8bit_linear modules_to_not_convert default value fix (#22238)
2023-03-20|||Update vision docstring bool masked pos (#22237)
2023-03-20|||Example of pad_to_multiple_of for padding and truncation guide & docstring update (#22278)
2023-03-20|||Move torch.compile() wrapping after DDP/FSDP wrapping to ensure correct graph breaks during training (#22279)
2023-03-20|||Fix doc links (#22274)
2023-03-20|||Proper map location for optimizer load (#22273)
2023-03-20|||Rework a bit the LLaMA conversion script (#22236)
2023-03-20|||Fix balanced and auto device_map (#22271)
2023-03-20|||Fix the gradient checkpointing bug of the llama model (#22270)
2023-03-20|||[Trainer] Add optional communication backends for torch.distributed when using GPU (#22247)
2023-03-20|||Italian translation perf_infer_cpu (#22243)
2023-03-20|||[Docs] fix typos in some tokenizer docs (#22256)
2023-03-20|||Update training_args.py -- a nightly install is not required anymore for torch.compile (#22266)
2023-03-17|||[trainer] param count for deepspeed zero3 (#22193)
2023-03-18|||Fix Unnecessary move of tensors from CPU to GPU in LlamaRotaryEmbedding (#22234)
2023-03-17|||Revert "Use `dash==2.8.1` for now for daily CI" (#22233)
2023-03-17|||Fix natten (#22229)
2023-03-17|||fix(docs): fix task guide links in model docs (#22226)
2023-03-17|||Removed .mdx extension in two links (#22230)
2023-03-17|||Add LlamaForSequenceClassification (#22209)
2023-03-17|||fix AutoTP in deepspeed could not work for bloom (#22196)
2023-03-17|||LLaMA house-keeping (#22216)
2023-03-17|||Depth estimation task guide (#22205)
2023-03-17|||Use `dash==2.8.1` for now for daily CI (#22227)
2023-03-17|||fix code example in mgp-str doc (#22219)
2023-03-17|||fix typos in llama.mdx (#22223)
2023-03-16|||Hotfix for natten issue with torch 2.0.0 on CircleCI (#22218)
2023-03-16|||üî•py38 + torch 2 üî•üî•üî•üöÄ (#22204)
2023-03-16|||fixes a typo in WhisperFeatureExtractor docs. (#22208)
2023-03-16|||[`XGLM`] Add `accelerate` support for XGLM (#22207)
2023-03-16|||Temporarily fix ONNX model exporting error (#21830)
2023-03-16|||Update tiny model creation script (#22202)
2023-03-16|||LLaMA Implementation (#21955)
2023-03-16|||LLaMA Implementation (#21955)
2023-03-16|||Italian Translation of migration.mdx (#22183)
2023-03-16|||Update expected values in `MgpstrModelIntegrationTest` (#22195)
2023-03-16|||Fix typo in  Align docs  (#22199)
2023-03-16|||Fix DeepSpeed CI (#22194)
2023-03-15|||t5 remove data dependency (#22097)
2023-03-15|||Update BridgeTowerForContrastiveLearning (#22145)
2023-03-15|||Regression pipeline device (#22190)
2023-03-15|||Revert 22152 MaskedImageCompletionOutput changes (#22187)
2023-03-16|||Fix: unfinished_sequences with correct device  (#22184)
2023-03-14|||Run all tests by default (#22162)
2023-03-14|||Load optimizer state on CPU to avoid CUDA OOM (#22159)
2023-03-14|||v4.28.0.dev0
2023-03-14|||Revert "Enforce same behavior as PyTorch 2.0 for older versions" (#22163)
2023-03-14|||[trainer] add `--optim adamw_torch_fused` for pt-2.0+ (#22144)
2023-03-14|||to_pil - don't rescale if int and in range 0-255 (#22158)
2023-03-14|||Create MaskedImageCompletionOutput and fix ViT docs (#22152)
2023-03-14|||Fix big model inference for T5 models in float16 (#22095)
2023-03-14|||Translation Italian: perf_train_cpu and perf_train_cpu_many (#22151)
2023-03-14|||Update 2 doctest expected values for torch 2.0.0 (#22148)
2023-03-14|||Add ConvNeXT V2 (#21679)
2023-03-14|||Move `is_pipeline_test_to_skip` to specific model test classes (#21999)
2023-03-14|||[üõ†Ô∏è] Fix-whisper-breaking-changes  (#21965)
2023-03-13|||docs:  New terms and updates to glossary (#21982)
2023-03-13|||Prepare daily CI for torch 2.0.0 (#22135)
2023-03-13|||[Safetensors] Add explicit  flag to from pretrained (#22083)
2023-03-13|||Remove backend check for torch.compile (#22140)
2023-03-13|||[deepspeed docs] Activation Checkpointing (#22099)
2023-03-13|||[trainer] fix bug in grad accum with multiple epochs (#22098)
2023-03-13|||Enforce same behavior as PyTorch 2.0 for older versions (#22136)
2023-03-13|||Trainer: let generate pick its inputs (#22108)
2023-03-13|||[`Whiper`] add `get_input_embeddings` to `WhisperForAudioClassification` (#22133)
2023-03-13|||Update configuration_align.py (projected_dim=640) (#22139)
2023-03-13|||Add a new script to check model testers' config (#22063)
2023-03-13|||Adding Type Hints to TF_Pegasus model (#21941)
2023-03-13|||Fix doc link for MGP-STR (#22138)
2023-03-13|||Zero-shot image classification task guide (#22132)
2023-03-13|||Fix gradient checkpointing bug in trocr (#22126)
2023-03-13|||Fix gradient checkpointing bug in LongT5 (#22130)
2023-03-13|||Fix gradient checkpointing bug in xmod (#22129)
2023-03-13|||[`Blip2`] skip accelerate test (#22124)
2023-03-13||| Added big_models.mdx italian translation #17600  (#22115)
2023-03-13|||Fix gradient checkpointing bug in xlm_roberta_xl (#22128)
2023-03-13|||Fix gradient checkpointing bug in Trajectory Transformer (#22125)
2023-03-13|||Fix gradient checkpointing bug in xglm (#22127)
2023-03-13|||Add pr_checks.mdx Italian translation (#17459) (#22116)
2023-03-13|||add new model of MGP-STR (#21418)
2023-03-13|||Add AutoModelForZeroShotImageClassification (#22087)
2023-03-11|||[Whisper] Remove embed_tokens from encoder docstring (#21996)
2023-03-10|||Revert "[GPT2] Propose fix for #21080" (#22093)
2023-03-10|||Fix imports of TF MobileViT (#22065)
2023-03-10|||GPT-J specific half precision on CPU note (#22086)
2023-03-10|||handle numpy inputs in whole word mask data collator (#22032)
2023-03-10|||Fix hint in src/transformers/modeling_utils.py (#22074)
2023-03-10|||Fix gradient checkpointing bug in Speecht5 (#22080)
2023-03-10|||Generate - Fix broken documentation links (#22078)
2023-03-10|||Fix small typo in flan-ul2.mdx (#22068)
2023-03-10|||[GPT2] Propose fix for #21080 (#21853)
2023-03-10|||Fix gradient checkpointing bug in switch transformer (#22081)
2023-03-10|||Fix gradient checkpointing bug in Speech2Text (#22079)
2023-03-09|||Add a progress bar for the total download of shards (#22062)
2023-03-09|||Fix case when using --gradient_accumulation_steps with DDP disabled. (#22007)
2023-03-09|||Update tiny model creation script (#22058)
2023-03-09|||Add setters by type of args to TrainingArguments (#21570)
2023-03-09|||Skip 3 tests for `WhisperEncoderModelTest` (#22060)
2023-03-09|||Edit the docstring of `image_processing_donut` to match code (#22033)
2023-03-09|||[deepspeed] offload + non-cpuadam optimizer exception (#22043)
2023-03-09|||rm $ symbol from code block from contributing.md (#22057)
2023-03-09|||pt-to-tf model architecture override (#22055)
2023-03-09|||Return analysis for hyperparameter_search with Ray backend (#22040)
2023-03-09|||Show the number of `huggingface_hub` warnings in CI report (#22054)
2023-03-09|||Remove set_access_token usage + fail tests if FutureWarning (#22051)
2023-03-09|||Can't install tf2 on M1 Chip by default (#22046)
2023-03-09|||Docs Improvement - In ZSH, not using ' ' around pip install fails, fix it (#22045)
2023-03-09|||[21737][T5]: Fix gradient checkpoint bug (#22036)
2023-03-09|||Update ALIGN docs (#22025)
2023-03-09|||Bug fix: token classification pipeline while passing offset_mapping (#22034)
2023-03-08|||Mark all `BridgeTower` tests slow for now (#22039)
2023-03-08|||Avoid `text_config_dict` and `vision_config_dict` being saved  for CLIP-like models (#22035)
2023-03-09|||fixes the gradient checkpointing of whisper (#22019)
2023-03-08|||[examples/speech-recognition] Add SpecAugment to run_speech_recognition_seq2seq.py (#21942)
2023-03-08|||Add tokenize_kwargs parameter definition in the FeatureExtractionPipeline (#22031)
2023-03-08|||Fix test for torchneuroncore in Trainer (#22028)
2023-03-08|||[WIP] Add BridgeTowerForContrastiveLearning (#21964)
2023-03-08|||[`bnb`] Fix bnb error message (#22026)
2023-03-08|||Update `AudioClassificationPipelineTests::test_small_model_pt` for PT 2.0.0 (#22023)
2023-03-08|||update: bertology paper (#22012)
2023-03-08|||VideoMAE doctest - use valid dummy pixel values (#22022)
2023-03-08|||Generate - add 1 to cur_len to make up the new beam length (#21993)
2023-03-07|||Update tiny model creation script and some others files (#22006)
2023-03-08|||[Time-Series] informer model (#21099)
2023-03-07|||[DETR and friends] Remove is_timm_available (#21814)
2023-03-07|||[TF] Fix creating a PR while pushing in TF framework (#21968)
2023-03-07|||Stop requiring Torch for our TF examples! (#21997)
2023-03-07|||[Whisper] Add model for audio classification (#21754)
2023-03-07|||Skip `test_multi_gpu_data_parallel_forward` for some model tests (#21991)
2023-03-07|||Update `notification_service.py` (#21992)
2023-03-07|||Remove unneeded casts to bool (#21983)
2023-03-07|||[DETR, YOLOS] Fix device bug (#21974)
2023-03-07|||Fix MinNewTokensLengthLogitsProcessor when used with a list of eos tokens (#21959)
2023-03-07|||Add check before int casting for PIL conversion (#21969)
2023-03-07|||Update `Jukebox` tests (#21984)
2023-03-06|||docs: improve clarity for language modeling (#21952)
2023-03-06|||Fix gradient checkpointing bug in ESM (#21980)
2023-03-06|||Fix gradient checkpointing bug in Codegen (#21979)
2023-03-06|||Fix gradient checkpointing bug in BlipText (#21978)
2023-03-06|||Fix gradient checkpointing bug in Blenderbot Small (#21977)
2023-03-06|||Fix gradient checkpointing bug in BigBird Pegasus (#21976)
2023-03-06|||Update expected values for `test_xglm_sample` (#21975)
2023-03-06|||Add TF contrastive image text finetuning example (#21939)
2023-03-06|||Use larger atol in `torch.allclose` for some tests (#21966)
2023-03-06|||Add missing parameter definition in layoutlm config (#21960)
2023-03-06|||[Generate] Fix gradient_checkpointing and use_cache bug for BLOOM (#21956)
2023-03-06|||Fix bert issue (#21963)
2023-03-06|||Disable DDP for neuron (#21953)
2023-03-06|||[CI] Fix ci  (#21940)
2023-03-06|||Update expected values in `XLMProphetNetModelIntegrationTest` (#21957)
2023-03-04|||Fixed gradient_checkpointing/use_cache bug in blenderbot (#21833)
2023-03-04|||Fix gradient checkpointing bug in Roformer (#21946)
2023-03-04|||Fix gradient checkpointing bug in Rembert (#21945)
2023-03-04|||Fix gradient checkpointing bug in Pegasus (#21944)
2023-03-04|||Fix gradient checkpointing bug in OPT (#21943)
2023-03-03|||[Whisper] Fix feature normalization in `WhisperFeatureExtractor` (#21938)
2023-03-03|||[CLAP] Support batched inputs for CLAP. Fixes pipeline issues (#21931)
2023-03-03|||Update README logo (#21933)
2023-03-03|||[Flan-UL2] Add-flan-ul2 (#21929)
2023-03-03|||Fix wrong documentation about DataCollator padding defaults (#21919)
2023-03-03|||Avoid failure in `check_repo.py` due to missing backends (#21930)
2023-03-03|||Fix `AlignModelTest` tests (#21923)
2023-03-03|||feat: filter try/except when looking at custom code (#21914)
2023-03-03|||Cleanup more auto mapping names  (#21909)
2023-03-03|||Use large VM for `repo_utils_job` (#21928)
2023-03-03|||Update `model_split_percents` for `WhisperModelTest` (#21922)
2023-03-03|||Fix gradient checkpointing megatron bert (#21921)
2023-03-03|||Fix gradient checkpointing bug in mvp (#21920)
2023-03-03|||Fix gradient checkpointing bug in MBart (#21918)
2023-03-03|||faster forward following what is done for images (#21906)
2023-03-03|||Fix doctests for TFVisionTextDualEncoder (#21910)
2023-03-02|||Avoid modeling tests run in pipeline CI jobs (#21911)
2023-03-02|||[time series] Add Time series inputs tests (#21846)
2023-03-02|||Faster zero shot image (#21897)
2023-03-02|||Temporarily skip 3 tests in `BridgeTowerModelTest` (#21908)
2023-03-02|||Add Blip and Blip2 for pipeline tests (#21904)
2023-03-02|||Refactor whisper asr pipeline to include language too. (#21427)
2023-03-02|||Make schedulers picklable by making lr_lambda fns global (#21768)
2023-03-02|||Prophetnet batch dimension inversion fix (#21870)
2023-03-02|||Clean up auto mapping names (#21903)
2023-03-02|||Mark pipeline tests to skip them easily (#21887)
2023-03-02|||Fix gradient checkpointing bug marian (#21842)
2023-03-02|||Fix gradient checkpointing bug M2M 100 (#21841)
2023-03-02|||Fix gradient checkpointing bug LED (#21840)
2023-03-02|||fsdp bf16 enable autocast (#21847)
2023-03-02|||[GPT-J] add deprecation warning (#21869)
2023-03-02|||fix typo in Bart's attention (#21898)
2023-03-02|||[Whisper] Add rescaling function with `do_normalize` (#21263)
2023-03-02|||[T5 doc] Fix confusing documentation about `d_kv` (#21896)
2023-03-02|||Add `inputs_embeds` functionality when generating with BioGPT  (#21889)
2023-03-02|||Use PyAV instead of Decord in examples (#21572)
2023-03-02|||[ZAC] fix ci daily  (#21893)
2023-03-02|||[Refactor] Relative imports wherever we can (#21880)
2023-03-02|||fix checkpoint (#21874)
2023-03-01|||Fix `test_load_default_pipelines_pt` for `ClapModel` (#21886)
2023-03-01|||Fix `WhisperModelTest`  (#21883)
2023-03-02|||Fix Gradient checkpointing bug BigBird (#21882)
2023-03-01|||Add ALIGN to transformers (#21741)
2023-03-01|||Add TFVisionTextDualEncoder (#21873)
2023-03-02|||Make loading of pretrained gpt2 faster by avoiding initialization of Conv1D's weights (#21879)
2023-03-01|||Add check for different embedding types in examples (#21881)
2023-03-01|||Add an utility file to get information from test files (#21856)
2023-03-01|||[doc] deepspeed tests (#21859)
2023-03-01|||update FSDP and add XLA-FSDP documentation (#21812)
2023-03-01|||Removed BLIP mention from the troubleshooting guide (#21872)
2023-03-01|||[`Blip`] Fix blip doctest (#21868)
2023-03-01|||Italian translation of community.mdx (#21871)
2023-03-01|||Change the way tensor is reshaped in BartAttention (from .view to .reshape) (#21860)
2023-03-01|||[deepspeed] check whether model is NLP one instead of counting on input type (#21800)
2023-03-01|||Fix gradient checkpointing bug Bart (#21866)
2023-03-01|||Flax beam search fix (#21857)
2023-03-01|||[ConvBert] Fix #21523 (#21849)
2023-03-01|||prepare for "__floordiv__ is deprecated  and its behavior will change in a future version of pytorch" (#20211)
2023-02-28|||Fix flaky test for log level (#21776)
2023-02-28|||Improve TF weight loading, especially PT crossloading (#21792)
2023-02-28|||üî•Rework pipeline testing by removing `PipelineTestCaseMeta` üöÄ (#21516)
2023-02-28|||Add loss for BridgeTowerForMaskedLM and BridgeTowerForImageAndTextRetrieval (#21684)
2023-02-28|||[`Blip2`] Fix Blip-2 multi gpu (#21707)
2023-02-28|||Make Slack CI reporting stronger (#21823)
2023-02-28|||Add: task guide for zero shot object detection (#21829)
2023-02-28|||[GPTJ] Fix gradient checkpointing bug  (#21794)
2023-02-28|||Fix the issue of blip model returning loss even when the label is not provided.  (#21811)
2023-02-28|||[`Blip2`] Add `Blip2Model` (#21817)
2023-02-28|||[`T5`] Fix torchquant issue (#21843)
2023-02-28|||Fix tf random token masking probability in data collator (#21834)
2023-02-28|||Fix gradient checkpointing imagegpt (#21816)
2023-02-28|||Fix gradient checkpointing bug in git (#21818)
2023-02-28|||check for None forced tokens (#21793)
2023-02-28|||Fix gradient checkpointing bug BioGpt (#21844)
2023-02-28|||Rename `MobileViTModelTest` to `TFMobileViTModelTest` (#21825)
2023-02-27|||introduce `logger.warning_once` and use it for grad checkpointing code (#21804)
2023-02-27|||Fix quality with `ruff==0.0.253` (#21828)
2023-02-27|||Inheritance-based framework detection (#21784)
2023-02-27|||Fix gradient checkpointing bug in gptneox (#21815)
2023-02-27|||Fix nn.init.trunc_normal_ call on torch.float16 data (#21789)
2023-02-27|||Fix PyTorch Perceiver `PerceiverFourierPositionEncoding` with fp16 (#21787)
2023-02-27|||[`tests`] add `accelerate` marker (#21743)
2023-02-27|||[torch] remove deprecated uint8 in favor of bool (#21384)
2023-02-27|||[Pipeline] Add zero shot audio classificatoin pipeline (#21600)
2023-02-27|||[FX tracer] Make `concrete_args` from outside available (#21775)
2023-02-27|||Fix en documentation typos (#21799)
2023-02-27|||Fix type in gpt2 config docstring (#21782)
2023-02-27|||[examples/summarization] deal with `max_length` and `num_beams` (#21740)
2023-02-25|||Fix resume_from_checkpoint for deepspeed (#21735)
2023-02-24|||[SpeechT5] Fix HiFiGAN tests (#21788)
2023-02-24|||[GPT2, ProphetNet] Fix gradient checkpointing bug (#21772)
2023-02-24|||[time series] updated expected values for integration test. (#21762)
2023-02-24|||Generate - update cookie cutters to not initialize cache with training and gradient checkpointing (#21759)
2023-02-24|||Fix-ci-whisper (#21767)
2023-02-24|||[Whisper] Add SpecAugment (#21298)
2023-02-24|||[Flax] Fix erroneous kwargs being passed to generate config (#21765)
2023-02-24|||Different behavior in DistilBERT when using "inputs_embeds" (#21752)
2023-02-24|||[Examples] Generalise run audio classification for log-mel models (#21756)
2023-02-24|||[Flax] adding support for batch norm layers (#21581)
2023-02-24|||fix: Change is_last chunk calc and add conditional break in chunk_iter (#21612)
2023-02-24|||Graphormer fix  (#21699)
2023-02-23|||[deepspeed tests] fix issues introduced by #21700 (#21769)
2023-02-23|||Auto api Value Error addition to Troubleshoot (#21708)
2023-02-23|||Added Type Hints for modeling_tf_encoder_decoder.py (#21673)
2023-02-23|||Skip test_log_level for now
2023-02-23|||Generate: Fix GIT batched captioning (#21738)
2023-02-23|||[`GPTNeo`] Fix gradient checkpointing bug (#21733)
2023-02-23|||Fix 2 quicktour file doctest (#21742)
2023-02-23|||Update doctest GH workflow file (#21744)
2023-02-23|||Make ImageProcessorMixin compatible with subfolder kwarg (#21725)
2023-02-23|||typos in french documentation (#21750)
2023-02-22|||Added "Open in Colab" to task guides  (#21729)
2023-02-22|||Fix to KerasMetricCallback when the model returns unstructured output (#21727)
2023-02-22|||[SpeechT5HifiGan] Handle batched inputs (#21702)
2023-02-22|||Fix `GPTSanJapaneseModel` (#21731)
2023-02-22|||Fix `ErnieMEmbeddings` device issue (#21726)
2023-02-22|||Change doc example for `BigBirdForQuestionAnswering` (#21723)
2023-02-22|||Remove `gptsan_japanese` from doctest list to avoid GPU OOM (#21722)
2023-02-22|||Respect documentation on passive log level (#21700)
2023-02-22|||Fix quality
2023-02-22|||[`MBart`] Fix cross attention mask check (#21730)
2023-02-22|||Apply ruff flake8-comprehensions (#21694)
2023-02-22|||Time series transformer: input projection and Std scaler (#21020)
2023-02-21|||Adding type hints to call() functions in this file (#21548)
2023-02-21|||Adding task guides to resources (#21704)
2023-02-21|||Fix TVLT (torch device issue) (#21710)
2023-02-21|||Fix `get_class_in_module` (#21709)
2023-02-21|||Fix typo in `PROCESSOR_MAPPING_NAMES` and add tests (#21703)
2023-02-21|||remove position ids and token type ids from forward args in docstring (#21701)
2023-02-20|||Fix axial positional encoding calculations for  reformer.mdx (#21649)
2023-02-21|||Add WhisperTokenizerFast (#21222)
2023-02-20|||Pass along revision in dynamic code fetch (#21698)
2023-02-20|||Fix-rag-finetune-project-requirement (#21697)
2023-02-20|||Add EfficientNet (#21563)
2023-02-20|||[`bnb`] fix `bnb` decoders bug (#21688)
2023-02-20|||add GPTSAN model (reopen) (#21291)
2023-02-20|||Fix quality
2023-02-20|||Fix for non-contiguous label tensors in VisonEncoderDecoder (#21582)
2023-02-20|||add flax whisper implementation (#20479)
2023-02-20|||Enable PyTorch/XLA Fully Sharded Data Parallel (FSDP) (#21406)
2023-02-17|||Fix dynamic module import error (#21646)
2023-02-17|||[`BLIP`] update blip path on slow tests (#21476)
2023-02-17|||[`ImageProcessor`] Refactor default `mean` & `std` to `OPENAI_CLIP_MEAN` & `OPENAI_CLIP_STD` (#21425)
2023-02-17|||Generate: eta sampling numerical stability (#21676)
2023-02-17|||Fix multi-gpu training error for LayoutLMv2 (#21675)
2023-02-17|||[`CLAP`] Fix few broken things (#21670)
2023-02-17|||[`bnb`] Introducing `BitsAndBytesConfig` (#21579)
2023-02-16|||Adapt PerceiverIO Multimodal class to work with arbitrary modalities (#20054)
2023-02-16|||[CLAP] Add CLAP to the library (#21370)
2023-02-16|||Sort deps alphabetically
2023-02-16|||Add OPT resources to the transformers documentation (#21625)
2023-02-16|||[bloom] gradient_checkpointing fix (#21655)
2023-02-16|||refactor: Make direct_transformers_import util (#21652)
2023-02-16|||[WhisperModel] fix bug in reshaping labels (#21653)
2023-02-16|||Bump werkzeug from 2.0.3 to 2.2.3 in /examples/research_projects/decision_transformer (#21658)
2023-02-16|||Update document of WhisperDecoderLayer (#21621)
2023-02-16|||[WIP] Move X-MOD models to facebook organization (#21640)
2023-02-16|||Fix typos in contrastive-image-text example README (#21665)
2023-02-15|||Update deprecated load_module (#21651)
2023-02-15|||Generate: PT Dynamo without graph breaks in the main greedy/sample loop (#21648)
2023-02-15|||Refactor model summary (#21408)
2023-02-15|||Add TVLT (#20725)
2023-02-15|||Pass parent exception as context exception to provide clearer stack trace (#21636)
2023-02-15|||Skipping more high mem tests - Wav2Vec2 Hubert (#21647)
2023-02-15|||Add Ernie-M Model to huggingface (#21349)
2023-02-15|||Fix passing kwargs to TFBertTokenizer (#21619)
2023-02-15|||Skip wav2vec2 hubert high mem tests (#21643)
2023-02-15|||Fix Blip-2 CI again (#21637)
2023-02-14|||Remove extra "`max_length` is reached." from InfNaNLogitsProcessor documentation (#21634)
2023-02-14|||fix: Race Condition when using Sagemaker Checkpointing and Model Repository (#21614)
2023-02-14|||Fix typo in QA task guide (#21608)
2023-02-14|||Error (also in original) model, scaling only q matrix not qk.T dot product (qk.T/sqrt(dim_per_head)) (#21627)
2023-02-14|||Fix typo in documentation. (#21632)
2023-02-14|||Removes duplicate computations in DETR post processing (#21592)
2023-02-14|||Fix generation config for empty state dict (#21630)
2023-02-14|||Fix the real failing test
2023-02-14|||Remove Niels from templates (#21564)
2023-02-14|||Final cleanup of TOKENIZER_FOR_DOC (#21565)
2023-02-14|||Skip failing test
2023-02-14|||Generate: input expansion for any model input (#21624)
2023-02-14|||Generate: filter encoder inputs when its signature does not accept wildcards (#21603)
2023-02-14|||Enable `requires_grad` on input embedding to train on top of frozen layers (#21598)
2023-02-13|||Add in big model inference to issue template (#21611)
2023-02-13|||Fix TF CTC tests (#21606)
2023-02-13|||Fix env. variable type issue in testing (#21609)
2023-02-13|||Clarify available pipelines in quicktour (#21607)
2023-02-13|||[deepspeed] performance docs (#21573)
2023-02-13|||Update setup.py (#21584)
2023-02-13|||[i18n-fr] Translate quicktour page to French (#21589)
2023-02-13|||Generate: correct default model input creation for decoder-only models (#21580)
2023-02-13|||Fix Blip-2 CI (#21595)
2023-02-13|||Add missing arguemtn to run_clip.py (#21588)
2023-02-13|||Correct Markdown bullets indentation (#21583)
2023-02-13|||Bump ipython from 8.1.1 to 8.10.0 in /examples/research_projects/decision_transformer (#21577)
2023-02-13|||annotated TFvisionEncoderDecoder input type hints (#21432)
2023-02-13|||[`bnb`] Let's make the daily CI green üçè  (#21597)
2023-02-13|||Generate: Fix flaky indexing error in `test_constrained_beam_search_generate_dict_output` (#21561)
2023-02-13|||Add `inputs_embeds` support when generating with GPT-J (#21575)
2023-02-13|||[MINOR] Fix link in timeseries transformer docs (#21602)
2023-02-13|||Remove trailing 'extractive' word from en documentation (#21594)
2023-02-13|||CI: skip failing TF hubert test (#21601)
2023-02-13|||Add: document question answering task guide (#21518)
2023-02-13|||Generate: TF supports multiple eos tokens (#21571)
2023-02-11|||Fix quality on main (ruff release)
2023-02-10|||[`Blip2`] Add int8 support for `blip2-flan-t5-xxl`  (#21574)
2023-02-10|||Remove more unused attributes in config classes (#21543)
2023-02-10|||Added timesformer configuration (#21446)
2023-02-10|||Replace input_values_processing with unpack_inputs (#21502)
2023-02-10|||improving contributing tests section (#21569)
2023-02-10|||[deepspeed] deal with models w/o `config.hidden_size` (#21504)
2023-02-10|||Goodbye to Blip-2 doctests (#21566)
2023-02-10|||[Tasks] Adds image captioning  (#21512)
2023-02-10|||[from_pretrained] extend `torch_dtype="auto"` to look up `config.torch_dtype` first, expand docs (#21524)
2023-02-10|||[Tests] Improve flax test_attention_outputs (#21486)
2023-02-10|||Add _mp_fn to run_mae.py for XLA testing (#21551)
2023-02-10|||[Variant] Make sure variant files are not incorrectly deleted (#21562)
2023-02-10|||Replace inefficient torch.sqrt taking scalar input with numpy.sqrt (#21496)
2023-02-10|||Add X-MOD (#20939)
2023-02-10|||Fix stuff related to the causal_mask in CodeGen. (#21527)
2023-02-10|||Remove CLI spams with Whisper FeatureExtractor (#21267)
2023-02-10|||adding a tip for deepspeed integration in multi-node environment (#21459)
2023-02-10|||Added with torch.no_grad() to Camembert integration test (#21544)
2023-02-10|||[`pipeline`] A simple fix for half-precision & 8bit models  (#21479)
2023-02-09|||Skip failing test for now
2023-02-09|||Added with torch.no_grad() to XLM-Roberta integration test  (#21547)
2023-02-09|||üö®üö®üö® Enforce single model initialization (#21431)
2023-02-09|||Fix from_pretrained API with config and state_dict (#21542)
2023-02-09|||Fix inclusion of non py files in package (#21546)
2023-02-09|||Align BLIP-2 winit with others
2023-02-09|||Add BLIP-2 (#21441)
2023-02-09|||fix typo in  run_speech_recognition_ctc.py (#21528)
2023-02-09|||Tag tests as slow ‚åõ (#21537)
2023-02-09|||Fix ClearML Integration to run in ClearML pipelines and external Tasks. (#21531)
2023-02-09|||Fix missing unfinished_sequences (#21529)
2023-02-09|||Generate: TF `.generate()` can now be exported with dynamic length (#21474)
2023-02-09|||Generate: make TF `.generate()` signature == PT `.generate()` signature  (#21525)
2023-02-08|||Add `__len__` method to `_LazyAutoMapping`  (#21522)
2023-02-08|||Fix multiple `eos_token_id`s in model.generate(...) (#21461)
2023-02-08|||Fixing backward compatiblity `image_processor` in pipeline. (#21513)
2023-02-08|||[tests] add missing `report_to none` (#21505)
2023-02-08|||Update OPT conversion script to work for OPT-IML (#21519)
2023-02-08|||no more dummies for speech processors (#21517)
2023-02-08|||Generate: TF `compute_transition_scores` (#21341)
2023-02-08|||[Doc] Minor URL fixes in PyTorch Text Classification Readme (#21511)
2023-02-08|||Bump cryptography from 36.0.2 to 39.0.1 in /examples/research_projects/decision_transformer (#21507)
2023-02-08|||Exclude the madeup words from M2M100Tokenizer.vocab_size (#20976)
2023-02-08|||Wrap RemBert integration test forward passes with torch.no_grad() (#21503)
2023-02-07|||Fix import in Accelerate for find_exec_bs (#21501)
2023-02-07|||Check for mapping/dict in distributed_concat function (#21500)
2023-02-07|||Add XLM-V to Model Doc (#21498)
2023-02-07|||Add inverse sqrt learning rate scheduler (#21495)
2023-02-07|||[tokenizer] sanitize saved config (#21483)
2023-02-07|||Cleanup quality (#21493)
2023-02-07|||Add limit_all_gathers option to fsdp_config and fix forward_prefetch bug (#21489)
2023-02-07|||A new test to check config attributes being used (#21453)
2023-02-07|||[OPT] Adds `GPT2TokenizerFast` to the list of tokenizer to use for OPT. (#20823)
2023-02-07|||Sanity check the type of id2label and label2id arguments of from_pretrained for TokenClassification models (#21490)
2023-02-07|||Typos/fixes to link syntax (#21450)
2023-02-07|||:pen: fix typo in pytorch semantic segmentation readme (#21492)
2023-02-07|||changed "ot" to "to" (#21488)
2023-02-07|||[`Doc`] Fix int8 docs (#21487)
2023-02-07|||Generate: TF can now generate from embeddings in encoder-decoder models (#21475)
2023-02-07|||[CI ] Remove `past` in favor of `pat_key_values` (#21443)
2023-02-06|||Deprecate parallelize API (#21448)
2023-02-06|||Fix epoch number when resuming training (#21478)
2023-02-06|||Bump oauthlib from 3.2.1 to 3.2.2 in /examples/research_projects/decision_transformer (#21481)
2023-02-06|||Update quality tooling for formatting (#21480)
2023-02-06|||Add tips for generation with Int8 models (#21424)
2023-02-06|||OPT: BLIP2-ready `prepare_inputs_for_generation` (#21477)
2023-02-06|||[i18n-fr] Translate index page to French (#21458)
2023-02-06|||[examples] improve block_size warning message (#21463)
2023-02-06|||Removing `more_itertools` dependency. (#21473)
2023-02-06|||Generate: TF can now accept custom logits processors (#21454)
2023-02-06|||make SpeechT5 doc examples deterministic (#21470)
2023-02-06|||Fixed RAG script which was failing on dummy example (#21416)
2023-02-06|||Fix `PushToHubCallback` import in Share a model docs (#21457)
2023-02-06|||Added documentation for DagsHubCallback (#21452)
2023-02-06|||Add perf numbers for perf_train_cpu (#20974)
2023-02-06|||Fix `SpeechT5ForSpeechToSpeechIntegrationTests` device issue (#21460)
2023-02-03|||Avoid flaky generation sampling tests (#21445)
2023-02-03|||For IterableDataset, return DataLoader using self._train_batch_size. ‚Ä¶ (#21447)
2023-02-03|||Add tutorial doc for TF + TPU (#21429)
2023-02-04|||exclude deleted files in the fixup script (#21436)
2023-02-03|||[WIP] add SpeechT5 model (#18922)
2023-02-03|||do not scale gradient in bf16 mode (#21428)
2023-02-03|||Fix device issue in a `ConvBertModelTest` test (#21438)
2023-02-03|||Added model resources for LayoutLM Issue#19848 (#21377)
2023-02-03|||Remove more unused attributes in config classes (#21392)
2023-02-03|||Add `inputs_embeds` support for `.generate()` with BLOOM models (#21430)
2023-02-03|||üö®üö® Generate: standardize beam search behavior across frameworks (#21368)
2023-02-02|||Add VQGAN-CLIP research project (#21329)
2023-02-02|||Update task summary  (#21067)
2023-02-02|||Fixes bug in the creation of ExponentialDecayLengthPenalty (#21423)
2023-02-02|||Fix task guide formatting (#21409)
2023-02-02|||Fix some pipeline tests (#21401)
2023-02-02|||Allow to add more information in `is_flaky` (#21426)
2023-02-02|||[`bnb`] Fine-tuning HF 8-bit models (#21290)
2023-02-02|||Fix Graphormer test suite (#21419)
2023-02-02|||Add the GeLU activation from pytorch with the tanh approximation (#21345)
2023-02-02|||Add distinct section names for PyTorch and TF (#21422)
2023-02-02|||Fix image_processor_class bug (#21410)
2023-02-02|||Use torch `1.13.1` in push/schedule CI (#21421)
2023-02-01|||Generate: decoder-only models can generate with `inputs_embeds` (#21405)
2023-02-01|||Add TF image classification example script (#19956)
2023-02-01|||Added DagshubCallback (#21404)
2023-02-01|||Skip batches fast with accelerate (#21390)
2023-02-01|||Fix the issue of using only inputs_embeds in convbert model (#21398)
2023-02-01|||Moved LiLT under multimodal models in TOC (#21393)
2023-02-01|||Add variant to transformers (#21332)
2023-01-31|||Update `Graphormer` and fix its `torchscript` test failures (#21380)
2023-01-31|||Generate: fix TF XLA tests on models with `max_position_embeddings` or `max_target_positions` (#21389)
2023-01-31|||Remove more unused attributes in config classes (#21327)
2023-01-31|||Add support of backward_prefetch and forward_prefetch (#21237)
2023-01-31|||Simplify column_names in run_clm/mlm (#21382)
2023-01-31|||[Docs] Minor fixes (#21383)
2023-01-31|||Do not log the generation config for each prediction step in TrainerSeq2Seq (#21385)
2023-01-31|||Cleanup the usage of `layer_norm_eps` in some models (#21336)
2023-01-31|||Template for framework-agnostic tests (#21348)
2023-01-31|||Add DETA (#20983)
2023-01-30|||[`run_(clm|mlm).py` examples] add streaming dataset support (#21343)
2023-01-31|||translate index to zh(#20095) (#21351)
2023-01-30|||Adding resource section to GPT-J docs (#21270)
2023-01-30|||Fixes path for Graphormer checkpoint (#21367)
2023-01-30|||Generate: Relaxed `max_length` and `max_new_tokens` coexistence (#21347)
2023-01-30|||Add cPython files in build (#21372)
2023-01-30|||Fix DETR tests after #21144 (#21365)
2023-01-30|||Remove duplicate declarations in dummy inputs for TFLongformer (#21352)
2023-01-30|||Corrected (#21350)
2023-01-30|||fix the issue that the output dict of jit model could not get [0] (#21354)
2023-01-30|||Pipeline testing - using tiny models on Hub (#20426)
2023-01-30|||Fix `GitModelIntegrationTest.test_batched_generation` device issue (#21362)
2023-01-27|||Automated compatible models list for task guides (#21338)
2023-01-27|||Little cleanup: let huggingface_hub manage token retrieval (#21333)
2023-01-27|||[Whisper] another patch (#21324)
2023-01-27|||Fix `RobertaPreLayerNorm` doctest (#21337)
2023-01-27|||Bump onnx from 1.11.0 to 1.13.0 in /examples/research_projects/decision_transformer (#21331)
2023-01-27|||Fix M2M100 positional embedding creation for ONNX (#21328)
2023-01-26|||Update Hebrew language code to he per IANA registry (#21310)
2023-01-26|||[Doctest] Fix `Perceiver` doctest (#21318)
2023-01-26|||Generate: better `compute_transition_scores` examples (#21323)
2023-01-26|||Fix `TFEncoderDecoder` tests (#21301)
2023-01-26|||check paths in `utils/documentation_tests.txt` (#21315)
2023-01-26|||Small QoL for qa. (#21316)
2023-01-26|||[i18n-KO] Translated quicktour page to Korean (#20946)
2023-01-26|||Fix 2 paths in the doctest list (#21314)
2023-01-26|||Use `model_class.__name__` and compare against `XXX_MAPPING_NAMES` (#21304)
2023-01-26|||Accept batched tensor of images as input to image processor (#21144)
2023-01-25|||[WHISPER] Small patch (#21307)
2023-01-25|||Small fix to ExponentialDecayLengthPenalty docstring (#21308)
2023-01-25|||Add BridgeTower model (#20775)
2023-01-25|||[CI-Daily] replace `past` in prepare inputs for generation (#21296)
2023-01-25|||Documentation code sample fixes (#21302)
2023-01-25|||[Doctest] Fix `Blenderbot` doctest (#21297)
2023-01-25|||Update `OneFormerModelIntegrationTest` expected values (#21295)
2023-01-25|||[Hubert] Fix Hubert processing auto (#21299)
2023-01-25|||Fix `EfficientFormer` (#21294)
2023-01-25|||Moving to cleaner tokenizer version or `oneformer`. (#21292)
2023-01-25|||[Whisper] Refactor whisper (#21252)
2023-01-25|||[Mask2Former] Add doc tests (#21232)
2023-01-25|||Supporting `ImageProcessor` in place of `FeatureExtractor` for pipelines (#20851)
2023-01-25|||[GIT] Add test for batched generation (#21282)
2023-01-24|||Update expected values for doctest (#21284)
2023-01-24|||Fix `TrainingArguments.label_names` docs to reflect the correct default value behaviour (#21288)
2023-01-24|||[W2V2 with LM] Fix decoder test with params (#21277)
2023-01-24|||[GenerationConfig] add additional kwargs handling (#21269)
2023-01-24|||[examples/deepspeed] fix renamed api (#21283)
2023-01-24|||[`t5`] Fix T5 inference in `float16` + `bnb` error (#21281)
2023-01-24|||Fix MaskFormerImageProcessor.post_process_instance_segmentation (#21256)
2023-01-25|||Use `logger.info` instead of `print` to emit a logging message in `hub.py` (#21273)
2023-01-24|||Hotifx remove tuple for git config image processor. (#21278)
2023-01-24|||Use return_tensors="np" instead of "tf" (#21266)
2023-01-24|||[Doc] fix broken link (#21276)
2023-01-24|||Skip `test_multi_gpu_data_parallel_forward` for `UperNetModelTest` (#21216)
2023-01-23|||v4.27.0.dev0
2023-01-23|||Models docstring (#21225)
2023-01-23|||Supported pipeline tasks update (#21268)
2023-01-23|||[Whisper] fix all issues with unk token (#21250)
2023-01-23|||Add class properties with warnings (#21195)
2023-01-23|||[ci-daily] Fix pipeline tests (#21257)
2023-01-23|||Add: TensorFlow example for semantic segmentation task guide (#21223)
2023-01-23|||Notebook examples grouping and update (#21265)
2023-01-23|||Update tests: replace feature extractor tests with image processor (#20768)
2023-01-23|||Replace reduce_labels with do_reduce_labels (#21218)
2023-01-23|||Generate: save generation config with the models' `.save_pretrained()` (#21264)
2023-01-23|||Add missing checkpoint for doctest (#21258)
2023-01-23|||Add scikit-learn dependency to train langage-modeling (#21229)
2023-01-23|||Add Japanese translation installation.mdx (#21241)
2023-01-23|||Fix reformer CI (#21254)
2023-01-23|||Optimize by not computing gradients for parameters set to requires_grad=False (#21236)
2023-01-23|||[GIT] Convert more checkpoints (#21245)
2023-01-23|||Add test_image_processing_common.py (#20785)
2023-01-23|||Extend Script to enable conversion of Encoder Only  T5x Models to Pytorch (#20907)
2023-01-23|||[DETR and friends] Use AutoBackbone as alternative to timm (#20833)
2023-01-23|||Generate: precision fix in compute_transition_scores doctests (#21251)
2023-01-23|||[`BLIP`] fix doctest (#21217)
2023-01-20|||Skip failing test for now (#21226)
2023-01-20|||[`BLIP`] fix docstring for `BlipTextxxx` (#21224)
2023-01-20|||Microphone live inference catching up when inference is too slow (whisper). (#21219)
2023-01-20|||Remove all hf-internal-testing checkpoints that can be removed (#21199)
2023-01-20|||Fix task summary doctest  (#21200)
2023-01-20|||Fix OneFormer Docstrings (#21215)
2023-01-20|||Make `parallelism` for CircleCI jobs work - but keep it `1` for now (#21157)
2023-01-20|||Fix code example in training tutorial (#21201)
2023-01-20|||Declare __len__ method in PreTrainedTokenizerBase (#21210)
2023-01-20|||Fix `GPTJ` doctest (#21213)
2023-01-20|||Fix `CONFIG_ARCHIVE_MAP_MAPPING_NAMES` (#21207)
2023-01-20|||Update `huggingface_hub` version (#21212)
2023-01-20|||deleted references of self.vocab_size and self.type_vocab_size for multiple models [TF implementation] (#21164)
2023-01-20|||Generate: documented function to compute the transition scores (#21191)
2023-01-20|||Update modeling doc strings FE -> IP (#21106)
2023-01-20|||[Whispe]  Fix pipeline after timestamp merges (#21198)
2023-01-20|||Enabling live `automatic-speech-recognition` asr for Whisper. (#21196)
2023-01-20|||Efficientformer (#20459)
2023-01-19|||Add disclaimer for necessary fake models (#21178)
2023-01-19|||Graphormer model for Graph Classification (#20968)
2023-01-19|||revert Copyright 2023
2023-01-20|||Add Japanese translation index.mdx (#21186)
2023-01-19|||Flax dtype-dependent numerical masking (#21197)
2023-01-19|||[`CVT`] Fix module initialization issue (#21193)
2023-01-19|||Add hallucination filter (#18675)
2023-01-19|||[Whisper] Fix timestamp processor (#21187)
2023-01-19|||hertz is already per second (#21188)
2023-01-19|||Update examples with image processors (#21155)
2023-01-19|||Rename GLPN image processor tests (#21194)
2023-01-19|||Updates to computer vision section of the Preprocess doc (#21181)
2023-01-19|||Fix device issue in `UperNetModelIntegrationTest` (#21192)
2023-01-19|||Trigger CI
2023-01-19|||workaround documentation rendering bug (#21189)
2023-01-19|||Update year 2020 to 2023 in one file (#21190)
2023-01-19|||Fix `Mask2FormerForUniversalSegmentation` (#21175)
2023-01-19|||Add OneFormer Model (#20577)
2023-01-18|||[issues template] update deepspeed owners (#21027)
2023-01-18|||Rewrite a couple of lines in the TF XLA doc (#21177)
2023-01-18|||Add AWS Neuron torchrun support (#20806)
2023-01-18|||Bump future from 0.18.2 to 0.18.3 in /examples/research_projects/visual_bert (#21173)
2023-01-18|||Bump future from 0.18.2 to 0.18.3 in /examples/research_projects/lxmert (#21169)
2023-01-18|||Adapt repository creation to latest hf_hub (#21158)
2023-01-18|||Fix doctest CI (#21166)
2023-01-18|||using raw string for regex to search <extra_id> (#21162)
2023-01-18|||fix the issue that the output dict of jit model could not get [:2] (#21146)
2023-01-18|||Fix git model for generate with beam search. (#21071)
2023-01-18|||OPT: Fix batched generation with FLAX (#21150)
2023-01-18|||Fix typos in documentation (#21160)
2023-01-18|||Remove Roberta Dependencies from XLM Roberta Flax and Tensorflow models (#21047)
2023-01-18|||`blip` support for training (#21021)
2023-01-18|||Make `test_save_pretrained_signatures` slow test (#21105)
2023-01-18|||Add Japanese translation to multilingual.mdx (#21084)
2023-01-18|||üåê [i18n-KO] Translated `installation.mdx` to Korean (#20948)
2023-01-17|||Fixed num_channels!=3 normalization training (#20630)
2023-01-17|||Add Epsilon- and Eta-Sampling (#21121)
2023-01-17|||Refactoring of the text generate API docs (#21112)
2023-01-17|||Add: An introductory guide for text generation (#21090)
2023-01-17|||Add: tensorflow example for image classification task guide (#21038)
2023-01-17|||Add resources (#20872)
2023-01-17|||CLI: update hub PR URL (#21154)
2023-01-17|||Change variable name to prevent shadowing (#21153)
2023-01-17|||Add batch of resources (#20647)
2023-01-17|||Whisper Timestamp processor and prediction (#20620)
2023-01-17|||Fixing offline mode for pipeline (when inferring task). (#21113)
2023-01-17|||Clarify and add missing typical_p argument docstring. (#21095)
2023-01-17|||feat: add standalone guide on XLA support. (#21141)
2023-01-17|||Small simplification to TopKLogitsWarper (#21130)
2023-01-17|||Rename test_feature_extraction files (#21140)
2023-01-17|||Generate: TF contrastive search must pop `use_cache` from `model_kwargs` (#21149)
2023-01-17|||TF: serializable hubert (#20966)
2023-01-17|||Fixes to TF collators (#21143)
2023-01-16|||Add Mask2Former (#20792)
2023-01-16|||[GIT] Fix training (#21133)
2023-01-16|||Update `TFTapasEmbeddings` (#21107)
2023-01-16|||Added clefourrier as ref point for graph models in bug reports (#21139)
2023-01-16|||Fix `RealmModelIntegrationTest.test_inference_open_qa` (#21136)
2023-01-16|||Fixed issue #21053 (#21065)
2023-01-16|||Fixing batching pipelines on single items for ChunkPipeline (#21132)
2023-01-16|||Add `min_new_tokens` argument in generate() (implementation based on `MinNewTokensLengthLogitsProcessor`) (#21044)
2023-01-16|||[LongT5] Remove duplicate encoder_attention_mask default value check (#21124)
2023-01-16|||[VideoMAE] Fix docstring (#21111)
2023-01-16|||Add UperNet (#20648)
2023-01-15|||Fixed typo in docstring (#21115)
2023-01-15|||Use raw string for regex in tokenization_t5_fast.py (#21125)
2023-01-14|||[CI-doc-daily] Remove RobertaPreLayernorm random tests (#20992)
2023-01-14|||Rework automatic code samples in docstrings (#20757)
2023-01-14|||Add Spanish translation to community.mdx (#21055)
2023-01-13|||Update task summary part 1 (#21014)
2023-01-13|||[Tokenizers] Fix a small typo (#21104)
2023-01-13|||Fix `torchscript` tests for `AltCLIP` (#21102)
2023-01-12|||Fix past CI (#20967)
2023-01-12|||[bnb optim] fixing test (#21030)
2023-01-12|||Remove more unused attributes in config classes (#21000)
2023-01-12|||Fixed issue #21039 (#21062)
2023-01-12|||Optimize inference only mode memory if ipex is used (#21083)
2023-01-12|||fix typo in comment (#21088)
2023-01-11|||Update docstring for CLIPConfig (#21066)
2023-01-10|||Fix header level (#21072)
2023-01-10|||feature: update wandb callback to upload checkpoints (#21035)
2023-01-10|||Make the attention_head_size in distilbert an object attribute (#20970)
2023-01-09|||Patch-past-refactor (#21050)
2023-01-08|||remove flax file from `documentation_tests.txt` (#21036)
2023-01-08|||Fix warning for MCTC model (#21049)
2023-01-08|||Skip failing test until Athur looks at it.
2023-01-08|||Replace `past` with `past_key_values` (#20944)
2023-01-08|||fix typo (#21048)
2023-01-07|||fix typo (#21042)
2023-01-06|||fix levit timm conversion file (#20938)
2023-01-06|||fix parameter name in docstring (#21032)
2023-01-06|||Support turning off the model uploading in ClearML (#20969)
2023-01-06|||Fix arguments passed to predict function in QA Seq2seq training script (#21026)
2023-01-05|||[NumPy] Remove references to deprecated NumPy type aliases (#21022)
2023-01-05|||Added mask_time_prob and mask_time_length arguments to wav2vec2 pretraining script (#20985)
2023-01-05|||Generate: FLAX uses `GenerationConfig` as the basis for `.generate()` parametrization (#21007)
2023-01-05|||[CLIPSeg] Fix integration test (#20995)
2023-01-05|||Make sure dynamic objects can be saved and reloaded (#21008)
2023-01-05|||[`BLIP`] Fix daily CI failing test (#20877)
2023-01-05|||Generate: FLAX infers pad token in its absence and has functional example (#21009)
2023-01-05|||Generate: post-generate config TF doctest fix  (#21018)
2023-01-04|||Fix callback docstrings (#21005)
2023-01-04|||Bump gitpython from 3.0.2 to 3.1.30 in /examples/research_projects/distillation (#21011)
2023-01-04|||Bump gitpython from 3.1.18 to 3.1.30 in /examples/research_projects/decision_transformer (#21010)
2023-01-04|||Fix (DeepSpeed) docker image build issue (#21002)
2023-01-04|||Generate: Fix CI related to #20727  (#21003)
2023-01-04|||add: task guide on video classification model fine-tuning. (#20827)
2023-01-04|||Update PR template (#21006)
2023-01-04|||Fix repo consistency
2023-01-05|||Remove T5 dependency from mT5 model (#20949)
2023-01-04|||Update bug report template (#21004)
2023-01-04|||Generate: TF uses `GenerationConfig` as the basis for `.generate()` parametrization (#20994)
2023-01-04|||Refactor the function get_results (#20999)
2023-01-04|||Fix model hub link (#20998)
2023-01-04|||Don't call deprecated method (#20904)
2023-01-04|||Fix bug in segmentation postprocessing (#20198)
2023-01-04|||Update image processor parameters if creating with kwargs (#20866)
2023-01-04|||auxiliary_loss works for Deformable Detr (#20959)
2023-01-04|||Add: doc page for the object detection task (#20925)
2023-01-04|||update template (#20885)
2023-01-04|||Add AltCLIP (#20446)
2023-01-03|||Add custom stop token ids for generation (#20727)
2023-01-03|||Fix race condition on cleaning checkpoints when save_total_limit set to 1 (#20989)
2023-01-03|||Improve OWL-ViT postprocessing (#20980)
2023-01-03|||Fix for LXMERT (#20986)
2023-01-03|||Avoid CI runs under users' own CircleCI personal account (#20981)
2023-01-03|||Ignore errors when deleting old checkpoints in trainer (#20984)
2023-01-03|||Enable `decoder_attention_mask` in `generate` function (#20726)
2023-01-03|||Fix valid ratio for Deformable Detr (#20958)
2023-01-03|||[run_clm example] add torch_dtype option for model load. (#20971)
2023-01-03|||Remove more unused attributes in config classes (#20858)
2023-01-03|||Add GIT (GenerativeImage2Text) (#20295)
2023-01-03|||Fix post_process_object_detection method descriptions (#20977)
2023-01-03|||`MinNewTokensLengthLogitsProcessor` for `.generate` method #20814 (#20892)
2023-01-03|||Generate: delete unused TF `_reorder_cache` (#20964)
2023-01-03|||Fix T5 docstring (#20957)
2023-01-02|||Generate: TF XLA beam sample (#20927)